1.
TY  - journal-article
ID  - https://openalex.org/W2560438049
DO  - https://doi.org/10.1186/s13643-016-0384-4
TI  - Rayyan—a web and mobile app for systematic reviews
AB  - Synthesis of multiple randomized controlled trials (RCTs) in a systematic review can summarize the effects of individual outcomes and provide numerical answers about the effectiveness of interventions. Filtering of searches is time consuming, and no single method fulfills the principal requirements of speed with accuracy. Automation of systematic reviews is driven by a necessity to expedite the availability of current best evidence for policy and clinical decision-making. We developed Rayyan ( http://rayyan.qcri.org ), a free web and mobile app, that helps expedite the initial screening of abstracts and titles using a process of semi-automation while incorporating a high level of usability. For the beta testing phase, we used two published Cochrane reviews in which included studies had been selected manually. Their searches, with 1030 records and 273 records, were uploaded to Rayyan. Different features of Rayyan were tested using these two reviews. We also conducted a survey of Rayyan's users and collected feedback through a built-in feature.Pilot testing of Rayyan focused on usability, accuracy against manual methods, and the added value of the prediction feature. The "taster" review (273 records) allowed a quick overview of Rayyan for early comments on usability. The second review (1030 records) required several iterations to identify the previously identified 11 trials. The "suggestions" and "hints," based on the "prediction model," appeared as testing progressed beyond five included studies. Post rollout user experiences and a reflexive response by the developers enabled real-time modifications and improvements. The survey respondents reported 40% average time savings when using Rayyan compared to others tools, with 34% of the respondents reporting more than 50% time savings. In addition, around 75% of the respondents mentioned that screening and labeling studies as well as collaborating on reviews to be the two most important features of Rayyan. As of November 2016, Rayyan users exceed 2000 from over 60 countries conducting hundreds of reviews totaling more than 1.6M citations. Feedback from users, obtained mostly through the app web site and a recent survey, has highlighted the ease in exploration of searches, the time saved, and simplicity in sharing and comparing include-exclude decisions. The strongest features of the app, identified and reported in user feedback, were its ability to help in screening and collaboration as well as the time savings it affords to users.Rayyan is responsive and intuitive in use with significant potential to lighten the load of reviewers.
PY  - 2016
DA  - 2016-12-05
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://systematicreviewsjournal.biomedcentral.com/track/pdf/10.1186/s13643-016-0384-4', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Mourad Ouzzani
AU  - Hossam M. Hammady
AU  - Zbys Fedorowicz
AU  - Ahmed K. Elmagarmid
ER  - 

2.
TY  - journal-article
ID  - https://openalex.org/W2147469877
DO  - https://doi.org/10.1186/s13643-015-0031-5
TI  - Erratum to: Using text mining for study identification in systematic reviews: a systematic review of current approaches
AB  - The large and growing number of published studies, and their increasing rate of publication, makes the task of identifying relevant studies in an unbiased way for inclusion in systematic reviews both complex and time consuming. Text mining has been offered as a potential solution: through automating some of the screening process, reviewer time can be saved. The evidence base around the use of text mining for screening has not yet been pulled together systematically; this systematic review fills that research gap. Focusing mainly on non-technical issues, the review aims to increase awareness of the potential of these technologies and promote further collaborative research between the computer science and systematic review communities.Five research questions led our review: what is the state of the evidence base; how has workload reduction been evaluated; what are the purposes of semi-automation and how effective are they; how have key contextual problems of applying text mining to the systematic review field been addressed; and what challenges to implementation have emerged? We answered these questions using standard systematic review methods: systematic and exhaustive searching, quality-assured data extraction and a narrative synthesis to synthesise findings.The evidence base is active and diverse; there is almost no replication between studies or collaboration between research teams and, whilst it is difficult to establish any overall conclusions about best approaches, it is clear that efficiencies and reductions in workload are potentially achievable. On the whole, most suggested that a saving in workload of between 30% and 70% might be possible, though sometimes the saving in workload is accompanied by the loss of 5% of relevant studies (i.e. a 95% recall).Using text mining to prioritise the order in which items are screened should be considered safe and ready for use in 'live' reviews. The use of text mining as a 'second screener' may also be used cautiously. The use of text mining to eliminate studies automatically should be considered promising, but not yet fully proven. In highly technical/clinical areas, it may be used with a high degree of confidence; but more developmental and evaluative work is needed in other disciplines. The strongest features of the app, identified and reported in user feedback, were its ability to help in screening and collaboration as well as the time savings it affords to users.Rayyan is responsive and intuitive in use with significant potential to lighten the load of reviewers.
PY  - 2015
DA  - 2015-01-14
JO  - {'id': 'https://openalex.org/V82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://doi.org/10.1186/s13643-015-0031-5', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Alison O'Mara-Eves
AU  - James D. Thomas
AU  - John McNaught
AU  - Makoto Miwa
AU  - Sophia Ananiadou
ER  - 

3.
TY  - journal-article
ID  - https://openalex.org/W3092985072
DO  - https://doi.org/10.1016/j.jclinepi.2020.10.007
TI  - Cochrane Rapid Reviews Methods Group offers evidence-informed guidance to conduct rapid reviews
AB  - <h2>Abstract</h2><h3>Objectives</h3> To develop methods guidance to support the conduct of rapid reviews (RRs) produced within Cochrane and beyond, in response to requests for timely evidence syntheses for decision-making purposes including urgent health issues of high priority. <h3>Study Design and Setting</h3> Interim recommendations were informed by a scoping review of the underlying evidence, primary methods studies conducted, and a survey sent to 119 representatives from 20 Cochrane entities, who were asked to rate and rank RR methods across stages of review conduct. Discussions among those with expertise in RR methods further informed the list of recommendations with accompanying rationales provided. <h3>Results</h3> Based on survey results from 63 respondents (53% response rate), 26 RR methods recommendations are presented for which there was a high or moderate level of agreement or scored highest in the absence of such agreement. Where possible, how recommendations align with Cochrane methods guidance for systematic reviews is highlighted. <h3>Conclusion</h3> The Cochrane Rapid Reviews Methods Group offers new, interim guidance to support the conduct of RRs. Because best practice is limited by the lack of currently available evidence for some RR methods shortcuts taken, this guidance will need to be updated as additional abbreviated methods are evaluated. between studies or collaboration between research teams and, whilst it is difficult to establish any overall conclusions about best approaches, it is clear that efficiencies and reductions in workload are potentially achievable. On the whole, most suggested that a saving in workload of between 30% and 70% might be possible, though sometimes the saving in workload is accompanied by the loss of 5% of relevant studies (i.e. a 95% recall).Using text mining to prioritise the order in which items are screened should be considered safe and ready for use in 'live' reviews. The use of text mining as a 'second screener' may also be used cautiously. The use of text mining to eliminate studies automatically should be considered promising, but not yet fully proven. In highly technical/clinical areas, it may be used with a high degree of confidence; but more developmental and evaluative work is needed in other disciplines. The strongest features of the app, identified and reported in user feedback, were its ability to help in screening and collaboration as well as the time savings it affords to users.Rayyan is responsive and intuitive in use with significant potential to lighten the load of reviewers.
PY  - 2021
DA  - 2021-02-01
JO  - {'id': 'https://openalex.org/S64418186', 'issn_l': '0895-4356', 'issn': ['1878-5921', '0895-4356'], 'display_name': 'Journal of Clinical Epidemiology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'http://www.jclinepi.com/article/S089543562031146X/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc-nd'}
DP  - OpenAlex
AU  - Chantelle Garritty
AU  - Gerald Gartlehner
AU  - Barbara Nussbaumer-Streit
AU  - Valerie King
AU  - Candyce Hamel
AU  - Chris Kamel
AU  - Lisa Affengruber
AU  - Adrienne Stevens
ER  - 

4.
TY  - other
ID  - https://openalex.org/W2974858420
DO  - https://doi.org/10.1002/9781119536604.ch4
TI  - Searching for and selecting studies
AB  - No Abstract Found
PY  - 2019
DA  - 2019-09-20
JO  - {'id': None, 'issn_l': None, 'issn': None, 'display_name': 'Cochrane Handbook for Systematic Reviews of Interventions', 'publisher': None, 'type': None, 'url': 'https://doi.org/10.1002/9781119536604.ch4', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Carol Lefebvre
AU  - Julie Glanville
AU  - Chris Cooper
AU  - Anne Littlewood
AU  - Chris Marshall
AU  - Maria-Inti Metzendorf
AU  - Anna H Noel-Storr
AU  - Tamara Rader
AU  - Farhad Shokraneh
AU  - James D. Thomas
AU  - L. Susan Wieland
ER  - 

5.
TY  - journal-article
ID  - https://openalex.org/W2755149525
DO  - https://doi.org/10.1016/j.jclinepi.2017.08.011
TI  - Living systematic reviews: 2. Combining human and machine effort
AB  - New approaches to evidence synthesis, which use human effort and machine automation in mutually reinforcing ways, can enhance the feasibility and sustainability of living systematic reviews. Human effort is a scarce and valuable resource, required when automation is impossible or undesirable, and includes contributions from online communities ("crowds") as well as more conventional contributions from review authors and information specialists. Automation can assist with some systematic review tasks, including searching, eligibility assessment, identification and retrieval of full-text reports, extraction of data, and risk of bias assessment. Workflows can be developed in which human effort and machine automation can each enable the other to operate in more effective and efficient ways, offering substantial enhancement to the productivity of systematic reviews. This paper describes and discusses the potential-and limitations-of new ways of undertaking specific tasks in living systematic reviews, identifying areas where these human/machine "technologies" are already in use, and where further research and development is needed. While the context is living systematic reviews, many of these enabling technologies apply equally to standard approaches to systematic reviewing. of currently available evidence for some RR methods shortcuts taken, this guidance will need to be updated as additional abbreviated methods are evaluated. between studies or collaboration between research teams and, whilst it is difficult to establish any overall conclusions about best approaches, it is clear that efficiencies and reductions in workload are potentially achievable. On the whole, most suggested that a saving in workload of between 30% and 70% might be possible, though sometimes the saving in workload is accompanied by the loss of 5% of relevant studies (i.e. a 95% recall).Using text mining to prioritise the order in which items are screened should be considered safe and ready for use in 'live' reviews. The use of text mining as a 'second screener' may also be used cautiously. The use of text mining to eliminate studies automatically should be considered promising, but not yet fully proven. In highly technical/clinical areas, it may be used with a high degree of confidence; but more developmental and evaluative work is needed in other disciplines. The strongest features of the app, identified and reported in user feedback, were its ability to help in screening and collaboration as well as the time savings it affords to users.Rayyan is responsive and intuitive in use with significant potential to lighten the load of reviewers.
PY  - 2017
DA  - 2017-11-01
JO  - {'id': 'https://openalex.org/S64418186', 'issn_l': '0895-4356', 'issn': ['1878-5921', '0895-4356'], 'display_name': 'Journal of Clinical Epidemiology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'http://www.jclinepi.com/article/S0895435617306042/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc-nd'}
DP  - OpenAlex
AU  - James D. Thomas
AU  - Anna H Noel-Storr
AU  - Iain J. Marshall
AU  - Byron C. Wallace
AU  - Steve McDonald
AU  - Chris Mavergames
AU  - Paul Glasziou
AU  - Ian Shemilt
AU  - Anneliese Synnot
AU  - Tari Turner
AU  - Julian Elliott
ER  - 

6.
TY  - journal-article
ID  - https://openalex.org/W2763705877
DO  - https://doi.org/10.1017/s0033291717002653
TI  - Treating depression with physical activity in adolescents and young adults: a systematic review and meta-analysis of randomised controlled trials
AB  - Abstract We aimed to establish the treatment effect of physical activity for depression in young people through meta-analysis. Four databases were searched to September 2016 for randomised controlled trials of physical activity interventions for adolescents and young adults, 12–25 years, experiencing a diagnosis or threshold symptoms of depression. Random-effects meta-analysis was used to estimate the standardised mean difference (SMD) between physical activity and control conditions. Subgroup analysis and meta-regression investigated potential treatment effect modifiers. Acceptability was estimated using dropout. Trials were assessed against risk of bias domains and overall quality of evidence was assessed using GRADE criteria. Seventeen trials were eligible and 16 provided data from 771 participants showing a large effect of physical activity on depression symptoms compared to controls (SMD = −0.82, 95% CI = −1.02 to −0.61, p &lt; 0.05, I 2 = 38%). The effect remained robust in trials with clinical samples ( k = 5, SMD = −0.72, 95% CI = −1.15 to −0.30), and in trials using attention/activity placebo controls ( k = 7, SMD = −0.82, 95% CI = −1.05 to −0.59). Dropout was 11% across physical activity arms and equivalent in controls ( k = 12, RD = −0.01, 95% CI = −0.04 to 0.03, p = 0.70). However, the quality of RCT-level evidence contributing to the primary analysis was downgraded two levels to LOW (trial-level risk of bias, suspected publication bias), suggesting uncertainty in the size of effect and caution in its interpretation. While physical activity appears to be a promising and acceptable intervention for adolescents and young adults experiencing depression, robust clinical effectiveness trials that minimise risk of bias are required to increase confidence in the current finding. The specific intervention characteristics required to improve depression remain unclear, however best candidates given current evidence may include, but are not limited to, supervised, aerobic-based activity of moderate-to-vigorous intensity, engaged in multiple times per week over eight or more weeks. Further research is needed. (Registration: PROSPERO-CRD 42015024388). areas, it may be used with a high degree of confidence; but more developmental and evaluative work is needed in other disciplines. The strongest features of the app, identified and reported in user feedback, were its ability to help in screening and collaboration as well as the time savings it affords to users.Rayyan is responsive and intuitive in use with significant potential to lighten the load of reviewers.
PY  - 2017
DA  - 2017-10-10
JO  - {'id': 'https://openalex.org/S71144982', 'issn_l': '0033-2917', 'issn': ['0033-2917', '1469-8978'], 'display_name': 'Psychological Medicine', 'publisher': 'Cambridge University Press', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Adam Bailey
AU  - Sarah E Hetrick
AU  - Simon Rosenbaum
AU  - Rosemary Purcell
AU  - Alexandra G. Parker
ER  - 

7.
TY  - journal-article
ID  - https://openalex.org/W4313371821
DO  - https://doi.org/10.1186/2046-4053-4-5
TI  - Using text mining for study identification in systematic reviews: a systematic review of current approaches
AB  - BackgroundThe large and growing number of published studies, and their increasing rate of publication, makes the task of identifying relevant studies in an unbiased way for inclusion in systematic reviews both complex and time consuming. Text mining has been offered as a potential solution: through automating some of the screening process, reviewer time can be saved. The evidence base around the use of text mining for screening has not yet been pulled together systematically; this systematic review fills that research gap. Focusing mainly on non-technical issues, the review aims to increase awareness of the potential of these technologies and promote further collaborative research between the computer science and systematic review communities.MethodsFive research questions led our review: what is the state of the evidence base; how has workload reduction been evaluated; what are the purposes of semi-automation and how effective are they; how have key contextual problems of applying text mining to the systematic review field been addressed; and what challenges to implementation have emerged?We answered these questions using standard systematic review methods: systematic and exhaustive searching, quality-assured data extraction and a narrative synthesis to synthesise findings.ResultsThe evidence base is active and diverse; there is almost no replication between studies or collaboration between research teams and, whilst it is difficult to establish any overall conclusions about best approaches, it is clear that efficiencies and reductions in workload are potentially achievable.On the whole, most suggested that a saving in workload of between 30% and 70% might be possible, though sometimes the saving in workload is accompanied by the loss of 5% of relevant studies (i.e. a 95% recall).ConclusionsUsing text mining to prioritise the order in which items are screened should be considered safe and ready for use in ‘live’ reviews. The use of text mining as a ‘second screener’ may also be used cautiously. The use of text mining to eliminate studies automatically should be considered promising, but not yet fully proven. In highly technical/clinical areas, it may be used with a high degree of confidence; but more developmental and evaluative work is needed in other disciplines. other disciplines. The strongest features of the app, identified and reported in user feedback, were its ability to help in screening and collaboration as well as the time savings it affords to users.Rayyan is responsive and intuitive in use with significant potential to lighten the load of reviewers.
PY  - 2015
DA  - 2015-01-14
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://systematicreviewsjournal.biomedcentral.com/counter/pdf/10.1186/2046-4053-4-5', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Alison O’Mara-Eves
AU  - James Thomas
AU  - John McNaught
AU  - Makoto Miwa
AU  - Sophia Ananiadou
ER  - 

8.
TY  - journal-article
ID  - https://openalex.org/W2184378182
DO  - https://doi.org/10.1093/jamia/ocv044
TI  - RobotReviewer: evaluation of a system for automatically assessing bias in clinical trials
AB  - Abstract Objective To develop and evaluate RobotReviewer, a machine learning (ML) system that automatically assesses bias in clinical trials. From a (PDF-formatted) trial report, the system should determine risks of bias for the domains defined by the Cochrane Risk of Bias (RoB) tool, and extract supporting text for these judgments. Methods We algorithmically annotated 12,808 trial PDFs using data from the Cochrane Database of Systematic Reviews (CDSR). Trials were labeled as being at low or high/unclear risk of bias for each domain, and sentences were labeled as being informative or not. This dataset was used to train a multi-task ML model. We estimated the accuracy of ML judgments versus humans by comparing trials with two or more independent RoB assessments in the CDSR. Twenty blinded experienced reviewers rated the relevance of supporting text, comparing ML output with equivalent (human-extracted) text from the CDSR. Results By retrieving the top 3 candidate sentences per document (top3 recall), the best ML text was rated more relevant than text from the CDSR, but not significantly (60.4% ML text rated ‘highly relevant' v 56.5% of text from reviews; difference +3.9%, [−3.2% to +10.9%]). Model RoB judgments were less accurate than those from published reviews, though the difference was &amp;lt;10% (overall accuracy 71.0% with ML v 78.3% with CDSR). Conclusion Risk of bias assessment may be automated with reasonable accuracy. Automatically identified text supporting bias assessment is of equal quality to the manually identified text in the CDSR. This technology could substantially reduce reviewer workload and expedite evidence syntheses. accompanied by the loss of 5% of relevant studies (i.e. a 95% recall).ConclusionsUsing text mining to prioritise the order in which items are screened should be considered safe and ready for use in ‘live’ reviews. The use of text mining as a ‘second screener’ may also be used cautiously. The use of text mining to eliminate studies automatically should be considered promising, but not yet fully proven. In highly technical/clinical areas, it may be used with a high degree of confidence; but more developmental and evaluative work is needed in other disciplines. other disciplines. The strongest features of the app, identified and reported in user feedback, were its ability to help in screening and collaboration as well as the time savings it affords to users.Rayyan is responsive and intuitive in use with significant potential to lighten the load of reviewers.
PY  - 2016
DA  - 2016-01-01
JO  - {'id': 'https://openalex.org/V129839026', 'issn_l': '1067-5027', 'issn': ['1067-5027', '1527-974X'], 'display_name': 'Journal of the American Medical Informatics Association', 'publisher': 'Oxford University Press', 'type': 'journal', 'url': 'https://academic.oup.com/jamia/article-pdf/23/1/193/7051183/ocv044.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc'}
DP  - OpenAlex
AU  - Iain J. Marshall
AU  - Joël Kuiper
AU  - Byron C. Wallace
ER  - 

9.
TY  - journal-article
ID  - https://openalex.org/W2973631095
DO  - https://doi.org/10.1111/hir.12276
TI  - Meeting the review family: exploring review types and associated information retrieval requirements
AB  - The last decade has witnessed increased recognition of the value of literature reviews for advancing understanding and decision making. This has been accompanied by an expansion in the range of methodological approaches and types of review. However, there remains uncertainty over definitions and search requirements beyond those for the 'traditional' systematic review. This study aims to characterise health related reviews by type and to provide recommendations on appropriate methods of information retrieval based on the available guidance.A list of review types was generated from published typologies and categorised into 'families' based on their common features. Guidance on information retrieval for each review type was identified by searching pubmed, medline and Google Scholar, supplemented by scrutinising websites of review producing organisations.Forty-eight review types were identified and categorised into seven families. Published guidance reveals increasing specification of methods for information retrieval; however, much of it remains generic with many review types lacking explicit requirements for the identification of evidence.Defining review types and utilising appropriate search methods remain challenging. By familiarising themselves with a range of review methodologies and associated search methods, information specialists will be better equipped to select suitable approaches for future projects. less accurate than those from published reviews, though the difference was &amp;lt;10% (overall accuracy 71.0% with ML v 78.3% with CDSR). Conclusion Risk of bias assessment may be automated with reasonable accuracy. Automatically identified text supporting bias assessment is of equal quality to the manually identified text in the CDSR. This technology could substantially reduce reviewer workload and expedite evidence syntheses. accompanied by the loss of 5% of relevant studies (i.e. a 95% recall).ConclusionsUsing text mining to prioritise the order in which items are screened should be considered safe and ready for use in ‘live’ reviews. The use of text mining as a ‘second screener’ may also be used cautiously. The use of text mining to eliminate studies automatically should be considered promising, but not yet fully proven. In highly technical/clinical areas, it may be used with a high degree of confidence; but more developmental and evaluative work is needed in other disciplines. other disciplines. The strongest features of the app, identified and reported in user feedback, were its ability to help in screening and collaboration as well as the time savings it affords to users.Rayyan is responsive and intuitive in use with significant potential to lighten the load of reviewers.
PY  - 2019
DA  - 2019-09-01
JO  - {'id': 'https://openalex.org/S66051165', 'issn_l': '1471-1834', 'issn': ['1365-2532', '1471-1842', '0265-6647', '1471-1834'], 'display_name': 'Health Information and Libraries Journal', 'publisher': 'Wiley-Blackwell', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Anthea Sutton
AU  - Mark Clowes
AU  - Louise Preston
AU  - Andrew Booth
ER  - 

10.
TY  - journal-article
ID  - https://openalex.org/W1629765770
DO  - https://doi.org/10.1186/s13643-015-0066-7
TI  - Automating data extraction in systematic reviews: a systematic review
AB  - Automation of the parts of systematic review process, specifically the data extraction step, may be an important strategy to reduce the time necessary to complete a systematic review. However, the state of the science of automatically extracting data elements from full texts has not been well described. This paper performs a systematic review of published and unpublished methods to automate data extraction for systematic reviews.We systematically searched PubMed, IEEEXplore, and ACM Digital Library to identify potentially relevant articles. We included reports that met the following criteria: 1) methods or results section described what entities were or need to be extracted, and 2) at least one entity was automatically extracted with evaluation results that were presented for that entity. We also reviewed the citations from included reports.Out of a total of 1190 unique citations that met our search criteria, we found 26 published reports describing automatic extraction of at least one of more than 52 potential data elements used in systematic reviews. For 25 (48 %) of the data elements used in systematic reviews, there were attempts from various researchers to extract information automatically from the publication text. Out of these, 14 (27 %) data elements were completely extracted, but the highest number of data elements extracted automatically by a single study was 7. Most of the data elements were extracted with F-scores (a mean of sensitivity and positive predictive value) of over 70 %.We found no unified information extraction framework tailored to the systematic review process, and published reports focused on a limited (1-7) number of data elements. Biomedical natural language processing techniques have not been fully utilized to fully or even partially automate the data extraction step of systematic reviews. and ready for use in ‘live’ reviews. The use of text mining as a ‘second screener’ may also be used cautiously. The use of text mining to eliminate studies automatically should be considered promising, but not yet fully proven. In highly technical/clinical areas, it may be used with a high degree of confidence; but more developmental and evaluative work is needed in other disciplines. other disciplines. The strongest features of the app, identified and reported in user feedback, were its ability to help in screening and collaboration as well as the time savings it affords to users.Rayyan is responsive and intuitive in use with significant potential to lighten the load of reviewers.
PY  - 2015
DA  - 2015-06-15
JO  - {'id': 'https://openalex.org/V82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://doi.org/10.1186/s13643-015-0066-7', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Siddhartha Jonnalagadda
AU  - Pawan Goyal
AU  - Mark D. Huffman
ER  - 

11.
TY  - journal-article
ID  - https://openalex.org/W2865233769
DO  - https://doi.org/10.1016/j.scitotenv.2018.06.349
TI  - A systematic review on Asian's farmers' adaptation practices towards climate change
AB  - Climate change in Asia is affecting farmers' daily routines. Much of the focus surrounding climate change has targeted the economic and environmental repercussions on farming. Few systematic reviews have been carried out on the social impacts of climate change among farmers in Asia. The present article set out to analyse the existing literature on Asian farmers' adaptation practices towards the impacts of climate change. Guided by the PRISMA Statement (Preferred Reporting Items for Systematic reviews and Meta-Analyses) review method, a systematic review of the Scopus and Web of Science databases identified 38 related studies. Further review of these articles resulted in six main themes - crop management, irrigation and water management, farm management, financial management, physical infrastructure management and social activities. These six themes further produced a total of 35 sub-themes. Several recommendations are highlighted related to conducting more qualitative studies, to have specific and a standard systematic review method for guide research synthesis in context of climate change adaptation and to practice complimentary searching techniques such as citation tracking, reference searching, snowballing and contacting experts. from various researchers to extract information automatically from the publication text. Out of these, 14 (27 %) data elements were completely extracted, but the highest number of data elements extracted automatically by a single study was 7. Most of the data elements were extracted with F-scores (a mean of sensitivity and positive predictive value) of over 70 %.We found no unified information extraction framework tailored to the systematic review process, and published reports focused on a limited (1-7) number of data elements. Biomedical natural language processing techniques have not been fully utilized to fully or even partially automate the data extraction step of systematic reviews. and ready for use in ‘live’ reviews. The use of text mining as a ‘second screener’ may also be used cautiously. The use of text mining to eliminate studies automatically should be considered promising, but not yet fully proven. In highly technical/clinical areas, it may be used with a high degree of confidence; but more developmental and evaluative work is needed in other disciplines. other disciplines. The strongest features of the app, identified and reported in user feedback, were its ability to help in screening and collaboration as well as the time savings it affords to users.Rayyan is responsive and intuitive in use with significant potential to lighten the load of reviewers.
PY  - 2018
DA  - 2018-12-10
JO  - {'id': 'https://openalex.org/S86852077', 'issn_l': '0048-9697', 'issn': ['0048-9697', '1879-1026'], 'display_name': 'Science of The Total Environment', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Hayrol Azril Mohamed Shaffril
AU  - Steven Eric Krauss
AU  - Samsul Farid Samsuddin
ER  - 

12.
TY  - journal-article
ID  - https://openalex.org/W3003735349
DO  - https://doi.org/10.1016/j.jclinepi.2020.01.008
TI  - A full systematic review was completed in 2 weeks using automation tools: a case study
AB  - Abstract change in Background and Objectives farmers' Systematic reviews (SRs) are time and resource intensive, requiring approximately 1 year from protocol registration to submission for publication. Our aim was to describe the process, facilitators, and barriers to completing the first 2-week full SR. Asia. The present Study Design and Setting analyse We systematically reviewed evidence of the impact of increased fluid intake, on urinary tract infection (UTI) recurrence, in individuals at risk for UTIs. The review was conducted by experienced systematic reviewers with complementary skills (two researcher clinicians, an information specialist, and an epidemiologist), using Systematic Review Automation tools, and blocked off time for the duration of the project. The outcomes were time to complete the SR, time to complete individual SR tasks, facilitators and barriers to progress, and peer reviewer feedback on the SR manuscript. Times to completion were analyzed quantitatively (minutes and calendar days); facilitators and barriers were mapped onto the Theoretical Domains Framework; and peer reviewer feedback was analyzed quantitatively and narratively. searching techniques such Results citation The SR was completed in 61 person-hours (9 workdays; 12 calendar days); accepted version of the manuscript required 71 person-hours. Individual SR tasks ranged from 16 person-minutes (deduplication of search results) to 461 person-minutes (data extraction). The least time-consuming SR tasks were obtaining full-texts, searches, citation analysis, data synthesis, and deduplication. The most time-consuming tasks were data extraction, write-up, abstract screening, full-text screening, and risk of bias. Facilitators and barriers mapped onto the following domains: knowledge; skills; memory, attention, and decision process; environmental context and resources; and technology and infrastructure. Two sets of peer reviewer feedback were received on the manuscript: the first included 34 comments requesting changes, 17 changes were made, requiring 173 person-minutes; the second requested 13 changes, and eight were made, requiring 121 person-minutes. screener’ may also Conclusion used A small and experienced systematic reviewer team using Systematic Review Automation tools who have protected time to focus solely on the SR can complete a moderately sized SR in 2 weeks. degree of confidence; but more developmental and evaluative work is needed in other disciplines. other disciplines. The strongest features of the app, identified and reported in user feedback, were its ability to help in screening and collaboration as well as the time savings it affords to users.Rayyan is responsive and intuitive in use with significant potential to lighten the load of reviewers.
PY  - 2020
DA  - 2020-05-01
JO  - {'id': 'https://openalex.org/S64418186', 'issn_l': '0895-4356', 'issn': ['1878-5921', '0895-4356'], 'display_name': 'Journal of Clinical Epidemiology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'http://www.jclinepi.com/article/S089543561930719X/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': None}
DP  - OpenAlex
AU  - Justin Clark
AU  - Paul Glasziou
AU  - Chris Del Mar
AU  - Alexandra Bannach-Brown
AU  - Paulina Stehlik
AU  - Anna Mae Scott
ER  - 

13.
TY  - journal-article
ID  - https://openalex.org/W122374328
DO  - https://doi.org/10.4073/cmg.2016.1
TI  - Searching for studies: a guide to information retrieval for Campbell systematic reviews
AB  - No Abstract Found
PY  - 2017
DA  - 2017-01-01
JO  - {'id': 'https://openalex.org/S2739193000', 'issn_l': '1891-1803', 'issn': ['1891-1803'], 'display_name': 'Campbell Systematic Reviews', 'publisher': 'The Campbell Collaboration', 'type': 'journal', 'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.4073/cmg.2016.1', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Shannon Kugley
AU  - Anne Wade
AU  - James D. Thomas
AU  - Quenby Mahood
AU  - Anne-Marie Klint Jørgensen
AU  - Karianne Thune Hammerstrøm
AU  - Nila A Sathe
ER  - 

14.
TY  - journal-article
ID  - https://openalex.org/W2782172275
DO  - https://doi.org/10.1016/j.jamda.2017.10.023
TI  - Online Training and Support Programs Designed to Improve Mental Health and Reduce Burden Among Caregivers of People With Dementia: A Systematic Review
AB  - Dementia poses a considerable socioeconomic burden to society. On a global scale, family and other unpaid care predominates. Supporting caregivers is crucial, but scalable interventions are currently lacking. Because a growing number of studies have suggested that online training and support programs hold considerable promise for scaling up, we reviewed existing literature.We systematically searched 6 databases to identify studies of Internet-based interventions designed to train and support caregivers of people with dementia, and we formally assessed risk of bias. Our prespecified primary outcomes of interest included both mental health and caregiver burden/perceived stress. Our secondary outcomes of interest included knowledge, quality of life of caregivers, quality of care, caregiver response to challenging behaviors, coping, and self-efficacy.Eight randomized control trials met our inclusion criteria involving over 900 participants. The content and structure of Internet-based interventions, outcome measures, and duration differed markedly, and selection, performance, and reporting biases were varied and on occasion of concern. Six studies reported outcomes in caregivers' mental health outcomes, 3 studies reported burden outcomes. Three studies reported knowledge skills, quality of life and reaction to challenging behaviours, whereas 2 studies reported changes in coping outcomes and self-efficacy. No studies reported outcomes on quality of care.Although there is some evidence that Internet-based interventions can improve mental health outcomes for informal caregivers of people with dementia, marked methodological diversity across studies prevented the robust pooling of the results. A concerted and cohesive approach from all stakeholders is now required to help realize the full potential of this emerging field. process; environmental context and resources; and technology and infrastructure. Two sets of peer reviewer feedback were received on the manuscript: the first included 34 comments requesting changes, 17 changes were made, requiring 173 person-minutes; the second requested 13 changes, and eight were made, requiring 121 person-minutes. screener’ may also Conclusion used A small and experienced systematic reviewer team using Systematic Review Automation tools who have protected time to focus solely on the SR can complete a moderately sized SR in 2 weeks. degree of confidence; but more developmental and evaluative work is needed in other disciplines. other disciplines. The strongest features of the app, identified and reported in user feedback, were its ability to help in screening and collaboration as well as the time savings it affords to users.Rayyan is responsive and intuitive in use with significant potential to lighten the load of reviewers.
PY  - 2018
DA  - 2018-03-01
JO  - {'id': 'https://openalex.org/S132839637', 'issn_l': '1525-8610', 'issn': ['1538-9375', '1525-8610'], 'display_name': 'Journal of the American Medical Directors Association', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Kieren J. Egan
AU  - Ángel C Pinto-Bruno
AU  - Irene Bighelli
AU  - Marla Berg-Weger
AU  - Annemieke van Straten
AU  - Emiliano Albanese
AU  - Anne Margriet Pot
ER  - 

15.
TY  - journal-article
ID  - https://openalex.org/W2906109115
DO  - https://doi.org/10.1016/j.tree.2018.11.007
TI  - Research Weaving: Visualizing the Future of Research Synthesis
AB  - We propose a new framework for research synthesis of both evidence and influence, named research weaving. It summarizes and visualizes information content, history, and networks among a collection of documents on any given topic. Research weaving achieves this feat by combining the power of two methods: systematic mapping and bibliometrics. Systematic mapping provides a snapshot of the current state of knowledge, identifying areas needing more research attention and those ready for full synthesis. Bibliometrics enables researchers to see how pieces of evidence are connected, revealing the structure and development of a field. We explain how researchers can use some or all of these tools to gain a deeper, more nuanced understanding of the scientific literature. self-efficacy.Eight randomized control trials met our inclusion criteria involving over 900 participants. The content and structure of Internet-based interventions, outcome measures, and duration differed markedly, and selection, performance, and reporting biases were varied and on occasion of concern. Six studies reported outcomes in caregivers' mental health outcomes, 3 studies reported burden outcomes. Three studies reported knowledge skills, quality of life and reaction to challenging behaviours, whereas 2 studies reported changes in coping outcomes and self-efficacy. No studies reported outcomes on quality of care.Although there is some evidence that Internet-based interventions can improve mental health outcomes for informal caregivers of people with dementia, marked methodological diversity across studies prevented the robust pooling of the results. A concerted and cohesive approach from all stakeholders is now required to help realize the full potential of this emerging field. process; environmental context and resources; and technology and infrastructure. Two sets of peer reviewer feedback were received on the manuscript: the first included 34 comments requesting changes, 17 changes were made, requiring 173 person-minutes; the second requested 13 changes, and eight were made, requiring 121 person-minutes. screener’ may also Conclusion used A small and experienced systematic reviewer team using Systematic Review Automation tools who have protected time to focus solely on the SR can complete a moderately sized SR in 2 weeks. degree of confidence; but more developmental and evaluative work is needed in other disciplines. other disciplines. The strongest features of the app, identified and reported in user feedback, were its ability to help in screening and collaboration as well as the time savings it affords to users.Rayyan is responsive and intuitive in use with significant potential to lighten the load of reviewers.
PY  - 2019
DA  - 2019-03-01
JO  - {'id': 'https://openalex.org/V79131028', 'issn_l': '0169-5347', 'issn': ['0169-5347', '1872-8383'], 'display_name': 'Trends in Ecology and Evolution', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Shinichi Nakagawa
AU  - Gihan Samarasinghe
AU  - Neal R. Haddaway
AU  - Martin J. Westgate
AU  - Rose E. O'Dea
AU  - Daniel W. A. Noble
AU  - Malgorzata Lagisz
ER  - 

16.
TY  - proceedings-article
ID  - https://openalex.org/W3099977667
DO  - https://doi.org/10.18653/v1/2020.emnlp-main.609
TI  - Fact or Fiction: Verifying Scientific Claims
AB  - We introduce scientific claim verification, a new task to select abstracts from the research literature containing evidence that SUPPORTS or REFUTES a given scientific claim, and to identify rationales justifying each decision. To study this task, we construct SciFact, a dataset of 1.4K expert-written scientific claims paired with evidence-containing abstracts annotated with labels and rationales. We develop baseline models for SciFact, and demonstrate that simple domain adaptation techniques substantially improve performance compared to models trained on Wikipedia or political news. We show that our system is able to verify claims related to COVID-19 by identifying evidence from the CORD-19 corpus. Our experiments indicate that SciFact will provide a challenging testbed for the development of new systems designed to retrieve and reason over corpora containing specialized domain knowledge. Data and code for this new task are publicly available at https://github.com/allenai/scifact. A leaderboard and COVID-19 fact-checking demo are available at https://scifact.apps.allenai.org. on occasion of concern. Six studies reported outcomes in caregivers' mental health outcomes, 3 studies reported burden outcomes. Three studies reported knowledge skills, quality of life and reaction to challenging behaviours, whereas 2 studies reported changes in coping outcomes and self-efficacy. No studies reported outcomes on quality of care.Although there is some evidence that Internet-based interventions can improve mental health outcomes for informal caregivers of people with dementia, marked methodological diversity across studies prevented the robust pooling of the results. A concerted and cohesive approach from all stakeholders is now required to help realize the full potential of this emerging field. process; environmental context and resources; and technology and infrastructure. Two sets of peer reviewer feedback were received on the manuscript: the first included 34 comments requesting changes, 17 changes were made, requiring 173 person-minutes; the second requested 13 changes, and eight were made, requiring 121 person-minutes. screener’ may also Conclusion used A small and experienced systematic reviewer team using Systematic Review Automation tools who have protected time to focus solely on the SR can complete a moderately sized SR in 2 weeks. degree of confidence; but more developmental and evaluative work is needed in other disciplines. other disciplines. The strongest features of the app, identified and reported in user feedback, were its ability to help in screening and collaboration as well as the time savings it affords to users.Rayyan is responsive and intuitive in use with significant potential to lighten the load of reviewers.
PY  - 2020
DA  - 2020-04-30
JO  - {'id': 'https://openalex.org/V4306418267', 'issn_l': None, 'issn': None, 'display_name': 'Empirical Methods in Natural Language Processing', 'publisher': None, 'type': 'conference', 'url': 'https://www.aclweb.org/anthology/2020.emnlp-main.609.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - David Wadden
AU  - Shanchuan Lin
AU  - Kyle Lo
AU  - Lucy Lu Wang
AU  - Madeleine van Zuylen
AU  - Arman Cohan
AU  - Hannaneh Hajishirzi
ER  - 

17.
TY  - journal-article
ID  - https://openalex.org/W2104793920
DO  - https://doi.org/10.2196/medinform.3503
TI  - Adoption of Clinical Decision Support in Multimorbidity: A Systematic Review
AB  - Patients with multiple conditions have complex needs and are increasing in number as populations age. This multimorbidity is one of the greatest challenges facing health care. Having more than 1 condition generates (1) interactions between pathologies, (2) duplication of tests, (3) difficulties in adhering to often conflicting clinical practice guidelines, (4) obstacles in the continuity of care, (5) confusing self-management information, and (6) medication errors. In this context, clinical decision support (CDS) systems need to be able to handle realistic complexity and minimize iatrogenic risks.The aim of this review was to identify to what extent CDS is adopted in multimorbidity.This review followed PRISMA guidance and adopted a multidisciplinary approach. Scopus and PubMed searches were performed by combining terms from 3 different thesauri containing synonyms for (1) multimorbidity and comorbidity, (2) polypharmacy, and (3) CDS. The relevant articles were identified by examining the titles and abstracts. The full text of selected/relevant articles was analyzed in-depth. For articles appropriate for this review, data were collected on clinical tasks, diseases, decision maker, methods, data input context, user interface considerations, and evaluation of effectiveness.A total of 50 articles were selected for the full in-depth analysis and 20 studies were included in the final review. Medication (n=10) and clinical guidance (n=8) were the predominant clinical tasks. Four studies focused on merging concurrent clinical practice guidelines. A total of 17 articles reported their CDS systems were knowledge-based. Most articles reviewed considered patients' clinical records (n=19), clinical practice guidelines (n=12), and clinicians' knowledge (n=10) as contextual input data. The most frequent diseases mentioned were cardiovascular (n=9) and diabetes mellitus (n=5). In all, 12 articles mentioned generalist doctor(s) as the decision maker(s). For articles reviewed, there were no studies referring to the active involvement of the patient in the decision-making process or to patient self-management. None of the articles reviewed adopted mobile technologies. There were no rigorous evaluations of usability or effectiveness of the CDS systems reported.This review shows that multimorbidity is underinvestigated in the informatics of supporting clinical decisions. CDS interventions that systematize clinical practice guidelines without considering the interactions of different conditions and care processes may lead to unhelpful or harmful clinical actions. To improve patient safety in multimorbidity, there is a need for more evidence about how both conditions and care processes interact. The data needed to build this evidence base exist in many electronic health record systems and are underused.
PY  - 2015
DA  - 2015-01-07
JO  - {'id': 'https://openalex.org/V2764650051', 'issn_l': '2291-9694', 'issn': ['2291-9694'], 'display_name': 'JMIR medical informatics', 'publisher': 'JMIR Publications', 'type': 'journal', 'url': 'https://doi.org/10.2196/medinform.3503', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Paolo Fraccaro
AU  - Mercedes Arguello Casteleiro
AU  - John Ainsworth
AU  - Iain Buchan
ER  - 

18.
TY  - journal-article
ID  - https://openalex.org/W2285413972
DO  - https://doi.org/10.1186/s12916-016-0555-0
TI  - Wasted research when systematic reviews fail to provide a complete and up-to-date evidence synthesis: the example of lung cancer
AB  - Multiple treatments are frequently available for a given condition, and clinicians and patients need a comprehensive, up-to-date synthesis of evidence for all competing treatments. We aimed to quantify the waste of research related to the failure of systematic reviews to provide a complete and up-to-date evidence synthesis over time.We performed a series of systematic overviews and networks of randomized trials assessing the gap between evidence covered by systematic reviews and available trials of second-line treatments for advanced non-small cell lung cancer. We searched the Cochrane Database of Systematic Reviews, Database of Abstracts of Reviews of Effects, MEDLINE, EMBASE, and other resources sequentially by year from 2009 to March 2, 2015. We sequentially compared the amount of evidence missing from systematic reviews to the randomized evidence available for inclusion each year. We constructed cumulative networks of randomized evidence over time and evaluated the proportion of trials, patients, treatments, and treatment comparisons not covered by systematic reviews on December 31 each year from 2009 to 2015.We identified 77 trials (28,636 patients) assessing 47 treatments with 54 comparisons and 29 systematic reviews (13 published after 2013). From 2009 to 2015, the evidence covered by existing systematic reviews was consistently incomplete: 45 % to 70 % of trials; 30 % to 58 % of patients; 40 % to 66 % of treatments; and 38 % to 71 % of comparisons were missing. In the cumulative networks of randomized evidence, 10 % to 17 % of treatment comparisons were partially covered by systematic reviews and 55 % to 85 % were partially or not covered.We illustrate how systematic reviews of a given condition provide a fragmented, out-of-date panorama of the evidence for all treatments. This waste of research might be reduced by the development of live cumulative network meta-analyses. to patient self-management. None of the articles reviewed adopted mobile technologies. There were no rigorous evaluations of usability or effectiveness of the CDS systems reported.This review shows that multimorbidity is underinvestigated in the informatics of supporting clinical decisions. CDS interventions that systematize clinical practice guidelines without considering the interactions of different conditions and care processes may lead to unhelpful or harmful clinical actions. To improve patient safety in multimorbidity, there is a need for more evidence about how both conditions and care processes interact. The data needed to build this evidence base exist in many electronic health record systems and are underused.
PY  - 2016
DA  - 2016-01-20
JO  - {'id': 'https://openalex.org/S135560524', 'issn_l': '1741-7015', 'issn': ['1741-7015'], 'display_name': 'BMC Medicine', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://bmcmedicine.biomedcentral.com/track/pdf/10.1186/s12916-016-0555-0', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Perrine Créquit
AU  - Ludovic Trinquart
AU  - Amélie Yavchitz
AU  - Philippe Ravaud
ER  - 

19.
TY  - journal-article
ID  - https://openalex.org/W2467158152
DO  - https://doi.org/10.1186/s12940-016-0156-6
TI  - A proposed framework for the systematic review and integrated assessment (SYRINA) of endocrine disrupting chemicals
AB  - The issue of endocrine disrupting chemicals (EDCs) is receiving wide attention from both the scientific and regulatory communities. Recent analyses of the EDC literature have been criticized for failing to use transparent and objective approaches to draw conclusions about the strength of evidence linking EDC exposures to adverse health or environmental outcomes. Systematic review methodologies are ideal for addressing this issue as they provide transparent and consistent approaches to study selection and evaluation. Objective methods are needed for integrating the multiple streams of evidence (epidemiology, wildlife, laboratory animal, in vitro, and in silico data) that are relevant in assessing EDCs.We have developed a framework for the systematic review and integrated assessment (SYRINA) of EDC studies. The framework was designed for use with the International Program on Chemical Safety (IPCS) and World Health Organization (WHO) definition of an EDC, which requires appraisal of evidence regarding 1) association between exposure and an adverse effect, 2) association between exposure and endocrine disrupting activity, and 3) a plausible link between the adverse effect and the endocrine disrupting activity.Building from existing methodologies for evaluating and synthesizing evidence, the SYRINA framework includes seven steps: 1) Formulate the problem; 2) Develop the review protocol; 3) Identify relevant evidence; 4) Evaluate evidence from individual studies; 5) Summarize and evaluate each stream of evidence; 6) Integrate evidence across all streams; 7) Draw conclusions, make recommendations, and evaluate uncertainties. The proposed method is tailored to the IPCS/WHO definition of an EDC but offers flexibility for use in the context of other definitions of EDCs.When using the SYRINA framework, the overall objective is to provide the evidence base needed to support decision making, including any action to avoid/minimise potential adverse effects of exposures. This framework allows for the evaluation and synthesis of evidence from multiple evidence streams. Finally, a decision regarding regulatory action is not only dependent on the strength of evidence, but also the consequences of action/inaction, e.g. limited or weak evidence may be sufficient to justify action if consequences are serious or irreversible. that systematize clinical practice guidelines without considering the interactions of different conditions and care processes may lead to unhelpful or harmful clinical actions. To improve patient safety in multimorbidity, there is a need for more evidence about how both conditions and care processes interact. The data needed to build this evidence base exist in many electronic health record systems and are underused.
PY  - 2016
DA  - 2016-07-14
JO  - {'id': 'https://openalex.org/S191320764', 'issn_l': '1476-069X', 'issn': ['1476-069X'], 'display_name': 'Environmental Health', 'publisher': 'BioMed Central', 'type': 'journal', 'url': 'https://doi.org/10.1186/s12940-016-0156-6', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Laura N. Vandenberg
AU  - Marlene Ågerstrand
AU  - Anna Beronius
AU  - Claire Beausoleil
AU  - Åke Bergman
AU  - Lisa Bero
AU  - Carl-Gustaf Bornehag
AU  - C. Scott Boyer
AU  - Glinda S. Cooper
AU  - Ian A. Cotgreave
AU  - David G. Gee
AU  - Philippe Grandjean
AU  - Kathryn Z. Guyton
AU  - Ulla Hass
AU  - Jerrold J. Heindel
AU  - Susan Jobling
AU  - Karen A. Kidd
AU  - Andreas Kortenkamp
AU  - Malcolm R. Macleod
AU  - Olwenn V. Martin
AU  - Ulf Norinder
AU  - Martin Scheringer
AU  - Kristina A. Thayer
AU  - Jorma Toppari
AU  - Paul Whaley
AU  - Tracey J. Woodruff
AU  - Christina Rudén
ER  - 

20.
TY  - journal-article
ID  - https://openalex.org/W2765221357
DO  - https://doi.org/10.15171/bi.2017.25
TI  - Study-based registers of randomized controlled trials: Starting a systematic review with data extraction or meta-analysis
AB  - Introduction: Despite years of use of study-based registers for storing reports of randomized controlled trials (RCTs), the methodology used in developing such registers/databases has not been documented. Such registers are integral to the process of scientific reviewing. We document and discuss methodological aspects of the development and use of study-based registers. Although the content is focused on the study-based register of randomized/controlled clinical trials, this work applies to developers of databases of all sorts of studies related to the human, animals, cells, genes, and molecules.
Methods: We describe necessity, rationale, and steps for the development, utilization and maintenance of study-based registers as well as the challenges and gains for the organizations supporting systematic reviews of the published and unpublished literature.
Conclusion: The ultimate goal of having a study-based register is to facilitate efficient production of systematic reviews providing rapid, yet accurate, evidence for the decision-makers. We argue that moving towards study-based registers is an inevitable welcome direction and that infrastructures are ready for such movement. plausible link between the adverse effect and the endocrine disrupting activity.Building from existing methodologies for evaluating and synthesizing evidence, the SYRINA framework includes seven steps: 1) Formulate the problem; 2) Develop the review protocol; 3) Identify relevant evidence; 4) Evaluate evidence from individual studies; 5) Summarize and evaluate each stream of evidence; 6) Integrate evidence across all streams; 7) Draw conclusions, make recommendations, and evaluate uncertainties. The proposed method is tailored to the IPCS/WHO definition of an EDC but offers flexibility for use in the context of other definitions of EDCs.When using the SYRINA framework, the overall objective is to provide the evidence base needed to support decision making, including any action to avoid/minimise potential adverse effects of exposures. This framework allows for the evaluation and synthesis of evidence from multiple evidence streams. Finally, a decision regarding regulatory action is not only dependent on the strength of evidence, but also the consequences of action/inaction, e.g. limited or weak evidence may be sufficient to justify action if consequences are serious or irreversible. that systematize clinical practice guidelines without considering the interactions of different conditions and care processes may lead to unhelpful or harmful clinical actions. To improve patient safety in multimorbidity, there is a need for more evidence about how both conditions and care processes interact. The data needed to build this evidence base exist in many electronic health record systems and are underused.
PY  - 2017
DA  - 2017-09-17
JO  - {'id': 'https://openalex.org/S4210202379', 'issn_l': '2228-5652', 'issn': ['2228-5652', '2228-5660'], 'display_name': 'Bioimpacts', 'publisher': 'Tabriz University of Medical Sciences', 'type': 'journal', 'url': 'https://bi.tbzmed.ac.ir/PDF/bi-17429', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc'}
DP  - OpenAlex
AU  - Farhad Shokraneh
AU  - Clive E Adams
ER  - 

21.
TY  - journal-article
ID  - https://openalex.org/W2963483681
DO  - https://doi.org/10.1111/2041-210x.13268
TI  - An automated approach to identifying search terms for systematic reviews using keyword co‐occurrence networks
AB  - No Abstract Found
PY  - 2019
DA  - 2019-10-01
JO  - {'id': 'https://openalex.org/V1131227', 'issn_l': '2041-210X', 'issn': ['2041-210X'], 'display_name': 'Methods in Ecology and Evolution', 'publisher': 'Wiley-Blackwell', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Eliza M. Grames
AU  - Andrew N. Stillman
AU  - Morgan W. Tingley
AU  - Chris S. Elphick
ER  - 

22.
TY  - journal-article
ID  - https://openalex.org/W990652630
DO  - https://doi.org/10.1016/j.zefq.2015.06.005
TI  - Information overload in healthcare: too much of a good thing?
AB  - The rapidly growing production of healthcare information - both scientific and popular - increasingly leads to a situation of information overload affecting all actors of the healthcare system and threatening to impede the adoption of evidence-based practice. In preparation for the 2015 Cochrane Colloquium in Vienna, we discuss the issues faced by three major actors of this system: patients, healthcare practitioners, and systematic reviewers. We analyze their situation through the concept of "filter failure", positing that the main problem is not that there is "too much information", but that the traditional means of managing and evaluating information are ill-suited to the realities of the digital age. Some of the major instances of filter failure are inadequate information retrieval systems for point-of-care settings, the problem of identifying all relevant evidence in an exceedingly diverse landscape of information resources, and the very basic lack of health information literacy, concerning not only the general public. Finally, we give an overview of proposed solutions to the problem of information overload. These new or adapted filtering systems include adapting review literature to the specific needs of practitioners or patients, technological improvements to information systems, strengthening the roles of intermediaries, as well as improving health literacy. evidence; 4) Evaluate evidence from individual studies; 5) Summarize and evaluate each stream of evidence; 6) Integrate evidence across all streams; 7) Draw conclusions, make recommendations, and evaluate uncertainties. The proposed method is tailored to the IPCS/WHO definition of an EDC but offers flexibility for use in the context of other definitions of EDCs.When using the SYRINA framework, the overall objective is to provide the evidence base needed to support decision making, including any action to avoid/minimise potential adverse effects of exposures. This framework allows for the evaluation and synthesis of evidence from multiple evidence streams. Finally, a decision regarding regulatory action is not only dependent on the strength of evidence, but also the consequences of action/inaction, e.g. limited or weak evidence may be sufficient to justify action if consequences are serious or irreversible. that systematize clinical practice guidelines without considering the interactions of different conditions and care processes may lead to unhelpful or harmful clinical actions. To improve patient safety in multimorbidity, there is a need for more evidence about how both conditions and care processes interact. The data needed to build this evidence base exist in many electronic health record systems and are underused.
PY  - 2015
DA  - 2015-01-01
JO  - {'id': 'https://openalex.org/S124485727', 'issn_l': '1865-9217', 'issn': ['1865-9217', '2212-0289'], 'display_name': 'Zeitschrift für Evidenz, Fortbildung und Qualität im Gesundheitswesen', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Irma Klerings
AU  - Alexandra Stephanie Weinhandl
AU  - Kylie J Thaler
ER  - 

23.
TY  - journal-article
ID  - https://openalex.org/W2805303998
DO  - https://doi.org/10.1186/s13643-018-0740-7
TI  - Making progress with the automation of systematic reviews: principles of the International Collaboration for the Automation of Systematic Reviews (ICASR)
AB  - Systematic reviews (SR) are vital to health care, but have become complicated and time-consuming, due to the rapid expansion of evidence to be synthesised. Fortunately, many tasks of systematic reviews have the potential to be automated or may be assisted by automation. Recent advances in natural language processing, text mining and machine learning have produced new algorithms that can accurately mimic human endeavour in systematic review activity, faster and more cheaply. Automation tools need to be able to work together, to exchange data and results. Therefore, we initiated the International Collaboration for the Automation of Systematic Reviews (ICASR), to successfully put all the parts of automation of systematic review production together. The first meeting was held in Vienna in October 2015. We established a set of principles to enable tools to be developed and integrated into toolkits.This paper sets out the principles devised at that meeting, which cover the need for improvement in efficiency of SR tasks, automation across the spectrum of SR tasks, continuous improvement, adherence to high quality standards, flexibility of use and combining components, the need for a collaboration and varied skills, the desire for open source, shared code and evaluation, and a requirement for replicability through rigorous and open evaluation.Automation has a great potential to improve the speed of systematic reviews. Considerable work is already being done on many of the steps involved in a review. The 'Vienna Principles' set out in this paper aim to guide a more coordinated effort which will allow the integration of work by separate teams and build on the experience, code and evaluations done by the many teams working across the globe. including any action to avoid/minimise potential adverse effects of exposures. This framework allows for the evaluation and synthesis of evidence from multiple evidence streams. Finally, a decision regarding regulatory action is not only dependent on the strength of evidence, but also the consequences of action/inaction, e.g. limited or weak evidence may be sufficient to justify action if consequences are serious or irreversible. that systematize clinical practice guidelines without considering the interactions of different conditions and care processes may lead to unhelpful or harmful clinical actions. To improve patient safety in multimorbidity, there is a need for more evidence about how both conditions and care processes interact. The data needed to build this evidence base exist in many electronic health record systems and are underused.
PY  - 2018
DA  - 2018-05-19
JO  - {'id': 'https://openalex.org/V82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://doi.org/10.1186/s13643-018-0740-7', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Elaine Beller
AU  - Justin Clark
AU  - Guy Tsafnat
AU  - Clive E Adams
AU  - Heinz Diehl
AU  - Hans Lund
AU  - Mourad Ouzzani
AU  - Kristina A. Thayer
AU  - James D. Thomas
AU  - Tari Turner
AU  - Jun Xia
AU  - Karen A. Robinson
AU  - Paul Glasziou
ER  - 

24.
TY  - journal-article
ID  - https://openalex.org/W2461395063
DO  - https://doi.org/10.1177/0363546516652900
TI  - The Clinical Effect of a Rotator Cuff Retear: A Meta-analysis of Arthroscopic Single-Row and Double-Row Repairs
AB  - Background: The clinical effect of a retear after rotator cuff repair remains unclear. While some studies have indicated clinical deficits due to a retear, others have stated that a retear does not detrimentally affect outcomes. Purpose: To conduct a meta-analysis comparing clinical outcomes between intact and retorn rotator cuffs after arthroscopic repair. Study Design: Meta-analysis. Methods: A literature search using the terms “arthroscopic,” “rotator cuff,” “repair,” “retear,” “re-tear,” “defect,” “single-row,” “double-row,” “clinical outcomes,” and “functional outcomes” was conducted. Article inclusion criteria were an adequate description of the surgical technique, stratification of outcomes by intact rotator cuff versus retear with a minimum of 1 year of follow-up, and documentation of the presence/absence of a full-thickness retear using imaging. Exclusion criteria were isolated subscapularis tears/repairs, labral repairs, infections, postoperative fractures, insufficient data or statistical indications, and postoperative data not stratified by retear versus intact rotator cuff. A meta-analysis was performed using a random-effects model on variables that had comparisons from at least 3 studies. Single-row (SR) and double-row (DR) studies were analyzed both separately and together in an “all arthroscopic repairs” (AAR) comparison. The calculated effect was considered significant at a P value &lt;.05. Results: Within the SR group, patients with a rotator cuff retear had a significantly lower Constant score (mean difference [95% CI], −6.79 [–8.94 to −4.65]; P &lt; .001) and lower University of California, Los Angeles (UCLA) score (−3.21 [–5.27 to −1.15]; P = .002) but not higher pain (0.071 [–0.34 to 0.49]; P = .739). Within the DR group, patients with a rotator cuff retear had a significantly lower Constant score (mean difference [95% CI], −9.35 [–12.2 to −6.50]; P &lt; .001), lower American Shoulder and Elbow Surgeons (ASES) score (−12.1 [–17.1 to −7.26]; P &lt; .001), lower UCLA score (−3.07 [–4.85 to −1.29]; P &lt; .001), higher pain (0.622 [0.19 to 1.05]; P = .005), and lower abduction strength ( P &lt; .001). In the AAR comparison, patients with a retear had a significantly lower Constant score (mean difference [95% CI], −7.56 [–9.55 to −5.57]; P &lt; .001), lower ASES score (−10.1 [–15.5 to −4.64]; P &lt; .001), lower UCLA score (−3.00 [–4.47 to −1.53]; P &lt; .001), and lower abduction strength (in kg·f) (−3.32 [–4.53 to −2.12]; P &lt; .001) but not higher pain (0.332 [–0.014 to 0.680]; P = .060). Conclusion: Patients with a full-thickness rotator cuff retear exhibited significantly lower clinical outcome scores and strength compared with patients with an intact or partially torn rotator cuff.
PY  - 2017
DA  - 2017-03-01
JO  - {'id': 'https://openalex.org/S154904565', 'issn_l': '0363-5465', 'issn': ['1552-3365', '0363-5465'], 'display_name': 'American Journal of Sports Medicine', 'publisher': 'SAGE Publishing', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Jeffrey Yang
AU  - Matthew S. Robbins
AU  - Jordan Reilly
AU  - Tristan Maerz
AU  - Kyle R. Anderson
ER  - 

25.
TY  - journal-article
ID  - https://openalex.org/W2405537375
DO  - https://doi.org/10.3310/hsdr04160
TI  - Challenges, solutions and future directions in the evaluation of service innovations in health care and public health
AB  - Headline Evaluating service innovations in health care and public health requires flexibility, collaboration and pragmatism; this collection identifies robust, innovative and mixed methods to inform such evaluations. that a retear does not detrimentally affect outcomes. Purpose: To conduct a meta-analysis comparing clinical outcomes between intact and retorn rotator cuffs after arthroscopic repair. Study Design: Meta-analysis. Methods: A literature search using the terms “arthroscopic,” “rotator cuff,” “repair,” “retear,” “re-tear,” “defect,” “single-row,” “double-row,” “clinical outcomes,” and “functional outcomes” was conducted. Article inclusion criteria were an adequate description of the surgical technique, stratification of outcomes by intact rotator cuff versus retear with a minimum of 1 year of follow-up, and documentation of the presence/absence of a full-thickness retear using imaging. Exclusion criteria were isolated subscapularis tears/repairs, labral repairs, infections, postoperative fractures, insufficient data or statistical indications, and postoperative data not stratified by retear versus intact rotator cuff. A meta-analysis was performed using a random-effects model on variables that had comparisons from at least 3 studies. Single-row (SR) and double-row (DR) studies were analyzed both separately and together in an “all arthroscopic repairs” (AAR) comparison. The calculated effect was considered significant at a P value &lt;.05. Results: Within the SR group, patients with a rotator cuff retear had a significantly lower Constant score (mean difference [95% CI], −6.79 [–8.94 to −4.65]; P &lt; .001) and lower University of California, Los Angeles (UCLA) score (−3.21 [–5.27 to −1.15]; P = .002) but not higher pain (0.071 [–0.34 to 0.49]; P = .739). Within the DR group, patients with a rotator cuff retear had a significantly lower Constant score (mean difference [95% CI], −9.35 [–12.2 to −6.50]; P &lt; .001), lower American Shoulder and Elbow Surgeons (ASES) score (−12.1 [–17.1 to −7.26]; P &lt; .001), lower UCLA score (−3.07 [–4.85 to −1.29]; P &lt; .001), higher pain (0.622 [0.19 to 1.05]; P = .005), and lower abduction strength ( P &lt; .001). In the AAR comparison, patients with a retear had a significantly lower Constant score (mean difference [95% CI], −7.56 [–9.55 to −5.57]; P &lt; .001), lower ASES score (−10.1 [–15.5 to −4.64]; P &lt; .001), lower UCLA score (−3.00 [–4.47 to −1.53]; P &lt; .001), and lower abduction strength (in kg·f) (−3.32 [–4.53 to −2.12]; P &lt; .001) but not higher pain (0.332 [–0.014 to 0.680]; P = .060). Conclusion: Patients with a full-thickness rotator cuff retear exhibited significantly lower clinical outcome scores and strength compared with patients with an intact or partially torn rotator cuff.
PY  - 2016
DA  - 2016-05-01
JO  - {'id': 'https://openalex.org/S2764367346', 'issn_l': '2050-4349', 'issn': ['2050-4357', '2050-4349'], 'display_name': 'Health Services and Delivery Research', 'publisher': 'NIHR Journals Library', 'type': 'journal', 'url': 'https://njl-admin.nihr.ac.uk/document/download/2004136', 'is_oa': True, 'version': 'publishedVersion', 'license': 'publisher-specific license'}
DP  - OpenAlex
AU  - Rosalind Raine
AU  - Ray Fitzpatrick
AU  - Helen Barratt
AU  - Gywn Bevan
AU  - Nick Black
AU  - Ruth Boaden
AU  - Peter Bower
AU  - Marion K Campbell
AU  - Jean-Louis Denis
AU  - Kelly J. Devers
AU  - Mary Dixon-Woods
AU  - Lesley Fallowfield
AU  - Julien E. Forder
AU  - Robbie Foy
AU  - Nick Freemantle
AU  - Naomi Fulop
AU  - Elizabeth Gibbons
AU  - Clare L Gillies
AU  - Lucy Goulding
AU  - Richard Grieve
AU  - Jeremy M. Grimshaw
AU  - Emma Howarth
AU  - Richard J. Lilford
AU  - Ruth McDonald
AU  - Graham Moore
AU  - Laurence Moore
AU  - Robin P. Newhouse
AU  - Alicia O’Cathain
AU  - Zeynep Or
AU  - Chrysanthi Papoutsi
AU  - Stephanie L. Prady
AU  - Jo Rycroft-Malone
AU  - Jasjeet S. Sekhon
AU  - Simon Turner
AU  - Samuel I. Watson
AU  - Merrick Zwarenstein
ER  - 

26.
TY  - journal-article
ID  - https://openalex.org/W2910642642
DO  - https://doi.org/10.1186/s13643-019-0942-7
TI  - Machine learning algorithms for systematic review: reducing workload in a preclinical review of animal studies and reducing human screening error
AB  - Here, we outline a method of applying existing machine learning (ML) approaches to aid citation screening in an on-going broad and shallow systematic review of preclinical animal studies. The aim is to achieve a high-performing algorithm comparable to human screening that can reduce human resources required for carrying out this step of a systematic review.We applied ML approaches to a broad systematic review of animal models of depression at the citation screening stage. We tested two independently developed ML approaches which used different classification models and feature sets. We recorded the performance of the ML approaches on an unseen validation set of papers using sensitivity, specificity and accuracy. We aimed to achieve 95% sensitivity and to maximise specificity. The classification model providing the most accurate predictions was applied to the remaining unseen records in the dataset and will be used in the next stage of the preclinical biomedical sciences systematic review. We used a cross-validation technique to assign ML inclusion likelihood scores to the human screened records, to identify potential errors made during the human screening process (error analysis).ML approaches reached 98.7% sensitivity based on learning from a training set of 5749 records, with an inclusion prevalence of 13.2%. The highest level of specificity reached was 86%. Performance was assessed on an independent validation dataset. Human errors in the training and validation sets were successfully identified using the assigned inclusion likelihood from the ML model to highlight discrepancies. Training the ML algorithm on the corrected dataset improved the specificity of the algorithm without compromising sensitivity. Error analysis correction leads to a 3% improvement in sensitivity and specificity, which increases precision and accuracy of the ML algorithm.This work has confirmed the performance and application of ML algorithms for screening in systematic reviews of preclinical animal studies. It has highlighted the novel use of ML algorithms to identify human error. This needs to be confirmed in other reviews with different inclusion prevalence levels, but represents a promising approach to integrating human decisions and automation in systematic review methodology. to −5.57]; P &lt; .001), lower ASES score (−10.1 [–15.5 to −4.64]; P &lt; .001), lower UCLA score (−3.00 [–4.47 to −1.53]; P &lt; .001), and lower abduction strength (in kg·f) (−3.32 [–4.53 to −2.12]; P &lt; .001) but not higher pain (0.332 [–0.014 to 0.680]; P = .060). Conclusion: Patients with a full-thickness rotator cuff retear exhibited significantly lower clinical outcome scores and strength compared with patients with an intact or partially torn rotator cuff.
PY  - 2019
DA  - 2019-01-15
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://systematicreviewsjournal.biomedcentral.com/track/pdf/10.1186/s13643-019-0942-7', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Alexandra Bannach-Brown
AU  - Piotr Przybyła
AU  - James D. Thomas
AU  - Andrew S.C. Rice
AU  - Sophia Ananiadou
AU  - Jing Liao
AU  - Malcolm R. Macleod
ER  - 

27.
TY  - journal-article
ID  - https://openalex.org/W2911904818
DO  - https://doi.org/10.1136/bmjgh-2018-001178
TI  - Using rapid reviews to strengthen health policy and systems and progress towards universal health coverage
AB  - ### Summary box

As many countries are developing policies addressing universal health coverage (UHC) and the Sustainable Development Goals, there is increasing demand for relevant and contextualised evidence to inform health policy and systems decision-making.1 Policy-makers and health systems managers require valid evidence to support time-sensitive decisions regarding the coverage, quality, efficiency and equity of health systems. There are several health system challenges for which decision-makers require timely evidence, including integrated service delivery models, effective health financing schemes and equitable access to quality health systems interventions (table 1). Progressing towards UHC requires evidence to address a range of questions including the effectiveness of health systems interventions and policies, how and in what settings these interventions work, their cost-effectiveness, as well as the legal, ethical and societal implications of implementing these interventions.2 3

View this table:

Table 1 
Examples of health … be used in the next stage of the preclinical biomedical sciences systematic review. We used a cross-validation technique to assign ML inclusion likelihood scores to the human screened records, to identify potential errors made during the human screening process (error analysis).ML approaches reached 98.7% sensitivity based on learning from a training set of 5749 records, with an inclusion prevalence of 13.2%. The highest level of specificity reached was 86%. Performance was assessed on an independent validation dataset. Human errors in the training and validation sets were successfully identified using the assigned inclusion likelihood from the ML model to highlight discrepancies. Training the ML algorithm on the corrected dataset improved the specificity of the algorithm without compromising sensitivity. Error analysis correction leads to a 3% improvement in sensitivity and specificity, which increases precision and accuracy of the ML algorithm.This work has confirmed the performance and application of ML algorithms for screening in systematic reviews of preclinical animal studies. It has highlighted the novel use of ML algorithms to identify human error. This needs to be confirmed in other reviews with different inclusion prevalence levels, but represents a promising approach to integrating human decisions and automation in systematic review methodology. to −5.57]; P &lt; .001), lower ASES score (−10.1 [–15.5 to −4.64]; P &lt; .001), lower UCLA score (−3.00 [–4.47 to −1.53]; P &lt; .001), and lower abduction strength (in kg·f) (−3.32 [–4.53 to −2.12]; P &lt; .001) but not higher pain (0.332 [–0.014 to 0.680]; P = .060). Conclusion: Patients with a full-thickness rotator cuff retear exhibited significantly lower clinical outcome scores and strength compared with patients with an intact or partially torn rotator cuff.
PY  - 2019
DA  - 2019-02-01
JO  - {'id': 'https://openalex.org/V2764928273', 'issn_l': '2059-7908', 'issn': ['2059-7908'], 'display_name': 'BMJ Global Health', 'publisher': 'BMJ', 'type': 'journal', 'url': 'https://gh.bmj.com/content/bmjgh/4/1/e001178.full.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc'}
DP  - OpenAlex
AU  - Etienne V. Langlois
AU  - Sharon E. Straus
AU  - Jesmin Antony
AU  - Valerie King
AU  - Andrea C. Tricco
ER  - 

28.
TY  - journal-article
ID  - https://openalex.org/W2612847450
DO  - https://doi.org/10.1007/s00204-017-1980-3
TI  - A primer on systematic reviews in toxicology
AB  - Systematic reviews, pioneered in the clinical field, provide a transparent, methodologically rigorous and reproducible means of summarizing the available evidence on a precisely framed research question. Having matured to a well-established approach in many research fields, systematic reviews are receiving increasing attention as a potential tool for answering toxicological questions. In the larger framework of evidence-based toxicology, the advantages and obstacles of, as well as the approaches for, adapting and adopting systematic reviews to toxicology are still being explored. To provide the toxicology community with a starting point for conducting or understanding systematic reviews, we herein summarized available guidance documents from various fields of application. We have elaborated on the systematic review process by breaking it down into ten steps, starting with planning the project, framing the question, and writing and publishing the protocol, and concluding with interpretation and reporting. In addition, we have identified the specific methodological challenges of toxicological questions and have summarized how these can be addressed. Ultimately, this primer is intended to stimulate scientific discussions of the identified issues to fuel the development of toxicology-specific methodology and to encourage the application of systematic review methodology to toxicological issues. records, with an inclusion prevalence of 13.2%. The highest level of specificity reached was 86%. Performance was assessed on an independent validation dataset. Human errors in the training and validation sets were successfully identified using the assigned inclusion likelihood from the ML model to highlight discrepancies. Training the ML algorithm on the corrected dataset improved the specificity of the algorithm without compromising sensitivity. Error analysis correction leads to a 3% improvement in sensitivity and specificity, which increases precision and accuracy of the ML algorithm.This work has confirmed the performance and application of ML algorithms for screening in systematic reviews of preclinical animal studies. It has highlighted the novel use of ML algorithms to identify human error. This needs to be confirmed in other reviews with different inclusion prevalence levels, but represents a promising approach to integrating human decisions and automation in systematic review methodology. to −5.57]; P &lt; .001), lower ASES score (−10.1 [–15.5 to −4.64]; P &lt; .001), lower UCLA score (−3.00 [–4.47 to −1.53]; P &lt; .001), and lower abduction strength (in kg·f) (−3.32 [–4.53 to −2.12]; P &lt; .001) but not higher pain (0.332 [–0.014 to 0.680]; P = .060). Conclusion: Patients with a full-thickness rotator cuff retear exhibited significantly lower clinical outcome scores and strength compared with patients with an intact or partially torn rotator cuff.
PY  - 2017
DA  - 2017-05-13
JO  - {'id': 'https://openalex.org/V87018847', 'issn_l': '0340-5761', 'issn': ['0003-9446', '0340-5761', '1432-0738'], 'display_name': 'Archives of Toxicology', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Sebastian Hoffmann
AU  - Rob B. M. de Vries
AU  - Martin L. Stephens
AU  - Nancy B. Beck
AU  - Hubert Dirven
AU  - John R. Fowle
AU  - Julie E. Goodman
AU  - Thomas Hartung
AU  - Ian Kimber
AU  - Manoj M. Lalu
AU  - Kristina A. Thayer
AU  - Paul Whaley
AU  - Daniele Wikoff
AU  - Katya Tsaioun
ER  - 

29.
TY  - journal-article
ID  - https://openalex.org/W3111412136
DO  - https://doi.org/10.1093/bib/bbaa296
TI  - Text mining approaches for dealing with the rapidly expanding literature on COVID-19
AB  - Abstract More than 50 000 papers have been published about COVID-19 since the beginning of 2020 and several hundred new papers continue to be published every day. This incredible rate of scientific productivity leads to information overload, making it difficult for researchers, clinicians and public health officials to keep up with the latest findings. Automated text mining techniques for searching, reading and summarizing papers are helpful for addressing information overload. In this review, we describe the many resources that have been introduced to support text mining applications over the COVID-19 literature; specifically, we discuss the corpora, modeling resources, systems and shared tasks that have been introduced for COVID-19. We compile a list of 39 systems that provide functionality such as search, discovery, visualization and summarization over the COVID-19 literature. For each system, we provide a qualitative description and assessment of the system’s performance, unique data or user interface features and modeling decisions. Many systems focus on search and discovery, though several systems provide novel features, such as the ability to summarize findings over multiple documents or linking between scientific articles and clinical trials. We also describe the public corpora, models and shared tasks that have been introduced to help reduce repeated effort among community members; some of these resources (especially shared tasks) can provide a basis for comparing the performance of different systems. Finally, we summarize promising results and open challenges for text mining the COVID-19 literature. discrepancies. Training the ML algorithm on the corrected dataset improved the specificity of the algorithm without compromising sensitivity. Error analysis correction leads to a 3% improvement in sensitivity and specificity, which increases precision and accuracy of the ML algorithm.This work has confirmed the performance and application of ML algorithms for screening in systematic reviews of preclinical animal studies. It has highlighted the novel use of ML algorithms to identify human error. This needs to be confirmed in other reviews with different inclusion prevalence levels, but represents a promising approach to integrating human decisions and automation in systematic review methodology. to −5.57]; P &lt; .001), lower ASES score (−10.1 [–15.5 to −4.64]; P &lt; .001), lower UCLA score (−3.00 [–4.47 to −1.53]; P &lt; .001), and lower abduction strength (in kg·f) (−3.32 [–4.53 to −2.12]; P &lt; .001) but not higher pain (0.332 [–0.014 to 0.680]; P = .060). Conclusion: Patients with a full-thickness rotator cuff retear exhibited significantly lower clinical outcome scores and strength compared with patients with an intact or partially torn rotator cuff.
PY  - 2021
DA  - 2021-03-22
JO  - {'id': 'https://openalex.org/S91767247', 'issn_l': '1467-5463', 'issn': ['1467-5463', '1477-4054'], 'display_name': 'Briefings in Bioinformatics', 'publisher': 'Oxford University Press', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Lucy Lu Wang
AU  - Kyle Lo
ER  - 

30.
TY  - journal-article
ID  - https://openalex.org/W2809387633
DO  - https://doi.org/10.1371/journal.pone.0199041
TI  - The anxiolytic effect of probiotics: A systematic review and meta-analysis of the clinical and preclinical literature
AB  - Probiotics have generated intensive research interest in recent years as a novel mode of treatment for physical and mental illness. Nevertheless, the anxiolytic potential of probiotics remains unclear. The present systematic review and meta-analysis aimed to evaluate the clinical and preclinical (animal model) evidence regarding the effect of probiotic administration on anxiety.The PubMed, PsycINFO, and Web of Science databases were reviewed for preclinical and clinical studies that met the defined inclusion and exclusion criteria. The effects of probiotics on anxiety-like behavior and symptoms of anxiety were analyzed by meta-analyses. Separate subgroup analyses were conducted on diseased versus healthy animals, specific preclinical probiotic species, and clinical versus healthy human samples.Data were extracted from 22 preclinical studies (743 animals) and 14 clinical studies (1527 individuals). Overall, probiotics reduced anxiety-like behavior in animals (Hedges' g = -0.47, 95% CI -0.77 --0.16, p = 0.004). Subgroup analyses revealed a significant reduction only among diseased animals. Probiotic species-level analyses identified only Lactobacillus (L.) rhamnosus as an anxiolytic species, but these analyses were broadly under-powered. Probiotics did not significantly reduce symptoms of anxiety in humans (Hedges' g = -0.12, 95% CI -0.29-0.05, p = 0.151), and did not differentially affect clinical and healthy human samples.While preclinical (animal) studies suggest that probiotics may help reduce anxiety, such findings have not yet translated to clinical research in humans, perhaps due to the dearth of extant research with clinically anxious populations. Further investigation of probiotic treatment for clinically relevant anxiety is warranted, particularly with respect to the probiotic species L. rhamnosus. without compromising sensitivity. Error analysis correction leads to a 3% improvement in sensitivity and specificity, which increases precision and accuracy of the ML algorithm.This work has confirmed the performance and application of ML algorithms for screening in systematic reviews of preclinical animal studies. It has highlighted the novel use of ML algorithms to identify human error. This needs to be confirmed in other reviews with different inclusion prevalence levels, but represents a promising approach to integrating human decisions and automation in systematic review methodology. to −5.57]; P &lt; .001), lower ASES score (−10.1 [–15.5 to −4.64]; P &lt; .001), lower UCLA score (−3.00 [–4.47 to −1.53]; P &lt; .001), and lower abduction strength (in kg·f) (−3.32 [–4.53 to −2.12]; P &lt; .001) but not higher pain (0.332 [–0.014 to 0.680]; P = .060). Conclusion: Patients with a full-thickness rotator cuff retear exhibited significantly lower clinical outcome scores and strength compared with patients with an intact or partially torn rotator cuff.
PY  - 2018
DA  - 2018-06-20
JO  - {'id': 'https://openalex.org/S202381698', 'issn_l': '1932-6203', 'issn': ['1932-6203'], 'display_name': 'PLOS ONE', 'publisher': 'Public Library of Science', 'type': 'journal', 'url': 'https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0199041&type=printable', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Daniel G. Reis
AU  - Stephen S. Ilardi
AU  - Stephanie E. W. Punt
ER  - 

31.
TY  - journal-article
ID  - https://openalex.org/W2754091488
DO  - https://doi.org/10.1136/bmjsem-2017-000261
TI  - The anticipatory stress response to sport competition; a systematic review with meta-analysis of cortisol reactivity
AB  - Athletes anticipating sport competition regularly experience distinct emotional and physiological responses as a result of the expected psychosocial and physical stress. Specifically, cortisol, an indicator of hypothalamic-pituitary-adrenal axis activation, prepares the athlete for the psychological and physiological demands of competition. The objective of this meta-analysis is to analyse the magnitude of the anticipatory cortisol response in athletes preparing to participate in sport competition and to examine the influence of gender, level of competition and data collection time.Systematic review with meta-analysis.Four electronic databases were searched to March 2017: PubMed, PsycINFO, SPORTDiscus and Scopus.(1) Athletes participating in real sport competition;(2) salivary cortisol concentration collected before competition in addition to baseline sample(s);(3) original research article published in English language.Data from 25 studies provided 27 effect sizes. A significant anticipatory cortisol response of g=0.85, p<0.001 was identified. Males had a stronger trend for greater cortisol reactivity (g=1.07) than females (g=0.56, p=0.07). Females and athletes competing at international level did not demonstrate a significant anticipatory stress response. There were no significant differences between level of competition, type of sport or time of competition. Meta-regression indicated that the anticipatory cortisol response is greater when assessed closer to the start of competition (Q=6.85, p=0.009).The anticipatory cortisol response before sport competition reflects moderate cortisol reactivity that prepares athletes optimally for the demands of sport competition via the influence on cognitive processes and attentional control. However, both female athletes and international competitors did not demonstrate a significant anticipatory cortisol response, possibly due to differences in appraisal of the stress of sport competition. compromising sensitivity. Error analysis correction leads to a 3% improvement in sensitivity and specificity, which increases precision and accuracy of the ML algorithm.This work has confirmed the performance and application of ML algorithms for screening in systematic reviews of preclinical animal studies. It has highlighted the novel use of ML algorithms to identify human error. This needs to be confirmed in other reviews with different inclusion prevalence levels, but represents a promising approach to integrating human decisions and automation in systematic review methodology. to −5.57]; P &lt; .001), lower ASES score (−10.1 [–15.5 to −4.64]; P &lt; .001), lower UCLA score (−3.00 [–4.47 to −1.53]; P &lt; .001), and lower abduction strength (in kg·f) (−3.32 [–4.53 to −2.12]; P &lt; .001) but not higher pain (0.332 [–0.014 to 0.680]; P = .060). Conclusion: Patients with a full-thickness rotator cuff retear exhibited significantly lower clinical outcome scores and strength compared with patients with an intact or partially torn rotator cuff.
PY  - 2017
DA  - 2017-09-01
JO  - {'id': 'https://openalex.org/S2764939095', 'issn_l': '2055-7647', 'issn': ['2055-7647'], 'display_name': 'BMJ open sport and exercise medicine', 'publisher': 'BMJ', 'type': 'journal', 'url': 'https://bmjopensem.bmj.com/content/bmjosem/3/1/e000261.full.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc'}
DP  - OpenAlex
AU  - Kjell N. van Paridon
AU  - Matthew A. Timmis
AU  - Charlotte M. Nevison
AU  - Matt Bristow
ER  - 

32.
TY  - journal-article
ID  - https://openalex.org/W2790821231
DO  - https://doi.org/10.1093/nutrit/nux074
TI  - An analysis of methods used to synthesize evidence and grade recommendations in food-based dietary guidelines
AB  - Evidence-informed guideline development methods underpinned by systematic reviews ensure that guidelines are transparently developed, free from overt bias, and based on the best available evidence. Only recently has the nutrition field begun using these methods to develop public health nutrition guidelines. Given the importance of following an evidence-informed approach and recent advances in related methods, this study sought to describe the methods used to synthesize evidence, rate evidence quality, grade recommendations, and manage conflicts of interest (COIs) in national food-based dietary guidelines (FBDGs). The Food and Agriculture Organization's FBDGs database was searched to identify the latest versions of FBDGs published from 2010 onward. Relevant data from 32 FBDGs were extracted, and the findings are presented narratively. This study shows that despite advances in evidence-informed methods for developing dietary guidelines, there are variations and deficiencies in methods used to review evidence, rate evidence quality, and grade recommendations. Dietary guidelines should follow systematic and transparent methods and be informed by the best available evidence, while considering important contextual factors and managing conflicts of interest. of sport or time of competition. Meta-regression indicated that the anticipatory cortisol response is greater when assessed closer to the start of competition (Q=6.85, p=0.009).The anticipatory cortisol response before sport competition reflects moderate cortisol reactivity that prepares athletes optimally for the demands of sport competition via the influence on cognitive processes and attentional control. However, both female athletes and international competitors did not demonstrate a significant anticipatory cortisol response, possibly due to differences in appraisal of the stress of sport competition. compromising sensitivity. Error analysis correction leads to a 3% improvement in sensitivity and specificity, which increases precision and accuracy of the ML algorithm.This work has confirmed the performance and application of ML algorithms for screening in systematic reviews of preclinical animal studies. It has highlighted the novel use of ML algorithms to identify human error. This needs to be confirmed in other reviews with different inclusion prevalence levels, but represents a promising approach to integrating human decisions and automation in systematic review methodology. to −5.57]; P &lt; .001), lower ASES score (−10.1 [–15.5 to −4.64]; P &lt; .001), lower UCLA score (−3.00 [–4.47 to −1.53]; P &lt; .001), and lower abduction strength (in kg·f) (−3.32 [–4.53 to −2.12]; P &lt; .001) but not higher pain (0.332 [–0.014 to 0.680]; P = .060). Conclusion: Patients with a full-thickness rotator cuff retear exhibited significantly lower clinical outcome scores and strength compared with patients with an intact or partially torn rotator cuff.
PY  - 2018
DA  - 2018-04-01
JO  - {'id': 'https://openalex.org/S38078933', 'issn_l': '0029-6643', 'issn': ['1753-4887', '0029-6643'], 'display_name': 'Nutrition Reviews', 'publisher': 'Oxford University Press', 'type': 'journal', 'url': 'https://academic.oup.com/nutritionreviews/article-pdf/76/4/290/25091789/nux074.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc-nd'}
DP  - OpenAlex
AU  - Phillipa Blake
AU  - Solange Durao
AU  - Celeste E Naude
AU  - Lisa Bero
ER  - 

33.
TY  - journal-article
ID  - https://openalex.org/W2180291732
DO  - https://doi.org/10.1186/s13643-015-0147-7
TI  - How to conduct systematic reviews more expeditiously?
AB  - Healthcare consumers, researchers, patients and policy makers increasingly use systematic reviews (SRs) to aid their decision-making process. However, the conduct of SRs can be a time-consuming and resource-intensive task. Often, clinical practice guideline developers or other decision-makers need to make informed decisions in a timely fashion (e.g. outbreaks of infection, hospital-based health technology assessments). Possible approaches to address the issue of timeliness in the production of SRs are to (a) implement process parallelisation, (b) adapt and apply innovative technologies, and/or (c) modify SR processes (e.g. study eligibility criteria, search sources, data extraction or quality assessment). Highly parallelised systematic reviewing requires substantial resources to support a team of experienced information specialists, reviewers and methodologists working alongside with clinical content experts to minimise the time for completing individual review steps while maximising the parallel progression of multiple steps. Effective coordination and management within the team and across external stakeholders are essential elements of this process. Emerging innovative technologies have a great potential for reducing workload and improving efficiency of SR production. The most promising areas of application would be to allow automation of specific SR tasks, in particular if these tasks are time consuming and resource intensive (e.g. language translation, study selection, data extraction). Modification of SR processes involves restricting, truncating and/or bypassing one or more SR steps, which may risk introducing bias to the review findings. Although the growing experiences in producing various types of rapid reviews (RR) and the accumulation of empirical studies exploring potential bias associated with specific SR tasks have contributed to the methodological development for expediting SR production, there is still a dearth of research examining the actual impact of methodological modifications and comparing the findings between RRs and SRs. This evidence would help to inform as to which SR tasks can be accelerated or truncated and to what degree, while maintaining the validity of review findings. Timely delivered SRs can be of value in informing healthcare decisions and recommendations, especially when there is practical urgency and there is no other relevant synthesised evidence. −5.57]; P &lt; .001), lower ASES score (−10.1 [–15.5 to −4.64]; P &lt; .001), lower UCLA score (−3.00 [–4.47 to −1.53]; P &lt; .001), and lower abduction strength (in kg·f) (−3.32 [–4.53 to −2.12]; P &lt; .001) but not higher pain (0.332 [–0.014 to 0.680]; P = .060). Conclusion: Patients with a full-thickness rotator cuff retear exhibited significantly lower clinical outcome scores and strength compared with patients with an intact or partially torn rotator cuff.
PY  - 2015
DA  - 2015-11-12
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://doi.org/10.1186/s13643-015-0147-7', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Alexander Tsertsvadze
AU  - Yen-Fu Chen
AU  - David Moher
AU  - Paul Sutcliffe
AU  - Noel D. McCarthy
ER  - 

34.
TY  - journal-article
ID  - https://openalex.org/W2883671141
DO  - https://doi.org/10.1016/j.ipm.2018.07.003
TI  - Information retrieval in the workplace: A comparison of professional search practices
AB  - Legal researchers, recruitment professionals, healthcare information professionals, and patent analysts all undertake work tasks where search forms a core part of their duties. In these instances, the search task is often complex and time-consuming and requires specialist expertise to identify relevant documents and insights within large domain-specific repositories and collections. Several studies have been made investigating the search practices of professionals such as these, but few have attempted to directly compare their professional practices and so it remains unclear to what extent insights and approaches from one domain can be applied to another. In this paper we describe the results of a survey of a purposive sample of 108 legal researchers, 64 recruitment professionals and 107 healthcare information professionals. Their responses are compared with results from a previous survey of 81 patent analysts. The survey investigated their search practices and preferences, the types of functionality they value, and their requirements for future information retrieval systems. The results reveal that these professions share many fundamental needs and face similar challenges. In particular a continuing preference to formulate queries as Boolean expressions, the need to manage, organise and re-use search strategies and results and an ambivalence toward the use of relevance ranking. The results stress the importance of recall and coverage for the healthcare and patent professionals, while precision and recency were more important to the legal and recruitment professionals. The results also highlight the need to ensure that search systems give confidence to the professional searcher and so trust, explainability and accountability remains a significant challenge when developing such systems. The findings suggest that translational research between the different areas could benefit professionals across domains. modifications and comparing the findings between RRs and SRs. This evidence would help to inform as to which SR tasks can be accelerated or truncated and to what degree, while maintaining the validity of review findings. Timely delivered SRs can be of value in informing healthcare decisions and recommendations, especially when there is practical urgency and there is no other relevant synthesised evidence. −5.57]; P &lt; .001), lower ASES score (−10.1 [–15.5 to −4.64]; P &lt; .001), lower UCLA score (−3.00 [–4.47 to −1.53]; P &lt; .001), and lower abduction strength (in kg·f) (−3.32 [–4.53 to −2.12]; P &lt; .001) but not higher pain (0.332 [–0.014 to 0.680]; P = .060). Conclusion: Patients with a full-thickness rotator cuff retear exhibited significantly lower clinical outcome scores and strength compared with patients with an intact or partially torn rotator cuff.
PY  - 2018
DA  - 2018-11-01
JO  - {'id': 'https://openalex.org/S174847851', 'issn_l': '0306-4573', 'issn': ['0306-4573', '1873-5371'], 'display_name': 'Information Processing and Management', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Tony Russell-Rose
AU  - Jon Chamberlain
AU  - Leif Azzopardi
ER  - 

35.
TY  - journal-article
ID  - https://openalex.org/W2953029151
DO  - https://doi.org/10.1186/s13643-019-1062-0
TI  - A question of trust: can we build an evidence base to gain trust in systematic review automation technologies?
AB  - Although many aspects of systematic reviews use computational tools, systematic reviewers have been reluctant to adopt machine learning tools. We discuss that the potential reason for the slow adoption of machine learning tools into systematic reviews is multifactorial. We focus on the current absence of trust in automation and set-up challenges as major barriers to adoption. It is important that reviews produced using automation tools are considered non-inferior or superior to current practice. However, this standard will likely not be sufficient to lead to widespread adoption. As with many technologies, it is important that reviewers see “others” in the review community using automation tools. Adoption will also be slow if the automation tools are not compatible with workflows and tasks currently used to produce reviews. Many automation tools being developed for systematic reviews mimic classification problems. Therefore, the evidence that these automation tools are non-inferior or superior can be presented using methods similar to diagnostic test evaluations, i.e., precision and recall compared to a human reviewer. However, the assessment of automation tools does present unique challenges for investigators and systematic reviewers, including the need to clarify which metrics are of interest to the systematic review community and the unique documentation challenges for reproducible software experiments. We discuss adoption barriers with the goal of providing tool developers with guidance as to how to design and report such evaluations and for end users to assess their validity. Further, we discuss approaches to formatting and announcing publicly available datasets suitable for assessment of automation technologies and tools. Making these resources available will increase trust that tools are non-inferior or superior to current practice. Finally, we identify that, even with evidence that automation tools are non-inferior or superior to current practice, substantial set-up challenges remain for main stream integration of automation into the systematic review process. degree, while maintaining the validity of review findings. Timely delivered SRs can be of value in informing healthcare decisions and recommendations, especially when there is practical urgency and there is no other relevant synthesised evidence. −5.57]; P &lt; .001), lower ASES score (−10.1 [–15.5 to −4.64]; P &lt; .001), lower UCLA score (−3.00 [–4.47 to −1.53]; P &lt; .001), and lower abduction strength (in kg·f) (−3.32 [–4.53 to −2.12]; P &lt; .001) but not higher pain (0.332 [–0.014 to 0.680]; P = .060). Conclusion: Patients with a full-thickness rotator cuff retear exhibited significantly lower clinical outcome scores and strength compared with patients with an intact or partially torn rotator cuff.
PY  - 2019
DA  - 2019-06-18
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://doi.org/10.1186/s13643-019-1062-0', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Annette M. O'Connor
AU  - Guy Tsafnat
AU  - James D. Thomas
AU  - Paul Glasziou
AU  - Stephen B. Gilbert
AU  - Brian Hutton
ER  - 

36.
TY  - journal-article
ID  - https://openalex.org/W3010940523
DO  - https://doi.org/10.1016/j.envint.2020.105623
TI  - SWIFT-Active Screener: Accelerated document screening through active learning and integrated recall estimation
AB  - In the screening phase of systematic review, researchers use detailed inclusion/exclusion criteria to decide whether each article in a set of candidate articles is relevant to the research question under consideration. A typical review may require screening thousands or tens of thousands of articles in and can utilize hundreds of person-hours of labor.Here we introduce SWIFT-Active Screener, a web-based, collaborative systematic review software application, designed to reduce the overall screening burden required during this resource-intensive phase of the review process. To prioritize articles for review, SWIFT-Active Screener uses active learning, a type of machine learning that incorporates user feedback during screening. Meanwhile, a negative binomial model is employed to estimate the number of relevant articles remaining in the unscreened document list. Using a simulation involving 26 diverse systematic review datasets that were previously screened by reviewers, we evaluated both the document prioritization and recall estimation methods.On average, 95% of the relevant articles were identified after screening only 40% of the total reference list. In the 5 document sets with 5,000 or more references, 95% recall was achieved after screening only 34% of the available references, on average. Furthermore, the recall estimator we have proposed provides a useful, conservative estimate of the percentage of relevant documents identified during the screening process.SWIFT-Active Screener can result in significant time savings compared to traditional screening and the savings are increased for larger project sizes. Moreover, the integration of explicit recall estimation during screening solves an important challenge faced by all machine learning systems for document screening: when to stop screening a prioritized reference list. The software is currently available in the form of a multi-user, collaborative, online web application. with evidence that automation tools are non-inferior or superior to current practice, substantial set-up challenges remain for main stream integration of automation into the systematic review process. degree, while maintaining the validity of review findings. Timely delivered SRs can be of value in informing healthcare decisions and recommendations, especially when there is practical urgency and there is no other relevant synthesised evidence. −5.57]; P &lt; .001), lower ASES score (−10.1 [–15.5 to −4.64]; P &lt; .001), lower UCLA score (−3.00 [–4.47 to −1.53]; P &lt; .001), and lower abduction strength (in kg·f) (−3.32 [–4.53 to −2.12]; P &lt; .001) but not higher pain (0.332 [–0.014 to 0.680]; P = .060). Conclusion: Patients with a full-thickness rotator cuff retear exhibited significantly lower clinical outcome scores and strength compared with patients with an intact or partially torn rotator cuff.
PY  - 2020
DA  - 2020-03-20
JO  - {'id': 'https://openalex.org/S143381477', 'issn_l': '0160-4120', 'issn': ['0160-4120', '1873-6750'], 'display_name': 'Environment International', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'https://doi.org/10.1016/j.envint.2020.105623', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc-nd'}
DP  - OpenAlex
AU  - Brian M. Howard
AU  - Jason J. Phillips
AU  - Arpit Tandon
AU  - Adyasha Maharana
AU  - Rebecca C. Elmore
AU  - Deepak Mav
AU  - Alex Sedykh
AU  - Kristina A. Thayer
AU  - B. Alex Merrick
AU  - Vickie R. Walker
AU  - Andrew A. Rooney
AU  - Ruchir R. Shah
ER  - 

37.
TY  - journal-article
ID  - https://openalex.org/W2990632815
DO  - https://doi.org/10.3389/fpsyg.2019.02616
TI  - Effects and Moderators of Acute Aerobic Exercise on Subsequent Interference Control: A Systematic Review and Meta-Analysis
AB  - Background: Acute aerobic exercise leads to positive physiological adaptations within the central nervous system. These findings inspired research on potential cognitive benefits following acute aerobic exercise. The effects of acute aerobic exercise on subsequent cognitive performance, by far, have been the most researched for interference control, a subcomponent of executive function. The results of primary studies on the effects of acute aerobic exercise on subsequent interference control performance are inconsistent. Therefore, we used meta-analytic methods to pool available effect sizes, and to identify covariates that determine the magnitude of exercise-induced interference control benefits. Methods: Medline, PsycINFO, and SPORTDiscus were searched for eligible records. Hedges' g corrected standardized mean difference values (SMDs) were used for analyses. Random-effects weights were used to pool effect sizes. Moderator analyses were conducted using meta-regressions and subgroups analyses. Covariates that were here tested for moderation included parameters of the applied exercise regimen (exercise intensity and exercise duration), characteristics of examined participants (age and fitness), and methodological features of existing research (type of control group, familiarization with test procedure, type of test variable, delay between exercise cessation, and testing). Results: Fifty studies, with data from 2,366 participants, were included in qualitative and quantitative synthesis. A small, significant beneficial effect of acute aerobic exercise on time-dependent measures of interference control was revealed (k = 49, Hedges' g = -0.26, 95%CI: -34 to -0.18). Effect sizes from time-dependent measures of interference control varied widely and heterogeneity reached statistical significance (T2 = 0.0557, I2 = 28.8%). Moderator analyses revealed that higher exercise intensities (vigorous intensity and high-intensity interval training), also participants at younger or older age, and participants who are familiar with the testing procedure prior to the experiment, benefitted most from acute aerobic exercise. However, noticeable heterogeneity remained unexplained within specific subgroups (high-intensity interval training, preadolescent children, and active and supervised control group). Conclusion: Acute aerobic exercise improves subsequent interference control performance. However, the covariates exercise intensity, participants' age, and familiarization with testing procedure determine the magnitude of that effect. Methodological features were not found to influence the magnitude of effects. This dismisses some doubts that exercise induced benefits for interference control performance are scientific artifacts. The fact that large heterogeneity remained unexplained in some subgroups indicates the need for further research on covariates within these subgroups. It should be noted that effect sizes for all analyses were small. rotator cuff retear exhibited significantly lower clinical outcome scores and strength compared with patients with an intact or partially torn rotator cuff.
PY  - 2019
DA  - 2019-11-21
JO  - {'id': 'https://openalex.org/S9692511', 'issn_l': '1664-1078', 'issn': ['1664-1078'], 'display_name': 'Frontiers in Psychology', 'publisher': 'Frontiers Media', 'type': 'journal', 'url': 'https://www.frontiersin.org/articles/10.3389/fpsyg.2019.02616/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Max Oberste
AU  - Florian Javelle
AU  - Sophia Sharma
AU  - Niklas Joisten
AU  - David Walzik
AU  - Wilhelm Bloch
AU  - Philipp Zimmer
ER  - 

38.
TY  - journal-article
ID  - https://openalex.org/W2544262221
DO  - https://doi.org/10.1186/s13643-016-0360-z
TI  - Cochrane Rapid Reviews Methods Group to play a leading role in guiding the production of informed high-quality, timely research evidence syntheses
AB  - Policymakers and healthcare stakeholders are increasingly seeking evidence to inform the policymaking process, and often use existing or commissioned systematic reviews to inform decisions. However, the methodologies that make systematic reviews authoritative take time, typically 1 to 2 years to complete. Outside the traditional SR timeline, "rapid reviews" have emerged as an efficient tool to get evidence to decision-makers more quickly. However, the use of rapid reviews does present challenges. To date, there has been limited published empirical information about this approach to compiling evidence. Thus, it remains a poorly understood and ill-defined set of diverse methodologies with various labels. In recent years, the need to further explore rapid review methods, characteristics, and their use has been recognized by a growing network of healthcare researchers, policymakers, and organizations, several with ties to Cochrane, which is recognized as representing an international gold standard for high-quality, systematic reviews.In this commentary, we introduce the newly established Cochrane Rapid Reviews Methods Group developed to play a leading role in guiding the production of rapid reviews given they are increasingly employed as a research synthesis tool to support timely evidence-informed decision-making. We discuss how the group was formed and outline the group's structure and remit. We also discuss the need to establish a more robust evidence base for rapid reviews in the published literature, and the importance of promoting registration of rapid review protocols in an effort to promote efficiency and transparency in research.As with standard systematic reviews, the core principles of evidence-based synthesis should apply to rapid reviews in order to minimize bias to the extent possible. The Cochrane Rapid Reviews Methods Group will serve to establish a network of rapid review stakeholders and provide a forum for discussion and training. By facilitating exchange, the group will strive to conduct research to advance the methods of rapid reviews. Conclusion: Acute aerobic exercise improves subsequent interference control performance. However, the covariates exercise intensity, participants' age, and familiarization with testing procedure determine the magnitude of that effect. Methodological features were not found to influence the magnitude of effects. This dismisses some doubts that exercise induced benefits for interference control performance are scientific artifacts. The fact that large heterogeneity remained unexplained in some subgroups indicates the need for further research on covariates within these subgroups. It should be noted that effect sizes for all analyses were small. rotator cuff retear exhibited significantly lower clinical outcome scores and strength compared with patients with an intact or partially torn rotator cuff.
PY  - 2016
DA  - 2016-10-28
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://systematicreviewsjournal.biomedcentral.com/track/pdf/10.1186/s13643-016-0360-z', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Chantelle Garritty
AU  - Adrienne Stevens
AU  - Gerald Gartlehner
AU  - Valerie King
AU  - Chris Kamel
ER  - 

39.
TY  - journal-article
ID  - https://openalex.org/W3149778443
DO  - https://doi.org/10.1016/j.infsof.2021.106589
TI  - Automation of systematic literature reviews: A systematic literature review
AB  - Systematic Literature Review (SLR) studies aim to identify relevant primary papers, extract the required data, analyze, and synthesize results to gain further and broader insight into the investigated domain. Multiple SLR studies have been conducted in several domains, such as software engineering, medicine, and pharmacy. Conducting an SLR is a time-consuming, laborious, and costly effort. As such, several researchers developed different techniques to automate the SLR process. However, a systematic overview of the current state-of-the-art in SLR automation seems to be lacking. This study aims to collect and synthesize the studies that focus on the automation of SLR to pave the way for further research. A systematic literature review is conducted on published primary studies on the automation of SLR studies, in which 41 primary studies have been analyzed. This SLR identifies the objectives of automation studies, application domains, automated steps of the SLR, automation techniques, and challenges and solution directions. According to our study, the leading automated step is the Selection of Primary Studies . Although many studies have provided automation approaches for systematic literature reviews, no study has been found to apply automation techniques in the planning and reporting phase. Further research is needed to support the automation of the other activities of the SLR process. more robust evidence base for rapid reviews in the published literature, and the importance of promoting registration of rapid review protocols in an effort to promote efficiency and transparency in research.As with standard systematic reviews, the core principles of evidence-based synthesis should apply to rapid reviews in order to minimize bias to the extent possible. The Cochrane Rapid Reviews Methods Group will serve to establish a network of rapid review stakeholders and provide a forum for discussion and training. By facilitating exchange, the group will strive to conduct research to advance the methods of rapid reviews. Conclusion: Acute aerobic exercise improves subsequent interference control performance. However, the covariates exercise intensity, participants' age, and familiarization with testing procedure determine the magnitude of that effect. Methodological features were not found to influence the magnitude of effects. This dismisses some doubts that exercise induced benefits for interference control performance are scientific artifacts. The fact that large heterogeneity remained unexplained in some subgroups indicates the need for further research on covariates within these subgroups. It should be noted that effect sizes for all analyses were small. rotator cuff retear exhibited significantly lower clinical outcome scores and strength compared with patients with an intact or partially torn rotator cuff.
PY  - 2021
DA  - 2021-08-01
JO  - {'id': 'https://openalex.org/S205010575', 'issn_l': '0950-5849', 'issn': ['0950-5849', '1873-6025'], 'display_name': 'Information & Software Technology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Raymon van Dinter
AU  - Bedir Tekinerdogan
AU  - Daniel Rodriguez
ER  - 

40.
TY  - journal-article
ID  - https://openalex.org/W2587837170
DO  - https://doi.org/10.1016/j.jaip.2016.11.004
TI  - Urinary Leukotriene E4 to Determine Aspirin Intolerance in Asthma: A Systematic Review and Meta-Analysis
AB  - Urinary leukotriene E4 (ULTE4) may be a biomarker that distinguishes aspirin-intolerant asthma from other asthma subtypes.To estimate the diagnostic testing accuracy of ULTE4 as a marker of aspirin intolerance in patients with asthma using previously published studies.We identified relevant clinical studies from a systematic review of English and non-English articles using MEDLINE, EMBASE, and CENTRAL (inception to February 10, 2015). Articles were screened at the abstract and full-text level by 2 independent reviewers. We included previously published studies that analyzed ULTE4 in human subjects with asthma characterized as having or not having aspirin intolerance on the basis of a specified definition: convincing history of aspirin intolerance, positive aspirin challenge, or both as the criterion standard. Individual-level data points from all included studies were obtained and analyzed.The search strategy identified 867 potential articles, of which 86 were reviewed at the full-text level and 10 met criteria for inclusion. The sensitivity, specificity, positive predictive value, and negative predictive values of ULTE4 to determine aspirin intolerance in subjects with asthma were 0.55, 0.82, 0.75, and 0.66 (Amersham-enzyme immunoassay); 0.76, 0.77, 0.70, and 0.78 (Cayman-enzyme immunoassay); 0.70, 0.81, 0.86, and 0.79 (mass spectrometry); and 0.81,0.79, 0.65, and 0.88 (radioimmunoassay) at optimal thresholds of 192, 510, 167 to 173, and 66 to 69 pg/mg Cr, respectively. The diagnostic odds ratio for each methodology was 6.0, 11.9, 10.5, and 19.1, respectively.ULTE4 is a marker for aspirin-intolerant asthma and could potentially be used as a clinical test to identify the risk of aspirin intolerance in subjects with asthma. to rapid reviews in order to minimize bias to the extent possible. The Cochrane Rapid Reviews Methods Group will serve to establish a network of rapid review stakeholders and provide a forum for discussion and training. By facilitating exchange, the group will strive to conduct research to advance the methods of rapid reviews. Conclusion: Acute aerobic exercise improves subsequent interference control performance. However, the covariates exercise intensity, participants' age, and familiarization with testing procedure determine the magnitude of that effect. Methodological features were not found to influence the magnitude of effects. This dismisses some doubts that exercise induced benefits for interference control performance are scientific artifacts. The fact that large heterogeneity remained unexplained in some subgroups indicates the need for further research on covariates within these subgroups. It should be noted that effect sizes for all analyses were small. rotator cuff retear exhibited significantly lower clinical outcome scores and strength compared with patients with an intact or partially torn rotator cuff.
PY  - 2017
DA  - 2017-07-01
JO  - {'id': 'https://openalex.org/S2754868259', 'issn_l': '2213-2198', 'issn': ['2213-2201', '2213-2198'], 'display_name': 'The Journal of Allergy and Clinical Immunology: In Practice', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - John Hagan
AU  - Tanya M. Laidlaw
AU  - Rohit Divekar
AU  - Erin K. O'Brien
AU  - Hirohito Kita
AU  - Gerald W. Volcheck
AU  - Christina R. Hagan
AU  - Devyani Lal
AU  - Harry G. Teaford
AU  - Patricia J. Erwin
AU  - Nan Zhang
AU  - Matthew A. Rank
ER  - 

41.
TY  - journal-article
ID  - https://openalex.org/W2807298829
DO  - https://doi.org/10.1007/s40279-018-0945-x
TI  - Threshold of Energy Deficit and Lower-Body Performance Declines in Military Personnel: A Meta-Regression
AB  - No Abstract Found
PY  - 2018
DA  - 2018-09-01
JO  - {'id': 'https://openalex.org/S137994755', 'issn_l': '0112-1642', 'issn': ['1179-2035', '0112-1642'], 'display_name': 'Sports Medicine', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Nancy A. Murphy
AU  - Christopher T. Carrigan
AU  - J. Philip Karl
AU  - Stefan M. Pasiakos
AU  - Lee M. Margolis
ER  - 

42.
TY  - journal-article
ID  - https://openalex.org/W2947064635
DO  - https://doi.org/10.1186/s13643-019-1035-3
TI  - Study-based registers reduce waste in systematic reviewing: discussion and case report
AB  - Maintained study-based registers (SBRs) have, at their core, study records linked to, potentially, multiple other records such as references, data sets, standard texts and full-text reports. Such registers can minimise and refine searching, de-duplicating, screening and acquisition of full texts. SBRs can facilitate new review titles/updates and, within seconds, inform the team about the potential workload of each task. We discuss the advantages/disadvantages of SBRs and report a case of how such a register was used to develop a successful grant application and deliver results—reducing considerable redundancy of effort. SBRs saved time in question-setting and scoping and made rapid production of nine Cochrane systematic reviews possible. Whilst helping prioritise and conduct systematic reviews, SBRs improve quality. Those funding information specialists for literature reviewing could reasonably stipulate the resulting SBR to be delivered for dissemination and use beyond the life of the project. 10 met criteria for inclusion. The sensitivity, specificity, positive predictive value, and negative predictive values of ULTE4 to determine aspirin intolerance in subjects with asthma were 0.55, 0.82, 0.75, and 0.66 (Amersham-enzyme immunoassay); 0.76, 0.77, 0.70, and 0.78 (Cayman-enzyme immunoassay); 0.70, 0.81, 0.86, and 0.79 (mass spectrometry); and 0.81,0.79, 0.65, and 0.88 (radioimmunoassay) at optimal thresholds of 192, 510, 167 to 173, and 66 to 69 pg/mg Cr, respectively. The diagnostic odds ratio for each methodology was 6.0, 11.9, 10.5, and 19.1, respectively.ULTE4 is a marker for aspirin-intolerant asthma and could potentially be used as a clinical test to identify the risk of aspirin intolerance in subjects with asthma. to rapid reviews in order to minimize bias to the extent possible. The Cochrane Rapid Reviews Methods Group will serve to establish a network of rapid review stakeholders and provide a forum for discussion and training. By facilitating exchange, the group will strive to conduct research to advance the methods of rapid reviews. Conclusion: Acute aerobic exercise improves subsequent interference control performance. However, the covariates exercise intensity, participants' age, and familiarization with testing procedure determine the magnitude of that effect. Methodological features were not found to influence the magnitude of effects. This dismisses some doubts that exercise induced benefits for interference control performance are scientific artifacts. The fact that large heterogeneity remained unexplained in some subgroups indicates the need for further research on covariates within these subgroups. It should be noted that effect sizes for all analyses were small. rotator cuff retear exhibited significantly lower clinical outcome scores and strength compared with patients with an intact or partially torn rotator cuff.
PY  - 2019
DA  - 2019-05-30
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://doi.org/10.1186/s13643-019-1035-3', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Farhad Shokraneh
AU  - Clive E Adams
ER  - 

43.
TY  - journal-article
ID  - https://openalex.org/W1972820856
DO  - https://doi.org/10.2196/jmir.3369
TI  - Automatic Evidence Retrieval for Systematic Reviews
AB  - Background: Snowballing involves recursively pursuing relevant references cited in the retrieved literature and adding them to the search results. Snowballing is an alternative approach to discover additional evidence that was not retrieved through conventional search. Snowballing&#8217;s effectiveness makes it best practice in systematic reviews despite being time-consuming and tedious. Objective: Our goal was to evaluate an automatic method for citation snowballing&#8217;s capacity to identify and retrieve the full text and/or abstracts of cited articles. Methods: Using 20 review articles that contained 949 citations to journal or conference articles, we manually searched Microsoft Academic Search (MAS) and identified 78.0% (740/949) of the cited articles that were present in the database. We compared the performance of the automatic citation snowballing method against the results of this manual search, measuring precision, recall, and F1 score. Results: The automatic method was able to correctly identify 633 (as proportion of included citations: recall=66.7%, F1 score=79.3%; as proportion of citations in MAS: recall=85.5%, F1 score=91.2%) of citations with high precision (97.7%), and retrieved the full text or abstract for 490 (recall=82.9%, precision=92.1%, F1 score=87.3%) of the 633 correctly retrieved citations. Conclusions: The proposed method for automatic citation snowballing is accurate and is capable of obtaining the full texts or abstracts for a substantial proportion of the scholarly citations in review articles. By automating the process of citation snowballing, it may be possible to reduce the time and effort of common evidence surveillance tasks such as keeping trial registries up to date and conducting systematic reviews. with asthma. to rapid reviews in order to minimize bias to the extent possible. The Cochrane Rapid Reviews Methods Group will serve to establish a network of rapid review stakeholders and provide a forum for discussion and training. By facilitating exchange, the group will strive to conduct research to advance the methods of rapid reviews. Conclusion: Acute aerobic exercise improves subsequent interference control performance. However, the covariates exercise intensity, participants' age, and familiarization with testing procedure determine the magnitude of that effect. Methodological features were not found to influence the magnitude of effects. This dismisses some doubts that exercise induced benefits for interference control performance are scientific artifacts. The fact that large heterogeneity remained unexplained in some subgroups indicates the need for further research on covariates within these subgroups. It should be noted that effect sizes for all analyses were small. rotator cuff retear exhibited significantly lower clinical outcome scores and strength compared with patients with an intact or partially torn rotator cuff.
PY  - 2014
DA  - 2014-10-01
JO  - {'id': 'https://openalex.org/V17147534', 'issn_l': '1438-8871', 'issn': ['1439-4456', '1438-8871'], 'display_name': 'Journal of Medical Internet Research', 'publisher': 'JMIR Publications', 'type': 'journal', 'url': 'https://doi.org/10.2196/jmir.3369', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Miew Keen Choong
AU  - Filippo Galgani
AU  - Adam G. Dunn
AU  - Guy Tsafnat
ER  - 

44.
TY  - journal-article
ID  - https://openalex.org/W2271587360
DO  - https://doi.org/10.1093/ije/dyv306
TI  - Machine learning to assist risk-of-bias assessments in systematic reviews
AB  - Risk-of-bias assessments are now a standard component of systematic reviews. At present, reviewers need to manually identify relevant parts of research articles for a set of methodological elements that affect the risk of bias, in order to make a risk-of-bias judgement for each of these elements. We investigate the use of text mining methods to automate risk-of-bias assessments in systematic reviews. We aim to identify relevant sentences within the text of included articles, to rank articles by risk of bias and to reduce the number of risk-of-bias assessments that the reviewers need to perform by hand.We use supervised machine learning to train two types of models, for each of the three risk-of-bias properties of sequence generation, allocation concealment and blinding. The first model predicts whether a sentence in a research article contains relevant information. The second model predicts a risk-of-bias value for each research article. We use logistic regression, where each independent variable is the frequency of a word in a sentence or article, respectively.We found that sentences can be successfully ranked by relevance with area under the receiver operating characteristic (ROC) curve (AUC) > 0.98. Articles can be ranked by risk of bias with AUC > 0.72. We estimate that more than 33% of articles can be assessed by just one reviewer, where two reviewers are normally required.We show that text mining can be used to assist risk-of-bias assessments. and effort of common evidence surveillance tasks such as keeping trial registries up to date and conducting systematic reviews. with asthma. to rapid reviews in order to minimize bias to the extent possible. The Cochrane Rapid Reviews Methods Group will serve to establish a network of rapid review stakeholders and provide a forum for discussion and training. By facilitating exchange, the group will strive to conduct research to advance the methods of rapid reviews. Conclusion: Acute aerobic exercise improves subsequent interference control performance. However, the covariates exercise intensity, participants' age, and familiarization with testing procedure determine the magnitude of that effect. Methodological features were not found to influence the magnitude of effects. This dismisses some doubts that exercise induced benefits for interference control performance are scientific artifacts. The fact that large heterogeneity remained unexplained in some subgroups indicates the need for further research on covariates within these subgroups. It should be noted that effect sizes for all analyses were small. rotator cuff retear exhibited significantly lower clinical outcome scores and strength compared with patients with an intact or partially torn rotator cuff.
PY  - 2016
DA  - 2016-02-01
JO  - {'id': 'https://openalex.org/S13389975', 'issn_l': '0300-5771', 'issn': ['1464-3685', '0300-5771'], 'display_name': 'International Journal of Epidemiology', 'publisher': 'Oxford University Press', 'type': 'journal', 'url': 'https://academic.oup.com/ije/article-pdf/45/1/266/24170552/dyv306.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Louise A C Millard
AU  - Peter A. Flach
AU  - Julian P T Higgins
ER  - 

45.
TY  - journal-article
ID  - https://openalex.org/W2728356165
DO  - https://doi.org/10.1186/s13643-017-0518-3
TI  - A systematic review of the processes used to link clinical trial registrations to their published results
AB  - Studies measuring the completeness and consistency of trial registration and reporting rely on linking registries with bibliographic databases. In this systematic review, we quantified the processes used to identify these links.PubMed and Embase databases were searched from inception to May 2016 for studies linking trial registries with bibliographic databases. The processes used to establish these links were categorised as automatic when the registration identifier was available in the bibliographic database or publication, or manual when linkage required inference or contacting of trial investigators. The number of links identified by each process was extracted where available. Linear regression was used to determine whether the proportions of links available via automatic processes had increased over time.In 43 studies that examined cohorts of registry entries, 24 used automatic and manual processes to find articles; 3 only automatic; and 11 only manual (5 did not specify). Twelve studies reported results for both manual and automatic processes and showed that a median of 23% (range from 13 to 42%) included automatic links to articles, while 17% (range from 5 to 42%) of registry entries required manual processes to find articles. There was no evidence that the proportion of registry entries with automatic links had increased (R 2 = 0.02, p = 0.36). In 39 studies that examined cohorts of articles, 21 used automatic and manual processes; 9 only automatic; and 2 only manual (7 did not specify). Sixteen studies reported numbers for automatic and manual processes and indicated that a median of 49% (range from 8 to 97%) of articles had automatic links to registry entries, and 10% (range from 0 to 28%) required manual processes to find registry entries. There was no evidence that the proportion of articles with automatic links to registry entries had increased (R 2 = 0.01, p = 0.73).The linkage of trial registries to their corresponding publications continues to require extensive manual processes. We did not find that the use of automatic linkage has increased over time. Further investigation is needed to inform approaches that will ensure publications are properly linked to trial registrations, thus enabling efficient monitoring of trial reporting. interference control performance are scientific artifacts. The fact that large heterogeneity remained unexplained in some subgroups indicates the need for further research on covariates within these subgroups. It should be noted that effect sizes for all analyses were small. rotator cuff retear exhibited significantly lower clinical outcome scores and strength compared with patients with an intact or partially torn rotator cuff.
PY  - 2017
DA  - 2017-07-03
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://systematicreviewsjournal.biomedcentral.com/track/pdf/10.1186/s13643-017-0518-3', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Rabia Bashir
AU  - Florence T. Bourgeois
AU  - Adam G. Dunn
ER  - 

46.
TY  - journal-article
ID  - https://openalex.org/W2596568673
DO  - https://doi.org/10.1016/j.jbi.2017.03.007
TI  - Using ontology-based semantic similarity to facilitate the article screening process for systematic reviews
AB  - • Joint use of SNOMED CT and MeSH resulted in a more comprehensive knowledge source. • We created a semantic concept modelling process to improve concepts representation. • Effective concepts and relations from ontologies can be used as semantic knowledge. • Ontology-based article semantic relationships can help identify relevant articles. Systematic Reviews (SRs) are utilized to summarize evidence from high quality studies and are considered the preferred source of evidence-based practice (EBP). However, conducting SRs can be time and labor intensive due to the high cost of article screening. In previous studies, we demonstrated utilizing established (lexical) article relationships to facilitate the identification of relevant articles in an efficient and effective manner. Here we propose to enhance article relationships with background semantic knowledge derived from Unified Medical Language System (UMLS) concepts and ontologies. We developed a pipelined semantic concepts representation process to represent articles from an SR into an optimized and enriched semantic space of UMLS concepts. Throughout the process, we leveraged concepts and concept relations encoded in biomedical ontologies (SNOMED-CT and MeSH) within the UMLS framework to prompt concept features of each article. Article relationships (similarities) were established and represented as a semantic article network, which was readily applied to assist with the article screening process. We incorporated the concept of active learning to simulate an interactive article recommendation process, and evaluated the performance on 15 completed SRs. We used work saved over sampling at 95% recall (WSS95) as the performance measure. We compared the WSS95 performance of our ontology-based semantic approach to existing lexical feature approaches and corpus-based semantic approaches, and found that we had better WSS95 in most SRs. We also had the highest average WSS95 of 43.81% and the highest total WSS95 of 657.18%. We demonstrated using ontology-based semantics to facilitate the identification of relevant articles for SRs. Effective concepts and concept relations derived from UMLS ontologies can be utilized to establish article semantic relationships. Our approach provided a promising performance and can easily apply to any SR topics in the biomedical domain with generalizability. properly linked to trial registrations, thus enabling efficient monitoring of trial reporting. interference control performance are scientific artifacts. The fact that large heterogeneity remained unexplained in some subgroups indicates the need for further research on covariates within these subgroups. It should be noted that effect sizes for all analyses were small. rotator cuff retear exhibited significantly lower clinical outcome scores and strength compared with patients with an intact or partially torn rotator cuff.
PY  - 2017
DA  - 2017-05-01
JO  - {'id': 'https://openalex.org/S11622463', 'issn_l': '1532-0464', 'issn': ['1532-0480', '1532-0464'], 'display_name': 'Journal of Biomedical Informatics', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'https://doi.org/10.1016/j.jbi.2017.03.007', 'is_oa': True, 'version': 'publishedVersion', 'license': 'elsevier-specific'}
DP  - OpenAlex
AU  - Xiaonan Ji
AU  - Alan Ritter
AU  - Po-Yin Yen
ER  - 

47.
TY  - journal-article
ID  - https://openalex.org/W2759699778
DO  - https://doi.org/10.2196/medinform.7680
TI  - Expert Search Strategies: The Information Retrieval Practices of Healthcare Information Professionals
AB  - Healthcare information professionals play a key role in closing the knowledge gap between medical research and clinical practice. Their work involves meticulous searching of literature databases using complex search strategies that can consist of hundreds of keywords, operators, and ontology terms. This process is prone to error and can lead to inefficiency and bias if performed incorrectly.The aim of this study was to investigate the search behavior of healthcare information professionals, uncovering their needs, goals, and requirements for information retrieval systems.A survey was distributed to healthcare information professionals via professional association email discussion lists. It investigated the search tasks they undertake, their techniques for search strategy formulation, their approaches to evaluating search results, and their preferred functionality for searching library-style databases. The popular literature search system PubMed was then evaluated to determine the extent to which their needs were met.The 107 respondents indicated that their information retrieval process relied on the use of complex, repeatable, and transparent search strategies. On average it took 60 minutes to formulate a search strategy, with a search task taking 4 hours and consisting of 15 strategy lines. Respondents reviewed a median of 175 results per search task, far more than they would ideally like (100). The most desired features of a search system were merging search queries and combining search results.Healthcare information professionals routinely address some of the most challenging information retrieval problems of any profession. However, their needs are not fully supported by current literature search systems and there is demand for improved functionality, in particular regarding the development and management of search strategies. approaches, and found that we had better WSS95 in most SRs. We also had the highest average WSS95 of 43.81% and the highest total WSS95 of 657.18%. We demonstrated using ontology-based semantics to facilitate the identification of relevant articles for SRs. Effective concepts and concept relations derived from UMLS ontologies can be utilized to establish article semantic relationships. Our approach provided a promising performance and can easily apply to any SR topics in the biomedical domain with generalizability. properly linked to trial registrations, thus enabling efficient monitoring of trial reporting. interference control performance are scientific artifacts. The fact that large heterogeneity remained unexplained in some subgroups indicates the need for further research on covariates within these subgroups. It should be noted that effect sizes for all analyses were small. rotator cuff retear exhibited significantly lower clinical outcome scores and strength compared with patients with an intact or partially torn rotator cuff.
PY  - 2017
DA  - 2017-10-02
JO  - {'id': 'https://openalex.org/S2764650051', 'issn_l': '2291-9694', 'issn': ['2291-9694'], 'display_name': 'JMIR medical informatics', 'publisher': 'JMIR Publications', 'type': 'journal', 'url': 'https://doi.org/10.2196/medinform.7680', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Tony Russell-Rose
AU  - Jon Chamberlain
ER  - 

48.
TY  - journal-article
ID  - https://openalex.org/W2765760594
DO  - https://doi.org/10.1111/cobi.13044
TI  - Using machine learning to disentangle homonyms in large text corpora
AB  - Systematic reviews are an increasingly popular decision-making tool that provides an unbiased summary of evidence to support conservation action. These reviews bridge the gap between researchers and managers by presenting a comprehensive overview of all studies relating to a particular topic and identify specifically where and under which conditions an effect is present. However, several technical challenges can severely hinder the feasibility and applicability of systematic reviews, for example, homonyms (terms that share spelling but differ in meaning). Homonyms add noise to search results and cannot be easily identified or removed. We developed a semiautomated approach that can aid in the classification of homonyms among narratives. We used a combination of automated content analysis and artificial neural networks to quickly and accurately sift through large corpora of academic texts and classify them to distinct topics. As an example, we explored the use of the word reintroduction in academic texts. Reintroduction is used within the conservation context to indicate the release of organisms to their former native habitat; however, a Web of Science search for this word returned thousands of publications in which the term has other meanings and contexts. Using our method, we automatically classified a sample of 3000 of these publications with over 99% accuracy, relative to a manual classification. Our approach can be used easily with other homonyms and can greatly facilitate systematic reviews or similar work in which homonyms hinder the harnessing of large text corpora. Beyond homonyms we see great promise in combining automated content analysis and machine-learning methods to handle and screen big data for relevant information in conservation science. we had better WSS95 in most SRs. We also had the highest average WSS95 of 43.81% and the highest total WSS95 of 657.18%. We demonstrated using ontology-based semantics to facilitate the identification of relevant articles for SRs. Effective concepts and concept relations derived from UMLS ontologies can be utilized to establish article semantic relationships. Our approach provided a promising performance and can easily apply to any SR topics in the biomedical domain with generalizability. properly linked to trial registrations, thus enabling efficient monitoring of trial reporting. interference control performance are scientific artifacts. The fact that large heterogeneity remained unexplained in some subgroups indicates the need for further research on covariates within these subgroups. It should be noted that effect sizes for all analyses were small. rotator cuff retear exhibited significantly lower clinical outcome scores and strength compared with patients with an intact or partially torn rotator cuff.
PY  - 2018
DA  - 2018-06-01
JO  - {'id': 'https://openalex.org/S98137347', 'issn_l': '0888-8892', 'issn': ['0888-8892', '1523-1739'], 'display_name': 'Conservation Biology', 'publisher': 'Wiley-Blackwell', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Uri Roll
AU  - Ricardo A. Correia
AU  - Oded Berger-Tal
ER  - 

49.
TY  - journal-article
ID  - https://openalex.org/W3011172676
DO  - https://doi.org/10.3389/fphys.2020.00185
TI  - Physical Activity for the Treatment of Adolescent Depression: A Systematic Review and Meta-Analysis
AB  - Background: A noticeable proportion of adolescents with depression do not respond to guideline recommended treatment options. This systematic review and meta-analysis investigated the effectiveness of physical activity interventions as an alternative or complementary treatment for adolescents (12-18 years) with depression. The characteristics of the physical activity treatment that were most effective in reducing symptoms in adolescents with depression and the impact of methodological shortcomings in the existing research were also examined. Methods: Medline, PsycINFO, SPORTDiscus, ProQuest, and CENTRAL were searched for eligible records. Effect size estimates were pooled based on the application of a random-effects model. Potential moderation by physical activity characteristics (i.e., intensity, type, context, and time frame) and methodological features (i.e., type of control group and diagnostic tool to identify depression at baseline) was investigated by means of subgroup analyses and meta-regressions. The certainty of evidence was assessed by the Grading of Recommendations, Assessment, Development, and Evaluation (GRADE) approach. The primary outcome was the antidepressant effect of physical activity at postintervention measurement time point. As secondary outcomes, the sustainability of effects after the end of physical activity treatment and the acceptability of physical activity treatments were assessed. Overall, 10 studies were included in the qualitative synthesis and 9 studies involving 431 patients were included in the quantitative synthesis. Results: A moderate, significant antidepressant effect of physical activity was found (Hedges' g = -0.47, 95% CI = -0.71 to -0.24). Heterogeneity was small (T2 = 0.0313, I2 = 27%, p = 0.18). However, the certainty of evidence was downgraded to low because the included studies contained serious methodological limitations. Moderator analyses revealed that session intensity significantly moderated the antidepressant effect of physical activity. Moreover, noticeably smaller effect sizes were found in studies that used non-physical activity sham treatments as control treatments (e.g., playing board games), compared to studies that used no control group treatments. Only three studies assessed the sustainability of effects after the end of physical activity treatment. The results suggest that the antidepressant effects further increase after the end of physical activity interventions. There was no significant difference in dropout risk between the physical activity and control groups. Conclusions: This review suggests that physical activity is effective in treating depression in adolescents. Physical activity sessions should be at least moderately intense [rate of perceived exertion (RPE) between 11 and 13] to be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2020
DA  - 2020-03-19
JO  - {'id': 'https://openalex.org/S52732750', 'issn_l': '1664-042X', 'issn': ['1664-042X'], 'display_name': 'Frontiers in Physiology', 'publisher': 'Frontiers Media', 'type': 'journal', 'url': 'https://www.frontiersin.org/articles/10.3389/fphys.2020.00185/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Max Oberste
AU  - Marie Medele
AU  - Florian Javelle
AU  - Heidrun Lioba Wunram
AU  - Daniel Walter
AU  - Wilhelm Bloch
AU  - Stephan Bender
AU  - Oliver Fricke
AU  - Niklas Joisten
AU  - David Walzik
AU  - Nicola Großheinrich
AU  - Philipp Zimmer
ER  - 

50.
TY  - journal-article
ID  - https://openalex.org/W2982683456
DO  - https://doi.org/10.1186/s13643-019-1222-2
TI  - Performance and usability of machine learning for screening in systematic reviews: a comparative evaluation of three tools
AB  - Abstract Background We explored the performance of three machine learning tools designed to facilitate title and abstract screening in systematic reviews (SRs) when used to (a) eliminate irrelevant records (automated simulation) and (b) complement the work of a single reviewer (semi-automated simulation). We evaluated user experiences for each tool. Methods We subjected three SRs to two retrospective screening simulations. In each tool (Abstrackr, DistillerSR, RobotAnalyst), we screened a 200-record training set and downloaded the predicted relevance of the remaining records. We calculated the proportion missed and workload and time savings compared to dual independent screening. To test user experiences, eight research staff tried each tool and completed a survey. Results Using Abstrackr, DistillerSR, and RobotAnalyst, respectively, the median (range) proportion missed was 5 (0 to 28) percent, 97 (96 to 100) percent, and 70 (23 to 100) percent for the automated simulation and 1 (0 to 2) percent, 2 (0 to 7) percent, and 2 (0 to 4) percent for the semi-automated simulation. The median (range) workload savings was 90 (82 to 93) percent, 99 (98 to 99) percent, and 85 (85 to 88) percent for the automated simulation and 40 (32 to 43) percent, 49 (48 to 49) percent, and 35 (34 to 38) percent for the semi-automated simulation. The median (range) time savings was 154 (91 to 183), 185 (95 to 201), and 157 (86 to 172) hours for the automated simulation and 61 (42 to 82), 92 (46 to 100), and 64 (37 to 71) hours for the semi-automated simulation. Abstrackr identified 33–90% of records missed by a single reviewer. RobotAnalyst performed less well and DistillerSR provided no relative advantage. User experiences depended on user friendliness, qualities of the user interface, features and functions, trustworthiness, ease and speed of obtaining predictions, and practicality of the export file(s). Conclusions The workload savings afforded in the automated simulation came with increased risk of missing relevant records. Supplementing a single reviewer’s decisions with relevance predictions (semi-automated simulation) sometimes reduced the proportion missed, but performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable. is effective in treating depression in adolescents. Physical activity sessions should be at least moderately intense [rate of perceived exertion (RPE) between 11 and 13] to be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2019
DA  - 2019-11-15
JO  - {'id': 'https://openalex.org/V82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://doi.org/10.1186/s13643-019-1222-2', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Allison Gates
AU  - Samantha Guitard
AU  - Jennifer Pillay
AU  - Sarah A. Elliott
AU  - Michele P Dyson
AU  - Amanda S Newton
AU  - Lisa Hartling
ER  - 

51.
TY  - journal-article
ID  - https://openalex.org/W3087265411
DO  - https://doi.org/10.1016/j.emj.2020.09.007
TI  - Re-examining systematic literature review in management research: Additional benefits and execution protocols
AB  - A systematic literature review provides a comprehensive overview of literature related to a research question and synthesizes previous work to strengthen a particular topic’s foundation of knowledge, while adhering to the concepts of transparency and bias reduction. In the growing, complex, and dynamic, management research field, systematic literature reviews have value, yet there is relatively little work published describing how management researchers might apply this approach. In explaining the purpose of systematic reviews, we define a systematic review and describe its rationale. We then discuss how systematic literature reviews may enhance management research and address current management research shortcomings. We present a detailed systematic literature review execution guideline, outlining systematic literature review steps, and providing keys to effective implementation. proportion missed was 5 (0 to 28) percent, 97 (96 to 100) percent, and 70 (23 to 100) percent for the automated simulation and 1 (0 to 2) percent, 2 (0 to 7) percent, and 2 (0 to 4) percent for the semi-automated simulation. The median (range) workload savings was 90 (82 to 93) percent, 99 (98 to 99) percent, and 85 (85 to 88) percent for the automated simulation and 40 (32 to 43) percent, 49 (48 to 49) percent, and 35 (34 to 38) percent for the semi-automated simulation. The median (range) time savings was 154 (91 to 183), 185 (95 to 201), and 157 (86 to 172) hours for the automated simulation and 61 (42 to 82), 92 (46 to 100), and 64 (37 to 71) hours for the semi-automated simulation. Abstrackr identified 33–90% of records missed by a single reviewer. RobotAnalyst performed less well and DistillerSR provided no relative advantage. User experiences depended on user friendliness, qualities of the user interface, features and functions, trustworthiness, ease and speed of obtaining predictions, and practicality of the export file(s). Conclusions The workload savings afforded in the automated simulation came with increased risk of missing relevant records. Supplementing a single reviewer’s decisions with relevance predictions (semi-automated simulation) sometimes reduced the proportion missed, but performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable. is effective in treating depression in adolescents. Physical activity sessions should be at least moderately intense [rate of perceived exertion (RPE) between 11 and 13] to be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2021
DA  - 2021-08-01
JO  - {'id': 'https://openalex.org/S105567970', 'issn_l': '0263-2373', 'issn': ['1873-5681', '0263-2373'], 'display_name': 'European Management Journal', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Ralph Vaughan Williams
AU  - Leigh Clark
AU  - W. Randy Clark
AU  - Deana M. Raffo
ER  - 

52.
TY  - journal-article
ID  - https://openalex.org/W2952174148
DO  - https://doi.org/10.1093/bib/bbx057
TI  - Biomedical text mining for research rigor and integrity: tasks, challenges, directions
AB  - An estimated quarter of a trillion US dollars is invested in the biomedical research enterprise annually. There is growing alarm that a significant portion of this investment is wasted because of problems in reproducibility of research findings and in the rigor and integrity of research conduct and reporting. Recent years have seen a flurry of activities focusing on standardization and guideline development to enhance the reproducibility and rigor of biomedical research. Research activity is primarily communicated via textual artifacts, ranging from grant applications to journal publications. These artifacts can be both the source and the manifestation of practices leading to research waste. For example, an article may describe a poorly designed experiment, or the authors may reach conclusions not supported by the evidence presented. In this article, we pose the question of whether biomedical text mining techniques can assist the stakeholders in the biomedical research enterprise in doing their part toward enhancing research integrity and rigor. In particular, we identify four key areas in which text mining techniques can make a significant contribution: plagiarism/fraud detection, ensuring adherence to reporting guidelines, managing information overload and accurate citation/enhanced bibliometrics. We review the existing methods and tools for specific tasks, if they exist, or discuss relevant research that can provide guidance for future work. With the exponential increase in biomedical research output and the ability of text mining approaches to perform automatic tasks at large scale, we propose that such approaches can support tools that promote responsible research practices, providing significant benefits for the biomedical research enterprise. identified 33–90% of records missed by a single reviewer. RobotAnalyst performed less well and DistillerSR provided no relative advantage. User experiences depended on user friendliness, qualities of the user interface, features and functions, trustworthiness, ease and speed of obtaining predictions, and practicality of the export file(s). Conclusions The workload savings afforded in the automated simulation came with increased risk of missing relevant records. Supplementing a single reviewer’s decisions with relevance predictions (semi-automated simulation) sometimes reduced the proportion missed, but performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable. is effective in treating depression in adolescents. Physical activity sessions should be at least moderately intense [rate of perceived exertion (RPE) between 11 and 13] to be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2017
DA  - 2017-02-14
JO  - {'id': 'https://openalex.org/V91767247', 'issn_l': '1467-5463', 'issn': ['1467-5463', '1477-4054'], 'display_name': 'Briefings in Bioinformatics', 'publisher': 'Oxford University Press', 'type': 'journal', 'url': 'https://academic.oup.com/bib/article-pdf/19/6/1400/27118801/bbx057.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'pd'}
DP  - OpenAlex
AU  - Halil Kilicoglu
ER  - 

53.
TY  - journal-article
ID  - https://openalex.org/W2954093663
DO  - https://doi.org/10.1016/j.jss.2019.07.002
TI  - Evolution of statistical analysis in empirical software engineering research: Current state and steps forward
AB  - Software engineering research is evolving and papers are increasingly based on empirical data from a multitude of sources, using statistical tests to determine if and to what degree empirical evidence supports their hypotheses. To investigate the practices and trends of statistical analysis in empirical software engineering (ESE), this paper presents a review of a large pool of papers from top-ranked software engineering journals. First, we manually reviewed 161 papers and in the second phase of our method, we conducted a more extensive semi-automatic classification of papers spanning the years 2001--2015 and 5,196 papers. Results from both review steps was used to: i) identify and analyze the predominant practices in ESE (e.g., using t-test or ANOVA), as well as relevant trends in usage of specific statistical methods (e.g., nonparametric tests and effect size measures) and, ii) develop a conceptual model for a statistical analysis workflow with suggestions on how to apply different statistical methods as well as guidelines to avoid pitfalls. Lastly, we confirm existing claims that current ESE practices lack a standard to report practical significance of results. We illustrate how practical significance can be discussed in terms of both the statistical analysis and in the practitioner's context. they exist, or discuss relevant research that can provide guidance for future work. With the exponential increase in biomedical research output and the ability of text mining approaches to perform automatic tasks at large scale, we propose that such approaches can support tools that promote responsible research practices, providing significant benefits for the biomedical research enterprise. identified 33–90% of records missed by a single reviewer. RobotAnalyst performed less well and DistillerSR provided no relative advantage. User experiences depended on user friendliness, qualities of the user interface, features and functions, trustworthiness, ease and speed of obtaining predictions, and practicality of the export file(s). Conclusions The workload savings afforded in the automated simulation came with increased risk of missing relevant records. Supplementing a single reviewer’s decisions with relevance predictions (semi-automated simulation) sometimes reduced the proportion missed, but performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable. is effective in treating depression in adolescents. Physical activity sessions should be at least moderately intense [rate of perceived exertion (RPE) between 11 and 13] to be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2019
DA  - 2019-10-01
JO  - {'id': 'https://openalex.org/S37879656', 'issn_l': '0164-1212', 'issn': ['0164-1212', '1873-1228'], 'display_name': 'Journal of Systems and Software', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Francisco Gomes de Oliveira Neto
AU  - Richard Torkar
AU  - Robert Feldt
AU  - Lucas Gren
AU  - Carlo A. Furia
AU  - Z. L. Huang
ER  - 

54.
TY  - journal-article
ID  - https://openalex.org/W2896286428
DO  - https://doi.org/10.1007/s00500-018-3568-0
TI  - Information retrieval methodology for aiding scientific database search
AB  - During literature reviews, and specially when conducting systematic literature reviews, finding and screening relevant papers during scientific document search may involve managing and processing large amounts of unstructured text data. In those cases where the search topic is difficult to establish or has fuzzy limits, researchers require to broaden the scope of the search and, in consequence, data from retrieved scientific publications may become huge and uncorrelated. However, through a convenient analysis of these data the researcher may be able to discover new knowledge which may be hidden within the search output, thus exploring the limits of the search and enhancing the review scope. With that aim, this paper presents an iterative methodology that applies text mining and machine learning techniques to a downloaded corpus of abstracts from scientific databases, combining automatic processing algorithms with tools for supervised decision-making in an iterative process sustained on the researchers’ judgement, so as to adapt, screen and tune the search output. The paper ends showing a working example that employs a set of developed scripts that implement the different stages of the proposed methodology. practical significance can be discussed in terms of both the statistical analysis and in the practitioner's context. they exist, or discuss relevant research that can provide guidance for future work. With the exponential increase in biomedical research output and the ability of text mining approaches to perform automatic tasks at large scale, we propose that such approaches can support tools that promote responsible research practices, providing significant benefits for the biomedical research enterprise. identified 33–90% of records missed by a single reviewer. RobotAnalyst performed less well and DistillerSR provided no relative advantage. User experiences depended on user friendliness, qualities of the user interface, features and functions, trustworthiness, ease and speed of obtaining predictions, and practicality of the export file(s). Conclusions The workload savings afforded in the automated simulation came with increased risk of missing relevant records. Supplementing a single reviewer’s decisions with relevance predictions (semi-automated simulation) sometimes reduced the proportion missed, but performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable. is effective in treating depression in adolescents. Physical activity sessions should be at least moderately intense [rate of perceived exertion (RPE) between 11 and 13] to be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2020
DA  - 2020-04-01
JO  - {'id': 'https://openalex.org/S65753830', 'issn_l': '1432-7643', 'issn': ['1433-7479', '1432-7643'], 'display_name': 'Soft Computing', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Samuel Marcos-Pablos
AU  - Francisco José García-Peñalvo
ER  - 

55.
TY  - journal-article
ID  - https://openalex.org/W2978009674
DO  - https://doi.org/10.1093/advances/nmz104
TI  - Utility of Ketone Supplementation to Enhance Physical Performance: A Systematic Review
AB  - Ingesting exogenous ketone bodies has been touted as producing ergogenic effects by altering substrate metabolism; however, research findings from recent studies appear inconsistent. This systematic review aimed to aggregate data from the current literature to examine the impact of consuming ketone supplements on enhancing physical performance. A systematic search was performed for randomized controlled trials that measured physical performance outcomes in response to ingesting exogenous ketone supplements compared with a control (nutritive or non-nutritive) in humans. A total of 161 articles were screened. Data were extracted from 10 eligible studies (112 participants; 109 men, 3 women ) containing 16 performance outcomes [lower-body power (n = 8) and endurance performance (n = 8)]. Ketone supplements were grouped as ketone esters (n = 8) or ketone salts/precursors (n = 8). Of the 16 performance outcomes identified by the systematic review, 3 reported positive, 10 reported null, and 3 reported negative effects of ketone supplementation on physical performance compared with controls. Heterogeneity was detected for lower-body power ( Q = 40, I2 = 83%, P < 0.01) and endurance performance (Q = 95, I2 = 93%, P < 0.01) between studies. Similarly high levels of heterogeneity were detected in studies providing ketone esters (Q = 111, I2 = 93%, P < 0.01), and to a lesser extent studies with ketone salts/precursors (Q = 25, I2 = 72%, P < 0.01). Heterogeneity across studies makes it difficult to conclude any benefit or detriment to consuming ketone supplements on physical performance. This systematic review discusses factors within individual studies that may contribute to discordant outcomes across investigations to elucidate if there is sufficient evidence to warrant recommendation of consuming exogenous ketone supplements to enhance physical performance. the user interface, features and functions, trustworthiness, ease and speed of obtaining predictions, and practicality of the export file(s). Conclusions The workload savings afforded in the automated simulation came with increased risk of missing relevant records. Supplementing a single reviewer’s decisions with relevance predictions (semi-automated simulation) sometimes reduced the proportion missed, but performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable. is effective in treating depression in adolescents. Physical activity sessions should be at least moderately intense [rate of perceived exertion (RPE) between 11 and 13] to be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2019
DA  - 2019-10-05
JO  - {'id': 'https://openalex.org/S2491932416', 'issn_l': '2161-8313', 'issn': ['2161-8313', '2156-5376'], 'display_name': 'Advances in Nutrition', 'publisher': 'American Society for Nutrition', 'type': 'journal', 'url': 'https://academic.oup.com/advances/article-pdf/11/2/412/32667241/nmz104.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'pd'}
DP  - OpenAlex
AU  - Lee M. Margolis
AU  - Kevin S. O'Fallon
ER  - 

56.
TY  - journal-article
ID  - https://openalex.org/W3185963978
DO  - https://doi.org/10.1016/j.addr.2021.113872
TI  - Adherence to minimal experimental requirements for defining extracellular vesicles and their functions
AB  - Rigorous measures are required to cope with the advance of extracellular vesicle (EV) research, from 183 studies published in 2012 to 2,309 studies published in 2020. The International Society for Extracellular Vesicles (ISEV) proposed Minimal Information for Studies of Extracellular Vesicles (MISEV) guidelines in 2014, updated in 2018, for assuring and improving EV research quality. We performed a systematic review using a text mining approach to assess adherence to MISEV criteria. A keyword search was conducted in 5,093 accessible publications over the period 2012-2020 and analyzed the methodology used for EV isolation and characterization. We found a significant improvement over the years particularly regarding EV characterization where recent papers used a higher number of methods and EV markers to check for quantity and purity. Interestingly, we also found that EV papers using more methods and EV markers were cited more frequently. Papers citing MISEV criteria were more prone to use a higher number of characterization methods. We therefore established a concise checklist summarizing MISEV criteria to support EV researchers towards reaching the highest standards in the field. (Q = 95, I2 = 93%, P < 0.01) between studies. Similarly high levels of heterogeneity were detected in studies providing ketone esters (Q = 111, I2 = 93%, P < 0.01), and to a lesser extent studies with ketone salts/precursors (Q = 25, I2 = 72%, P < 0.01). Heterogeneity across studies makes it difficult to conclude any benefit or detriment to consuming ketone supplements on physical performance. This systematic review discusses factors within individual studies that may contribute to discordant outcomes across investigations to elucidate if there is sufficient evidence to warrant recommendation of consuming exogenous ketone supplements to enhance physical performance. the user interface, features and functions, trustworthiness, ease and speed of obtaining predictions, and practicality of the export file(s). Conclusions The workload savings afforded in the automated simulation came with increased risk of missing relevant records. Supplementing a single reviewer’s decisions with relevance predictions (semi-automated simulation) sometimes reduced the proportion missed, but performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable. is effective in treating depression in adolescents. Physical activity sessions should be at least moderately intense [rate of perceived exertion (RPE) between 11 and 13] to be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2021
DA  - 2021-07-17
JO  - {'id': 'https://openalex.org/S114437232', 'issn_l': '0169-409X', 'issn': ['1872-8294', '0169-409X'], 'display_name': 'Advanced Drug Delivery Reviews', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'https://doi.org/10.1016/j.addr.2021.113872', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Rodolphe Poupardin
AU  - Martin Wolf
AU  - Dirk Strunk
ER  - 

57.
TY  - journal-article
ID  - https://openalex.org/W2560701680
DO  - https://doi.org/10.1371/journal.pone.0167170
TI  - Development of a Search Strategy for an Evidence Based Retrieval Service
AB  - Physicians are often encouraged to locate answers for their clinical queries via an evidence-based literature search approach. The methods used are often not clearly specified. Inappropriate search strategies, time constraint and contradictory information complicate evidence retrieval.Our study aimed to develop a search strategy to answer clinical queries among physicians in a primary care setting.Six clinical questions of different medical conditions seen in primary care were formulated. A series of experimental searches to answer each question was conducted on 3 commonly advocated medical databases. We compared search results from a PICO (patients, intervention, comparison, outcome) framework for questions using different combinations of PICO elements. We also compared outcomes from doing searches using text words, Medical Subject Headings (MeSH), or a combination of both. All searches were documented using screenshots and saved search strategies.Answers to all 6 questions using the PICO framework were found. A higher number of systematic reviews were obtained using a 2 PICO element search compared to a 4 element search. A more optimal choice of search is a combination of both text words and MeSH terms. Despite searching using the Systematic Review filter, many non-systematic reviews or narrative reviews were found in PubMed. There was poor overlap between outcomes of searches using different databases. The duration of search and screening for the 6 questions ranged from 1 to 4 hours.This strategy has been shown to be feasible and can provide evidence to doctors' clinical questions. It has the potential to be incorporated into an interventional study to determine the impact of an online evidence retrieval system. discordant outcomes across investigations to elucidate if there is sufficient evidence to warrant recommendation of consuming exogenous ketone supplements to enhance physical performance. the user interface, features and functions, trustworthiness, ease and speed of obtaining predictions, and practicality of the export file(s). Conclusions The workload savings afforded in the automated simulation came with increased risk of missing relevant records. Supplementing a single reviewer’s decisions with relevance predictions (semi-automated simulation) sometimes reduced the proportion missed, but performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable. is effective in treating depression in adolescents. Physical activity sessions should be at least moderately intense [rate of perceived exertion (RPE) between 11 and 13] to be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2016
DA  - 2016-12-09
JO  - {'id': 'https://openalex.org/S202381698', 'issn_l': '1932-6203', 'issn': ['1932-6203'], 'display_name': 'PLOS ONE', 'publisher': 'Public Library of Science', 'type': 'journal', 'url': 'https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0167170&type=printable', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Gah Juan Ho
AU  - Su May Liew
AU  - Chirk Jenn Ng
AU  - Ranita Hisham
AU  - Paul Glasziou
ER  - 

58.
TY  - journal-article
ID  - https://openalex.org/W2905431510
DO  - https://doi.org/10.1002/jrsm.1335
TI  - Usage of automation tools in systematic reviews
AB  - Systematic reviews are a cornerstone of today's evidence-informed decision making. With the rapid expansion of questions to be addressed and scientific information produced, there is a growing workload on reviewers, making the current practice unsustainable without the aid of automation tools. While many automation tools have been developed and are available, uptake seems to be lagging. For this reason, we set out to investigate the current level of uptake and what the potential barriers and facilitators are for the adoption of automation tools in systematic reviews. We deployed surveys among systematic reviewers that gathered information on tool uptake, demographics, systematic review characteristics, and barriers and facilitators for uptake. Systematic reviewers from multiple domains were targeted during recruitment; however, responders were predominantly from the biomedical sciences. We found that automation tools are currently not widely used among the participants. When tools are used, participants mostly learn about them from their environment, for example, through colleagues, peers, or organization. Tools are often chosen on the basis of user experience, either by own experience or from colleagues or peers. Lastly, licensing, steep learning curve, lack of support, and mismatch to workflow are often reported by participants as relevant barriers. While conclusions can only be drawn for the biomedical field, our work provides evidence and confirms the conclusions and recommendations of previous work, which was based on expert opinions. Furthermore, our study highlights the importance that organizations and best practices in a field can have for the uptake of automation tools for systematic reviews. the impact of an online evidence retrieval system. discordant outcomes across investigations to elucidate if there is sufficient evidence to warrant recommendation of consuming exogenous ketone supplements to enhance physical performance. the user interface, features and functions, trustworthiness, ease and speed of obtaining predictions, and practicality of the export file(s). Conclusions The workload savings afforded in the automated simulation came with increased risk of missing relevant records. Supplementing a single reviewer’s decisions with relevance predictions (semi-automated simulation) sometimes reduced the proportion missed, but performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable. is effective in treating depression in adolescents. Physical activity sessions should be at least moderately intense [rate of perceived exertion (RPE) between 11 and 13] to be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2019
DA  - 2019-03-01
JO  - {'id': 'https://openalex.org/S205768342', 'issn_l': '1759-2879', 'issn': ['1759-2879', '1759-2887'], 'display_name': 'Research Synthesis Methods', 'publisher': 'Wiley-Blackwell', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Allard J. van Altena
AU  - René Spijker
AU  - Silvia D. Olabarriaga
ER  - 

59.
TY  - journal-article
ID  - https://openalex.org/W3153816950
DO  - https://doi.org/10.1002/mar.21491
TI  - Factors influencing users' adoption and use of conversational agents: A systematic review
AB  - No Abstract Found
PY  - 2021
DA  - 2021-07-01
JO  - {'id': 'https://openalex.org/S102896891', 'issn_l': '0742-6046', 'issn': ['0742-6046', '1520-6793'], 'display_name': 'Psychology & Marketing', 'publisher': 'Wiley-Blackwell', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Erin Ling
AU  - Iis P. Tussyadiah
AU  - Aarni Tuomi
AU  - Jason L. Stienmetz
AU  - Athina Ioannou
ER  - 

60.
TY  - journal-article
ID  - https://openalex.org/W1994916733
DO  - https://doi.org/10.1186/s13063-015-0575-7
TI  - Making research articles fit for purpose: structured reporting of key methods and findings
AB  - ‘If physicians are to base treatment decisions on the evidence in the medical literature, all the relevant results of trials must be available easily and consistently. Yet it is common to have trouble identifying the hypothesis, the research question, and the design of a published trial. It is even more common to lose count of the participants or to be unable to tell who received what therapies and the type of analysis used. As a result, it is often impossible to know whether the conclusions are justified by the data’ [1]. reviewers that gathered information on tool uptake, demographics, systematic review characteristics, and barriers and facilitators for uptake. Systematic reviewers from multiple domains were targeted during recruitment; however, responders were predominantly from the biomedical sciences. We found that automation tools are currently not widely used among the participants. When tools are used, participants mostly learn about them from their environment, for example, through colleagues, peers, or organization. Tools are often chosen on the basis of user experience, either by own experience or from colleagues or peers. Lastly, licensing, steep learning curve, lack of support, and mismatch to workflow are often reported by participants as relevant barriers. While conclusions can only be drawn for the biomedical field, our work provides evidence and confirms the conclusions and recommendations of previous work, which was based on expert opinions. Furthermore, our study highlights the importance that organizations and best practices in a field can have for the uptake of automation tools for systematic reviews. the impact of an online evidence retrieval system. discordant outcomes across investigations to elucidate if there is sufficient evidence to warrant recommendation of consuming exogenous ketone supplements to enhance physical performance. the user interface, features and functions, trustworthiness, ease and speed of obtaining predictions, and practicality of the export file(s). Conclusions The workload savings afforded in the automated simulation came with increased risk of missing relevant records. Supplementing a single reviewer’s decisions with relevance predictions (semi-automated simulation) sometimes reduced the proportion missed, but performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable. is effective in treating depression in adolescents. Physical activity sessions should be at least moderately intense [rate of perceived exertion (RPE) between 11 and 13] to be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2015
DA  - 2015-02-20
JO  - {'id': 'https://openalex.org/S109512841', 'issn_l': '1745-6215', 'issn': ['1745-6215'], 'display_name': 'Trials', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://trialsjournal.biomedcentral.com/track/pdf/10.1186/s13063-015-0575-7', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Douglas G. Altman
ER  - 

61.
TY  - journal-article
ID  - https://openalex.org/W2946572280
DO  - https://doi.org/10.3390/su11102910
TI  - Tangible Technologies for Childhood Education: A Systematic Review
AB  - This study reviews published scientific literature on the use of tangible technologies in childhood education, in order to (a) identify the what tangible technologies have been used, (b) recognize the educational purposes and uses these technologies of, and (c) present a synthesis of the available empirical evidence on its educational effectiveness. After systematically searching in WoS, 288 relevant articles were located and analyzed using the Science Mapping Analysis Software Tool from 1968 to 2018. Then, 29 relevant papers of the last five years were included in the review study. For each article, we analyze the purpose of the study, the type of tangible technology used, the research method applied, the sample characteristics and the main results observed. The articles reviewed suggest that the main tangible technology used in childhood education is the tablet and literacy (basic and emergent) is the area most studied with promising results. them from their environment, for example, through colleagues, peers, or organization. Tools are often chosen on the basis of user experience, either by own experience or from colleagues or peers. Lastly, licensing, steep learning curve, lack of support, and mismatch to workflow are often reported by participants as relevant barriers. While conclusions can only be drawn for the biomedical field, our work provides evidence and confirms the conclusions and recommendations of previous work, which was based on expert opinions. Furthermore, our study highlights the importance that organizations and best practices in a field can have for the uptake of automation tools for systematic reviews. the impact of an online evidence retrieval system. discordant outcomes across investigations to elucidate if there is sufficient evidence to warrant recommendation of consuming exogenous ketone supplements to enhance physical performance. the user interface, features and functions, trustworthiness, ease and speed of obtaining predictions, and practicality of the export file(s). Conclusions The workload savings afforded in the automated simulation came with increased risk of missing relevant records. Supplementing a single reviewer’s decisions with relevance predictions (semi-automated simulation) sometimes reduced the proportion missed, but performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable. is effective in treating depression in adolescents. Physical activity sessions should be at least moderately intense [rate of perceived exertion (RPE) between 11 and 13] to be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2019
DA  - 2019-05-22
JO  - {'id': 'https://openalex.org/S10134376', 'issn_l': '2071-1050', 'issn': ['2071-1050'], 'display_name': 'Sustainability', 'publisher': 'MDPI', 'type': 'journal', 'url': 'https://www.mdpi.com/2071-1050/11/10/2910/pdf?version=1558522307', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Carina Soledad González González
AU  - María Dolores Guzmán Franco
AU  - Alfonso Infante Moro
ER  - 

62.
TY  - journal-article
ID  - https://openalex.org/W1203019046
DO  - https://doi.org/10.1007/s10796-015-9589-7
TI  - Advanced analytics for the automation of medical systematic reviews
AB  - No Abstract Found
PY  - 2016
DA  - 2016-04-01
JO  - {'id': 'https://openalex.org/S181659395', 'issn_l': '1387-3326', 'issn': ['1572-9419', '1387-3326'], 'display_name': 'Information Systems Frontiers', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Prem Timsina
AU  - Jun Liu
AU  - Omar F. El-Gayar
ER  - 

63.
TY  - journal-article
ID  - https://openalex.org/W2478599206
DO  - https://doi.org/10.1136/bmjopen-2016-011841
TI  - Live cumulative network meta-analysis: protocol for second-line treatments in advanced non-small-cell lung cancer with wild-type or unknown status for epidermal growth factor receptor
AB  - Many second-line treatments for advanced non-small-cell lung cancer (NSCLC) have been assessed in randomised controlled trials, but which treatments work the best remains unclear. Novel treatments are being rapidly developed. We need a comprehensive up-to-date evidence synthesis of all these treatments. We present the protocol for a live cumulative network meta-analysis (NMA) to address this need.We will consider trials of second-line treatments in patients with advanced NSCLC with wild-type or unknown epidermal growth factor receptor status. We will consider any single agent of cytotoxic chemotherapy, targeted therapy, combination of cytotoxic chemotherapy and targeted therapy and any combination of targeted therapies. The primary outcomes will be overall survival and progression-free survival. The live cumulative NMA will be initiated with a NMA and then iterations will be repeated at regular intervals to keep the NMA up-to-date over time. We have defined the update frequency as 4 months, based on an assessment of the pace of evidence production on this topic. Each iteration will consist of six methodological steps: adaptive search for treatments and trials, screening of reports and selection of trials, data extraction, assessment of risk of bias, update of the network of trials and synthesis, and dissemination. We will set up a research community in lung cancer, with different groups of contributors of different skills. We will distribute tasks through online crowdsourcing. This proof-of-concept study in second-line treatments of advanced NSCLC will allow one for assessing the feasibility of live cumulative NMA and opening the path for this new form of synthesis.Ethical approval is not required because our study will not include confidential participant data and interventions. The description of all the steps and the results of this live cumulative NMA will be available online.CRD42015017592. features and functions, trustworthiness, ease and speed of obtaining predictions, and practicality of the export file(s). Conclusions The workload savings afforded in the automated simulation came with increased risk of missing relevant records. Supplementing a single reviewer’s decisions with relevance predictions (semi-automated simulation) sometimes reduced the proportion missed, but performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable. is effective in treating depression in adolescents. Physical activity sessions should be at least moderately intense [rate of perceived exertion (RPE) between 11 and 13] to be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2016
DA  - 2016-08-01
JO  - {'id': 'https://openalex.org/V79054089', 'issn_l': '2044-6055', 'issn': ['2044-6055'], 'display_name': 'BMJ Open', 'publisher': 'BMJ', 'type': 'journal', 'url': 'https://bmjopen.bmj.com/content/bmjopen/6/8/e011841.full.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc'}
DP  - OpenAlex
AU  - Perrine Créquit
AU  - Ludovic Trinquart
AU  - Philippe Ravaud
ER  - 

64.
TY  - journal-article
ID  - https://openalex.org/W2801856446
DO  - https://doi.org/10.1186/s13643-018-0724-7
TI  - Automated screening of research studies for systematic reviews using study characteristics
AB  - Screening candidate studies for inclusion in a systematic review is time-consuming when conducted manually. Automation tools could reduce the human effort devoted to screening. Existing methods use supervised machine learning which train classifiers to identify relevant words in the abstracts of candidate articles that have previously been labelled by a human reviewer for inclusion or exclusion. Such classifiers typically reduce the number of abstracts requiring manual screening by about 50%.We extracted four key characteristics of observational studies (population, exposure, confounders and outcomes) from the text of titles and abstracts for all articles retrieved using search strategies from systematic reviews. Our screening method excluded studies if they did not meet a predefined set of characteristics. The method was evaluated using three systematic reviews. Screening results were compared to the actual inclusion list of the reviews.The best screening threshold rule identified studies that mentioned both exposure (E) and outcome (O) in the study abstract. This screening rule excluded 93.7% of retrieved studies with a recall of 98%.Filtering studies for inclusion in a systematic review based on the detection of key study characteristics in abstracts significantly outperformed standard approaches to automated screening and appears worthy of further development and evaluation. will set up a research community in lung cancer, with different groups of contributors of different skills. We will distribute tasks through online crowdsourcing. This proof-of-concept study in second-line treatments of advanced NSCLC will allow one for assessing the feasibility of live cumulative NMA and opening the path for this new form of synthesis.Ethical approval is not required because our study will not include confidential participant data and interventions. The description of all the steps and the results of this live cumulative NMA will be available online.CRD42015017592. features and functions, trustworthiness, ease and speed of obtaining predictions, and practicality of the export file(s). Conclusions The workload savings afforded in the automated simulation came with increased risk of missing relevant records. Supplementing a single reviewer’s decisions with relevance predictions (semi-automated simulation) sometimes reduced the proportion missed, but performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable. is effective in treating depression in adolescents. Physical activity sessions should be at least moderately intense [rate of perceived exertion (RPE) between 11 and 13] to be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2018
DA  - 2018-04-25
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://systematicreviewsjournal.biomedcentral.com/track/pdf/10.1186/s13643-018-0724-7', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Guy Tsafnat
AU  - Paul Glasziou
AU  - George Karystianis
AU  - Enrico Coiera
ER  - 

65.
TY  - proceedings-article
ID  - https://openalex.org/W2897159192
DO  - https://doi.org/10.23919/picmet.2018.8481746
TI  - Improving Systematic Literature Review with Automation and Bibliometrics
AB  - The foundation of a good research paper is the literature review. But with the vast amount of research papers available today it has become more challenging to search and screen for appropriate papers to include in the review. This paper has analyzed different approaches to a literature review and explains the evolution from the traditional literature review to a more modern systematic literature review. The systematic literature review (SLR) can be classified into four key stages: Planning, Conducting, Analysis & Synthesis, and Reporting. The purpose of this paper is to propose a modified SLR process that includes automation and bibliometrics. Automation is a method that can operationalize the manual tasks of the SLR by using specific tools and computer systems. Bibliometrics is a method to analyze the bibliographic data of published literature to provide an overview of the body of knowledge for a given field of inquiry. The proposed modified SLR process improves the previous versions that rely only on manual search and extraction, by combining the strength of both methods and integrating them into the stages of the SLR process. This addition to the traditional SLR will facilitate the process to produce a faster and more effective Literature review. a research community in lung cancer, with different groups of contributors of different skills. We will distribute tasks through online crowdsourcing. This proof-of-concept study in second-line treatments of advanced NSCLC will allow one for assessing the feasibility of live cumulative NMA and opening the path for this new form of synthesis.Ethical approval is not required because our study will not include confidential participant data and interventions. The description of all the steps and the results of this live cumulative NMA will be available online.CRD42015017592. features and functions, trustworthiness, ease and speed of obtaining predictions, and practicality of the export file(s). Conclusions The workload savings afforded in the automated simulation came with increased risk of missing relevant records. Supplementing a single reviewer’s decisions with relevance predictions (semi-automated simulation) sometimes reduced the proportion missed, but performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable. is effective in treating depression in adolescents. Physical activity sessions should be at least moderately intense [rate of perceived exertion (RPE) between 11 and 13] to be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2018
DA  - 2018-08-01
JO  - {'id': 'https://openalex.org/S4306420711', 'issn_l': None, 'issn': None, 'display_name': 'Portland International Conference on Management of Engineering and Technology', 'publisher': None, 'type': 'conference', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Nonthapat Pulsiri
AU  - Ronald Vatananan-Thesenvitz
ER  - 

66.
TY  - proceedings-article
ID  - https://openalex.org/W2621485502
DO  - https://doi.org/10.1145/3084226.3084243
TI  - A Machine Learning Approach for Semi-Automated Search and Selection in Literature Studies
AB  - Background. Search and selection of primary studies in Systematic Literature Reviews (SLR) is labour intensive, and hard to replicate and update. Aims. We explore a machine learning approach to support semi-automated search and selection in SLRs to address these weaknesses. Method. We 1) train a classifier on an initial set of papers, 2) extend this set of papers by automated search and snowballing, 3) have the researcher validate the top paper, selected by the classifier, and 4) update the set of papers and iterate the process until a stopping criterion is met. Results. We demonstrate with a proof-of-concept tool that the proposed automated search and selection approach generates valid search strings and that the performance for subsets of primary studies can reduce the manual work by half. Conclusions. The approach is promising and the demonstrated advantages include cost savings and replicability. The next steps include further tool development and evaluate the approach on a complete SLR. that rely only on manual search and extraction, by combining the strength of both methods and integrating them into the stages of the SLR process. This addition to the traditional SLR will facilitate the process to produce a faster and more effective Literature review. a research community in lung cancer, with different groups of contributors of different skills. We will distribute tasks through online crowdsourcing. This proof-of-concept study in second-line treatments of advanced NSCLC will allow one for assessing the feasibility of live cumulative NMA and opening the path for this new form of synthesis.Ethical approval is not required because our study will not include confidential participant data and interventions. The description of all the steps and the results of this live cumulative NMA will be available online.CRD42015017592. features and functions, trustworthiness, ease and speed of obtaining predictions, and practicality of the export file(s). Conclusions The workload savings afforded in the automated simulation came with increased risk of missing relevant records. Supplementing a single reviewer’s decisions with relevance predictions (semi-automated simulation) sometimes reduced the proportion missed, but performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable. is effective in treating depression in adolescents. Physical activity sessions should be at least moderately intense [rate of perceived exertion (RPE) between 11 and 13] to be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2017
DA  - 2017-06-15
JO  - {'id': 'https://openalex.org/S4306418396', 'issn_l': None, 'issn': None, 'display_name': 'Evaluation and Assessment in Software Engineering', 'publisher': None, 'type': 'conference', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Rasmus Ros
AU  - Elizabeth Bjarnason
AU  - Per Runeson
ER  - 

67.
TY  - proceedings-article
ID  - https://openalex.org/W2741023348
DO  - https://doi.org/10.1145/3077136.3080707
TI  - A Test Collection for Evaluating Retrieval of Studies for Inclusion in Systematic Reviews
AB  - This paper introduces a test collection for evaluating the effectiveness of different methods used to retrieve research studies for inclusion in systematic reviews. Systematic reviews appraise and synthesise studies that meet specific inclusion criteria. Systematic reviews intended for a biomedical science audience use boolean queries with many, often complex, search clauses to retrieve studies; these are then manually screened to determine eligibility for inclusion in the review. This process is expensive and time consuming. The development of systems that improve retrieval effectiveness will have an immediate impact by reducing the complexity and resources required for this process. Our test collection consists of approximately 26 million research studies extracted from the freely available MEDLINE database, 94 review (query) topics extracted from Cochrane systematic reviews, and corresponding relevance assessments. Tasks for which the collection can be used for information retrieval system evaluation are described and the use of the collection to evaluate common baselines within one such task is demonstrated. The test collection is available at https://github.com/ielab/SIGIR2017-PICO-Collection. combining the strength of both methods and integrating them into the stages of the SLR process. This addition to the traditional SLR will facilitate the process to produce a faster and more effective Literature review. a research community in lung cancer, with different groups of contributors of different skills. We will distribute tasks through online crowdsourcing. This proof-of-concept study in second-line treatments of advanced NSCLC will allow one for assessing the feasibility of live cumulative NMA and opening the path for this new form of synthesis.Ethical approval is not required because our study will not include confidential participant data and interventions. The description of all the steps and the results of this live cumulative NMA will be available online.CRD42015017592. features and functions, trustworthiness, ease and speed of obtaining predictions, and practicality of the export file(s). Conclusions The workload savings afforded in the automated simulation came with increased risk of missing relevant records. Supplementing a single reviewer’s decisions with relevance predictions (semi-automated simulation) sometimes reduced the proportion missed, but performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable. is effective in treating depression in adolescents. Physical activity sessions should be at least moderately intense [rate of perceived exertion (RPE) between 11 and 13] to be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2017
DA  - 2017-08-07
JO  - {'id': 'https://openalex.org/S4306418959', 'issn_l': None, 'issn': None, 'display_name': 'International ACM SIGIR Conference on Research and Development in Information Retrieval', 'publisher': None, 'type': 'conference', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Harrisen Scells
AU  - Guido Zuccon
AU  - Bevan Koopman
AU  - Anthony Deacon
AU  - Leif Azzopardi
AU  - Shlomo Geva
ER  - 

68.
TY  - journal-article
ID  - https://openalex.org/W2904388176
DO  - https://doi.org/10.12688/wellcomeopenres.14738.3
TI  - The development and evaluation of an online application to assist in the extraction of data from graphs for use in systematic reviews
AB  - Background: The extraction of data from the reports of primary studies, on which the results of systematic reviews depend, needs to be carried out accurately. To aid reliability, it is recommended that two researchers carry out data extraction independently. The extraction of statistical data from graphs in PDF files is particularly challenging, as the process is usually completely manual, and reviewers need sometimes to revert to holding a ruler against the page to read off values: an inherently time-consuming and error-prone process. Methods: To mitigate some of the above problems we developed a new web-based graphical data extraction tool to assist reviewers in extracting data from graphs. This tool aims to facilitate more accurate and timely data extraction through a user interface which can be used to extract data through mouse clicks. We carried out a non-inferiority evaluation to examine its performance in comparison to standard practice. Results: We found that our new graphical data extraction tool is not inferior to users' prior preferred current approaches. Our study was not designed to show superiority, but suggests that there may be a saving in time of around 6 minutes per graph, accompanied by a substantial increase in accuracy. Conclusions: Our study suggests that the incorporation of this type of tool in online systematic review software would be beneficial in facilitating the production of accurate and timely evidence synthesis to improve decision-making. will allow one for assessing the feasibility of live cumulative NMA and opening the path for this new form of synthesis.Ethical approval is not required because our study will not include confidential participant data and interventions. The description of all the steps and the results of this live cumulative NMA will be available online.CRD42015017592. features and functions, trustworthiness, ease and speed of obtaining predictions, and practicality of the export file(s). Conclusions The workload savings afforded in the automated simulation came with increased risk of missing relevant records. Supplementing a single reviewer’s decisions with relevance predictions (semi-automated simulation) sometimes reduced the proportion missed, but performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable. is effective in treating depression in adolescents. Physical activity sessions should be at least moderately intense [rate of perceived exertion (RPE) between 11 and 13] to be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2019
DA  - 2019-03-07
JO  - {'id': 'https://openalex.org/V4210218052', 'issn_l': '2398-502X', 'issn': ['2398-502X'], 'display_name': 'Wellcome open research', 'publisher': 'Wellcome', 'type': 'journal', 'url': 'https://doi.org/10.12688/wellcomeopenres.14738.3', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Fala Cramond
AU  - Alison O'Mara-Eves
AU  - Lee Doran-Constant
AU  - Andrew S.C. Rice
AU  - Malcolm R. Macleod
AU  - James D. Thomas
ER  - 

69.
TY  - journal-article
ID  - https://openalex.org/W3128139448
DO  - https://doi.org/10.3390/data6020018
TI  - The State of the Art in Methodologies of Course Recommender Systems—A Review of Recent Research
AB  - In recent years, education institutions have offered a wide range of course selections with overlaps. This presents significant challenges to students in selecting successful courses that match their current knowledge and personal goals. Although many studies have been conducted on Recommender Systems (RS), a review of methodologies used in course RS is still insufficiently explored. To fill this literature gap, this paper presents the state of the art of methodologies used in course RS along with the summary of the types of data sources used to evaluate these techniques. This review aims to recognize emerging trends in course RS techniques in recent research literature to deliver insights for researchers for further investigation. We provide a systematic review process followed by research findings on the current methodologies implemented in different course RS in selected research journals such as: collaborative, content-based, knowledge-based, Data Mining (DM), hybrid, statistical and Conversational RS (CRS). This study analyzed publications between 2016 and June 2020, in three repositories; IEEE Xplore, ACM, and Google Scholar. These papers were explored and classified based on the methodology used in recommending courses. This review has revealed that there is a growing popularity in hybrid course RS and followed by DM techniques in recent publications. However, few CRS-based course RS were present in the selected publications. Finally, we discussed future avenues based on the research outcome, which might lead to next-generation course RS. allow one for assessing the feasibility of live cumulative NMA and opening the path for this new form of synthesis.Ethical approval is not required because our study will not include confidential participant data and interventions. The description of all the steps and the results of this live cumulative NMA will be available online.CRD42015017592. features and functions, trustworthiness, ease and speed of obtaining predictions, and practicality of the export file(s). Conclusions The workload savings afforded in the automated simulation came with increased risk of missing relevant records. Supplementing a single reviewer’s decisions with relevance predictions (semi-automated simulation) sometimes reduced the proportion missed, but performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable. is effective in treating depression in adolescents. Physical activity sessions should be at least moderately intense [rate of perceived exertion (RPE) between 11 and 13] to be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2021
DA  - 2021-02-11
JO  - {'id': 'https://openalex.org/S4210226510', 'issn_l': '2306-5729', 'issn': ['2306-5729'], 'display_name': 'Data', 'publisher': 'MDPI', 'type': 'journal', 'url': 'https://www.mdpi.com/2306-5729/6/2/18/pdf?version=1613980805', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Deepani B. Guruge
AU  - Rajan Kadel
AU  - Sharly Joana Halder
ER  - 

70.
TY  - journal-article
ID  - https://openalex.org/W2795548366
DO  - https://doi.org/10.1109/tse.2018.2870388
TI  - Finding Trends in Software Research
AB  - This paper explores the structure of research papers in software engineering. Using text mining, we study 35,391 software engineering (SE) papers from 34 leading SE venues over the last 25 years. These venues were divided, nearly evenly, between conferences and journals. An important aspect of this analysis is that it is fully automated and repeatable. To achieve that automation, we used a stable topic modeling technique called LDADE that fully automates parameter tuning in LDA. Using LDADE, we mine 11 topics that represent much of the structure of contemporary SE. The 11 topics presented here should not be "set in stone" as the only topics worthy of study in SE. Rather our goal is to report that (a) text mining methods can detect large scale trends within our community; (b) those topic change with time; so (c) it is important to have automatic agents that can update our understanding of our community whenever new data arrives. June 2020, in three repositories; IEEE Xplore, ACM, and Google Scholar. These papers were explored and classified based on the methodology used in recommending courses. This review has revealed that there is a growing popularity in hybrid course RS and followed by DM techniques in recent publications. However, few CRS-based course RS were present in the selected publications. Finally, we discussed future avenues based on the research outcome, which might lead to next-generation course RS. allow one for assessing the feasibility of live cumulative NMA and opening the path for this new form of synthesis.Ethical approval is not required because our study will not include confidential participant data and interventions. The description of all the steps and the results of this live cumulative NMA will be available online.CRD42015017592. features and functions, trustworthiness, ease and speed of obtaining predictions, and practicality of the export file(s). Conclusions The workload savings afforded in the automated simulation came with increased risk of missing relevant records. Supplementing a single reviewer’s decisions with relevance predictions (semi-automated simulation) sometimes reduced the proportion missed, but performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable. is effective in treating depression in adolescents. Physical activity sessions should be at least moderately intense [rate of perceived exertion (RPE) between 11 and 13] to be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2019
DA  - 2019-01-01
JO  - {'id': 'https://openalex.org/S8351582', 'issn_l': '0098-5589', 'issn': ['0098-5589', '1939-3520', '2326-3881'], 'display_name': 'IEEE Transactions on Software Engineering', 'publisher': 'IEEE Computer Society', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - George Mathew
AU  - Amritanshu Agrawal
AU  - Tim Menzies
ER  - 

71.
TY  - journal-article
ID  - https://openalex.org/W1882531574
DO  - https://doi.org/10.1016/j.siny.2015.10.002
TI  - Systematic reviews and meta-analysis
AB  - Systematic reviews and meta-analyses are at the top of the 'evidence hierarchy' when assessing the effectiveness of health interventions. As such, they are important sources of synthesized information for decision-makers including consumers, clinicians, funders, payers, regulators, and researchers. The main reasons for undertaking systematic reviews and meta-analyses are to minimize bias and to maximize data by collating all the relevant, available evidence on a particular topic. In order to correctly inform decision-makers, but not mislead them, a number of key methodological conditions need to be met when undertaking these types of analysis. In this article we first review the history of systematic reviews and meta-analyses and then outline those conditions that may lead to the correct, or incorrect, use of these types of study. Also, new variations on standard systematic review methods are explored, with the pros and cons of each outlined. automatic agents that can update our understanding of our community whenever new data arrives. June 2020, in three repositories; IEEE Xplore, ACM, and Google Scholar. These papers were explored and classified based on the methodology used in recommending courses. This review has revealed that there is a growing popularity in hybrid course RS and followed by DM techniques in recent publications. However, few CRS-based course RS were present in the selected publications. Finally, we discussed future avenues based on the research outcome, which might lead to next-generation course RS. allow one for assessing the feasibility of live cumulative NMA and opening the path for this new form of synthesis.Ethical approval is not required because our study will not include confidential participant data and interventions. The description of all the steps and the results of this live cumulative NMA will be available online.CRD42015017592. features and functions, trustworthiness, ease and speed of obtaining predictions, and practicality of the export file(s). Conclusions The workload savings afforded in the automated simulation came with increased risk of missing relevant records. Supplementing a single reviewer’s decisions with relevance predictions (semi-automated simulation) sometimes reduced the proportion missed, but performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable. is effective in treating depression in adolescents. Physical activity sessions should be at least moderately intense [rate of perceived exertion (RPE) between 11 and 13] to be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2015
DA  - 2015-12-01
JO  - {'id': 'https://openalex.org/S4210205002', 'issn_l': '1744-165X', 'issn': ['1744-165X', '1878-0946'], 'display_name': 'Seminars in fetal & neonatal medicine', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Lisa M. Askie
AU  - Martin Offringa
ER  - 

72.
TY  - journal-article
ID  - https://openalex.org/W2893752993
DO  - https://doi.org/10.1016/j.jclinepi.2018.08.023
TI  - Automatic extraction of quantitative data from ClinicalTrials.gov to conduct meta-analyses
AB  - Systematic reviews and meta-analyses are labor-intensive and time-consuming. Automated extraction of quantitative data from primary studies can accelerate this process. ClinicalTrials.gov, launched in 2000, is the world's largest trial repository of results data from clinical trials; it has been used as a source instead of journal articles. We have developed a Web application called EXACT (EXtracting Accurate efficacy and safety information from ClinicalTrials.gov) that allows users without advanced programming skills to automatically extract data from ClinicalTrials.gov in analysis-ready format. We have also used the automatically extracted data to examine the reproducibility of meta-analyses in three published systematic reviews.We developed a Python-based software application (EXACT) that automatically extracts data required for meta-analysis from the ClinicalTrials.gov database in a spreadsheet format. We confirmed the accuracy of the extracted data and then used those data to repeat meta-analyses in three published systematic reviews. To ensure that we used the same statistical methods and outcomes as the published systematic reviews, we repeated the meta-analyses using data manually extracted from the relevant journal articles. For the outcomes whose results we were able to reproduce using those journal article data, we examined the usability of ClinicalTrials.gov data.EXACT extracted data at ClincalTrials.gov with 100% accuracy, and it required 60% less time than the usual practice of manually extracting data from journal articles. We found that 87% of the data elements extracted using EXACT matched those extracted manually from the journal articles. We were able to reproduce 24 of 28 outcomes using the journal article data. Of these 24 outcomes, we were able to reproduce 83.3% of the published estimates using data at ClinicalTrials.gov.EXACT (http://bio-nlp.org/EXACT) automatically and accurately extracted data elements from ClinicalTrials.gov and thus reduced time in data extraction. The ClinicalTrials.gov data reproduced most meta-analysis results in our study, but this conclusion needs further validation. export file(s). Conclusions The workload savings afforded in the automated simulation came with increased risk of missing relevant records. Supplementing a single reviewer’s decisions with relevance predictions (semi-automated simulation) sometimes reduced the proportion missed, but performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable. is effective in treating depression in adolescents. Physical activity sessions should be at least moderately intense [rate of perceived exertion (RPE) between 11 and 13] to be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2019
DA  - 2019-01-01
JO  - {'id': 'https://openalex.org/S64418186', 'issn_l': '0895-4356', 'issn': ['1878-5921', '0895-4356'], 'display_name': 'Journal of Clinical Epidemiology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Richeek Pradhan
AU  - David C. Hoaglin
AU  - Matthew Cornell
AU  - Weisong Liu
AU  - Victoria Wang
AU  - Hong Yu
ER  - 

73.
TY  - journal-article
ID  - https://openalex.org/W2912817959
DO  - https://doi.org/10.1038/s41598-018-36507-9
TI  - The antidepressant impact of minocycline in rodents: A systematic review and meta-analysis
AB  - Abstract Evidence from recent animal studies suggest that minocycline, a broad-spectrum antibiotic capable of regulating immune processes, may possess antidepressant properties. These studies, however, have yet to be comprehensively reviewed. Accordingly, this systematic review and meta-analysis summarizes the extant literature examining the effect of minocycline on depressive-like behavior in rodent models. PubMed, PsycINFO, and Web of Science databases were systematically searched for articles that met prespecified inclusion and exclusion criteria, and standardized mean differences (SMDs) were calculated for each continuous measure of depressive-like behavior. The overall effect of minocycline on depressive-like behavior was estimated using robust variance estimation meta-analysis. Separate subgroup analyses were conducted on diseased vs healthy animal models, different rodent species, and immobility-based vs anhedonia-based measures of depressive-like behavior. A total of 22 preclinical studies (816 animals) were included. Overall, minocycline reduced depressive-like behavior in rodents (SMD = −1.07, 95% CI −1.41–−0.74, p &lt; 0.001). Subgroup analyses revealed that minocycline reduced depressive-like behavior in diseased, but not healthy, animal models. Finally, minocycline was found to reduce both immobility-based and anhedonia-based outcomes. These findings suggest that minocycline may be an effective treatment of core depressive symptoms, and that further investigation of minocycline treatment for clinically relevant depression in humans is warranted. less time than the usual practice of manually extracting data from journal articles. We found that 87% of the data elements extracted using EXACT matched those extracted manually from the journal articles. We were able to reproduce 24 of 28 outcomes using the journal article data. Of these 24 outcomes, we were able to reproduce 83.3% of the published estimates using data at ClinicalTrials.gov.EXACT (http://bio-nlp.org/EXACT) automatically and accurately extracted data elements from ClinicalTrials.gov and thus reduced time in data extraction. The ClinicalTrials.gov data reproduced most meta-analysis results in our study, but this conclusion needs further validation. export file(s). Conclusions The workload savings afforded in the automated simulation came with increased risk of missing relevant records. Supplementing a single reviewer’s decisions with relevance predictions (semi-automated simulation) sometimes reduced the proportion missed, but performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable. is effective in treating depression in adolescents. Physical activity sessions should be at least moderately intense [rate of perceived exertion (RPE) between 11 and 13] to be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2019
DA  - 2019-01-22
JO  - {'id': 'https://openalex.org/S196734849', 'issn_l': '2045-2322', 'issn': ['2045-2322'], 'display_name': 'Scientific Reports', 'publisher': 'Nature Portfolio', 'type': 'journal', 'url': 'https://www.nature.com/articles/s41598-018-36507-9.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Daniel G. Reis
AU  - Emily J. Casteen
AU  - Stephen S. Ilardi
ER  - 

74.
TY  - journal-article
ID  - https://openalex.org/W3045380424
DO  - https://doi.org/10.1111/hir.12318
TI  - How to keep up to date with medical information using web‐based resources: a systematised review and narrative synthesis
AB  - Background Evidence Keeping up to date with the latest medical information using Web-based resources has been sparsely described, and a comprehensive up-to-date review is needed. yet Objectives be To summarise the Web-based 'channels' that may assist the actors of the health care system (clinicians, medical researchers and students) to keep up to date with medical information. Science Methods were We searched PubMed and Scopus for English language articles published between January 1990 and February 2019 that investigated ways for keeping up with medical information. We used the results from our search and relevant information from other sources to conduct a narrative synthesis. were Results on We found that resources that push information (e.g. web alerts, medical newsletters, listservs), resources that rely on the active information seeking (e.g. access to health librarians and electronic databases, podcasts, mobile apps), collaborative resources (e.g. web conferences, online journal clubs, web social media) and resources that synthesise information (e.g. bibliometrics, living systematic reviews) can contribute in keeping up with new findings and can enhance evidence-based medicine. Clinicians, medical researchers and students can benefit from the proper use of such Internet-based technological innovations. and Conclusion further Internet provides many resources that can help the actors of the health care system stay up to date with the latest scientific findings. journal articles. We found that 87% of the data elements extracted using EXACT matched those extracted manually from the journal articles. We were able to reproduce 24 of 28 outcomes using the journal article data. Of these 24 outcomes, we were able to reproduce 83.3% of the published estimates using data at ClinicalTrials.gov.EXACT (http://bio-nlp.org/EXACT) automatically and accurately extracted data elements from ClinicalTrials.gov and thus reduced time in data extraction. The ClinicalTrials.gov data reproduced most meta-analysis results in our study, but this conclusion needs further validation. export file(s). Conclusions The workload savings afforded in the automated simulation came with increased risk of missing relevant records. Supplementing a single reviewer’s decisions with relevance predictions (semi-automated simulation) sometimes reduced the proportion missed, but performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable. is effective in treating depression in adolescents. Physical activity sessions should be at least moderately intense [rate of perceived exertion (RPE) between 11 and 13] to be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2020
DA  - 2020-07-21
JO  - {'id': 'https://openalex.org/S66051165', 'issn_l': '1471-1834', 'issn': ['1365-2532', '1471-1842', '0265-6647', '1471-1834'], 'display_name': 'Health Information and Libraries Journal', 'publisher': 'Wiley-Blackwell', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Konstantinos I. Bougioukas
AU  - Emmanouil Bouras
AU  - Konstantinos N. Syrigos
AU  - Theodore Dardavessis
AU  - Anna-Bettina Haidich
ER  - 

75.
TY  - journal-article
ID  - https://openalex.org/W4238407538
DO  - https://doi.org/10.12688/wellcomeopenres.14738.1
TI  - The development and evaluation of an online application to assist in the extraction of data from graphs for use in systematic reviews
AB  - Background: The extraction of data from the reports of primary studies, on which the results of systematic reviews depend, needs to be carried out accurately. To aid reliability, it is recommended that two researchers carry out data extraction independently. The extraction of statistical data from graphs in PDF files is particularly challenging, as the process is usually completely manual, and reviewers need sometimes to revert to holding a ruler against the page to read off values: an inherently time-consuming and error-prone process. Methods: To mitigate some of the above problems we developed a new web-based graphical data extraction tool to assist reviewers in extracting data from graphs. This tool aims to facilitate more accurate and timely data extraction through a user interface which can be used to extract data through mouse clicks. We carried out a non-inferiority evaluation to examine its performance in comparison to standard practice. Results: We found that our new graphical data extraction tool is not inferior to users' prior preferred current approaches. Our study was not designed to show superiority, but suggests that there may be a saving in time of around 6 minutes per graph, accompanied by a substantial increase in accuracy. Conclusions: Our study suggests that the incorporation of this type of tool in online systematic review software would be beneficial in facilitating the production of accurate and timely evidence synthesis to improve decision-making. from the journal articles. We were able to reproduce 24 of 28 outcomes using the journal article data. Of these 24 outcomes, we were able to reproduce 83.3% of the published estimates using data at ClinicalTrials.gov.EXACT (http://bio-nlp.org/EXACT) automatically and accurately extracted data elements from ClinicalTrials.gov and thus reduced time in data extraction. The ClinicalTrials.gov data reproduced most meta-analysis results in our study, but this conclusion needs further validation. export file(s). Conclusions The workload savings afforded in the automated simulation came with increased risk of missing relevant records. Supplementing a single reviewer’s decisions with relevance predictions (semi-automated simulation) sometimes reduced the proportion missed, but performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable. is effective in treating depression in adolescents. Physical activity sessions should be at least moderately intense [rate of perceived exertion (RPE) between 11 and 13] to be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2018
DA  - 2018-12-10
JO  - {'id': 'https://openalex.org/V4210218052', 'issn_l': '2398-502X', 'issn': ['2398-502X'], 'display_name': 'Wellcome open research', 'publisher': 'Wellcome', 'type': 'journal', 'url': 'https://doi.org/10.12688/wellcomeopenres.14738.1', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Fala Cramond
AU  - Alison O'Mara-Eves
AU  - Lee Doran-Constant
AU  - Andrew S.C. Rice
AU  - Malcolm R. Macleod
AU  - James D. Thomas
ER  - 

76.
TY  - journal-article
ID  - https://openalex.org/W2551680670
DO  - https://doi.org/10.1007/s10796-016-9724-0
TI  - A comparative analysis of semi-supervised learning: The case of article selection for medical systematic reviews
AB  - No Abstract Found
PY  - 2018
DA  - 2018-04-01
JO  - {'id': 'https://openalex.org/S181659395', 'issn_l': '1387-3326', 'issn': ['1572-9419', '1387-3326'], 'display_name': 'Information Systems Frontiers', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Jun Liu
AU  - Prem Timsina
AU  - Omar F. El-Gayar
ER  - 

77.
TY  - journal-article
ID  - https://openalex.org/W2992824360
DO  - https://doi.org/10.1186/s12911-019-0992-8
TI  - Improving reference prioritisation with PICO recognition
AB  - Machine learning can assist with multiple tasks during systematic reviews to facilitate the rapid retrieval of relevant references during screening and to identify and extract information relevant to the study characteristics, which include the PICO elements of patient/population, intervention, comparator, and outcomes. The latter requires techniques for identifying and categorising fragments of text, known as named entity recognition.A publicly available corpus of PICO annotations on biomedical abstracts is used to train a named entity recognition model, which is implemented as a recurrent neural network. This model is then applied to a separate collection of abstracts for references from systematic reviews within biomedical and health domains. The occurrences of words tagged in the context of specific PICO contexts are used as additional features for a relevancy classification model. Simulations of the machine learning-assisted screening are used to evaluate the work saved by the relevancy model with and without the PICO features. Chi-squared and statistical significance of positive predicted values are used to identify words that are more indicative of relevancy within PICO contexts.Inclusion of PICO features improves the performance metric on 15 of the 20 collections, with substantial gains on certain systematic reviews. Examples of words whose PICO context are more precise can explain this increase.Words within PICO tagged segments in abstracts are predictive features for determining inclusion. Combining PICO annotation model into the relevancy classification pipeline is a promising approach. The annotations may be useful on their own to aid users in pinpointing necessary information for data extraction, or to facilitate semantic search. were able to reproduce 83.3% of the published estimates using data at ClinicalTrials.gov.EXACT (http://bio-nlp.org/EXACT) automatically and accurately extracted data elements from ClinicalTrials.gov and thus reduced time in data extraction. The ClinicalTrials.gov data reproduced most meta-analysis results in our study, but this conclusion needs further validation. export file(s). Conclusions The workload savings afforded in the automated simulation came with increased risk of missing relevant records. Supplementing a single reviewer’s decisions with relevance predictions (semi-automated simulation) sometimes reduced the proportion missed, but performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable. is effective in treating depression in adolescents. Physical activity sessions should be at least moderately intense [rate of perceived exertion (RPE) between 11 and 13] to be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2019
DA  - 2019-12-05
JO  - {'id': 'https://openalex.org/V107516304', 'issn_l': '1472-6947', 'issn': ['1472-6947'], 'display_name': 'BMC Medical Informatics and Decision Making', 'publisher': 'BioMed Central', 'type': 'journal', 'url': 'https://bmcmedinformdecismak.biomedcentral.com/track/pdf/10.1186/s12911-019-0992-8', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - John McNaught
AU  - Meizhi Ju
AU  - Piotr Przybyła
AU  - Sophia Ananiadou
ER  - 

78.
TY  - journal-article
ID  - https://openalex.org/W3111697368
DO  - https://doi.org/10.1016/j.pnpbp.2020.110189
TI  - Effects of probiotics supplementation on dementia and cognitive impairment: A systematic review and meta-analysis of preclinical and clinical studies
AB  - Dementia is a chronic syndrome characterized by cognitive and behavioral symptoms, which may include short-term memory impairment and problems related to orientation, language, attention and perception. Although cognitive impairment (CI) is increasingly considered the main geriatric condition predisposing to dementia, its early management could still promote symptomatic relief and delay disease progression. Recently, probiotics treatment has been studied as a potential new therapeutic approach to attenuate dementia-related decline and mild cognitive impairment (MCI). Therefore, we conducted a systematic review and meta-analysis to review and analyse the available evidence on the effect of probiotics on MCI and dementia.A systematic search and meta-analysis were performed on Cochrane Library, ProQuest, Web of Science, PubMed-Medline, The Cumulative Index to Nursing and Allied Health Literature (CINAHL), Scopus, ScienceDirect and Open Grey. Search terms included diagnoses of interest (dementia and MCI) and the intervention of interest (probiotic, lactobacillus and bifidobacterium). Original articles reporting the use of probiotics supplementation for the treatment of dementia and MCI were screened and studied independently by two researchers. After that, a random and fixed effects model was used at the meta-analysis stage of the results to determine its effect size.A total of 16 articles (10 preclinical and 6 clinical) that met the inclusion criteria for the systematic review, and 15 articles (10 preclinical and 5 clinical) for meta-analysis were finally included. In humans, the administration of probiotics improved general cognitive function after the treatment period. Similarly, an improvement in memory and spatial/non-spatial learning was identified in the probiotic group of animals compared to the control group. On the other hand, the results showed an increase in the levels of the brain-derived neurotrophic factor, an improvement in the inflammatory profile and regulation of cellular biomarkers after probiotics administration.Probiotics supplementation could be an adequate therapeutic strategy both in dementia and CI based on clinical and preclinical evidence. However, it is therefore important to translate preclinical data into clinical data where the evidence is more limited. with relevance predictions (semi-automated simulation) sometimes reduced the proportion missed, but performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable. is effective in treating depression in adolescents. Physical activity sessions should be at least moderately intense [rate of perceived exertion (RPE) between 11 and 13] to be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2021
DA  - 2021-06-08
JO  - {'id': 'https://openalex.org/S142279999', 'issn_l': '0278-5846', 'issn': ['1878-4216', '0278-5846'], 'display_name': 'Progress in Neuro-psychopharmacology & Biological Psychiatry', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Cristofer Ruiz-Gonzalez
AU  - Pablo Roman
AU  - Lola Rueda-Ruzafa
AU  - Miguel Rodriguez-Arrastia
AU  - Diana M. Cardona
ER  - 

79.
TY  - journal-article
ID  - https://openalex.org/W2792396640
DO  - https://doi.org/10.1080/19439342.2018.1441166
TI  - What have we learned after ten years of systematic reviews in international development?
AB  - The paper discusses the role of systematic evidence in helping make better decisions to reach global development targets. Coming at the end of the first decade of serious funding and support for sy... the main geriatric condition predisposing to dementia, its early management could still promote symptomatic relief and delay disease progression. Recently, probiotics treatment has been studied as a potential new therapeutic approach to attenuate dementia-related decline and mild cognitive impairment (MCI). Therefore, we conducted a systematic review and meta-analysis to review and analyse the available evidence on the effect of probiotics on MCI and dementia.A systematic search and meta-analysis were performed on Cochrane Library, ProQuest, Web of Science, PubMed-Medline, The Cumulative Index to Nursing and Allied Health Literature (CINAHL), Scopus, ScienceDirect and Open Grey. Search terms included diagnoses of interest (dementia and MCI) and the intervention of interest (probiotic, lactobacillus and bifidobacterium). Original articles reporting the use of probiotics supplementation for the treatment of dementia and MCI were screened and studied independently by two researchers. After that, a random and fixed effects model was used at the meta-analysis stage of the results to determine its effect size.A total of 16 articles (10 preclinical and 6 clinical) that met the inclusion criteria for the systematic review, and 15 articles (10 preclinical and 5 clinical) for meta-analysis were finally included. In humans, the administration of probiotics improved general cognitive function after the treatment period. Similarly, an improvement in memory and spatial/non-spatial learning was identified in the probiotic group of animals compared to the control group. On the other hand, the results showed an increase in the levels of the brain-derived neurotrophic factor, an improvement in the inflammatory profile and regulation of cellular biomarkers after probiotics administration.Probiotics supplementation could be an adequate therapeutic strategy both in dementia and CI based on clinical and preclinical evidence. However, it is therefore important to translate preclinical data into clinical data where the evidence is more limited. with relevance predictions (semi-automated simulation) sometimes reduced the proportion missed, but performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable. is effective in treating depression in adolescents. Physical activity sessions should be at least moderately intense [rate of perceived exertion (RPE) between 11 and 13] to be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2018
DA  - 2018-03-21
JO  - {'id': 'https://openalex.org/S136516072', 'issn_l': '1943-9407', 'issn': ['1943-9342', '1943-9407'], 'display_name': 'Journal of Development Effectiveness', 'publisher': 'Taylor & Francis', 'type': 'journal', 'url': 'https://www.tandfonline.com/doi/pdf/10.1080/19439342.2018.1441166?needAccess=true', 'is_oa': True, 'version': 'publishedVersion', 'license': None}
DP  - OpenAlex
AU  - Hugh Waddington
AU  - Edoardo Masset
AU  - Emmanuel Jimenez
ER  - 

80.
TY  - journal-article
ID  - https://openalex.org/W2810434445
DO  - https://doi.org/10.1016/j.jclinepi.2018.06.011
TI  - Improving the conduct of systematic reviews: a process mining perspective
AB  - To illustrate the use of process mining concepts, techniques, and tools to improve the systematic review process.We simulated review activities and step-specific methods in the process for systematic reviews conducted by one research team over 1 year to generate an event log of activities, with start/end dates, reviewer assignment by expertise, and person-hours worked. Process mining techniques were applied to the event log to "discover" process models, which allowed visual display, animation, or replay of the simulated review activities. Summary statistics were calculated for person-time and timelines. We also analyzed the social networks of team interactions.The 12 simulated reviews included an average of 3,831 titles/abstracts (range: 1,565-6,368) and 20 studies (6-42). The average review completion time was 463 days (range: 289-629) (881 person-hours [range: 243-1,752]). The average person-hours per activity were study selection 26%, data collection 24%, report preparation 23%, and meta-analysis 17%. Social network analyses showed the organizational interaction of team members, including how they worked together to complete review tasks and to hand over tasks upon completion.Event log and process mining can be valuable tools for research teams interested in improving and modernizing the systematic review process. total of 16 articles (10 preclinical and 6 clinical) that met the inclusion criteria for the systematic review, and 15 articles (10 preclinical and 5 clinical) for meta-analysis were finally included. In humans, the administration of probiotics improved general cognitive function after the treatment period. Similarly, an improvement in memory and spatial/non-spatial learning was identified in the probiotic group of animals compared to the control group. On the other hand, the results showed an increase in the levels of the brain-derived neurotrophic factor, an improvement in the inflammatory profile and regulation of cellular biomarkers after probiotics administration.Probiotics supplementation could be an adequate therapeutic strategy both in dementia and CI based on clinical and preclinical evidence. However, it is therefore important to translate preclinical data into clinical data where the evidence is more limited. with relevance predictions (semi-automated simulation) sometimes reduced the proportion missed, but performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable. is effective in treating depression in adolescents. Physical activity sessions should be at least moderately intense [rate of perceived exertion (RPE) between 11 and 13] to be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2018
DA  - 2018-11-01
JO  - {'id': 'https://openalex.org/S64418186', 'issn_l': '0895-4356', 'issn': ['1878-5921', '0895-4356'], 'display_name': 'Journal of Clinical Epidemiology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Ba' Pham
AU  - Ebrahim Bagheri
AU  - Patricia Rios
AU  - Asef Pourmasoumi
AU  - Reid Robson
AU  - Jeremiah Hwee
AU  - Wanrudee Isaranuwatchai
AU  - Nazia Darvesh
AU  - Matthew J. Page
AU  - Andrea C. Tricco
ER  - 

81.
TY  - journal-article
ID  - https://openalex.org/W2927122354
DO  - https://doi.org/10.13105/wjma.v7.i3.66
TI  - Reproducibility and replicability of systematic reviews
AB  - Irreproducibility of research causes a major concern in academia. This concern affects all study designs regardless of scientific fields. Without testing the reproducibility and replicability it is almost impossible to repeat the research and to gain the same or similar results. In addition, irreproducibility limits the translation of research findings into practice where the same results are expected. To find the solutions, the Interacademy Partnership for Health gathered academics from established networks of science, medicine and engineering around a table to introduce seven strategies that can enhance the reproducibility: pre-registration, open methods, open data, collaboration, automation, reporting guidelines, and post-publication reviews. The current editorial discusses the generalisability and practicality of these strategies to systematic reviews and claims that systematic reviews have even a greater potential than other research designs to lead the movement toward the reproducibility of research. Moreover, I discuss the potential of reproducibility, on the other hand, to upgrade the systematic review from review to research. Furthermore, there are references to the successful and ongoing practices from collaborative efforts around the world to encourage the systematic reviewers, the journal editors and publishers, the organizations linked to evidence synthesis, and the funders and policy makers to facilitate this movement and to gain the public trust in research. 15 articles (10 preclinical and 5 clinical) for meta-analysis were finally included. In humans, the administration of probiotics improved general cognitive function after the treatment period. Similarly, an improvement in memory and spatial/non-spatial learning was identified in the probiotic group of animals compared to the control group. On the other hand, the results showed an increase in the levels of the brain-derived neurotrophic factor, an improvement in the inflammatory profile and regulation of cellular biomarkers after probiotics administration.Probiotics supplementation could be an adequate therapeutic strategy both in dementia and CI based on clinical and preclinical evidence. However, it is therefore important to translate preclinical data into clinical data where the evidence is more limited. with relevance predictions (semi-automated simulation) sometimes reduced the proportion missed, but performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable. is effective in treating depression in adolescents. Physical activity sessions should be at least moderately intense [rate of perceived exertion (RPE) between 11 and 13] to be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2019
DA  - 2019-03-31
JO  - {'id': 'https://openalex.org/S4210210314', 'issn_l': '2308-3840', 'issn': ['2308-3840'], 'display_name': 'World journal of meta-analysis', 'publisher': 'Baishideng Publishing Group', 'type': 'journal', 'url': 'https://doi.org/10.13105/wjma.v7.i3.66', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc'}
DP  - OpenAlex
AU  - Farhad Shokraneh
ER  - 

82.
TY  - journal-article
ID  - https://openalex.org/W2911208765
DO  - https://doi.org/10.1093/jamiaopen/ooy062
TI  - Trial2rev: Combining machine learning and crowd-sourcing to create a shared space for updating systematic reviews
AB  - Abstract Objectives Systematic reviews of clinical trials could be updated faster by automatically monitoring relevant trials as they are registered, completed, and reported. Our aim was to provide a public interface to a database of curated links between systematic reviews and trial registrations. Materials and Methods We developed the server-side system components in Python, connected them to a PostgreSQL database, and implemented the web-based user interface using Javascript, HTML, and CSS. All code is available on GitHub under an open source MIT license and registered users can access and download all available data. Results The trial2rev system is a web-based interface to a database that collates and augments information from multiple sources including bibliographic databases, the ClinicalTrials.gov registry, and the actions of registered users. Users interact with the system by browsing, searching, or adding systematic reviews, verifying links to trials included in the review, and adding or voting on trials that they would expect to include in an update of the systematic review. The system can trigger the actions of software agents that add or vote on included and relevant trials, in response to user interactions or by scheduling updates from external resources. Discussion and Conclusion We designed a publicly-accessible resource to help systematic reviewers make decisions about systematic review updates. Where previous approaches have sought to reactively filter published reports of trials for inclusion in systematic reviews, our approach is to proactively monitor for relevant trials as they are registered and completed. identified in the probiotic group of animals compared to the control group. On the other hand, the results showed an increase in the levels of the brain-derived neurotrophic factor, an improvement in the inflammatory profile and regulation of cellular biomarkers after probiotics administration.Probiotics supplementation could be an adequate therapeutic strategy both in dementia and CI based on clinical and preclinical evidence. However, it is therefore important to translate preclinical data into clinical data where the evidence is more limited. with relevance predictions (semi-automated simulation) sometimes reduced the proportion missed, but performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable. is effective in treating depression in adolescents. Physical activity sessions should be at least moderately intense [rate of perceived exertion (RPE) between 11 and 13] to be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2019
DA  - 2019-01-11
JO  - {'id': 'https://openalex.org/V4210237468', 'issn_l': '2574-2531', 'issn': ['2574-2531'], 'display_name': 'JAMIA open', 'publisher': 'University of Oxford', 'type': 'journal', 'url': 'https://academic.oup.com/jamiaopen/article-pdf/2/1/15/31501530/ooy062.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc'}
DP  - OpenAlex
AU  - Paige Martin
AU  - Didi Surian
AU  - Rabia Bashir
AU  - Florence T. Bourgeois
AU  - Adam G. Dunn
ER  - 

83.
TY  - journal-article
ID  - https://openalex.org/W3178695691
DO  - https://doi.org/10.1016/j.jclinepi.2021.06.030
TI  - Systematic review automation tools improve efficiency but lack of knowledge impedes their adoption: a survey
AB  - <h2>Abstract</h2><h3>Objective</h3> We investigated systematic review automation tool use by systematic reviewers, health technology assessors and clinical guideline developerst. <h3>Study design and setting</h3> An online, 16-question survey was distributed across several evidence synthesis, health technology assessment and guideline development organizations. We asked the respondents what tools they use and abandon, how often and when do they use the tools, their perceived time savings and accuracy, and desired new tools. Descriptive statistics were used to report the results. <h3>Results</h3> A total of 253 respondents completed the survey; 89% have used systematic review automation tools – most frequently whilst screening (79%). Respondents' "top 3" tools included: Covidence (45%), RevMan (35%), Rayyan and GRADEPro (both 22%); most commonly abandoned were Rayyan (19%), Covidence (15%), DistillerSR (14%) and RevMan (13%). Tools saved time (80%) and increased accuracy (54%). Respondents taught themselves to how to use the tools (72%); lack of knowledge was the most frequent barrier to tool adoption (51%). New tool development was suggested for the searching and data extraction stages. <h3>Conclusion</h3> Automation tools will likely have an increasingly important role in high-quality and timely reviews. Further work is required in training and dissemination of automation tools and ensuring they meet the desirable features of those conducting systematic reviews. make decisions about systematic review updates. Where previous approaches have sought to reactively filter published reports of trials for inclusion in systematic reviews, our approach is to proactively monitor for relevant trials as they are registered and completed. identified in the probiotic group of animals compared to the control group. On the other hand, the results showed an increase in the levels of the brain-derived neurotrophic factor, an improvement in the inflammatory profile and regulation of cellular biomarkers after probiotics administration.Probiotics supplementation could be an adequate therapeutic strategy both in dementia and CI based on clinical and preclinical evidence. However, it is therefore important to translate preclinical data into clinical data where the evidence is more limited. with relevance predictions (semi-automated simulation) sometimes reduced the proportion missed, but performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable. is effective in treating depression in adolescents. Physical activity sessions should be at least moderately intense [rate of perceived exertion (RPE) between 11 and 13] to be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2021
DA  - 2021-07-07
JO  - {'id': 'https://openalex.org/S64418186', 'issn_l': '0895-4356', 'issn': ['1878-5921', '0895-4356'], 'display_name': 'Journal of Clinical Epidemiology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Anna Mae Scott
AU  - Connor M. Forbes
AU  - Justin Clark
AU  - Matt Carter
AU  - Paul Glasziou
AU  - Zachary Munn
ER  - 

84.
TY  - journal-article
ID  - https://openalex.org/W2756868207
DO  - https://doi.org/10.1016/j.jbi.2018.01.008
TI  - A shared latent space matrix factorisation method for recommending new trial evidence for systematic review updates
AB  - Clinical trial registries can be used to monitor the production of trial evidence and signal when systematic reviews become out of date. However, this use has been limited to date due to the extensive manual review required to search for and screen relevant trial registrations. Our aim was to evaluate a new method that could partially automate the identification of trial registrations that may be relevant for systematic review updates. We identified 179 systematic reviews of drug interventions for type 2 diabetes, which included 537 clinical trials that had registrations in ClinicalTrials.gov. We tested a matrix factorisation approach that uses a shared latent space to learn how to rank relevant trial registrations for each systematic review, comparing the performance to document similarity to rank relevant trial registrations. The two approaches were tested on a holdout set of the newest trials from the set of type 2 diabetes systematic reviews and an unseen set of 141 clinical trial registrations from 17 updated systematic reviews published in the Cochrane Database of Systematic Reviews. The matrix factorisation approach outperformed the document similarity approach with a median rank of 59 and recall@100 of 60.9%, compared to a median rank of 138 and recall@100 of 42.8% in the document similarity baseline. In the second set of systematic reviews and their updates, the highest performing approach used document similarity and gave a median rank of 67 (recall@100 of 62.9%). The proposed method was useful for ranking trial registrations to reduce the manual workload associated with finding relevant trials for systematic review updates. The results suggest that the approach could be used as part of a semi-automated pipeline for monitoring potentially new evidence for inclusion in a review update. biomarkers after probiotics administration.Probiotics supplementation could be an adequate therapeutic strategy both in dementia and CI based on clinical and preclinical evidence. However, it is therefore important to translate preclinical data into clinical data where the evidence is more limited. with relevance predictions (semi-automated simulation) sometimes reduced the proportion missed, but performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable. is effective in treating depression in adolescents. Physical activity sessions should be at least moderately intense [rate of perceived exertion (RPE) between 11 and 13] to be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2018
DA  - 2018-03-01
JO  - {'id': 'https://openalex.org/V11622463', 'issn_l': '1532-0464', 'issn': ['1532-0480', '1532-0464'], 'display_name': 'Journal of Biomedical Informatics', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Didi Surian
AU  - Adam G. Dunn
AU  - Liat Orenstein
AU  - Rabia Bashir
AU  - Enrico Coiera
AU  - Florence T. Bourgeois
ER  - 

85.
TY  - journal-article
ID  - https://openalex.org/W2903751171
DO  - https://doi.org/10.1016/j.jclinepi.2018.12.008
TI  - Living network meta-analysis was feasible when considering the pace of evidence generation
AB  - The aim of the study was to assess the feasibility of living network meta-analysis (NMA) taking into account the pace of evidence generation across different medical areas.We performed a systematic review to identify published NMAs. For each NMA, we calculated the cumulative number of new trials. To assess the feasibility of living NMA, we considered different update frequencies (4, 6, and 12 months), then evaluated the number of new trials to be included at each update in the NMA and the workload percentage for an update relative to the initial NMA.We identified 77 NMAs covering 17 different medical areas; 60 (78%) had fewer than four new trials included per year, on average, and 5 (7%) had more than seven trials. With an update frequency of 4, 6, and 12 months, the median number of new trials to be included in the NMA was 0 (interquartile range, 0-1), 1 (0-2), and 2 (1-4), respectively, with mean of 4%, 5%, and 11% workload per update, respectively.The workload associated with updating a living NMA represents about one-tenth of the initial workload; therefore, living NMA is manageable. rank of 59 and recall@100 of 60.9%, compared to a median rank of 138 and recall@100 of 42.8% in the document similarity baseline. In the second set of systematic reviews and their updates, the highest performing approach used document similarity and gave a median rank of 67 (recall@100 of 62.9%). The proposed method was useful for ranking trial registrations to reduce the manual workload associated with finding relevant trials for systematic review updates. The results suggest that the approach could be used as part of a semi-automated pipeline for monitoring potentially new evidence for inclusion in a review update. biomarkers after probiotics administration.Probiotics supplementation could be an adequate therapeutic strategy both in dementia and CI based on clinical and preclinical evidence. However, it is therefore important to translate preclinical data into clinical data where the evidence is more limited. with relevance predictions (semi-automated simulation) sometimes reduced the proportion missed, but performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable. is effective in treating depression in adolescents. Physical activity sessions should be at least moderately intense [rate of perceived exertion (RPE) between 11 and 13] to be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2019
DA  - 2019-04-01
JO  - {'id': 'https://openalex.org/V64418186', 'issn_l': '0895-4356', 'issn': ['1878-5921', '0895-4356'], 'display_name': 'Journal of Clinical Epidemiology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Perrine Créquit
AU  - Tania Martin-Montoya
AU  - Nassima Attiche
AU  - Ludovic Trinquart
AU  - Alexandre Vivot
AU  - Philippe Ravaud
ER  - 

86.
TY  - journal-article
ID  - https://openalex.org/W3042309317
DO  - https://doi.org/10.1088/1748-9326/aba660
TI  - Systematic map of the literature on carbon lock-in induced by long-lived capital
AB  - Abstract Long-lived capital-stocks (LLCS) such as infrastructure and buildings have significant and long-lasting implications for greenhouse gas emissions. They contribute to carbon lock-in and may hinder a rapid decarbonization of energy systems. Here we provide a systematic map of the literature on carbon lock-in induced by LLCS. Based on a structured search of the Web of Science and Scopus, we identified 226 publications from 38 095 search results using a supervised machine learning approach. We show biases toward power generation and toward developed countries. We also identify 11 indicators used to quantify carbon lock-in. Quantifications of committed emissions (cumulative emissions that would occur over the remaining operational lifetime of an asset) or stranded assets (premature retirement/retrofitting or under-utilization of assets along a given pathway) are the most commonly used metrics, whereas institutional indicators are scarcely represented. The synthesis of quantifications shows that (i) global committed emissions have slightly increased over time, (ii) coal power plants are a major source of committed emissions and are exposed to risk of becoming stranded, (iii) delayed mitigation action increases stranded assets and (iv) sectoral distribution and amount of stranded assets differ between countries. A thematic analysis of policy implications highlights the need to assure stability and legitimacy of climate policies and to enable coordination between stakeholders. Carbon pricing is one of the most cited policy instrument, but the literature emphasizes that it should not be the only instrument used and should instead be complemented with other policy instruments, such as technical regulations and financial support for low carbon capital deployment. Further research is warranted on urban-scale, in developing countries and outside the electricity generation sector, notably on buildings, where stranded assets could be high. review update. biomarkers after probiotics administration.Probiotics supplementation could be an adequate therapeutic strategy both in dementia and CI based on clinical and preclinical evidence. However, it is therefore important to translate preclinical data into clinical data where the evidence is more limited. with relevance predictions (semi-automated simulation) sometimes reduced the proportion missed, but performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable. is effective in treating depression in adolescents. Physical activity sessions should be at least moderately intense [rate of perceived exertion (RPE) between 11 and 13] to be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2021
DA  - 2021-04-29
JO  - {'id': 'https://openalex.org/S139338987', 'issn_l': '1748-9326', 'issn': ['1748-9326'], 'display_name': 'Environmental Research Letters', 'publisher': 'IOP Publishing', 'type': 'journal', 'url': 'https://doi.org/10.1088/1748-9326/aba660', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Vivien Fisch-Romito
AU  - Céline Guivarch
AU  - Felix Creutzig
AU  - Jan C. Minx
AU  - Max Callaghan
ER  - 

87.
TY  - journal-article
ID  - https://openalex.org/W3082537963
DO  - https://doi.org/10.1093/advances/nmaa101
TI  - High-Fat Ketogenic Diets and Physical Performance: A Systematic Review
AB  - Use of high-fat, ketogenic diets (KDs) to support physical performance has grown in popularity over recent years. While these diets enhance fat and reduce carbohydrate oxidation during exercise, the impact of a KD on physical performance remains controversial. The objective of this work was to assess the effect of KDs on physical performance compared with mixed macronutrient diets [control (CON)]. A systematic review of the literature was conducted using PubMed and Cochrane Library databases. Randomized and nonrandomized studies were included if participants were healthy (free of chronic disease), nonobese [BMI (kg/m2) <30], trained or untrained men or women consuming KD (<50 g carbohydrate/d or serum or whole-blood β-hydroxybutyrate >0.5 mmol/L) compared with CON (fat, 12-38% of total energy intake) diets for ≥14 d, followed by a physical performance test. Seventeen studies (10 parallel, 7 crossover) with 29 performance (13 endurance, 16 power or strength) outcomes were identified. Of the 13 endurance-type performance outcomes, 3 (1 time trial, 2 time-to-exhaustion) reported lower and 10 (4 time trials, 6 time-to-exhaustion) reported no difference in performance between the KD compared with CON. Of the 16 power or strength performance outcomes, 3 (1 power, 2 strength) reported lower, 11 (4 power, 7 strength) no difference, and 2 (power) enhanced performance in the KD compared with the CON. Risk of bias identified some concern of bias primarily due to studies allowing participants to self-select diet intervention groups and the inability to blind participants to the study intervention. Overall, the majority of null results across studies suggest that a KD does not have a positive or negative impact on physical performance compared with a CON diet. However, discordant results between studies may be due to multiple factors, such as the duration consuming study diets, training status, performance test, and sex differences, which will be discussed in this systematic review. evidence. However, it is therefore important to translate preclinical data into clinical data where the evidence is more limited. with relevance predictions (semi-automated simulation) sometimes reduced the proportion missed, but performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable. is effective in treating depression in adolescents. Physical activity sessions should be at least moderately intense [rate of perceived exertion (RPE) between 11 and 13] to be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2021
DA  - 2021-02-01
JO  - {'id': 'https://openalex.org/S2491932416', 'issn_l': '2161-8313', 'issn': ['2161-8313', '2156-5376'], 'display_name': 'Advances in Nutrition', 'publisher': 'American Society for Nutrition', 'type': 'journal', 'url': 'https://academic.oup.com/advances/article-pdf/12/1/223/38878292/nmaa101.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'pd'}
DP  - OpenAlex
AU  - Nancy A. Murphy
AU  - Christopher T. Carrigan
AU  - Lee M. Margolis
ER  - 

88.
TY  - journal-article
ID  - https://openalex.org/W3143985904
DO  - https://doi.org/10.1186/s13643-021-01635-3
TI  - Research Screener: a machine learning tool to semi-automate abstract screening for systematic reviews
AB  - Systematic reviews and meta-analyses provide the highest level of evidence to help inform policy and practice, yet their rigorous nature is associated with significant time and economic demands. The screening of titles and abstracts is the most time consuming part of the review process with analysts required review thousands of articles manually, taking on average 33 days. New technologies aimed at streamlining the screening process have provided initial promising findings, yet there are limitations with current approaches and barriers to the widespread use of these tools. In this paper, we introduce and report initial evidence on the utility of Research Screener, a semi-automated machine learning tool to facilitate abstract screening.Three sets of analyses (simulation, interactive and sensitivity) were conducted to provide evidence of the utility of the tool through both simulated and real-world examples.Research Screener delivered a workload saving of between 60 and 96% across nine systematic reviews and two scoping reviews. Findings from the real-world interactive analysis demonstrated a time saving of 12.53 days compared to the manual screening, which equates to a financial saving of USD 2444. Conservatively, our results suggest that analysts who scan 50% of the total pool of articles identified via a systematic search are highly likely to have identified 100% of eligible papers.In light of these findings, Research Screener is able to reduce the burden for researchers wishing to conduct a comprehensive systematic review without reducing the scientific rigour for which they strive to achieve. intervention. Overall, the majority of null results across studies suggest that a KD does not have a positive or negative impact on physical performance compared with a CON diet. However, discordant results between studies may be due to multiple factors, such as the duration consuming study diets, training status, performance test, and sex differences, which will be discussed in this systematic review. evidence. However, it is therefore important to translate preclinical data into clinical data where the evidence is more limited. with relevance predictions (semi-automated simulation) sometimes reduced the proportion missed, but performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable. is effective in treating depression in adolescents. Physical activity sessions should be at least moderately intense [rate of perceived exertion (RPE) between 11 and 13] to be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2021
DA  - 2021-04-01
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://systematicreviewsjournal.biomedcentral.com/counter/pdf/10.1186/s13643-021-01635-3', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Kevin Chai
AU  - Robin L. J. Lines
AU  - Daniel F. Gucciardi
AU  - Leo Ng
ER  - 

89.
TY  - journal-article
ID  - https://openalex.org/W2297572769
DO  - https://doi.org/10.1016/j.kint.2015.11.030
TI  - Recommendations for kidney disease guideline updating: a report by the KDIGO Methods Committee
AB  - Updating rather than de novo guideline development now accounts for the majority of guideline activities for many guideline development organizations, including Kidney Disease: Improving Global Outcomes (KDIGO), an international kidney disease guideline development entity that has produced guidelines on kidney diseases since 2008. Increasingly, guideline developers are moving away from updating at fixed intervals in favor of more flexible approaches that use periodic expert assessment of guideline currency (with or without an updated systematic review) to determine the need for updating. Determining the need for guideline updating in an efficient, transparent, and timely manner is challenging, and updating of systematic reviews and guidelines is labor intensive. Ideally, guidelines should be updated dynamically when new evidence indicates a need for a substantive change in the guideline based on a priori criteria. This dynamic updating (sometimes referred to as a living guideline model) can be facilitated with the use of integrated electronic platforms that allow updating of specific recommendations. This report summarizes consensus-based recommendations from a panel of guideline methodology professionals on how to keep KDIGO guidelines up to date. 2444. Conservatively, our results suggest that analysts who scan 50% of the total pool of articles identified via a systematic search are highly likely to have identified 100% of eligible papers.In light of these findings, Research Screener is able to reduce the burden for researchers wishing to conduct a comprehensive systematic review without reducing the scientific rigour for which they strive to achieve. intervention. Overall, the majority of null results across studies suggest that a KD does not have a positive or negative impact on physical performance compared with a CON diet. However, discordant results between studies may be due to multiple factors, such as the duration consuming study diets, training status, performance test, and sex differences, which will be discussed in this systematic review. evidence. However, it is therefore important to translate preclinical data into clinical data where the evidence is more limited. with relevance predictions (semi-automated simulation) sometimes reduced the proportion missed, but performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable. is effective in treating depression in adolescents. Physical activity sessions should be at least moderately intense [rate of perceived exertion (RPE) between 11 and 13] to be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2016
DA  - 2016-04-01
JO  - {'id': 'https://openalex.org/V97303050', 'issn_l': '0085-2538', 'issn': ['0085-2538', '1523-1755'], 'display_name': 'Kidney International', 'publisher': 'Nature Portfolio', 'type': 'journal', 'url': 'http://www.kidney-international.org/article/S0085253816002799/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'elsevier-specific'}
DP  - OpenAlex
AU  - Katrin Uhlig
AU  - Jeffrey S. Berns
AU  - Serena Carville
AU  - Wiley Chan
AU  - Michael Cheung
AU  - Gordon H. Guyatt
AU  - Allyson Hart
AU  - Sandra J. Lewis
AU  - Marcello Tonelli
AU  - Angela C Webster
AU  - Timothy J Wilt
AU  - Bertram L. Kasiske
ER  - 

90.
TY  - journal-article
ID  - https://openalex.org/W2356939740
DO  - https://doi.org/10.1109/tnb.2016.2565481
TI  - Data Sampling and Supervised Learning for HIV Literature Screening
AB  - This paper presents a supervised learning approach to support the screening of HIV literature. The manual screening of biomedical literature is an important task in the process of systematic reviews. Researchers and curators have the very demanding, time-consuming and error-prone task of manually identifying documents that should be included in a systematic review concerning a specific problem. We developed a supervised learning approach to support screening tasks, by automatically flagging potentially relevant documents from a list retrieved by a literature database search. To overcome the main issues associated with the automatic literature screening task, we evaluated the use of data sampling, feature combinations, and feature selection methods, generating a total of 105 classification models. The models yielding the best results were composed of a Logistic Model Trees classifier, a fairly balanced training set, and feature combination of Bag-Of-Words and MeSH terms. According to our results, the system correctly labels the great majority of relevant documents, making it usable to support HIV systematic reviews to allow researchers to assess a greater number of documents in less time. to date. 2444. Conservatively, our results suggest that analysts who scan 50% of the total pool of articles identified via a systematic search are highly likely to have identified 100% of eligible papers.In light of these findings, Research Screener is able to reduce the burden for researchers wishing to conduct a comprehensive systematic review without reducing the scientific rigour for which they strive to achieve. intervention. Overall, the majority of null results across studies suggest that a KD does not have a positive or negative impact on physical performance compared with a CON diet. However, discordant results between studies may be due to multiple factors, such as the duration consuming study diets, training status, performance test, and sex differences, which will be discussed in this systematic review. evidence. However, it is therefore important to translate preclinical data into clinical data where the evidence is more limited. with relevance predictions (semi-automated simulation) sometimes reduced the proportion missed, but performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable. is effective in treating depression in adolescents. Physical activity sessions should be at least moderately intense [rate of perceived exertion (RPE) between 11 and 13] to be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2016
DA  - 2016-05-10
JO  - {'id': 'https://openalex.org/S187110076', 'issn_l': '1536-1241', 'issn': ['1536-1241', '1558-2639'], 'display_name': 'IEEE Transactions on Nanobioscience', 'publisher': 'Institute of Electrical and Electronics Engineers', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Hayda Almeida
AU  - Marie-Jean Meurs
AU  - Leila Kosseim
AU  - Adrian Tsang
ER  - 

91.
TY  - reference-entry
ID  - https://openalex.org/W2469709324
DO  - https://doi.org/10.1002/14651858.ed000091
TI  - #CochraneTech: Technology and the Future of Systematic Reviews
AB  - No Abstract Found
PY  - 2014
DA  - 2014-01-01
JO  - {'id': 'https://openalex.org/S71429176', 'issn_l': '1361-6137', 'issn': ['1361-6137', '1469-493X'], 'display_name': 'Cochrane Database of Systematic Reviews', 'publisher': 'Cochrane', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - J Elliott
AU  - I Sim
AU  - J. P. Thomas
AU  - N Owens
AU  - Gordon Dooley
AU  - J Riis
AU  - Byron C. Wallace
AU  - Anna H Noel-Storr
AU  - Gabriel Rada
AU  - C Struthers
AU  - Tracey E. Howe
AU  - Harriet MacLehose
AU  - Linn Brandt
AU  - Ilkka Kunnamo
AU  - Chris Mavergames
ER  - 

92.
TY  - journal-article
ID  - https://openalex.org/W2777333262
DO  - https://doi.org/10.1016/j.jphys.2017.11.009
TI  - Updating systematic reviews
AB  - No Abstract Found
PY  - 2018
DA  - 2018-01-01
JO  - {'id': 'https://openalex.org/S99546260', 'issn_l': '1836-9561', 'issn': ['1836-9553', '1836-9561'], 'display_name': 'Journal of Physiotherapy', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'https://doi.org/10.1016/j.jphys.2017.11.009', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc-nd'}
DP  - OpenAlex
AU  - Mark R. Elkins
ER  - 

93.
TY  - journal-article
ID  - https://openalex.org/W2778841805
DO  - https://doi.org/10.1016/j.jclinepi.2017.12.007
TI  - Unreported links between trial registrations and published articles were identified using document similarity measures in a cross-sectional analysis of ClinicalTrials.gov
AB  - Objectives: Trial registries can be used to measure reporting biases and support systematic reviews but 45% of registrations do not provide a link to the article reporting on the trial. We evaluated the use of document similarity methods to identify unreported links between ClinicalTrials.gov and PubMed. Study Design and Setting: We extracted terms and concepts from a dataset of 72,469 ClinicalTrials.gov registrations and 276,307 PubMed articles, and tested methods for ranking articles across 16,005 reported links and 90 manually-identified unreported links. Performance was measured by the median rank of matching articles, and the proportion of unreported links that could be found by screening ranked candidate articles in order. Results: The best performing concept-based representation produced a median rank of 3 (IQR 1-21) for reported links and 3 (IQR 1-19) for the manually-identified unreported links, and term-based representations produced a median rank of 2 (1-20) for reported links and 2 (IQR 1-12) in unreported links. The matching article was ranked first for 40% of registrations, and screening 50 candidate articles per registration identified 86% of the unreported links. Conclusions: Leveraging the growth in the corpus of reported links between ClinicalTrials.gov and PubMed, we found that document similarity methods can assist in the identification of unreported links between trial registrations and corresponding articles. these findings, Research Screener is able to reduce the burden for researchers wishing to conduct a comprehensive systematic review without reducing the scientific rigour for which they strive to achieve. intervention. Overall, the majority of null results across studies suggest that a KD does not have a positive or negative impact on physical performance compared with a CON diet. However, discordant results between studies may be due to multiple factors, such as the duration consuming study diets, training status, performance test, and sex differences, which will be discussed in this systematic review. evidence. However, it is therefore important to translate preclinical data into clinical data where the evidence is more limited. with relevance predictions (semi-automated simulation) sometimes reduced the proportion missed, but performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable. is effective in treating depression in adolescents. Physical activity sessions should be at least moderately intense [rate of perceived exertion (RPE) between 11 and 13] to be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2018
DA  - 2018-03-01
JO  - {'id': 'https://openalex.org/S64418186', 'issn_l': '0895-4356', 'issn': ['1878-5921', '0895-4356'], 'display_name': 'Journal of Clinical Epidemiology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Adam G. Dunn
AU  - Enrico Coiera
AU  - Florence T. Bourgeois
ER  - 

94.
TY  - journal-article
ID  - https://openalex.org/W3013835212
DO  - https://doi.org/10.12688/f1000research.22781.2
TI  - Data extraction methods for systematic review (semi)automation: A living review protocol
AB  - <ns4:p><ns4:bold>Background:</ns4:bold> Researchers in evidence-based medicine cannot keep up with the amounts of both old and newly published primary research articles. Support for the early stages of the systematic review process – searching and screening studies for eligibility – is necessary because it is currently impossible to search for relevant research with precision. Better automated data extraction may not only facilitate the stage of review traditionally labelled ‘data extraction’, but also change earlier phases of the review process by making it possible to identify relevant research. Exponential improvements in computational processing speed and data storage are fostering the development of data mining models and algorithms. This, in combination with quicker pathways to publication, led to a large landscape of tools and methods for data mining and extraction.</ns4:p><ns4:p> <ns4:bold>Objective:</ns4:bold> To review published methods and tools for data extraction to (semi)automate the systematic reviewing process.</ns4:p><ns4:p> <ns4:bold>Methods:</ns4:bold> We propose to conduct a living review. With this methodology we aim to do constant evidence surveillance, bi-monthly search updates, as well as review updates every 6 months if new evidence permits it. In a cross-sectional analysis we will extract methodological characteristics and assess the quality of reporting in our included papers.</ns4:p><ns4:p> <ns4:bold>Conclusions:</ns4:bold> We aim to increase transparency in the reporting and assessment of automation technologies to the benefit of data scientists, systematic reviewers and funders of health research. This living review will help to reduce duplicate efforts by data scientists who develop data mining methods. It will also serve to inform systematic reviewers about possibilities to support their data extraction.</ns4:p> does not have a positive or negative impact on physical performance compared with a CON diet. However, discordant results between studies may be due to multiple factors, such as the duration consuming study diets, training status, performance test, and sex differences, which will be discussed in this systematic review. evidence. However, it is therefore important to translate preclinical data into clinical data where the evidence is more limited. with relevance predictions (semi-automated simulation) sometimes reduced the proportion missed, but performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable. is effective in treating depression in adolescents. Physical activity sessions should be at least moderately intense [rate of perceived exertion (RPE) between 11 and 13] to be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2020
DA  - 2020-03-25
JO  - {'id': 'https://openalex.org/S4210239046', 'issn_l': '2046-1402', 'issn': ['2046-1402'], 'display_name': 'F1000Research', 'publisher': 'Faculty of 1000', 'type': 'journal', 'url': 'https://f1000research.com/articles/9-210/v2/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Lena Schmidt
AU  - Babatunde K. Olorisade
AU  - Adrian M. Price-Whelan
AU  - James D. Thomas
AU  - Julian P T Higgins
ER  - 

95.
TY  - journal-article
ID  - https://openalex.org/W3107597694
DO  - https://doi.org/10.1093/schizbullopen/sgaa061
TI  - Cochrane Schizophrenia Group’s Study-Based Register of Randomized Controlled Trials: Development and Content Analysis
AB  - Abstract Background Study-based registers facilitate systematic reviews through shortening the process for review team and reducing considerable waste during the review process. Such a register also provides new insights about trends of trials in a sub-specialty. This paper reports development and content analysis of Cochrane Schizophrenia Group’s Study-Based Register. Methods The randomized controlled trials were collected through systematic searches of major information sources. Data points were extracted, curated and classified in the register. We report trends using regression analyses in Microsoft Excel and we used GIS mapping (GunnMap 2) to visualize the geographical distribution of the origin of schizophrenia trials. Results Although only 17% of trials were registered, the number of reports form registered trials is steadily increasing and registered trials produce more reports. Clinical trial registers are main source of trial reports followed by sub-specialty journals. Schizophrenia trials have been published in 23 languages from 90 countries while 105 nations do not have any reported schizophrenia trials. Only 9.7% of trials were included in at least one Cochrane review. Pharmacotherapy is the main target of trials while trials targeting psychotherapy are increasing in a continuous rate. The number of people randomized in trials is on average 114 with 60 being the most frequent sample size. Conclusions Curated datasets within the register uncover new patterns in data that have implications for research, policy, and practice for testing new interventions in trials or systematic reviews. who develop data mining methods. It will also serve to inform systematic reviewers about possibilities to support their data extraction.</ns4:p> does not have a positive or negative impact on physical performance compared with a CON diet. However, discordant results between studies may be due to multiple factors, such as the duration consuming study diets, training status, performance test, and sex differences, which will be discussed in this systematic review. evidence. However, it is therefore important to translate preclinical data into clinical data where the evidence is more limited. with relevance predictions (semi-automated simulation) sometimes reduced the proportion missed, but performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable. is effective in treating depression in adolescents. Physical activity sessions should be at least moderately intense [rate of perceived exertion (RPE) between 11 and 13] to be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2020
DA  - 2020-01-01
JO  - {'id': 'https://openalex.org/S4210209414', 'issn_l': '2632-7899', 'issn': ['2632-7899'], 'display_name': 'Schizophrenia bulletin open', 'publisher': 'Oxford University Press', 'type': 'journal', 'url': 'https://academic.oup.com/schizbullopen/advance-article-pdf/doi/10.1093/schizbullopen/sgaa061/34559040/sgaa061.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc'}
DP  - OpenAlex
AU  - Farhad Shokraneh
AU  - Clive E Adams
ER  - 

96.
TY  - journal-article
ID  - https://openalex.org/W3182264895
DO  - https://doi.org/10.1002/1348-9585.12243
TI  - Physical relaxation for occupational stress in healthcare workers: A systematic review and network meta‐analysis of randomized controlled trials
AB  - Objectives Work related stress is a major occupational health problem that is associated with adverse effects on physical and mental health. Healthcare workers are particularly vulnerable in the era of COVID-19. Physical methods of stress relief such as yoga and massage therapy may reduce occupational stress. The objective of this systematic review and network meta-analysis is to determine the effects of yoga, massage therapy, progressive muscle relaxation, and stretching on alleviating stress and improving physical and mental health in healthcare workers. Methods Databases were searched for randomized controlled trials on the use of physical relaxation methods for occupational stress in healthcare workers with any duration of follow-up. Meta-analysis was performed for standard mean differences in stress measures from baseline between subjects undergoing relaxation vs non-intervention controls. Network meta-analysis was conducted to determine the best relaxation method. Results Fifteen trials representing 688 healthcare workers were identified. Random-effects meta-analysis shows that physical relaxation methods overall reduced measures of occupational stress at the longest duration of follow-up vs baseline compared to non-intervention controls (SMD −0.53; 95% CI [−0.74 to −0.33]; p < .00001). On network meta-analysis, only yoga alone (SMD −0.71; 95% CI [−1.01 to −0.41]) and massage therapy alone (SMD −0.43; 95% CI [−0.72 to −0.14]) were more effective than control, with yoga identified as the best method (p-score = .89). Conclusion Physical relaxation may help reduce occupational stress in healthcare workers. Yoga is particularly effective and offers the convenience of online delivery. Employers should consider implementing these methods into workplace wellness programs. their data extraction.</ns4:p> does not have a positive or negative impact on physical performance compared with a CON diet. However, discordant results between studies may be due to multiple factors, such as the duration consuming study diets, training status, performance test, and sex differences, which will be discussed in this systematic review. evidence. However, it is therefore important to translate preclinical data into clinical data where the evidence is more limited. with relevance predictions (semi-automated simulation) sometimes reduced the proportion missed, but performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable. is effective in treating depression in adolescents. Physical activity sessions should be at least moderately intense [rate of perceived exertion (RPE) between 11 and 13] to be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2021
DA  - 2021-01-01
JO  - {'id': 'https://openalex.org/S27728379', 'issn_l': '1341-9145', 'issn': ['1341-9145', '1348-9585'], 'display_name': 'Journal of Occupational Health', 'publisher': 'Wiley', 'type': 'journal', 'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/1348-9585.12243', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Michael Q. Zhang
AU  - Brittany Murphy
AU  - Abegail Cabanilla
AU  - Christina Yidi
ER  - 

97.
TY  - journal-article
ID  - https://openalex.org/W1938979978
DO  - https://doi.org/10.2196/medinform.3982
TI  - Using MEDLINE Elemental Similarity to Assist in the Article Screening Process for Systematic Reviews
AB  - Systematic reviews and their implementation in practice provide high quality evidence for clinical practice but are both time and labor intensive due to the large number of articles. Automatic text classification has proven to be instrumental in identifying relevant articles for systematic reviews. Existing approaches use machine learning model training to generate classification algorithms for the article screening process but have limitations.We applied a network approach to assist in the article screening process for systematic reviews using predetermined article relationships (similarity). The article similarity metric is calculated using the MEDLINE elements title (TI), abstract (AB), medical subject heading (MH), author (AU), and publication type (PT). We used an article network to illustrate the concept of article relationships. Using the concept, each article can be modeled as a node in the network and the relationship between 2 articles is modeled as an edge connecting them. The purpose of our study was to use the article relationship to facilitate an interactive article recommendation process.We used 15 completed systematic reviews produced by the Drug Effectiveness Review Project and demonstrated the use of article networks to assist article recommendation. We evaluated the predictive performance of MEDLINE elements and compared our approach with existing machine learning model training approaches. The performance was measured by work saved over sampling at 95% recall (WSS95) and the F-measure (F1). We also used repeated analysis over variance and Hommel's multiple comparison adjustment to demonstrate statistical evidence.We found that although there is no significant difference across elements (except AU), TI and AB have better predictive capability in general. Collaborative elements bring performance improvement in both F1 and WSS95. With our approach, a simple combination of TI+AB+PT could achieve a WSS95 performance of 37%, which is competitive to traditional machine learning model training approaches (23%-41% WSS95).We demonstrated a new approach to assist in labor intensive systematic reviews. Predictive ability of different elements (both single and composited) was explored. Without using model training approaches, we established a generalizable method that can achieve a competitive performance. performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable. is effective in treating depression in adolescents. Physical activity sessions should be at least moderately intense [rate of perceived exertion (RPE) between 11 and 13] to be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2015
DA  - 2015-08-31
JO  - {'id': 'https://openalex.org/S2764650051', 'issn_l': '2291-9694', 'issn': ['2291-9694'], 'display_name': 'JMIR medical informatics', 'publisher': 'JMIR Publications', 'type': 'journal', 'url': 'https://doi.org/10.2196/medinform.3982', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Xiaonan Ji
AU  - Po-Yin Yen
ER  - 

98.
TY  - journal-article
ID  - https://openalex.org/W2609740230
DO  - https://doi.org/10.1016/j.jbi.2017.04.004
TI  - Evaluation of a rule-based method for epidemiological document classification towards the automation of systematic reviews
AB  - Most data extraction efforts in epidemiology are focused on obtaining targeted information from clinical trials. In contrast, limited research has been conducted on the identification of information from observational studies, a major source for human evidence in many fields, including environmental health. The recognition of key epidemiological information (e.g., exposures) through text mining techniques can assist in the automation of systematic reviews and other evidence summaries.We designed and applied a knowledge-driven, rule-based approach to identify targeted information (study design, participant population, exposure, outcome, confounding factors, and the country where the study was conducted) from abstracts of epidemiological studies included in several systematic reviews of environmental health exposures. The rules were based on common syntactical patterns observed in text and are thus not specific to any systematic review. To validate the general applicability of our approach, we compared the data extracted using our approach versus hand curation for 35 epidemiological study abstracts manually selected for inclusion in two systematic reviews.The returned F-score, precision, and recall ranged from 70% to 98%, 81% to 100%, and 54% to 97%, respectively. The highest precision was observed for exposure, outcome and population (100%) while recall was best for exposure and study design with 97% and 89%, respectively. The lowest recall was observed for the population (54%), which also had the lowest F-score (70%).The generated performance of our text-mining approach demonstrated encouraging results for the identification of targeted information from observational epidemiological study abstracts related to environmental exposures. We have demonstrated that rules based on generic syntactic patterns in one corpus can be applied to other observational study design by simple interchanging the dictionaries aiming to identify certain characteristics (i.e., outcomes, exposures). At the document level, the recognised information can assist in the selection and categorization of studies included in a systematic review. new approach to assist in labor intensive systematic reviews. Predictive ability of different elements (both single and composited) was explored. Without using model training approaches, we established a generalizable method that can achieve a competitive performance. performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable. is effective in treating depression in adolescents. Physical activity sessions should be at least moderately intense [rate of perceived exertion (RPE) between 11 and 13] to be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2017
DA  - 2017-06-01
JO  - {'id': 'https://openalex.org/S11622463', 'issn_l': '1532-0464', 'issn': ['1532-0480', '1532-0464'], 'display_name': 'Journal of Biomedical Informatics', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'https://doi.org/10.1016/j.jbi.2017.04.004', 'is_oa': True, 'version': 'publishedVersion', 'license': 'elsevier-specific'}
DP  - OpenAlex
AU  - George Karystianis
AU  - Kristina A. Thayer
AU  - Mary Leigh Wolfe
AU  - Guy Tsafnat
ER  - 

99.
TY  - journal-article
ID  - https://openalex.org/W2918301483
DO  - https://doi.org/10.1016/j.jclinepi.2019.02.015
TI  - The risk of conclusion change in systematic review updates can be estimated by learning from a database of published examples
AB  - To determine which systematic review characteristics are needed to estimate the risk of conclusion change in systematic review updates.We applied classification trees (a machine learning method) to model the risk of conclusion change in systematic review updates, using pairs of systematic reviews and their updates as samples. The classifiers were constructed using a set of features extracted from systematic reviews and the relevant trials added in published updates. Model performance was measured by recall, precision, and area under the receiver operating characteristic curve (AUC).We identified 63 pairs of systematic reviews and updates, of which 20 (32%) exhibited a change in conclusion in their updates. A classifier using information about new trials exhibited the highest performance (AUC: 0.71; recall: 0.75; precision: 0.43) compared to a classifier that used fewer features (AUC: 0.65; recall: 0.75; precision: 0.39).When estimating the risk of conclusion change in systematic review updates, information about the sizes of trials that will be added in an update are most useful. Future tools aimed at signaling conclusion change risks would benefit from complementary tools that automate screening of relevant trials. was observed for exposure, outcome and population (100%) while recall was best for exposure and study design with 97% and 89%, respectively. The lowest recall was observed for the population (54%), which also had the lowest F-score (70%).The generated performance of our text-mining approach demonstrated encouraging results for the identification of targeted information from observational epidemiological study abstracts related to environmental exposures. We have demonstrated that rules based on generic syntactic patterns in one corpus can be applied to other observational study design by simple interchanging the dictionaries aiming to identify certain characteristics (i.e., outcomes, exposures). At the document level, the recognised information can assist in the selection and categorization of studies included in a systematic review. new approach to assist in labor intensive systematic reviews. Predictive ability of different elements (both single and composited) was explored. Without using model training approaches, we established a generalizable method that can achieve a competitive performance. performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable. is effective in treating depression in adolescents. Physical activity sessions should be at least moderately intense [rate of perceived exertion (RPE) between 11 and 13] to be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2019
DA  - 2019-06-01
JO  - {'id': 'https://openalex.org/S64418186', 'issn_l': '0895-4356', 'issn': ['1878-5921', '0895-4356'], 'display_name': 'Journal of Clinical Epidemiology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Rabia Bashir
AU  - Didi Surian
AU  - Adam G. Dunn
ER  - 

100.
TY  - journal-article
ID  - https://openalex.org/W3024017549
DO  - https://doi.org/10.1038/s41370-020-0228-0
TI  - Challenges and recommendations on the conduct of systematic reviews of observational epidemiologic studies in environmental and occupational health
AB  - Systematic reviews are powerful tools for drawing causal inference for evidence-based decision-making. Published systematic reviews and meta-analyses of environmental and occupational epidemiology studies have increased dramatically in recent years; however, the quality and utility of published reviews are variable. Most methodologies were adapted from clinical epidemiology and have not been adequately modified to evaluate and integrate evidence from observational epidemiology studies assessing environmental and occupational hazards, especially in evaluating the quality of exposure assessments. Although many reviews conduct a systematic and transparent assessment for the potential for bias, they are often deficient in subsequently integrating across a body of evidence. A cohesive review considers the impact of the direction and magnitude of potential biases on the results, systematically evaluates important scientific issues such as study sensitivity and effect modifiers, identifies how different studies complement each other, and assesses other potential sources of heterogeneity. Given these challenges of conducting informative systematic reviews of observational studies, we provide a series of specific recommendations based on practical examples for cohesive evidence integration to reach an overall conclusion on a body of evidence to better support policy making in public health. (100%) while recall was best for exposure and study design with 97% and 89%, respectively. The lowest recall was observed for the population (54%), which also had the lowest F-score (70%).The generated performance of our text-mining approach demonstrated encouraging results for the identification of targeted information from observational epidemiological study abstracts related to environmental exposures. We have demonstrated that rules based on generic syntactic patterns in one corpus can be applied to other observational study design by simple interchanging the dictionaries aiming to identify certain characteristics (i.e., outcomes, exposures). At the document level, the recognised information can assist in the selection and categorization of studies included in a systematic review. new approach to assist in labor intensive systematic reviews. Predictive ability of different elements (both single and composited) was explored. Without using model training approaches, we established a generalizable method that can achieve a competitive performance. performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable. is effective in treating depression in adolescents. Physical activity sessions should be at least moderately intense [rate of perceived exertion (RPE) between 11 and 13] to be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2021
DA  - 2021-01-01
JO  - {'id': 'https://openalex.org/S87749278', 'issn_l': '1559-0631', 'issn': ['1559-0631', '1559-064X'], 'display_name': 'Journal of Exposure Science and Environmental Epidemiology', 'publisher': 'Nature Portfolio', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Whitney D. Arroyave
AU  - Suril S. Mehta
AU  - Neela Guha
AU  - Pam Schwingl
AU  - Kyla W. Taylor
AU  - Barbara S. Glenn
AU  - Elizabeth G. Radke
AU  - Nadia Vilahur
AU  - Tania Carreón
AU  - Rebecca M. Nachman
AU  - Ruth M. Lunn
ER  - 

101.
TY  - journal-article
ID  - https://openalex.org/W3163124033
DO  - https://doi.org/10.12688/f1000research.51117.1
TI  - Data extraction methods for systematic review (semi)automation: A living systematic review
AB  - <ns3:p><ns3:bold>Background:</ns3:bold> The reliable and usable (semi)automation of data extraction can support the field of systematic review by reducing the workload required to gather information about the conduct and results of the included studies. This living systematic review examines published approaches for data extraction from reports of clinical studies.</ns3:p><ns3:p> <ns3:bold>Methods:</ns3:bold> We systematically and continually search MEDLINE, Institute of Electrical and Electronics Engineers (IEEE), arXiv, and the <ns3:italic>dblp computer science bibliography</ns3:italic> databases. Full text screening and data extraction are conducted within an open-source living systematic review application created for the purpose of this review. This iteration of the living review includes publications up to a cut-off date of 22 April 2020.</ns3:p><ns3:p> <ns3:bold>Results: </ns3:bold>In total, 53 publications are included in this version of our review. Of these, 41 (77%) of the publications addressed extraction of data from abstracts, while 14 (26%) used full texts. A total of 48 (90%) publications developed and evaluated classifiers that used randomised controlled trials as the main target texts. Over 30 entities were extracted, with PICOs (population, intervention, comparator, outcome) being the most frequently extracted. A description of their datasets was provided by 49 publications (94%), but only seven (13%) made the data publicly available. Code was made available by 10 (19%) publications, and five (9%) implemented publicly available tools.</ns3:p><ns3:p> <ns3:bold>Conclusions:</ns3:bold> This living systematic review presents an overview of (semi)automated data-extraction literature of interest to different types of systematic review. We identified a broad evidence base of publications describing data extraction for interventional reviews and a small number of publications extracting epidemiological or diagnostic accuracy data. The lack of publicly available gold-standard data for evaluation, and lack of application thereof, makes it difficult to draw conclusions on which is the best-performing system for each data extraction target. With this living review we aim to review the literature continually.</ns3:p> assist in labor intensive systematic reviews. Predictive ability of different elements (both single and composited) was explored. Without using model training approaches, we established a generalizable method that can achieve a competitive performance. performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable. is effective in treating depression in adolescents. Physical activity sessions should be at least moderately intense [rate of perceived exertion (RPE) between 11 and 13] to be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2021
DA  - 2021-05-19
JO  - {'id': 'https://openalex.org/S4210239046', 'issn_l': '2046-1402', 'issn': ['2046-1402'], 'display_name': 'F1000Research', 'publisher': 'Faculty of 1000', 'type': 'journal', 'url': 'https://f1000research.com/articles/10-401/v1/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Lena Schmidt
AU  - Babatunde K. Olorisade
AU  - Adrian M. Price-Whelan
AU  - James D. Thomas
AU  - Julian P T Higgins
ER  - 

102.
TY  - journal-article
ID  - https://openalex.org/W1760062773
DO  - https://doi.org/10.1089/neu.2015.4124
TI  - A New Approach to Evidence Synthesis in Traumatic Brain Injury: A Living Systematic Review
AB  - Living systematic reviews (LSRs) are online summaries of health care research that are updated as new research becomes available. This new development in evidence synthesis is being trialled as part of the Collaborative European NeuroTrauma Effectiveness Research in Traumatic Brain Injury (CENTER-TBI) project. We will develop and sustain an international TBI knowledge community that maintains up-to-date, high quality LSRs of the current state of knowledge in the most important questions in TBI. Automatic search updates will be run three-monthly, and newly identified studies incorporated into the review. Review teams will seek to publish journal updates at regular intervals, with abridged updates available more frequently online. Future project stages include the integration of LSR and other study findings into "living" clinical practice guidance. It is hoped these efforts will go some way to bridging current temporal disconnects between evidence, guidelines, and practice in TBI. of 48 (90%) publications developed and evaluated classifiers that used randomised controlled trials as the main target texts. Over 30 entities were extracted, with PICOs (population, intervention, comparator, outcome) being the most frequently extracted. A description of their datasets was provided by 49 publications (94%), but only seven (13%) made the data publicly available. Code was made available by 10 (19%) publications, and five (9%) implemented publicly available tools.</ns3:p><ns3:p> <ns3:bold>Conclusions:</ns3:bold> This living systematic review presents an overview of (semi)automated data-extraction literature of interest to different types of systematic review. We identified a broad evidence base of publications describing data extraction for interventional reviews and a small number of publications extracting epidemiological or diagnostic accuracy data. The lack of publicly available gold-standard data for evaluation, and lack of application thereof, makes it difficult to draw conclusions on which is the best-performing system for each data extraction target. With this living review we aim to review the literature continually.</ns3:p> assist in labor intensive systematic reviews. Predictive ability of different elements (both single and composited) was explored. Without using model training approaches, we established a generalizable method that can achieve a competitive performance. performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable. is effective in treating depression in adolescents. Physical activity sessions should be at least moderately intense [rate of perceived exertion (RPE) between 11 and 13] to be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2021
DA  - 2021-04-15
JO  - {'id': 'https://openalex.org/S85864898', 'issn_l': '0897-7151', 'issn': ['0897-7151', '1557-9042'], 'display_name': 'Journal of Neurotrauma', 'publisher': 'Mary Ann Liebert, Inc.', 'type': 'journal', 'url': 'https://doi.org/10.1089/neu.2015.4124', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc'}
DP  - OpenAlex
AU  - Anneliese Synnot
AU  - Russell L. Gruen
AU  - David K. Menon
AU  - Ewout W. Steyerberg
AU  - Andras Buki
AU  - Wilco C. Peul
AU  - Julian Elliott
AU  - Andrew I R Maas
ER  - 

103.
TY  - journal-article
ID  - https://openalex.org/W3121008219
DO  - https://doi.org/10.1016/j.emj.2021.01.002
TI  - Reproducibility and replicability crisis: How management compares to psychology and economics – A systematic review of literature
AB  - The past decade has been marked by concerns regarding the replicability and reproducibility of published research in the social sciences. Publicized failures to replicate landmark studies, along with high-profile cases of research fraud, have led scholars to reconsider the trustworthiness of both findings and institutionalized research practices. This paper considers two questions: (1) Relative to psychology and economics, what is the state of replication and reproduction research in management? (2) Are the disciplines equally advanced in the use of methods applied to study the replication problem? A systematic literature review identified 67 studies pertinent to these questions. The results indicate that the replication prevalence rate in management studies lies almost exactly between those of psychology and economics, while a high level of variation between management and other business-related disciplines can be noted. Further, similarly to psychology, but unlike economics, the surveys of published replications tend to report high replication success rates for management and other business-related disciplines. However, a comparison with recently obtained results in preregistered multi-study replications in psychology and economics suggests that these rates are almost certainly inflated. Method and data transparency are medium to low, often rendering attempts to reproduce or replicate studies impossible. Finally, the understanding of the replicability problem in management is held back by the underutilization of methods developed in other disciplines. The review also reveals that management, psychology, and economics exhibit strikingly different practices and approaches to replication, despite facing similar incentive structures. Disciplines in which replication and reproduction attempts are rare and which frequently involve authors of the original study in replication attempts lack strong deterrents against questionable research practices; thus, they are less likely to deliver replicable results. conclusions on which is the best-performing system for each data extraction target. With this living review we aim to review the literature continually.</ns3:p> assist in labor intensive systematic reviews. Predictive ability of different elements (both single and composited) was explored. Without using model training approaches, we established a generalizable method that can achieve a competitive performance. performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable. is effective in treating depression in adolescents. Physical activity sessions should be at least moderately intense [rate of perceived exertion (RPE) between 11 and 13] to be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2021
DA  - 2021-01-12
JO  - {'id': 'https://openalex.org/S105567970', 'issn_l': '0263-2373', 'issn': ['1873-5681', '0263-2373'], 'display_name': 'European Management Journal', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'https://doi.org/10.1016/j.emj.2021.01.002', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Przemysław G. Hensel
ER  - 

104.
TY  - journal-article
ID  - https://openalex.org/W3094744218
DO  - https://doi.org/10.1007/s10791-020-09381-1
TI  - A comparison of automatic Boolean query formulation for systematic reviews
AB  - No Abstract Found
PY  - 2021
DA  - 2021-02-01
JO  - {'id': 'https://openalex.org/S79460864', 'issn_l': '1386-4564', 'issn': ['1386-4564', '1573-7659'], 'display_name': 'Information Retrieval', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Harrisen Scells
AU  - Guido Zuccon
AU  - Bevan Koopman
ER  - 

105.
TY  - journal-article
ID  - https://openalex.org/W3164863290
DO  - https://doi.org/10.2196/24418
TI  - The Impact of Systematic Review Automation Tools on Methodological Quality and Time Taken to Complete Systematic Review Tasks: Case Study
AB  - Background Systematic reviews (SRs) are considered the highest level of evidence to answer research questions; however, they are time and resource intensive. Objective When comparing SR tasks done manually, using standard methods, versus those same SR tasks done using automated tools, (1) what is the difference in time to complete the SR task and (2) what is the impact on the error rate of the SR task? Methods A case study compared specific tasks done during the conduct of an SR on prebiotic, probiotic, and synbiotic supplementation in chronic kidney disease. Two participants (manual team) conducted the SR using current methods, comprising a total of 16 tasks. Another two participants (automation team) conducted the tasks where a systematic review automation (SRA) tool was available, comprising of a total of six tasks. The time taken and error rate of the six tasks that were completed by both teams were compared. Results The approximate time for the manual team to produce a draft of the background, methods, and results sections of the SR was 126 hours. For the six tasks in which times were compared, the manual team spent 2493 minutes (42 hours) on the tasks, compared to 708 minutes (12 hours) spent by the automation team. The manual team had a higher error rate in two of the six tasks—regarding Task 5: Run the systematic search, the manual team made eight errors versus three errors made by the automation team; regarding Task 12: Assess the risk of bias, 25 assessments differed from a reference standard for the manual team compared to 20 differences for the automation team. The manual team had a lower error rate in one of the six tasks—regarding Task 6: Deduplicate search results, the manual team removed one unique study and missed zero duplicates versus the automation team who removed two unique studies and missed seven duplicates. Error rates were similar for the two remaining compared tasks—regarding Task 7: Screen the titles and abstracts and Task 9: Screen the full text, zero relevant studies were excluded by both teams. One task could not be compared between groups—Task 8: Find the full text. Conclusions For the majority of SR tasks where an SRA tool was used, the time required to complete that task was reduced for novice researchers while methodological quality was maintained. be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2021
DA  - 2021-05-31
JO  - {'id': 'https://openalex.org/S4210212741', 'issn_l': '2369-3762', 'issn': ['2369-3762'], 'display_name': 'JMIR medical education', 'publisher': 'JMIR Publications', 'type': 'journal', 'url': 'https://mededu.jmir.org/2021/2/e24418/PDF', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Justin Clark
AU  - Catherine McFarlane
AU  - Gina Cleo
AU  - Christiane Ishikawa Ramos
AU  - Skye Marshall
ER  - 

106.
TY  - journal-article
ID  - https://openalex.org/W3207456925
DO  - https://doi.org/10.1177/02683962211048201
TI  - Artificial intelligence and the conduct of literature reviews
AB  - Artificial intelligence (AI) is beginning to transform traditional research practices in many areas. In this context, literature reviews stand out because they operate on large and rapidly growing volumes of documents, that is, partially structured (meta)data, and pervade almost every type of paper published in information systems research or related social science disciplines. To familiarize researchers with some of the recent trends in this area, we outline how AI can expedite individual steps of the literature review process. Considering that the use of AI in this context is in an early stage of development, we propose a comprehensive research agenda for AI-based literature reviews (AILRs) in our field. With this agenda, we would like to encourage design science research and a broader constructive discourse on shaping the future of AILRs in research. time taken and error rate of the six tasks that were completed by both teams were compared. Results The approximate time for the manual team to produce a draft of the background, methods, and results sections of the SR was 126 hours. For the six tasks in which times were compared, the manual team spent 2493 minutes (42 hours) on the tasks, compared to 708 minutes (12 hours) spent by the automation team. The manual team had a higher error rate in two of the six tasks—regarding Task 5: Run the systematic search, the manual team made eight errors versus three errors made by the automation team; regarding Task 12: Assess the risk of bias, 25 assessments differed from a reference standard for the manual team compared to 20 differences for the automation team. The manual team had a lower error rate in one of the six tasks—regarding Task 6: Deduplicate search results, the manual team removed one unique study and missed zero duplicates versus the automation team who removed two unique studies and missed seven duplicates. Error rates were similar for the two remaining compared tasks—regarding Task 7: Screen the titles and abstracts and Task 9: Screen the full text, zero relevant studies were excluded by both teams. One task could not be compared between groups—Task 8: Find the full text. Conclusions For the majority of SR tasks where an SRA tool was used, the time required to complete that task was reduced for novice researchers while methodological quality was maintained. be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2021
DA  - 2021-10-08
JO  - {'id': 'https://openalex.org/S135086714', 'issn_l': '0268-3962', 'issn': ['0268-3962', '1466-4437'], 'display_name': 'Journal of Information Technology', 'publisher': 'Macmillan Publishers', 'type': 'journal', 'url': 'https://journals.sagepub.com/doi/pdf/10.1177/02683962211048201', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Gerit Wagner
AU  - Roman Lukyanenko
AU  - Guy Paré
ER  - 

107.
TY  - journal-article
ID  - https://openalex.org/W2587369849
DO  - https://doi.org/10.1186/s13643-017-0421-y
TI  - RevManHAL: towards automatic text generation in systematic reviews
AB  - Systematic reviews are a key part of healthcare evaluation. They involve important painstaking but repetitive work. A major producer of systematic reviews, the Cochrane Collaboration, employs Review Manager (RevMan) programme-a software which assists reviewers and produces XML-structured files. This paper describes an add-on programme (RevManHAL) which helps auto-generate the abstract, results and discussion sections of RevMan-generated reviews in multiple languages. The paper also describes future developments for RevManHAL.RevManHAL was created in Java using NetBeans by a programmer working full time for 2 months.The resulting open-source programme uses editable phrase banks to envelop text/numbers from within the prepared RevMan file in formatted readable text of a chosen language. In this way, considerable parts of the review's 'abstract', 'results' and 'discussion' sections are created and a phrase added to 'acknowledgements'.RevManHAL's output needs to be checked by reviewers, but already, from our experience within the Cochrane Schizophrenia Group (200 maintained reviews, 900 reviewers), RevManHAL has saved much time which is better employed thinking about the meaning of the data rather than restating them. Many more functions will become possible as review writing becomes increasingly automated. compared, the manual team spent 2493 minutes (42 hours) on the tasks, compared to 708 minutes (12 hours) spent by the automation team. The manual team had a higher error rate in two of the six tasks—regarding Task 5: Run the systematic search, the manual team made eight errors versus three errors made by the automation team; regarding Task 12: Assess the risk of bias, 25 assessments differed from a reference standard for the manual team compared to 20 differences for the automation team. The manual team had a lower error rate in one of the six tasks—regarding Task 6: Deduplicate search results, the manual team removed one unique study and missed zero duplicates versus the automation team who removed two unique studies and missed seven duplicates. Error rates were similar for the two remaining compared tasks—regarding Task 7: Screen the titles and abstracts and Task 9: Screen the full text, zero relevant studies were excluded by both teams. One task could not be compared between groups—Task 8: Find the full text. Conclusions For the majority of SR tasks where an SRA tool was used, the time required to complete that task was reduced for novice researchers while methodological quality was maintained. be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2017
DA  - 2017-02-09
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://systematicreviewsjournal.biomedcentral.com/track/pdf/10.1186/s13643-017-0421-y', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Mercedes Torres Torres
AU  - Clive E Adams
ER  - 

108.
TY  - book-chapter
ID  - https://openalex.org/W3082069439
DO  - https://doi.org/10.1007/978-3-030-32489-6_12
TI  - Automating Systematic Literature Review
AB  - No Abstract Found
PY  - 2020
DA  - 2020-01-01
JO  - {'id': 'https://openalex.org/V4306463941', 'issn_l': None, 'issn': None, 'display_name': 'Springer International Publishing eBooks', 'publisher': 'Springer Nature', 'type': 'ebook platform', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Katia Romero Felizardo
AU  - Jeffrey C. Carver
ER  - 

109.
TY  - journal-article
ID  - https://openalex.org/W3128065054
DO  - https://doi.org/10.3389/fpsyg.2021.528352
TI  - Acute Exercise-Induced Set Shifting Benefits in Healthy Adults and Its Moderators: A Systematic Review and Meta-Analysis
AB  - Background: Positive effects of acute exercise on cognitive performances in general inspired research that investigated the effects of acute exercise on specific cognitive subdomains. Many existing studies examined beneficial effects of acute exercise on subsequent set shifting performance in healthy adults. Set shifting, a subdomain of executive function, is the ability to switch between different cognitive sets. The results of existing studies are inconsistent. Therefore, a meta-analysis was conducted that pooled available effect sizes. Additionally, moderator analyses were carried out to identify covariates that determine the magnitude of exercise-induced set shifting benefits. Methods: Medline, PsycINFO, and SPORTDiscus were searched for eligible studies. Hedges' g corrected standardized mean difference values were used for analyses. Random-effects weights were applied to pool effects. Potential moderation of the effect of acute exercise on subsequent set shifting performance by exercise intensity, type of exercise, participants' age, and type of control group were examined. Results: Twenty-two studies ( N = 1,900) were included into analysis. All aggregated effect sizes ranged from small to moderate. Overall, a small significant beneficial effect was revealed (g = −0.32, 95 % CI −0.45 to −0.18). Heterogeneity of included effect sizes was moderate and significant (T 2 = 0.0715, I 2 = 46.4%, ( p &amp;lt; 0.0016). Moderator analyses revealed a larger average effect in older adults than for studies examining younger adults (−0.42 vs. −0.29). Light exercise (−0.51) led to larger effects than moderate (−0.24) or vigorous exercise (−0.29). Studies testing acute exercise against active control groups showed a noticeably smaller average effect (−0.13) than studies that used passive (−0.38) or cognitive engaging control groups (−0.34). Interestingly, application of resistance or aerobic exercise led to no different average effect sizes (−0.30 vs. −0.32). However, none of the tested covariates reached statistical significance. Conclusion: Acute exercise improves subsequent set shifting performance. However, effect sizes are small, making the relevance for everyday life questionable. The results indicate that older adults benefit more from acute exercise than younger adults do. Light intensity exercise seems most effective while the type of exercise does not seem to influence the magnitude of effects. Research designs with active control groups show the smallest average effect, raising concerns about placebo effects. PROSPERO registration number: CRD42019138799 the time required to complete that task was reduced for novice researchers while methodological quality was maintained. be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2021
DA  - 2021-01-29
JO  - {'id': 'https://openalex.org/S9692511', 'issn_l': '1664-1078', 'issn': ['1664-1078'], 'display_name': 'Frontiers in Psychology', 'publisher': 'Frontiers Media', 'type': 'journal', 'url': 'https://www.frontiersin.org/articles/10.3389/fpsyg.2021.528352/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Max Oberste
AU  - Sophia Sharma
AU  - Wilhelm Bloch
AU  - Philipp Zimmer
ER  - 

110.
TY  - journal-article
ID  - https://openalex.org/W3139443298
DO  - https://doi.org/10.1016/j.jclinepi.2021.03.013
TI  - A prospective comparison of evidence synthesis search strategies developed with and without text-mining tools
AB  - We compared the process of developing searches with and without using text-mining tools (TMTs) for evidence synthesis products.This descriptive comparative analysis included seven systematic reviews, classified as simple or complex. Two librarians created MEDLINE strategies for each review, using either usual practice (UP) or TMTs. For each search we calculated sensitivity, number-needed-to-read (NNR) and time spent developing the search strategy.We found UP searches were more sensitive (UP 92% (95% CI, 85-99); TMT 84.9% (95% CI, 74.4-95.4)), with lower NNR (UP 83 (SD 34); TMT 90 (SD 68)). UP librarians spent an average of 12 h (SD 8) developing search strategies, compared to TMT librarians' 5 hours (SD 2).Across all reviews, TMT searches were less sensitive than UP searches, but confidence intervals overlapped. For simple SR topics, TMT searches were faster and slightly less sensitive than UP. For complex SR topics, TMT searches were faster and less sensitive than UP searches but identified unique eligible citations not found by the UP searches. effect sizes ranged from small to moderate. Overall, a small significant beneficial effect was revealed (g = −0.32, 95 % CI −0.45 to −0.18). Heterogeneity of included effect sizes was moderate and significant (T 2 = 0.0715, I 2 = 46.4%, ( p &amp;lt; 0.0016). Moderator analyses revealed a larger average effect in older adults than for studies examining younger adults (−0.42 vs. −0.29). Light exercise (−0.51) led to larger effects than moderate (−0.24) or vigorous exercise (−0.29). Studies testing acute exercise against active control groups showed a noticeably smaller average effect (−0.13) than studies that used passive (−0.38) or cognitive engaging control groups (−0.34). Interestingly, application of resistance or aerobic exercise led to no different average effect sizes (−0.30 vs. −0.32). However, none of the tested covariates reached statistical significance. Conclusion: Acute exercise improves subsequent set shifting performance. However, effect sizes are small, making the relevance for everyday life questionable. The results indicate that older adults benefit more from acute exercise than younger adults do. Light intensity exercise seems most effective while the type of exercise does not seem to influence the magnitude of effects. Research designs with active control groups show the smallest average effect, raising concerns about placebo effects. PROSPERO registration number: CRD42019138799 the time required to complete that task was reduced for novice researchers while methodological quality was maintained. be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2021
DA  - 2021-03-20
JO  - {'id': 'https://openalex.org/S64418186', 'issn_l': '0895-4356', 'issn': ['1878-5921', '0895-4356'], 'display_name': 'Journal of Clinical Epidemiology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'http://www.jclinepi.com/article/S0895435621000858/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Robin Paynter
AU  - Robin Featherstone
AU  - Elizabeth Stoeger
AU  - Celia Fiordalisi
AU  - Christiane Voisin
AU  - Gaelen P Adam
ER  - 

111.
TY  - journal-article
ID  - https://openalex.org/W4229023865
DO  - https://doi.org/10.1136/bmj-2021-068791
TI  - Searching clinical trials registers: guide for systematic reviewers
AB  - Systematic reviews should incorporate as much relevant evidence as possible to reduce bias and research waste and increase reliability of results. Clinical trials registers are a key resource for identifying potentially eligible studies, particularly those that are unpublished, and therefore searching these registers is mandated for best practice systematic reviews. However, the process of searching can be challenging and no clear and consistent guidance on how best to do this exists. This paper provides step-by-step guidance on how to conduct systematic searches for studies using clinical trials registers, with a case study to illustrate each step. The guidance encompasses where to search and how to formulate the search strategy, conduct the search, download results, screen records, obtain data, update searches, and report on these searches. topics, TMT searches were faster and slightly less sensitive than UP. For complex SR topics, TMT searches were faster and less sensitive than UP searches but identified unique eligible citations not found by the UP searches. effect sizes ranged from small to moderate. Overall, a small significant beneficial effect was revealed (g = −0.32, 95 % CI −0.45 to −0.18). Heterogeneity of included effect sizes was moderate and significant (T 2 = 0.0715, I 2 = 46.4%, ( p &amp;lt; 0.0016). Moderator analyses revealed a larger average effect in older adults than for studies examining younger adults (−0.42 vs. −0.29). Light exercise (−0.51) led to larger effects than moderate (−0.24) or vigorous exercise (−0.29). Studies testing acute exercise against active control groups showed a noticeably smaller average effect (−0.13) than studies that used passive (−0.38) or cognitive engaging control groups (−0.34). Interestingly, application of resistance or aerobic exercise led to no different average effect sizes (−0.30 vs. −0.32). However, none of the tested covariates reached statistical significance. Conclusion: Acute exercise improves subsequent set shifting performance. However, effect sizes are small, making the relevance for everyday life questionable. The results indicate that older adults benefit more from acute exercise than younger adults do. Light intensity exercise seems most effective while the type of exercise does not seem to influence the magnitude of effects. Research designs with active control groups show the smallest average effect, raising concerns about placebo effects. PROSPERO registration number: CRD42019138799 the time required to complete that task was reduced for novice researchers while methodological quality was maintained. be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2022
DA  - 2022-04-26
JO  - {'id': 'https://openalex.org/S4210185579', 'issn_l': '1756-1833', 'issn': ['1756-1833'], 'display_name': 'BMJ', 'publisher': 'BMJ', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Kylie E Hunter
AU  - Angela C Webster
AU  - Matthew J. Page
AU  - Melina L Willson
AU  - Steve McDonald
AU  - Slavica Berber
AU  - Peta Skeers
AU  - Ava Grace Tan-Koay
AU  - Anne Parkhill
AU  - Andreas Seidler
ER  - 

112.
TY  - journal-article
ID  - https://openalex.org/W2468613466
DO  - nan
TI  - Examining the Distribution, Modularity, and Community Structure in Article Networks for Systematic Reviews.
AB  - Systematic reviews (SRs) provide high quality evidence for clinical practice, but the article screening process is time and labor intensive. As SRs aim to identify relevant articles with a specific scope, we propose that a pre-defined article relationship, using similarity metrics, could accelerate this process. In this study, we established the article relationship using MEDLINE element similarities and visualized the article network with the Force Atlas layout. We also analyzed the article networks with graph diameter, closeness centrality, and module classes. The results revealed the distribution of articles and found that included articles tended to aggregate together in some module classes, providing further evidence of the existence of strong relationships among included articles. This approach can be utilized to facilitate the articles selection process through early identification of these dominant module classes. We are optimistic that the use of article network visualization can help better SR work prioritization. UP searches but identified unique eligible citations not found by the UP searches. effect sizes ranged from small to moderate. Overall, a small significant beneficial effect was revealed (g = −0.32, 95 % CI −0.45 to −0.18). Heterogeneity of included effect sizes was moderate and significant (T 2 = 0.0715, I 2 = 46.4%, ( p &amp;lt; 0.0016). Moderator analyses revealed a larger average effect in older adults than for studies examining younger adults (−0.42 vs. −0.29). Light exercise (−0.51) led to larger effects than moderate (−0.24) or vigorous exercise (−0.29). Studies testing acute exercise against active control groups showed a noticeably smaller average effect (−0.13) than studies that used passive (−0.38) or cognitive engaging control groups (−0.34). Interestingly, application of resistance or aerobic exercise led to no different average effect sizes (−0.30 vs. −0.32). However, none of the tested covariates reached statistical significance. Conclusion: Acute exercise improves subsequent set shifting performance. However, effect sizes are small, making the relevance for everyday life questionable. The results indicate that older adults benefit more from acute exercise than younger adults do. Light intensity exercise seems most effective while the type of exercise does not seem to influence the magnitude of effects. Research designs with active control groups show the smallest average effect, raising concerns about placebo effects. PROSPERO registration number: CRD42019138799 the time required to complete that task was reduced for novice researchers while methodological quality was maintained. be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2015
DA  - 2015-11-05
JO  - {'id': 'https://openalex.org/S4306417663', 'issn_l': None, 'issn': None, 'display_name': 'American Medical Informatics Association Annual Symposium', 'publisher': None, 'type': 'conference', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Xiaonan Ji
AU  - Raghu Machiraju
AU  - Alan Ritter
AU  - Po-Yin Yen
ER  - 

113.
TY  - journal-article
ID  - https://openalex.org/W2636913666
DO  - https://doi.org/10.1093/intqhc/mzx076
TI  - Linking quality indicators to clinical trials: an automated approach
AB  - Quality improvement of health care requires robust measurable indicators to track performance. However identifying which indicators are supported by strong clinical evidence, typically from clinical trials, is often laborious. This study tests a novel method for automatically linking indicators to clinical trial registrations.A set of 522 quality of care indicators for 22 common conditions drawn from the CareTrack study were automatically mapped to outcome measures reported in 13 971 trials from ClinicalTrials.gov.Text mining methods extracted phrases mentioning indicators and outcome phrases, and these were compared using the Levenshtein edit distance ratio to measure similarity.Number of care indicators that mapped to outcome measures in clinical trials.While only 13% of the 522 CareTrack indicators were thought to have Level I or II evidence behind them, 353 (68%) could be directly linked to randomized controlled trials. Within these 522, 50 of 70 (71%) Level I and II evidence-based indicators, and 268 of 370 (72%) Level V (consensus-based) indicators could be linked to evidence. Of the indicators known to have evidence behind them, only 5.7% (4 of 70) were mentioned in the trial reports but were missed by our method.We automatically linked indicators to clinical trial registrations with high precision. Whilst the majority of quality indicators studied could be directly linked to research evidence, a small portion could not and these require closer scrutiny. It is feasible to support the process of indicator development using automated methods to identify research evidence. exercise (−0.29). Studies testing acute exercise against active control groups showed a noticeably smaller average effect (−0.13) than studies that used passive (−0.38) or cognitive engaging control groups (−0.34). Interestingly, application of resistance or aerobic exercise led to no different average effect sizes (−0.30 vs. −0.32). However, none of the tested covariates reached statistical significance. Conclusion: Acute exercise improves subsequent set shifting performance. However, effect sizes are small, making the relevance for everyday life questionable. The results indicate that older adults benefit more from acute exercise than younger adults do. Light intensity exercise seems most effective while the type of exercise does not seem to influence the magnitude of effects. Research designs with active control groups show the smallest average effect, raising concerns about placebo effects. PROSPERO registration number: CRD42019138799 the time required to complete that task was reduced for novice researchers while methodological quality was maintained. be effective. Furthermore, our results suggest that physical activity treatments are well accepted. However, the low methodological quality in included studies might have led to effect overestimation. Therefore, more studies with higher methodological quality are needed to confirm the recommendation for physical activity treatments in adolescents with depression.
PY  - 2017
DA  - 2017-08-01
JO  - {'id': 'https://openalex.org/S74917805', 'issn_l': '1353-4505', 'issn': ['1464-3677', '1353-4505'], 'display_name': 'International Journal for Quality in Health Care', 'publisher': 'Oxford University Press', 'type': 'journal', 'url': 'https://academic.oup.com/intqhc/article-pdf/29/4/571/24325408/mzx076.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc'}
DP  - OpenAlex
AU  - Enrico Coiera
AU  - Miew Keen Choong
AU  - Guy Tsafnat
AU  - Peter Hibbert
AU  - William B. Runciman
ER  - 

114.
TY  - journal-article
ID  - https://openalex.org/W2982597005
DO  - https://doi.org/10.1016/j.jbi.2019.103321
TI  - Quantifying semantic similarity of clinical evidence in the biomedical literature to facilitate related evidence synthesis
AB  - • A publicly available expert-annotated data set of 1000 pairs of clinical evidence. • A generalisable approach for quantification of clinical evidence. • Unsupervised neural network representation of medical concepts for semantic similarity quantification. • Analysis of measures for quantifying semantic similarity of clinical evidence. Published clinical trials and high quality peer reviewed medical publications are considered as the main sources of evidence used for synthesizing systematic reviews or practicing Evidence Based Medicine (EBM). Finding all relevant published evidence for a particular medical case is a time and labour intensive task, given the breadth of the biomedical literature. Automatic quantification of conceptual relationships between key clinical evidence within and across publications, despite variations in the expression of clinically-relevant concepts, can help to facilitate synthesis of evidence. In this study, we aim to provide an approach towards expediting evidence synthesis by quantifying semantic similarity of key evidence as expressed in the form of individual sentences. Such semantic textual similarity can be applied as a key approach for supporting selection of related studies. We propose a generalisable approach for quantifying semantic similarity of clinical evidence in the biomedical literature, specifically considering the similarity of sentences corresponding to a given type of evidence, such as clinical interventions, population information, clinical findings, etc. We develop three sets of generic, ontology-based, and vector-space models of similarity measures that make use of a variety of lexical, conceptual, and contextual information to quantify the similarity of full sentences containing clinical evidence. To understand the impact of different similarity measures on the overall evidence semantic similarity quantification, we provide a comparative analysis of these measures when used as input to an unsupervised linear interpolation and a supervised regression ensemble. In order to provide a reliable test-bed for this experiment, we generate a dataset of 1000 pairs of sentences from biomedical publications that are annotated by ten human experts. We also extend the experiments on an external dataset for further generalisability testing. The combination of all diverse similarity measures showed stronger correlations with the gold standard similarity scores in the dataset than any individual kind of measure. Our approach reached near 0.80 average Pearson correlation across different clinical evidence types using the devised similarity measures. Although they were more effective when combined together, individual generic and vector-space measures also resulted in strong similarity quantification when used in both unsupervised and supervised models. On the external dataset, our similarity measures were highly competitive with the state-of-the-art approaches developed and trained specifically on that dataset for predicting semantic similarity. Experimental results showed that the proposed semantic similarity quantification approach can effectively identify related clinical evidence that is reported in the literature. The comparison with a state-of-the-art method demonstrated the effectiveness of the approach, and experiments with an external dataset support its generalisability.
PY  - 2019
DA  - 2019-12-01
JO  - {'id': 'https://openalex.org/S11622463', 'issn_l': '1532-0464', 'issn': ['1532-0480', '1532-0464'], 'display_name': 'Journal of Biomedical Informatics', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'https://doi.org/10.1016/j.jbi.2019.103321', 'is_oa': True, 'version': 'publishedVersion', 'license': 'elsevier-specific'}
DP  - OpenAlex
AU  - Hamed Hassanzadeh
AU  - Anthony Nguyen
AU  - Karin Verspoor
ER  - 

115.
TY  - journal-article
ID  - https://openalex.org/W2983931015
DO  - https://doi.org/10.1093/database/baz109
TI  - Evaluation of an automatic article selection method for timelier updates of the Comet Core Outcome Set database
AB  - Abstract Curated databases of scientific literature play an important role in helping researchers find relevant literature, but populating such databases is a labour intensive and time-consuming process. One such database is the freely accessible Comet Core Outcome Set database, which was originally populated using manual screening in an annually updated systematic review. In order to reduce the workload and facilitate more timely updates we are evaluating machine learning methods to reduce the number of references needed to screen. In this study we have evaluated a machine learning approach based on logistic regression to automatically rank the candidate articles. Data from the original systematic review and its four first review updates were used to train the model and evaluate performance. We estimated that using automatic screening would yield a workload reduction of at least 75% while keeping the number of missed references around 2%. We judged this to be an acceptable trade-off for this systematic review, and the method is now being used for the next round of the Comet database update. We propose a generalisable approach for quantifying semantic similarity of clinical evidence in the biomedical literature, specifically considering the similarity of sentences corresponding to a given type of evidence, such as clinical interventions, population information, clinical findings, etc. We develop three sets of generic, ontology-based, and vector-space models of similarity measures that make use of a variety of lexical, conceptual, and contextual information to quantify the similarity of full sentences containing clinical evidence. To understand the impact of different similarity measures on the overall evidence semantic similarity quantification, we provide a comparative analysis of these measures when used as input to an unsupervised linear interpolation and a supervised regression ensemble. In order to provide a reliable test-bed for this experiment, we generate a dataset of 1000 pairs of sentences from biomedical publications that are annotated by ten human experts. We also extend the experiments on an external dataset for further generalisability testing. The combination of all diverse similarity measures showed stronger correlations with the gold standard similarity scores in the dataset than any individual kind of measure. Our approach reached near 0.80 average Pearson correlation across different clinical evidence types using the devised similarity measures. Although they were more effective when combined together, individual generic and vector-space measures also resulted in strong similarity quantification when used in both unsupervised and supervised models. On the external dataset, our similarity measures were highly competitive with the state-of-the-art approaches developed and trained specifically on that dataset for predicting semantic similarity. Experimental results showed that the proposed semantic similarity quantification approach can effectively identify related clinical evidence that is reported in the literature. The comparison with a state-of-the-art method demonstrated the effectiveness of the approach, and experiments with an external dataset support its generalisability.
PY  - 2019
DA  - 2019-01-01
JO  - {'id': 'https://openalex.org/S4210201630', 'issn_l': '1758-0463', 'issn': ['1758-0463'], 'display_name': 'Database', 'publisher': 'University of Oxford', 'type': 'journal', 'url': 'https://academic.oup.com/database/article-pdf/doi/10.1093/database/baz109/30457495/baz109.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Christopher R. Norman
AU  - Elizabeth Gargon
AU  - Mariska M.G. Leeflang
AU  - Aurélie Névéol
AU  - Paula R Williamson
ER  - 

116.
TY  - journal-article
ID  - https://openalex.org/W3036561850
DO  - https://doi.org/10.3390/ijerph17124509
TI  - Semi-Supervised Text Classification Framework: An Overview of Dengue Landscape Factors and Satellite Earth Observation
AB  - In recent years there has been an increasing use of satellite Earth observation (EO) data in dengue research, in particular the identification of landscape factors affecting dengue transmission. Summarizing landscape factors and satellite EO data sources, and making the information public are helpful for guiding future research and improving health decision-making. In this case, a review of the literature would appear to be an appropriate tool. However, this is not an easy-to-use tool. The review process mainly includes defining the topic, searching, screening at both title/abstract and full-text levels and data extraction that needs consistent knowledge from experts and is time-consuming and labor intensive. In this context, this study integrates the review process, text scoring, active learning (AL) mechanism, and bidirectional long short-term memory (BiLSTM) networks, and proposes a semi-supervised text classification framework that enables the efficient and accurate selection of the relevant articles. Specifically, text scoring and BiLSTM-based active learning were used to replace the title/abstract screening and full-text screening, respectively, which greatly reduces the human workload. In this study, 101 relevant articles were selected from 4 bibliographic databases, and a catalogue of essential dengue landscape factors was identified and divided into four categories: land use (LU), land cover (LC), topography and continuous land surface features. Moreover, various satellite EO sensors and products used for identifying landscape factors were tabulated. Finally, possible future directions of applying satellite EO data in dengue research in terms of landscape patterns, satellite sensors and deep learning were proposed. The proposed semi-supervised text classification framework was successfully applied in research evidence synthesis that could be easily applied to other topics, particularly in an interdisciplinary context. to an unsupervised linear interpolation and a supervised regression ensemble. In order to provide a reliable test-bed for this experiment, we generate a dataset of 1000 pairs of sentences from biomedical publications that are annotated by ten human experts. We also extend the experiments on an external dataset for further generalisability testing. The combination of all diverse similarity measures showed stronger correlations with the gold standard similarity scores in the dataset than any individual kind of measure. Our approach reached near 0.80 average Pearson correlation across different clinical evidence types using the devised similarity measures. Although they were more effective when combined together, individual generic and vector-space measures also resulted in strong similarity quantification when used in both unsupervised and supervised models. On the external dataset, our similarity measures were highly competitive with the state-of-the-art approaches developed and trained specifically on that dataset for predicting semantic similarity. Experimental results showed that the proposed semantic similarity quantification approach can effectively identify related clinical evidence that is reported in the literature. The comparison with a state-of-the-art method demonstrated the effectiveness of the approach, and experiments with an external dataset support its generalisability.
PY  - 2020
DA  - 2020-06-23
JO  - {'id': 'https://openalex.org/S15239247', 'issn_l': '1660-4601', 'issn': ['1661-7827', '1660-4601'], 'display_name': 'International Journal of Environmental Research and Public Health', 'publisher': 'MDPI', 'type': 'journal', 'url': 'https://www.mdpi.com/1660-4601/17/12/4509/pdf?version=1592909580', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Zhichao Li
AU  - Helen da Costa Gurgel
AU  - Nadine Dessay
AU  - Luojia Hu
AU  - Lei Xu
AU  - Peng Gong
ER  - 

117.
TY  - journal-article
ID  - https://openalex.org/W3049274273
DO  - https://doi.org/10.2196/20007
TI  - Artificial Intelligence for Rapid Meta-Analysis: Case Study on Ocular Toxicity of Hydroxychloroquine
AB  - Background Rapid access to evidence is crucial in times of an evolving clinical crisis. To that end, we propose a novel approach to answer clinical queries, termed rapid meta-analysis (RMA). Unlike traditional meta-analysis, RMA balances a quick time to production with reasonable data quality assurances, leveraging artificial intelligence (AI) to strike this balance. Objective We aimed to evaluate whether RMA can generate meaningful clinical insights, but crucially, in a much faster processing time than traditional meta-analysis, using a relevant, real-world example. Methods The development of our RMA approach was motivated by a currently relevant clinical question: is ocular toxicity and vision compromise a side effect of hydroxychloroquine therapy? At the time of designing this study, hydroxychloroquine was a leading candidate in the treatment of coronavirus disease (COVID-19). We then leveraged AI to pull and screen articles, automatically extract their results, review the studies, and analyze the data with standard statistical methods. Results By combining AI with human analysis in our RMA, we generated a meaningful, clinical result in less than 30 minutes. The RMA identified 11 studies considering ocular toxicity as a side effect of hydroxychloroquine and estimated the incidence to be 3.4% (95% CI 1.11%-9.96%). The heterogeneity across individual study findings was high, which should be taken into account in interpretation of the result. Conclusions We demonstrate that a novel approach to meta-analysis using AI can generate meaningful clinical insights in a much shorter time period than traditional meta-analysis. and deep learning were proposed. The proposed semi-supervised text classification framework was successfully applied in research evidence synthesis that could be easily applied to other topics, particularly in an interdisciplinary context. to an unsupervised linear interpolation and a supervised regression ensemble. In order to provide a reliable test-bed for this experiment, we generate a dataset of 1000 pairs of sentences from biomedical publications that are annotated by ten human experts. We also extend the experiments on an external dataset for further generalisability testing. The combination of all diverse similarity measures showed stronger correlations with the gold standard similarity scores in the dataset than any individual kind of measure. Our approach reached near 0.80 average Pearson correlation across different clinical evidence types using the devised similarity measures. Although they were more effective when combined together, individual generic and vector-space measures also resulted in strong similarity quantification when used in both unsupervised and supervised models. On the external dataset, our similarity measures were highly competitive with the state-of-the-art approaches developed and trained specifically on that dataset for predicting semantic similarity. Experimental results showed that the proposed semantic similarity quantification approach can effectively identify related clinical evidence that is reported in the literature. The comparison with a state-of-the-art method demonstrated the effectiveness of the approach, and experiments with an external dataset support its generalisability.
PY  - 2020
DA  - 2020-08-17
JO  - {'id': 'https://openalex.org/S17147534', 'issn_l': '1438-8871', 'issn': ['1439-4456', '1438-8871'], 'display_name': 'Journal of Medical Internet Research', 'publisher': 'JMIR Publications', 'type': 'journal', 'url': 'https://www.jmir.org/2020/8/e20007/PDF', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Matthew Michelson
AU  - Tiffany W. Chow
AU  - Neil A. Martin
AU  - Mike Ross
AU  - Amelia Tee Qiao Ying
AU  - Steven Minton
ER  - 

118.
TY  - journal-article
ID  - https://openalex.org/W3098697762
DO  - https://doi.org/10.1016/j.actbio.2020.11.011
TI  - Osseointegration Pharmacology: A Systematic Mapping Using Artificial Intelligence
AB  - Clinical performance of osseointegrated implants could be compromised by the medications taken by patients. The effect of a specific medication on osseointegration can be easily investigated using traditional systematic reviews. However, assessment of all known medications requires the use of evidence mapping methods. These methods allow assessment of complex questions, but they are very resource intensive when done manually. The objective of this study was to develop a machine learning algorithm to automatically map the literature assessing the effect of medications on osseointegration. Datasets of articles classified manually were used to train a machine-learning algorithm based on Support Vector Machines. The algorithm was then validated and used to screen 599,604 articles identified with an extremely sensitive search strategy. The algorithm included 281 relevant articles that described the effect of 31 different drugs on osseointegration. This approach achieved an accuracy of 95%, and compared to manual screening, it reduced the workload by 93%. The systematic mapping revealed that the treatment outcomes of osseointegrated medical devices could be influenced by drugs affecting homeostasis, inflammation, cell proliferation and bone remodeling. The effect of all known medications on the performance of osseointegrated medical devices can be assessed using evidence mappings executed with highly accurate machine learning algorithms. high, which should be taken into account in interpretation of the result. Conclusions We demonstrate that a novel approach to meta-analysis using AI can generate meaningful clinical insights in a much shorter time period than traditional meta-analysis. and deep learning were proposed. The proposed semi-supervised text classification framework was successfully applied in research evidence synthesis that could be easily applied to other topics, particularly in an interdisciplinary context. to an unsupervised linear interpolation and a supervised regression ensemble. In order to provide a reliable test-bed for this experiment, we generate a dataset of 1000 pairs of sentences from biomedical publications that are annotated by ten human experts. We also extend the experiments on an external dataset for further generalisability testing. The combination of all diverse similarity measures showed stronger correlations with the gold standard similarity scores in the dataset than any individual kind of measure. Our approach reached near 0.80 average Pearson correlation across different clinical evidence types using the devised similarity measures. Although they were more effective when combined together, individual generic and vector-space measures also resulted in strong similarity quantification when used in both unsupervised and supervised models. On the external dataset, our similarity measures were highly competitive with the state-of-the-art approaches developed and trained specifically on that dataset for predicting semantic similarity. Experimental results showed that the proposed semantic similarity quantification approach can effectively identify related clinical evidence that is reported in the literature. The comparison with a state-of-the-art method demonstrated the effectiveness of the approach, and experiments with an external dataset support its generalisability.
PY  - 2021
DA  - 2021-01-01
JO  - {'id': 'https://openalex.org/S173145877', 'issn_l': '1742-7061', 'issn': ['1742-7061', '1878-7568'], 'display_name': 'Acta Biomaterialia', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Mohammed Mahri
AU  - Nicole Shen
AU  - Francisco Berrizbeitia
AU  - Rania Rodan
AU  - Ammar Daer
AU  - Matthew Faigan
AU  - Doaa Taqi
AU  - Kevin C.-W. Wu
AU  - Motahareh Ahmadi
AU  - Maxime Ducret
AU  - Elham Emami
AU  - Faleh Tamimi
ER  - 

119.
TY  - journal-article
ID  - https://openalex.org/W3172773626
DO  - https://doi.org/10.1186/s12970-021-00440-6
TI  - Body composition changes in physically active individuals consuming ketogenic diets: a systematic review
AB  - Abstract Background To achieve ideal strength/power to mass ratio, athletes may attempt to lower body mass through reductions in fat mass (FM), while maintaining or increasing fat-free mass (FFM) by manipulating their training regimens and diets. Emerging evidence suggests that consumption of high-fat, ketogenic diets (KD) may be advantageous for reducing body mass and FM, while retaining FFM. Methods A systematic review of the literature was conducted using PubMed and Cochrane Library databases to compare the effects of KD versus control diets (CON) on body mass and composition in physically active populations. Randomized and non-randomized studies were included if participants were healthy (free of chronic disease), physically active men or women age ≥ 18 years consuming KD (&lt; 50 g carbohydrate/d or serum or whole blood β-hydroxybutyrate (βhb) &gt; 0.5 mmol/L) for ≥14 days. Results Thirteen studies (9 parallel and 4 crossover/longitudinal) that met the inclusion criteria were identified. Aggregated results from the 13 identified studies show body mass decreased 2.7 kg in KD and increased 0.3 kg in CON. FM decreased by 2.3 kg in KD and 0.3 kg in CON. FFM decreased by 0.3 kg in KD and increased 0.7 kg in CON. Estimated energy balance based on changes in body composition was − 339 kcal/d in KD and 5 kcal/d in CON. Risk of bias identified some concern of bias primarily due to studies which allowed participants to self-select diet intervention groups, as well as inability to blind participants to the study intervention, and/or longitudinal study design. Conclusion KD can promote mobilization of fat stores to reduce FM while retaining FFM. However, there is variance in results of FFM across studies and some risk-of-bias in the current literature that is discussed in this systematic review. for this experiment, we generate a dataset of 1000 pairs of sentences from biomedical publications that are annotated by ten human experts. We also extend the experiments on an external dataset for further generalisability testing. The combination of all diverse similarity measures showed stronger correlations with the gold standard similarity scores in the dataset than any individual kind of measure. Our approach reached near 0.80 average Pearson correlation across different clinical evidence types using the devised similarity measures. Although they were more effective when combined together, individual generic and vector-space measures also resulted in strong similarity quantification when used in both unsupervised and supervised models. On the external dataset, our similarity measures were highly competitive with the state-of-the-art approaches developed and trained specifically on that dataset for predicting semantic similarity. Experimental results showed that the proposed semantic similarity quantification approach can effectively identify related clinical evidence that is reported in the literature. The comparison with a state-of-the-art method demonstrated the effectiveness of the approach, and experiments with an external dataset support its generalisability.
PY  - 2021
DA  - 2021-06-05
JO  - {'id': 'https://openalex.org/S3207227496', 'issn_l': '1550-2783', 'issn': ['1550-2783'], 'display_name': 'Journal of the International Society of Sports Nutrition', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://doi.org/10.1186/s12970-021-00440-6', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Julie Coleman
AU  - Christopher T. Carrigan
AU  - Lee M. Margolis
ER  - 

120.
TY  - book-chapter
ID  - https://openalex.org/W2295673905
DO  - https://doi.org/10.1007/978-3-319-26585-8_4
TI  - Identifying Evidence Quality for Updating Evidence-Based Medical Guidelines
AB  - No Abstract Found
PY  - 2015
DA  - 2015-06-20
JO  - {'id': 'https://openalex.org/S4306463941', 'issn_l': None, 'issn': None, 'display_name': 'Springer International Publishing eBooks', 'publisher': 'Springer Nature', 'type': 'ebook platform', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Zhisheng Huang
AU  - Qing Hu
AU  - Annette ten Teije
AU  - Frank van Harmelen
ER  - 

121.
TY  - journal-article
ID  - https://openalex.org/W3101551698
DO  - https://doi.org/10.15347/wjm/2020.005
TI  - What are Systematic Reviews?
AB  - Systematic reviews are a type of review that uses repeatable analytical methods to collect secondary data and analyse it. Systematic reviews are a type of evidence synthesis which formulate research questions that are broad or narrow in scope, and identify and synthesize data that directly relate to the systematic review question. While some people might associate ‘systematic review’ with 'meta-analysis', there are multiple kinds of review which can be defined as ‘systematic’ which do not involve a meta-analysis. Some systematic reviews critically appraise research studies, and synthesize findings qualitatively or quantitatively. Systematic reviews are often designed to provide an exhaustive summary of current evidence relevant to a research question. For example, systematic reviews of randomized controlled trials are an important way of informing evidence-based medicine, and a review of existing studies is often quicker and cheaper than embarking on a new study. While systematic reviews are often applied in the biomedical or healthcare context, they can be used in other areas where an assessment of a precisely defined subject would be helpful. Systematic reviews may examine clinical tests, public health interventions, environmental interventions, social interventions, adverse effects, qualitative evidence syntheses, methodological reviews, policy reviews, and economic evaluations. An understanding of systematic reviews and how to implement them in practice is highly recommended for professionals involved in the delivery of health care, public health and public policy. studies which allowed participants to self-select diet intervention groups, as well as inability to blind participants to the study intervention, and/or longitudinal study design. Conclusion KD can promote mobilization of fat stores to reduce FM while retaining FFM. However, there is variance in results of FFM across studies and some risk-of-bias in the current literature that is discussed in this systematic review. for this experiment, we generate a dataset of 1000 pairs of sentences from biomedical publications that are annotated by ten human experts. We also extend the experiments on an external dataset for further generalisability testing. The combination of all diverse similarity measures showed stronger correlations with the gold standard similarity scores in the dataset than any individual kind of measure. Our approach reached near 0.80 average Pearson correlation across different clinical evidence types using the devised similarity measures. Although they were more effective when combined together, individual generic and vector-space measures also resulted in strong similarity quantification when used in both unsupervised and supervised models. On the external dataset, our similarity measures were highly competitive with the state-of-the-art approaches developed and trained specifically on that dataset for predicting semantic similarity. Experimental results showed that the proposed semantic similarity quantification approach can effectively identify related clinical evidence that is reported in the literature. The comparison with a state-of-the-art method demonstrated the effectiveness of the approach, and experiments with an external dataset support its generalisability.
PY  - 2020
DA  - 2020-01-01
JO  - {'id': 'https://openalex.org/S4210215671', 'issn_l': '2002-4436', 'issn': ['2002-4436'], 'display_name': 'WikiJournal of medicine', 'publisher': 'WikiJournal User Group', 'type': 'journal', 'url': 'https://upload.wikimedia.org/wikiversity/en/7/7a/What_are_Systematic_Reviews.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-sa'}
DP  - OpenAlex
AU  - Jack Nunn
AU  - Steven L. Chang
ER  - 

122.
TY  - journal-article
ID  - https://openalex.org/W3104156511
DO  - https://doi.org/10.1186/s13643-020-01528-x
TI  - Decoding semi-automated title-abstract screening: findings from a convenience sample of reviews
AB  - Abstract Background We evaluated the benefits and risks of using the Abstrackr machine learning (ML) tool to semi-automate title-abstract screening and explored whether Abstrackr’s predictions varied by review or study-level characteristics. Methods For a convenience sample of 16 reviews for which adequate data were available to address our objectives (11 systematic reviews and 5 rapid reviews), we screened a 200-record training set in Abstrackr and downloaded the relevance (relevant or irrelevant) of the remaining records, as predicted by the tool. We retrospectively simulated the liberal-accelerated screening approach. We estimated the time savings and proportion missed compared with dual independent screening. For reviews with pairwise meta-analyses, we evaluated changes to the pooled effects after removing the missed studies. We explored whether the tool’s predictions varied by review and study-level characteristics. Results Using the ML-assisted liberal-accelerated approach, we wrongly excluded 0 to 3 (0 to 14%) records that were included in the final reports, but saved a median (IQR) 26 (9, 42) h of screening time. One missed study was included in eight pairwise meta-analyses in one systematic review. The pooled effect for just one of those meta-analyses changed considerably (from MD (95% CI) − 1.53 (− 2.92, − 0.15) to − 1.17 (− 2.70, 0.36)). Of 802 records in the final reports, 87% were correctly predicted as relevant. The correctness of the predictions did not differ by review (systematic or rapid, P = 0.37) or intervention type (simple or complex, P = 0.47). The predictions were more often correct in reviews with multiple (89%) vs. single (83%) research questions ( P = 0.01), or that included only trials (95%) vs. multiple designs (86%) ( P = 0.003). At the study level, trials (91%), mixed methods (100%), and qualitative (93%) studies were more often correctly predicted as relevant compared with observational studies (79%) or reviews (83%) ( P = 0.0006). Studies at high or unclear (88%) vs. low risk of bias (80%) ( P = 0.039), and those published more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2020
DA  - 2020-11-27
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://systematicreviewsjournal.biomedcentral.com/track/pdf/10.1186/s13643-020-01528-x', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Allison Gates
AU  - Michelle Gates
AU  - D. DaRosa
AU  - Sarah A. Elliott
AU  - Jennifer Pillay
AU  - Sholeh Rahman
AU  - Ben Vandermeer
AU  - Lisa Hartling
ER  - 

123.
TY  - journal-article
ID  - https://openalex.org/W3110051524
DO  - https://doi.org/10.3109/13668250.2020.1834946
TI  - Mortality, predictors and causes among people with intellectual disabilities: A systematic narrative review supplemented by machine learning
AB  - There is a need to systematically compare and contrast mortality predictors and disparities in people with intellectual disabilities (ID) for global prevention strategy development. Bibliographic d... by review or study-level characteristics. Methods For a convenience sample of 16 reviews for which adequate data were available to address our objectives (11 systematic reviews and 5 rapid reviews), we screened a 200-record training set in Abstrackr and downloaded the relevance (relevant or irrelevant) of the remaining records, as predicted by the tool. We retrospectively simulated the liberal-accelerated screening approach. We estimated the time savings and proportion missed compared with dual independent screening. For reviews with pairwise meta-analyses, we evaluated changes to the pooled effects after removing the missed studies. We explored whether the tool’s predictions varied by review and study-level characteristics. Results Using the ML-assisted liberal-accelerated approach, we wrongly excluded 0 to 3 (0 to 14%) records that were included in the final reports, but saved a median (IQR) 26 (9, 42) h of screening time. One missed study was included in eight pairwise meta-analyses in one systematic review. The pooled effect for just one of those meta-analyses changed considerably (from MD (95% CI) − 1.53 (− 2.92, − 0.15) to − 1.17 (− 2.70, 0.36)). Of 802 records in the final reports, 87% were correctly predicted as relevant. The correctness of the predictions did not differ by review (systematic or rapid, P = 0.37) or intervention type (simple or complex, P = 0.47). The predictions were more often correct in reviews with multiple (89%) vs. single (83%) research questions ( P = 0.01), or that included only trials (95%) vs. multiple designs (86%) ( P = 0.003). At the study level, trials (91%), mixed methods (100%), and qualitative (93%) studies were more often correctly predicted as relevant compared with observational studies (79%) or reviews (83%) ( P = 0.0006). Studies at high or unclear (88%) vs. low risk of bias (80%) ( P = 0.039), and those published more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2021
DA  - 2021-04-03
JO  - {'id': 'https://openalex.org/S19769454', 'issn_l': '1366-8250', 'issn': ['1469-9532', '1366-8250'], 'display_name': 'Journal of Intellectual & Developmental Disability', 'publisher': 'Informa', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Freya Tyrer
AU  - Reza Kiani
AU  - Mark J. Rutherford
ER  - 

124.
TY  - journal-article
ID  - https://openalex.org/W3165198619
DO  - https://doi.org/10.1016/j.eswa.2021.115261
TI  - A decision support system for automating document retrieval and citation screening
AB  - • A Decision Support System for two steps in the Systematic Review process. • Automated document retrieval and citation screening. • Implementation of a Multi-Channel CNN model into the system. • A quantitative analysis of the effect of the system. • Our system is available at https://github.com/rvdinter/decision-support-system . The systematic literature review (SLR) process includes several steps to collect secondary data and analyze it to answer research questions. In this context, the document retrieval and primary study selection steps are heavily intertwined and known for their repetitiveness, high human workload, and difficulty identifying all relevant literature. This study aims to reduce human workload and error of the document retrieval and primary study selection processes using a decision support system (DSS). An open-source DSS is proposed that supports the document retrieval step, dataset preprocessing, and citation classification. The DSS is domain-independent, as it has proven to carefully select an article’s relevance based solely on the title and abstract. These features can be consistently retrieved from scientific database APIs. Additionally, the DSS is designed to run in the cloud without any required programming knowledge for reviewers. A Multi-Channel CNN architecture is implemented to support the citation screening process. With the provided DSS, reviewers can fill in their search strategy and manually label only a subset of the citations. The remaining unlabeled citations are automatically classified and sorted based on probability. It was shown that for four out of five review datasets, the DSS's use achieved significant workload savings of at least 10%. The cross-validation results show that the system provides consistent results up to 88.3% of work saved during citation screening. In two cases, our model yielded a better performance over the benchmark review datasets. As such, the proposed approach can assist the development of systematic literature reviews independent of the domain. The proposed DSS is effective and can substantially decrease the document retrieval and citation screening steps' workload and error rate. ( P = 0.039), and those published more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2021
DA  - 2021-11-15
JO  - {'id': 'https://openalex.org/S13144211', 'issn_l': '0957-4174', 'issn': ['1873-6793', '0957-4174'], 'display_name': 'Expert Systems With Applications', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'https://doi.org/10.1016/j.eswa.2021.115261', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Raymon van Dinter
AU  - Daniel Rodriguez
AU  - Bedir Tekinerdogan
ER  - 

125.
TY  - journal-article
ID  - https://openalex.org/W3203793329
DO  - https://doi.org/10.12688/openreseurope.14041.1
TI  - Implementing living evidence to inform health decisions: A strategy for building capacity in health sector (Protocol)
AB  - <ns4:p>Every day important healthcare decisions are made with incomplete or outdated information about the effects of the different health care interventions available, what delivers the best value for the health system and where more research is needed. It is necessary to invest in strategies that allow access to reliable and updated evidence on which to base health decisions.</ns4:p><ns4:p> The objective is to develop and evaluate a strategy for building the capacity among different actors of a country’s health system to implement the model known as “Living Evidence” [LE] in the evidence synthesis and dissemination of knowledge transfer [KT] products to inform health decisions. The study will involve professional members of health system organizations in charge of developing KT-products to inform health decisions.</ns4:p><ns4:p> The project will be developed in three complementary phases: 1) LE-implementation framework development through review of the literature, brainstorming meetings, user testing and expert consultation; 2) training in LE tools and strategies; 3) developing LE synthesis for KT-products by applying the framework to real-life diverse situations.</ns4:p><ns4:p> To achieve the capacity building strategy assessment goal, several surveys and interviews will take place during the process to assess: 1) the LE-implementation framework for the incorporation of LE synthesis in the development of KT-products; 2) the training workshops; 3) the whole capacity-building strategy used for health system organizations be able of implementing the LE as part of the KT-products they regularly produce.</ns4:p><ns4:p> The expected results are an effective capacity building strategy for health system organizations to implement the living evidence model in different KT products; a LE-implementation framework to be applicable to any country or region for incorporate LE in the KT-products; LE synthesis for KT-products directly applicable to the real-setting situations; integration of Epistemonikos-L.OVE platform for keeping the LE process in the development and updating of KT-products.</ns4:p> of the domain. The proposed DSS is effective and can substantially decrease the document retrieval and citation screening steps' workload and error rate. ( P = 0.039), and those published more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2021
DA  - 2021-09-28
JO  - {'id': 'https://openalex.org/S4210238080', 'issn_l': '2732-5121', 'issn': ['2732-5121'], 'display_name': 'Open research Europe', 'publisher': 'European Commission', 'type': 'journal', 'url': 'https://doi.org/10.12688/openreseurope.14041.1', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - María Ximena Rojas
AU  - Gerard Urrútia
AU  - Gabriel Rada
AU  - Pablo J. Alonso
AU  - David Rigau
AU  - Ariadna Auladell-Rispau
ER  - 

126.
TY  - journal-article
ID  - https://openalex.org/W4225269224
DO  - https://doi.org/10.1016/j.jclinepi.2022.04.027
TI  - Artificial intelligence in COVID-19 evidence syntheses was underutilized, but impactful: a methodological study
AB  - A rapidly developing scenario like a pandemic requires the prompt production of high-quality systematic reviews, which can be automated using artificial intelligence (AI) techniques. We evaluated the application of AI tools in COVID-19 evidence syntheses.After prospective registration of the review protocol, we automated the download of all open-access COVID-19 systematic reviews in the COVID-19 Living Overview of Evidence database, indexed them for AI-related keywords, and located those that used AI tools. We compared their journals' JCR Impact Factor, citations per month, screening workloads, completion times (from pre-registration to preprint or submission to a journal) and AMSTAR-2 methodology assessments (maximum score 13 points) with a set of publication date matched control reviews without AI.Of the 3,999 COVID-19 reviews, 28 (0.7%, 95% CI 0.47-1.03%) made use of AI. On average, compared to controls (n = 64), AI reviews were published in journals with higher Impact Factors (median 8.9 vs. 3.5, P < 0.001), and screened more abstracts per author (302.2 vs. 140.3, P = 0.009) and per included study (189.0 vs. 365.8, P < 0.001) while inspecting less full texts per author (5.3 vs. 14.0, P = 0.005). No differences were found in citation counts (0.5 vs. 0.6, P = 0.600), inspected full texts per included study (3.8 vs. 3.4, P = 0.481), completion times (74.0 vs. 123.0, P = 0.205) or AMSTAR-2 (7.5 vs. 6.3, P = 0.119).AI was an underutilized tool in COVID-19 systematic reviews. Its usage, compared to reviews without AI, was associated with more efficient screening of literature and higher publication impact. There is scope for the application of AI in automating systematic reviews. incorporate LE in the KT-products; LE synthesis for KT-products directly applicable to the real-setting situations; integration of Epistemonikos-L.OVE platform for keeping the LE process in the development and updating of KT-products.</ns4:p> of the domain. The proposed DSS is effective and can substantially decrease the document retrieval and citation screening steps' workload and error rate. ( P = 0.039), and those published more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2022
DA  - 2022-05-01
JO  - {'id': 'https://openalex.org/S64418186', 'issn_l': '0895-4356', 'issn': ['1878-5921', '0895-4356'], 'display_name': 'Journal of Clinical Epidemiology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'http://www.jclinepi.com/article/S0895435622001160/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc-nd'}
DP  - OpenAlex
AU  - Juan R. Tercero-Hidalgo
AU  - Khalid Mohammed Khan
AU  - Aurora Bueno-Cavanillas
AU  - Rodrigo Fernández-López
AU  - Juan F. Huete
AU  - Carmen Amezcua-Prieto
AU  - Javier Zamora
AU  - Juan M. Fernández-Luna
ER  - 

127.
TY  - journal-article
ID  - https://openalex.org/W2738227365
DO  - https://doi.org/10.1186/s12913-017-2324-y
TI  - Linking clinical quality indicators to research evidence - a case study in asthma management for children
AB  - Clinical quality indicators are used to monitor the performance of healthcare services and should wherever possible be based on research evidence. Little is known however about the extent to which indicators in common use are based on research. The objective of this study is to measure the extent to which clinical quality indicators used in asthma management in children with outcome measurements can be linked to results in randomised controlled clinical trial (RCT) reports. This work is part of a broader research program to trial methods that improve the efficiency and accuracy of indicator development.National-level indicators for asthma management in children were extracted from the National Quality Measures Clearinghouse database and the National Institute for Health and Care Excellence quality standards by two independent appraisers. Outcome measures were extracted from all published English language RCT reports for asthma management in children below the age of 12 published between 2005 and 2014. The two sets were then linked by manually mapping both to a common set of Unified Medical Language System (UMLS) concepts.The analysis identified 39 indicators and 562 full text RCTs dealing with asthma management in children. About 95% (37/39) of the indicators could be linked to RCT outcome measures.It is possible to identify relevant RCT reports for the majority of indicators used to assess the quality of asthma management in childhood. The methods reported here could be automated to more generally support assessment of candidate indicators against the research evidence. AI, was associated with more efficient screening of literature and higher publication impact. There is scope for the application of AI in automating systematic reviews. incorporate LE in the KT-products; LE synthesis for KT-products directly applicable to the real-setting situations; integration of Epistemonikos-L.OVE platform for keeping the LE process in the development and updating of KT-products.</ns4:p> of the domain. The proposed DSS is effective and can substantially decrease the document retrieval and citation screening steps' workload and error rate. ( P = 0.039), and those published more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2017
DA  - 2017-07-21
JO  - {'id': 'https://openalex.org/S12898181', 'issn_l': '1472-6963', 'issn': ['1472-6963'], 'display_name': 'BMC Health Services Research', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://bmchealthservres.biomedcentral.com/track/pdf/10.1186/s12913-017-2324-y', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Miew Keen Choong
AU  - Guy Tsafnat
AU  - Peter Hibbert
AU  - William B. Runciman
AU  - Enrico Coiera
ER  - 

128.
TY  - journal-article
ID  - https://openalex.org/W2746856526
DO  - https://doi.org/10.1177/1062860617726855
TI  - Advancing Guideline Development in the United States: A Call to Action by the US GRADE Network
AB  - No Abstract Found
PY  - 2017
DA  - 2017-08-28
JO  - {'id': 'https://openalex.org/V133181607', 'issn_l': '1062-8606', 'issn': ['1555-824X', '1062-8606'], 'display_name': 'American Journal of Medical Quality', 'publisher': 'SAGE Publishing', 'type': 'journal', 'url': 'https://journals.sagepub.com/doi/pdf/10.1177/1062860617726855', 'is_oa': True, 'version': 'publishedVersion', 'license': None}
DP  - OpenAlex
AU  - Rebecca L. Morgan
AU  - Shahnaz Sultan
AU  - Mohammad Hassan Murad
AU  - Reem A. Mustafa
AU  - Philipp Dahm
AU  - Mark Helfand
AU  - Yngve Falck-Ytter
AU  - Amir Qaseem
ER  - 

129.
TY  - journal-article
ID  - https://openalex.org/W2937445874
DO  - nan
TI  - Data Extraction and Synthesis in Systematic Reviews of Diagnostic Test Accuracy: A Corpus for Automating and Evaluating the Process.
AB  - Systematic reviews are critical for obtaining accurate estimates of diagnostic test accuracy, yet these require extracting information buried in free text articles, an often laborious process.We create a dataset describing the data extraction and synthesis processes in 63 DTA systematic reviews, and demonstrate its utility by using it to replicate the data synthesis in the original reviews.We construct our dataset using a custom automated extraction pipeline complemented with manual extraction, verification, and post-editing. We evaluate using manual assessment by two annotators and by comparing against data extracted from source files.The constructed dataset contains 5,848 test results for 1,354 diagnostic tests from 1,738 diagnostic studies. We observe an extraction error rate of 0.06-0.3%.This constitutes the first dataset describing the later stages of the DTA systematic review process, and is intended to be useful for automating or evaluating the process. management in children below the age of 12 published between 2005 and 2014. The two sets were then linked by manually mapping both to a common set of Unified Medical Language System (UMLS) concepts.The analysis identified 39 indicators and 562 full text RCTs dealing with asthma management in children. About 95% (37/39) of the indicators could be linked to RCT outcome measures.It is possible to identify relevant RCT reports for the majority of indicators used to assess the quality of asthma management in childhood. The methods reported here could be automated to more generally support assessment of candidate indicators against the research evidence. AI, was associated with more efficient screening of literature and higher publication impact. There is scope for the application of AI in automating systematic reviews. incorporate LE in the KT-products; LE synthesis for KT-products directly applicable to the real-setting situations; integration of Epistemonikos-L.OVE platform for keeping the LE process in the development and updating of KT-products.</ns4:p> of the domain. The proposed DSS is effective and can substantially decrease the document retrieval and citation screening steps' workload and error rate. ( P = 0.039), and those published more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2018
DA  - 2018-01-01
JO  - {'id': 'https://openalex.org/S4306400513', 'issn_l': None, 'issn': None, 'display_name': 'HAL (Le Centre pour la Communication Scientifique Directe)', 'publisher': 'Le Centre pour la Communication Scientifique Directe', 'type': 'repository', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Christopher R. Norman
AU  - Mariska M.G. Leeflang
AU  - Aurélie Névéol
ER  - 

130.
TY  - journal-article
ID  - https://openalex.org/W3006673017
DO  - https://doi.org/10.1002/jrsm.1398
TI  - Comparing machine and human reviewers to evaluate the risk of bias in randomized controlled trials
AB  - Background Evidence from new health technologies is growing, along with demands for evidence to inform policy decisions, creating challenges in completing health technology assessments (HTAs)/systematic reviews (SRs) in a timely manner. Software can decrease the time and burden by automating the process, but evidence validating such software is limited. We tested the accuracy of RobotReviewer, a semi-autonomous risk of bias (RoB) assessment tool, and its agreement with human reviewers. Methods Two reviewers independently conducted RoB assessments on a sample of randomized controlled trials (RCTs), and their consensus ratings were compared with those generated by RobotReviewer. Agreement with the human reviewers was assessed using percent agreement and weighted kappa (κ). The accuracy of RobotReviewer was also assessed by calculating the sensitivity, specificity, and area under the curve in comparison to the consensus agreement of the human reviewers. Results The study included 372 RCTs. Inter-rater reliability ranged from κ = −0.06 (no agreement) for blinding of participants and personnel to κ = 0.62 (good agreement) for random sequence generation (excluding overall RoB). RobotReviewer was found to use a high percentage of “irrelevant supporting quotations” to complement RoB assessments for blinding of participants and personnel (72.6%), blinding of outcome assessment (70.4%), and allocation concealment (54.3%). Conclusion RobotReviewer can help with risk of bias assessment of RCTs but cannot replace human evaluations. Thus, reviewers should check and validate RoB assessments from RobotReviewer by consulting the original article when not relevant supporting quotations are provided by RobotReviewer. This consultation is in line with the recommendation provided by the developers. There is scope for the application of AI in automating systematic reviews. incorporate LE in the KT-products; LE synthesis for KT-products directly applicable to the real-setting situations; integration of Epistemonikos-L.OVE platform for keeping the LE process in the development and updating of KT-products.</ns4:p> of the domain. The proposed DSS is effective and can substantially decrease the document retrieval and citation screening steps' workload and error rate. ( P = 0.039), and those published more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2020
DA  - 2020-03-03
JO  - {'id': 'https://openalex.org/S205768342', 'issn_l': '1759-2879', 'issn': ['1759-2879', '1759-2887'], 'display_name': 'Research Synthesis Methods', 'publisher': 'Wiley-Blackwell', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Susan Armijo-Olivo
AU  - Rodger Craig
AU  - Sandy Campbell
ER  - 

131.
TY  - journal-article
ID  - https://openalex.org/W3033427052
DO  - https://doi.org/10.1097/gco.0000000000000643
TI  - Artificial intelligence and automation of systematic reviews in women's health
AB  - Purpose of review new Evidence-based women's healthcare is underpinned by systematic reviews and guidelines. Generating an evidence synthesis to support guidance for clinical practice is a time-consuming and labour-intensive activity that delays transfer of research into practice. Artificial intelligence has the potential to rapidly collate, combine, and update high-quality medical evidence with accuracy and precision, and without bias. of Recent findings assessment This article describes the main fields of artificial intelligence with examples of its application to systematic reviews. These include the capabilities of processing natural language texts, retrieving information, reasoning, and learning. The complementarity and interconnection of the various artificial intelligence techniques can be harnessed to solve difficult problems in automation of reviews. Computer science can advance evidence-based medicine through development, testing, and refinement of artificial intelligence tools to deploy automation, creating 'living' evidence syntheses. Results Summary study Groundbreaking, high-quality, and impactful artificial intelligence will accelerate the transfer of individual research studies seamlessly into evidence syntheses for contemporaneously improving the quality of healthcare. random sequence generation (excluding overall RoB). RobotReviewer was found to use a high percentage of “irrelevant supporting quotations” to complement RoB assessments for blinding of participants and personnel (72.6%), blinding of outcome assessment (70.4%), and allocation concealment (54.3%). Conclusion RobotReviewer can help with risk of bias assessment of RCTs but cannot replace human evaluations. Thus, reviewers should check and validate RoB assessments from RobotReviewer by consulting the original article when not relevant supporting quotations are provided by RobotReviewer. This consultation is in line with the recommendation provided by the developers. There is scope for the application of AI in automating systematic reviews. incorporate LE in the KT-products; LE synthesis for KT-products directly applicable to the real-setting situations; integration of Epistemonikos-L.OVE platform for keeping the LE process in the development and updating of KT-products.</ns4:p> of the domain. The proposed DSS is effective and can substantially decrease the document retrieval and citation screening steps' workload and error rate. ( P = 0.039), and those published more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2020
DA  - 2020-10-01
JO  - {'id': 'https://openalex.org/S203280300', 'issn_l': '1040-872X', 'issn': ['1080-8256', '1040-872X', '1473-656X'], 'display_name': 'Current Opinion in Obstetrics & Gynecology', 'publisher': 'Lippincott Williams & Wilkins', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Carmen Amezcua-Prieto
AU  - Juan M. Fernández-Luna
AU  - Juan F Huete-Guadix
AU  - Aurora Bueno-Cavanillas
AU  - Khalid Mohammed Khan
ER  - 

132.
TY  - journal-article
ID  - https://openalex.org/W3040154644
DO  - https://doi.org/10.1210/jendso/bvaa090
TI  - Effects of Testosterone on Serum Concentrations, Fat-free Mass, and Physical Performance by Population: A Meta-analysis
AB  - Abstract Testosterone (T) administration (TA) increases serum T and fat-free mass (FFM). Although TA-mediated increases in FFM may enhance physical performance, the data are largely equivocal, which may be due to differences in study populations, the magnitude of change in serum T and FFM, or the performance metrics. This meta-analysis explored effects of TA on serum T, FFM, and performance. Associations between increases in serum T and FFM were assessed, and whether changes in serum T or FFM, study population, or the performance metrics affected performance was determined. A systematic review of double-blind randomized trials comparing TA versus placebo on serum T, FFM, and performance was performed. Data were extracted from 20 manuscripts. Effect sizes (ESs) were assessed using Hedge’s g and a random effects model. Data are presented as ES (95% confidence interval). No significant correlation between changes in serum T and FFM was observed (P = .167). Greater increases in serum T, but not FFM, resulted in larger effects on performance. Larger increases in testosterone (7.26 [0.76-13.75]) and FFM (0.80 [0.20-1.41]) were observed in young males, but performance only improved in diseased (0.16 [0.05-0.28]) and older males (0.19 [0.10-0.29]). TA increased lower body (0.12 [0.07-0.18]), upper body (0.26 [0.11-0.40]), and handgrip (0.13 [0.04-0.22]) strength, lower body muscular endurance (0.38 [0.09-0.68]), and functional performance (0.20 [0.00-0.41]), but not lower body power or aerobic endurance. TA elicits increases in serum T and FFM in younger, older, and diseased males; however, the performance-enhancing effects of TA across studies were small, observed mostly in muscular strength and endurance, and only in older and diseased males. automating systematic reviews. incorporate LE in the KT-products; LE synthesis for KT-products directly applicable to the real-setting situations; integration of Epistemonikos-L.OVE platform for keeping the LE process in the development and updating of KT-products.</ns4:p> of the domain. The proposed DSS is effective and can substantially decrease the document retrieval and citation screening steps' workload and error rate. ( P = 0.039), and those published more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2020
DA  - 2020-07-03
JO  - {'id': 'https://openalex.org/V2735747656', 'issn_l': '2472-1972', 'issn': ['2472-1972'], 'display_name': 'Journal of the Endocrine Society', 'publisher': 'Endocrine Society', 'type': 'journal', 'url': 'https://academic.oup.com/jes/article-pdf/4/9/bvaa090/33737740/bvaa090.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc-nd'}
DP  - OpenAlex
AU  - Alyssa N. Varanoske
AU  - Lee M. Margolis
AU  - Stefan M. Pasiakos
ER  - 

133.
TY  - posted-content
ID  - https://openalex.org/W3098622247
DO  - https://doi.org/10.1101/255760
TI  - Machine learning algorithms for systematic review: reducing workload in a preclinical review of animal studies and reducing human screening error
AB  - Abstract Background Here we outline a method of applying existing machine learning (ML) approaches to aid citation screening in an on-going broad and shallow systematic review of preclinical animal studies, with the aim of achieving a high performing algorithm comparable to human screening. Methods We applied ML approaches to a broad systematic review of animal models of depression at the citation screening stage. We tested two independently developed ML approaches which used different classification models and feature sets. We recorded the performance of the ML approaches on an unseen validation set of papers using sensitivity, specificity and accuracy. We aimed to achieve 95% sensitivity and to maximise specificity. The classification model providing the most accurate predictions was applied to the remaining unseen records in the dataset and will be used in the next stage of the preclinical biomedical sciences systematic review. We used a cross validation technique to assign ML inclusion likelihood scores to the human screened records, to identify potential errors made during the human screening process (error analysis). Results ML approaches reached 98.7% sensitivity based on learning from a training set of 5749 records, with an inclusion prevalence of 13.2%. The highest level of specificity reached was 86%. Performance was assessed on an independent validation dataset. Human errors in the training and validation sets were successfully identified using assigned the inclusion likelihood from the ML model to highlight discrepancies. Training the ML algorithm on the corrected dataset improved the specificity of the algorithm without compromising sensitivity. Error analysis correction leads to a 3% improvement in sensitivity and specificity, which increases precision and accuracy of the ML algorithm. Conclusions This work has confirmed the performance and application of ML algorithms for screening in systematic reviews of preclinical animal studies. It has highlighted the novel use of ML algorithms to identify human error. This needs to be confirmed in other reviews, , but represents a promising approach to integrating human decisions and automation in systematic review methodology. more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2018
DA  - 2018-10-30
JO  - {'id': 'https://openalex.org/S4306402567', 'issn_l': None, 'issn': None, 'display_name': 'bioRxiv (Cold Spring Harbor Laboratory)', 'publisher': 'Cold Spring Harbor Laboratory', 'type': 'repository', 'url': 'https://systematicreviewsjournal.biomedcentral.com/track/pdf/10.1186/s13643-019-0942-7', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Alexandra Bannach-Brown
AU  - Piotr Przybyła
AU  - James D. Thomas
AU  - Andrew S.C. Rice
AU  - Sophia Ananiadou
AU  - Jing Liao
AU  - Malcolm R. Macleod
ER  - 

134.
TY  - journal-article
ID  - https://openalex.org/W3144391370
DO  - https://doi.org/10.1186/s13643-021-01632-6
TI  - Successful incorporation of single reviewer assessments during systematic review screening: development and validation of sensitivity and work-saved of an algorithm that considers exclusion criteria and count.
AB  - Accepted systematic review (SR) methodology requires citation screening by two reviewers to maximise retrieval of eligible studies. We hypothesized that records could be excluded by a single reviewer without loss of sensitivity in two conditions; the record was ineligible for multiple reasons, or the record was ineligible for one or more specific reasons that could be reliably assessed.Twenty-four SRs performed at CHEO, a pediatric health care and research centre in Ottawa, Canada, were divided into derivation and validation sets. Exclusion criteria during abstract screening were sorted into 11 specific categories, with loss in sensitivity determined by individual category and by number of exclusion criteria endorsed. Five single reviewer algorithms that combined individual categories and multiple exclusion criteria were then tested on the derivation and validation sets, with success defined a priori as less than 5% loss of sensitivity.The 24 SRs included 930 eligible and 27390 ineligible citations. The reviews were mostly focused on pediatrics (70.8%, N=17/24), but covered various specialties. Using a single reviewer to exclude any citation led to an average loss of sensitivity of 8.6% (95%CI, 6.0-12.1%). Excluding citations with ≥2 exclusion criteria led to 1.2% average loss of sensitivity (95%CI, 0.5-3.1%). Five specific exclusion criteria performed with perfect sensitivity: conference abstract, ineligible age group, case report/series, not human research, and review article. In the derivation set, the five algorithms achieved a loss of sensitivity ranging from 0.0 to 1.9% and work-saved ranging from 14.8 to 39.1%. In the validation set, the loss of sensitivity for all 5 algorithms remained below 2.6%, with work-saved between 10.5% and 48.2%.Findings suggest that targeted application of single-reviewer screening, considering both type and number of exclusion criteria, could retain sensitivity and significantly decrease workload. Further research is required to investigate the potential for combining this approach with crowdsourcing or machine learning methodologies. identify human error. This needs to be confirmed in other reviews, , but represents a promising approach to integrating human decisions and automation in systematic review methodology. more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2021
DA  - 2021-04-05
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Nassr Nama
AU  - Mirna Hennawy
AU  - Nick Barrowman
AU  - Katie O’Hearn
AU  - Margaret Sampson
AU  - James G. McNally
ER  - 

135.
TY  - posted-content
ID  - https://openalex.org/W3153326066
DO  - nan
TI  - MS2: Multi-Document Summarization of Medical Studies.
AB  - To assess the effectiveness of any medical intervention, researchers must conduct a time-intensive and highly manual literature review. NLP systems can help to automate or assist in parts of this expensive process. In support of this goal, we release MS^2 (Multi-Document Summarization of Medical Studies), a dataset of over 470k documents and 20k summaries derived from the scientific literature. This dataset facilitates the development of systems that can assess and aggregate contradictory evidence across multiple studies, and is the first large-scale, publicly available multi-document summarization dataset in the biomedical domain. We experiment with a summarization system based on BART, with promising early results. We formulate our summarization inputs and targets in both free text and structured forms and modify a recently proposed metric to assess the quality of our system's generated summaries. Data and models are available at this https URL 930 eligible and 27390 ineligible citations. The reviews were mostly focused on pediatrics (70.8%, N=17/24), but covered various specialties. Using a single reviewer to exclude any citation led to an average loss of sensitivity of 8.6% (95%CI, 6.0-12.1%). Excluding citations with ≥2 exclusion criteria led to 1.2% average loss of sensitivity (95%CI, 0.5-3.1%). Five specific exclusion criteria performed with perfect sensitivity: conference abstract, ineligible age group, case report/series, not human research, and review article. In the derivation set, the five algorithms achieved a loss of sensitivity ranging from 0.0 to 1.9% and work-saved ranging from 14.8 to 39.1%. In the validation set, the loss of sensitivity for all 5 algorithms remained below 2.6%, with work-saved between 10.5% and 48.2%.Findings suggest that targeted application of single-reviewer screening, considering both type and number of exclusion criteria, could retain sensitivity and significantly decrease workload. Further research is required to investigate the potential for combining this approach with crowdsourcing or machine learning methodologies. identify human error. This needs to be confirmed in other reviews, , but represents a promising approach to integrating human decisions and automation in systematic review methodology. more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2021
DA  - 2021-04-13
JO  - {'id': 'https://openalex.org/V2596401190', 'issn_l': None, 'issn': None, 'display_name': 'arXiv: Computation and Language', 'publisher': None, 'type': 'journal', 'url': 'https://arxiv.org/pdf/2104.06486.pdf', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Jay DeYoung
AU  - Iz Beltagy
AU  - Madeleine van Zuylen
AU  - Bailey Kuehl
AU  - Lucy Lu Wang
ER  - 

136.
TY  - journal-article
ID  - https://openalex.org/W2274824198
DO  - https://doi.org/10.1186/s13643-016-0207-7
TI  - Using built-in functions of Adobe Acrobat Pro DC to help the selection process in systematic reviews of randomised trials
AB  - This letter describes a simple way of using Adobe Acrobat Pro DC to help select and auto-extract data from Portable Document Format (PDFs) of randomised trials in order to assist swift early selection of trials for a systematic review. MS^2 (Multi-Document Summarization of Medical Studies), a dataset of over 470k documents and 20k summaries derived from the scientific literature. This dataset facilitates the development of systems that can assess and aggregate contradictory evidence across multiple studies, and is the first large-scale, publicly available multi-document summarization dataset in the biomedical domain. We experiment with a summarization system based on BART, with promising early results. We formulate our summarization inputs and targets in both free text and structured forms and modify a recently proposed metric to assess the quality of our system's generated summaries. Data and models are available at this https URL 930 eligible and 27390 ineligible citations. The reviews were mostly focused on pediatrics (70.8%, N=17/24), but covered various specialties. Using a single reviewer to exclude any citation led to an average loss of sensitivity of 8.6% (95%CI, 6.0-12.1%). Excluding citations with ≥2 exclusion criteria led to 1.2% average loss of sensitivity (95%CI, 0.5-3.1%). Five specific exclusion criteria performed with perfect sensitivity: conference abstract, ineligible age group, case report/series, not human research, and review article. In the derivation set, the five algorithms achieved a loss of sensitivity ranging from 0.0 to 1.9% and work-saved ranging from 14.8 to 39.1%. In the validation set, the loss of sensitivity for all 5 algorithms remained below 2.6%, with work-saved between 10.5% and 48.2%.Findings suggest that targeted application of single-reviewer screening, considering both type and number of exclusion criteria, could retain sensitivity and significantly decrease workload. Further research is required to investigate the potential for combining this approach with crowdsourcing or machine learning methodologies. identify human error. This needs to be confirmed in other reviews, , but represents a promising approach to integrating human decisions and automation in systematic review methodology. more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2016
DA  - 2016-02-18
JO  - {'id': 'https://openalex.org/V82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://systematicreviewsjournal.biomedcentral.com/track/pdf/10.1186/s13643-016-0207-7', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Selin Nur
AU  - Clive E Adams
AU  - David F. Brailsford
ER  - 

137.
TY  - proceedings-article
ID  - https://openalex.org/W2324936983
DO  - https://doi.org/10.1145/2837185.2837279
TI  - Using rule-based classifiers in systematic reviews
AB  - Systematic review is the scientific process that provides reliable answers to a particular research question by interpreting the current pertinent literature. There is a significant shift from using manual human approach to decision support tools that provides a semi-automated screening phase by reducing the required time and effort to the group of experts. Most of proposed works apply supervised Machine Learning (ML) algorithms to infer exclusion and inclusion rules by observing a human screener. Unless, these techniques holds very little promise in study identification phase, because the rate of excluding citations erroneously still unreasonable. In this paper, we contribute to this line of works by proposing an alternative approach, not yet tested in this domain based on semantic rule-based classifiers. This approach involved applying a novel Hybrid Feature Selection Method (HFSM) within a Class Association Rules (CARs) algorithm. Experiments are conducted on a corpus resulting from an actual systematic review. The obtained results show that our algorithm outperforms the existing algorithms in the literature. to exclude any citation led to an average loss of sensitivity of 8.6% (95%CI, 6.0-12.1%). Excluding citations with ≥2 exclusion criteria led to 1.2% average loss of sensitivity (95%CI, 0.5-3.1%). Five specific exclusion criteria performed with perfect sensitivity: conference abstract, ineligible age group, case report/series, not human research, and review article. In the derivation set, the five algorithms achieved a loss of sensitivity ranging from 0.0 to 1.9% and work-saved ranging from 14.8 to 39.1%. In the validation set, the loss of sensitivity for all 5 algorithms remained below 2.6%, with work-saved between 10.5% and 48.2%.Findings suggest that targeted application of single-reviewer screening, considering both type and number of exclusion criteria, could retain sensitivity and significantly decrease workload. Further research is required to investigate the potential for combining this approach with crowdsourcing or machine learning methodologies. identify human error. This needs to be confirmed in other reviews, , but represents a promising approach to integrating human decisions and automation in systematic review methodology. more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2015
DA  - 2015-12-11
JO  - {'id': 'https://openalex.org/V4306418884', 'issn_l': None, 'issn': None, 'display_name': 'Information Integration and Web-based Applications & Services', 'publisher': None, 'type': 'conference', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Hamza Sellak
AU  - Brahim Ouhbi
AU  - Bouchra Frikh
ER  - 

138.
TY  - posted-content
ID  - https://openalex.org/W2592460572
DO  - https://doi.org/10.1101/108480
TI  - Biomedical Text Mining for Research Rigor and Integrity: Tasks, Challenges, Directions
AB  - Abstract An estimated quarter of a trillion US dollars is invested in the biomedical research enterprise annually. There is growing alarm that a significant portion of this investment is wasted, due to problems in reproducibility of research findings and in the rigor and integrity of research conduct and reporting. Recent years have seen a flurry of activities focusing on standardization and guideline development to enhance the reproducibility and rigor of biomedical research. Research activity is primarily communicated via textual artifacts, ranging from grant applications to journal publications. These artifacts can be both the source and the end result of practices leading to research waste. For example, an article may describe a poorly designed experiment, or the authors may reach conclusions not supported by the evidence presented. In this article, we pose the question of whether biomedical text mining techniques can assist the stakeholders in the biomedical research enterprise in doing their part towards enhancing research integrity and rigor. In particular, we identify four key areas in which text mining techniques can make a significant contribution: plagiarism/fraud detection, ensuring adherence to reporting guidelines, managing information overload, and accurate citation/enhanced bibliometrics. We review the existing methods and tools for specific tasks, if they exist, or discuss relevant research that can provide guidance for future work. With the exponential increase in biomedical research output and the ability of text mining approaches to perform automatic tasks at large scale, we propose that such approaches can add checks and balances that promote responsible research practices and can provide significant benefits for the biomedical research enterprise. Supplementary information Supplementary material is available at BioRxiv . type and number of exclusion criteria, could retain sensitivity and significantly decrease workload. Further research is required to investigate the potential for combining this approach with crowdsourcing or machine learning methodologies. identify human error. This needs to be confirmed in other reviews, , but represents a promising approach to integrating human decisions and automation in systematic review methodology. more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2017
DA  - 2017-02-14
JO  - {'id': 'https://openalex.org/S4306402567', 'issn_l': None, 'issn': None, 'display_name': 'bioRxiv (Cold Spring Harbor Laboratory)', 'publisher': 'Cold Spring Harbor Laboratory', 'type': 'repository', 'url': 'https://academic.oup.com/bib/article-pdf/19/6/1400/27118801/bbx057.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'pd'}
DP  - OpenAlex
AU  - Halil Kilicoglu
ER  - 

139.
TY  - journal-article
ID  - https://openalex.org/W2784587217
DO  - https://doi.org/10.5277/e-inf180104
TI  - Tool Features to Support Systematic Reviews in Software Engineering – A Cross Domain Study
AB  - No Abstract Found
PY  - 2018
DA  - 2018-01-01
JO  - {'id': 'https://openalex.org/V4306401280', 'issn_l': None, 'issn': None, 'display_name': 'DOAJ (DOAJ: Directory of Open Access Journals)', 'publisher': 'DOAJ: Directory of Open Access Journals', 'type': 'repository', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Christopher J. Marshall
AU  - Barbara Kitchenham
AU  - Pearl Brereton
ER  - 

140.
TY  - proceedings-article
ID  - https://openalex.org/W2900986433
DO  - https://doi.org/10.1145/3284179.3284292
TI  - Decision support tools for SLR search string construction
AB  - Systematic literature reviews (SLRs) have gained popularity during the last years as a form of providing state of the art about previous research. As part of the SLR tasks, devising the search strategy and particularly finding the right keywords to be included in the search string is a difficult and critical step, as it will determine what evidence will be identified in the different searched sources and thus condition the rest of the review. In order to support the search process, this paper presents an iterative methodology for search string construction along with a set of decision support tools that help in building the search string by finding appropriate key terms related to the topic of interest in order to assist the researcher in the SLR conduction. this article, we pose the question of whether biomedical text mining techniques can assist the stakeholders in the biomedical research enterprise in doing their part towards enhancing research integrity and rigor. In particular, we identify four key areas in which text mining techniques can make a significant contribution: plagiarism/fraud detection, ensuring adherence to reporting guidelines, managing information overload, and accurate citation/enhanced bibliometrics. We review the existing methods and tools for specific tasks, if they exist, or discuss relevant research that can provide guidance for future work. With the exponential increase in biomedical research output and the ability of text mining approaches to perform automatic tasks at large scale, we propose that such approaches can add checks and balances that promote responsible research practices and can provide significant benefits for the biomedical research enterprise. Supplementary information Supplementary material is available at BioRxiv . type and number of exclusion criteria, could retain sensitivity and significantly decrease workload. Further research is required to investigate the potential for combining this approach with crowdsourcing or machine learning methodologies. identify human error. This needs to be confirmed in other reviews, , but represents a promising approach to integrating human decisions and automation in systematic review methodology. more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2018
DA  - 2018-10-24
JO  - {'id': 'https://openalex.org/V4306421030', 'issn_l': None, 'issn': None, 'display_name': 'Technological Ecosystems for Enhancing Multiculturality', 'publisher': None, 'type': 'conference', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Samuel Marcos-Pablos
AU  - Francisco José García-Peñalvo
ER  - 

141.
TY  - journal-article
ID  - https://openalex.org/W2901634112
DO  - https://doi.org/10.1016/j.softx.2018.10.004
TI  - Buhos: A web-based systematic literature review management software
AB  - Abstract literature reviews Software can significantly facilitate the management of the complete systematic literature review process (SLR). However, most specialized software for use in SLR processes is designed to meet the requirements of the health and medical sciences and software engineering, and there is a need for dedicated software for the specific research requirements of the social sciences. Furthermore, most of the software currently used is closed and the open source code alternatives require personnel with expertise in configuration and setup. this We present Buhos, an application for managing the complete process of systematic literature reviews that is web-based and developed in Ruby. It offers functionalities for supporting the process of searching, screening, data extraction and reporting. Buhos can be used locally through an in-house web server, as well as in a distributed manner, integrated with other online services. can assist the stakeholders in the biomedical research enterprise in doing their part towards enhancing research integrity and rigor. In particular, we identify four key areas in which text mining techniques can make a significant contribution: plagiarism/fraud detection, ensuring adherence to reporting guidelines, managing information overload, and accurate citation/enhanced bibliometrics. We review the existing methods and tools for specific tasks, if they exist, or discuss relevant research that can provide guidance for future work. With the exponential increase in biomedical research output and the ability of text mining approaches to perform automatic tasks at large scale, we propose that such approaches can add checks and balances that promote responsible research practices and can provide significant benefits for the biomedical research enterprise. Supplementary information Supplementary material is available at BioRxiv . type and number of exclusion criteria, could retain sensitivity and significantly decrease workload. Further research is required to investigate the potential for combining this approach with crowdsourcing or machine learning methodologies. identify human error. This needs to be confirmed in other reviews, , but represents a promising approach to integrating human decisions and automation in systematic review methodology. more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2018
DA  - 2018-01-01
JO  - {'id': 'https://openalex.org/S2506067282', 'issn_l': '2352-7110', 'issn': ['2352-7110'], 'display_name': 'SoftwareX', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'https://doi.org/10.1016/j.softx.2018.10.004', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Claudio Navarrete
AU  - María ´Gabriela Morales Malverde
AU  - Pedro Salcedo Lagos
AU  - Alejandro Díaz Mujica
ER  - 

142.
TY  - journal-article
ID  - https://openalex.org/W2906214584
DO  - https://doi.org/10.1016/j.jclinepi.2018.12.014
TI  - Software engineering principles address current problems in the systematic review ecosystem.
AB  - Systematic reviewers are simultaneously unable to produce systematic reviews fast enough to keep up with the availability of new trial evidence while overproducing systematic reviews that are unlikely to change practice because they are redundant or biased. Although the transparency and completeness of trial reporting has improved with changes in policy and new technologies, systematic reviews have not yet benefited from the same level of effort. We found that new methods and tools used to automate aspects of systematic review processes have focused on improving the efficiency of individual systematic reviews rather than the efficiency of the entire ecosystem of systematic review production. We use software engineering principles to review challenges and opportunities for improving the interoperability, integrity, efficiency, and maintainability. We conclude by recommending ways to improve access to structured systematic review results. Major opportunities for improving systematic reviews will come from new tools and changes in policy focused on doing the right systematic reviews rather than just doing more of them faster. areas in which text mining techniques can make a significant contribution: plagiarism/fraud detection, ensuring adherence to reporting guidelines, managing information overload, and accurate citation/enhanced bibliometrics. We review the existing methods and tools for specific tasks, if they exist, or discuss relevant research that can provide guidance for future work. With the exponential increase in biomedical research output and the ability of text mining approaches to perform automatic tasks at large scale, we propose that such approaches can add checks and balances that promote responsible research practices and can provide significant benefits for the biomedical research enterprise. Supplementary information Supplementary material is available at BioRxiv . type and number of exclusion criteria, could retain sensitivity and significantly decrease workload. Further research is required to investigate the potential for combining this approach with crowdsourcing or machine learning methodologies. identify human error. This needs to be confirmed in other reviews, , but represents a promising approach to integrating human decisions and automation in systematic review methodology. more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2019
DA  - 2019-05-01
JO  - {'id': 'https://openalex.org/S64418186', 'issn_l': '0895-4356', 'issn': ['1878-5921', '0895-4356'], 'display_name': 'Journal of Clinical Epidemiology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Rabia Bashir
AU  - Adam G. Dunn
ER  - 

143.
TY  - journal-article
ID  - https://openalex.org/W2941924374
DO  - https://doi.org/10.1016/j.jclinepi.2019.04.008
TI  - Reducing waste and increasing value through embedded replicability and reproducibility in systematic review process and automation
AB  - No Abstract Found
PY  - 2019
DA  - 2019-04-23
JO  - {'id': 'https://openalex.org/V64418186', 'issn_l': '0895-4356', 'issn': ['1878-5921', '0895-4356'], 'display_name': 'Journal of Clinical Epidemiology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Farhad Shokraneh
ER  - 

144.
TY  - posted-content
ID  - https://openalex.org/W3023035014
DO  - nan
TI  - Fact or Fiction: Verifying Scientific Claims
AB  - We introduce scientific claim verification, a new task to select abstracts from the research literature containing evidence that supports or refutes a given scientific claim, and to identify rationales justifying each decision. To study this task, we construct SciFact, a dataset of 1.4K expert-written scientific claims paired with evidence-containing abstracts annotated with labels and rationales. We develop baseline models for SciFact, and demonstrate that these models benefit from combined training on a large dataset of claims about Wikipedia articles, together with the new SciFact data. We show that our claim verification system is able to identify plausible evidence for 23 / 36 claims relevant to COVID-19 on the CORD-19 corpus. Our results and experiments strongly suggest that our new task and data will support significant future research efforts. access to structured systematic review results. Major opportunities for improving systematic reviews will come from new tools and changes in policy focused on doing the right systematic reviews rather than just doing more of them faster. areas in which text mining techniques can make a significant contribution: plagiarism/fraud detection, ensuring adherence to reporting guidelines, managing information overload, and accurate citation/enhanced bibliometrics. We review the existing methods and tools for specific tasks, if they exist, or discuss relevant research that can provide guidance for future work. With the exponential increase in biomedical research output and the ability of text mining approaches to perform automatic tasks at large scale, we propose that such approaches can add checks and balances that promote responsible research practices and can provide significant benefits for the biomedical research enterprise. Supplementary information Supplementary material is available at BioRxiv . type and number of exclusion criteria, could retain sensitivity and significantly decrease workload. Further research is required to investigate the potential for combining this approach with crowdsourcing or machine learning methodologies. identify human error. This needs to be confirmed in other reviews, , but represents a promising approach to integrating human decisions and automation in systematic review methodology. more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2020
DA  - 2020-04-30
JO  - {'id': 'https://openalex.org/V2596401190', 'issn_l': None, 'issn': None, 'display_name': 'arXiv: Computation and Language', 'publisher': None, 'type': 'journal', 'url': 'http://export.arxiv.org/pdf/2004.14974', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - David Wadden
AU  - Shanchuan Lin
AU  - Kyle Lo
AU  - Lucy Lu Wang
AU  - Madeleine van Zuylen
AU  - Arman Cohan
AU  - Hannaneh Hajishirzi
ER  - 

145.
TY  - journal-article
ID  - https://openalex.org/W3108349105
DO  - https://doi.org/10.3390/app10238521
TI  - Performance Analysis of Selected Programming Languages in the Context of Supporting Decision-Making Processes for Industry 4.0
AB  - This study analyzes the possibility of using Go (Golang) in the context of Java and Python in decision-making processes, with particular emphasis on their use in industry-specific solutions for Industry 4.0. The authors intentionally compared Go with Java and Python, which have been widely used for many years for data analysis in many areas. The research work was based on decision trees data mining algorithms, and especially on classification trees, in which the measure of entropy as a heuristics to choose an attribute was taken into account. The tests were carried out on various parameters describing calculation time, RAM usage, and CPU usage. The source data, which were the basis for the computing of the decision tree algorithm implemented using these three languages, were obtained from a commercial remote prototyping system and were related to the target customers’ choice of methods and means of the full design-creation process. policy focused on doing the right systematic reviews rather than just doing more of them faster. areas in which text mining techniques can make a significant contribution: plagiarism/fraud detection, ensuring adherence to reporting guidelines, managing information overload, and accurate citation/enhanced bibliometrics. We review the existing methods and tools for specific tasks, if they exist, or discuss relevant research that can provide guidance for future work. With the exponential increase in biomedical research output and the ability of text mining approaches to perform automatic tasks at large scale, we propose that such approaches can add checks and balances that promote responsible research practices and can provide significant benefits for the biomedical research enterprise. Supplementary information Supplementary material is available at BioRxiv . type and number of exclusion criteria, could retain sensitivity and significantly decrease workload. Further research is required to investigate the potential for combining this approach with crowdsourcing or machine learning methodologies. identify human error. This needs to be confirmed in other reviews, , but represents a promising approach to integrating human decisions and automation in systematic review methodology. more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2020
DA  - 2020-11-01
JO  - {'id': 'https://openalex.org/S4210205812', 'issn_l': '2076-3417', 'issn': ['2076-3417'], 'display_name': 'Applied sciences', 'publisher': 'MDPI', 'type': 'journal', 'url': 'https://www.mdpi.com/2076-3417/10/23/8521/pdf?version=1606575358', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Paweł Dymora
AU  - Andrzej Paszkiewicz
ER  - 

146.
TY  - journal-article
ID  - https://openalex.org/W3113526370
DO  - https://doi.org/10.1186/s13643-021-01640-6
TI  - Iterative guided machine learning-assisted systematic literature reviews: a diabetes case study
AB  - Abstract Background Systematic Reviews (SR), studies of studies, use a formal process to evaluate the quality of scientific literature and determine ensuing effectiveness from qualifying articles to establish consensus findings around a hypothesis. Their value is increasing as the conduct and publication of research and evaluation has expanded and the process of identifying key insights becomes more time consuming. Text analytics and machine learning (ML) techniques may help overcome this problem of scale while still maintaining the level of rigor expected of SRs. Methods In this article, we discuss an approach that uses existing examples of SRs to build and test a method for assisting the SR title and abstract pre-screening by reducing the initial pool of potential articles down to articles that meet inclusion criteria. Our approach differs from previous approaches to using ML as a SR tool in that it incorporates ML configurations guided by previously conducted SRs, and human confirmation on ML predictions of relevant articles during multiple iterative reviews on smaller tranches of citations. We applied the tailored method to a new SR review effort to validate performance. Results The case study test of the approach proved a sensitivity (recall) in finding relevant articles during down selection that may rival many traditional processes and show ability to overcome most type II errors. The study achieved a sensitivity of 99.5% (213 out of 214) of total relevant articles while only conducting a human review of 31% of total articles available for review. Conclusions We believe this iterative method can help overcome bias in initial ML model training by having humans reinforce ML models with new and relevant information, and is an applied step towards transfer learning for ML in SR. research is required to investigate the potential for combining this approach with crowdsourcing or machine learning methodologies. identify human error. This needs to be confirmed in other reviews, , but represents a promising approach to integrating human decisions and automation in systematic review methodology. more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2021
DA  - 2021-04-02
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://systematicreviewsjournal.biomedcentral.com/counter/pdf/10.1186/s13643-021-01640-6', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - John Zimmerman
AU  - Robin Soler
AU  - James Lavinder
AU  - Sarah Murphy
AU  - Charisma Y. Atkins
AU  - Lashonda Hulbert
AU  - Richard Lusk
AU  - Boon Poh Ng
ER  - 

147.
TY  - posted-content
ID  - https://openalex.org/W3159559669
DO  - https://doi.org/10.1101/2021.04.26.21255833
TI  - Systematic review automation tool use by systematic reviewers, health technology assessors and clinical guideline developers: tools used, abandoned, and desired
AB  - Abstract Objective We investigated the use of systematic review automation tools by systematic reviewers, health technology assessors and clinical guideline developers. Study design and settings An online, 16-question survey was distributed across several evidence synthesis, health technology assessment and guideline development organisations internationally. We asked the respondents what tools they use and abandon, how often and when they use the tools, their perceived time savings and accuracy, and desired new tools. Descriptive statistics were used to report the results. Results 253 respondents completed the survey; 89% have used systematic review automation tools – most frequently whilst screening (79%). Respondents’ ‘top 3’ tools include: Covidence (45%), RevMan (35%), Rayyan and GRADEPro (both 22%); most commonly abandoned were Rayyan (19%), Covidence (15%), DistillerSR (14%) and RevMan (13%). Majority thought tools saved time (80%) and increased accuracy (54%). Respondents taught themselves to how to use the tools (72%), and were most often prevented by lack of knowledge from their adoption (51%). Most new tool development was suggested for the searching and data extraction stages. Conclusion Automation tools are likely to take on an increasingly important role in high quality and timely reviews. Further work is required in training and dissemination of automation tools and ensuring they meet the desirable features of those conducting systematic reviews. most type II errors. The study achieved a sensitivity of 99.5% (213 out of 214) of total relevant articles while only conducting a human review of 31% of total articles available for review. Conclusions We believe this iterative method can help overcome bias in initial ML model training by having humans reinforce ML models with new and relevant information, and is an applied step towards transfer learning for ML in SR. research is required to investigate the potential for combining this approach with crowdsourcing or machine learning methodologies. identify human error. This needs to be confirmed in other reviews, , but represents a promising approach to integrating human decisions and automation in systematic review methodology. more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2021
DA  - 2021-04-30
JO  - {'id': 'https://openalex.org/S4306400573', 'issn_l': None, 'issn': None, 'display_name': 'medRxiv (Cold Spring Harbor Laboratory)', 'publisher': 'Cold Spring Harbor Laboratory', 'type': 'repository', 'url': 'https://doi.org/10.1101/2021.04.26.21255833', 'is_oa': True, 'version': 'submittedVersion', 'license': None}
DP  - OpenAlex
AU  - Andrew M. Scott
AU  - Connor Forbes
AU  - John W. Clark
AU  - Matt Carter
AU  - Paul Glasziou
AU  - Zachary Munn
ER  - 

148.
TY  - journal-article
ID  - https://openalex.org/W3210180842
DO  - https://doi.org/10.3390/su132111935
TI  - Systematic Literature Review of Supply Chain Relationship Approaches amongst Business-to-Business Partners
AB  - Managing a business-to-business (B2B) supply chain relationship is an endless challenge. Many recent systematic literature review studies have discussed supply chain relationships from various perspectives. However, a comprehensive analysis, summarising the existing research, explicitly identified the implemented B2B supply chain relationships and found the effects of these relationships on supply chain performance remain lacking. To address the gap, this article presents a systematic literature review based on the PRISMA approach regarding the nature of the supply chain relationships between B2B partners and their effect on supply chain performance. Web of Science and Scopus were used in the compilation of studies published between 2000 and 2020. Findings indicate that the majority of B2B partners use a collaborative relationship approach and that the impacts are marked on the operational, financial, innovation, environmental, social and economic performance of their supply chain. This study seeks to contribute to the existing literature on B2B supply chain relationships by conducting a thorough and unbiased review of previous studies, drawing more general conclusions about the adopted supply chain relationships between B2B partners and providing insights for future research. important role in high quality and timely reviews. Further work is required in training and dissemination of automation tools and ensuring they meet the desirable features of those conducting systematic reviews. most type II errors. The study achieved a sensitivity of 99.5% (213 out of 214) of total relevant articles while only conducting a human review of 31% of total articles available for review. Conclusions We believe this iterative method can help overcome bias in initial ML model training by having humans reinforce ML models with new and relevant information, and is an applied step towards transfer learning for ML in SR. research is required to investigate the potential for combining this approach with crowdsourcing or machine learning methodologies. identify human error. This needs to be confirmed in other reviews, , but represents a promising approach to integrating human decisions and automation in systematic review methodology. more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2021
DA  - 2021-10-28
JO  - {'id': 'https://openalex.org/S10134376', 'issn_l': '2071-1050', 'issn': ['2071-1050'], 'display_name': 'Sustainability', 'publisher': 'MDPI', 'type': 'journal', 'url': 'https://www.mdpi.com/2071-1050/13/21/11935/pdf?version=1635423715', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Faridzah Jamaluddin
AU  - Nizaroyani Saibani
ER  - 

149.
TY  - journal-article
ID  - https://openalex.org/W4281788268
DO  - https://doi.org/10.1016/j.iswa.2022.200091
TI  - Search strategy formulation for systematic reviews: Issues, challenges and opportunities
AB  - • Boolean logic is dominant in the formulation of search strategies for evidence synthesis in professional search, notably healthcare, but in other domains such as law, patents and recruitment. • Boolean methods are complex, time consuming, resource intensive and error prone, and a new approach is required. • Alternative approaches either suffer from the same problems as Boolean methods or introduce further problems such as lack of trust and transparency. • We propose a set of design principles to address the shortcomings of Boolean logic when formulating search strategies for evidence synthesis. Systematic literature reviews play a vital role in identifying the best available evidence for health and social care research, policy, and practice. The resources required to produce systematic reviews can be significant, and a key to the success of any review is the search strategy used to identify relevant literature. However, the methods used to construct search strategies can be complex, time consuming, resource intensive and error prone. In this review, we examine the state of the art in resolving complex structured information needs, focusing primarily on the healthcare context. We analyse the literature to identify key challenges and issues and explore appropriate solutions and workarounds. From this analysis we propose a way forward to facilitate trust and to aid explainability and transparency, reproducibility and replicability through a set of key design principles for tools to support the development of search strategies in systematic literature reviews. 31% of total articles available for review. Conclusions We believe this iterative method can help overcome bias in initial ML model training by having humans reinforce ML models with new and relevant information, and is an applied step towards transfer learning for ML in SR. research is required to investigate the potential for combining this approach with crowdsourcing or machine learning methodologies. identify human error. This needs to be confirmed in other reviews, , but represents a promising approach to integrating human decisions and automation in systematic review methodology. more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2022
DA  - 2022-06-01
JO  - {'id': 'https://openalex.org/V4210234522', 'issn_l': '2667-3053', 'issn': ['2667-3053'], 'display_name': 'Intelligent systems with applications', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'https://doi.org/10.1016/j.iswa.2022.200091', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc-nd'}
DP  - OpenAlex
AU  - Andrew MacFarlane
AU  - Tony Russell-Rose
AU  - Farhad Shokraneh
ER  - 

150.
TY  - journal-article
ID  - https://openalex.org/W4283321486
DO  - https://doi.org/10.3390/su14137523
TI  - Systematic Literature Review on Variables Impacting Organization’s Zero Accident Vision in Occupational Safety and Health Perspectives
AB  - The zero-accident vision has sparked debate in the fields of occupational safety and health. While many organizations and policymakers have successfully implemented the zero-accident vision, numerous notable occupational safety and health scholars from various backgrounds argue against its use and success in theory and practice. This article aimed to analyze the existing literature on the variables impacting an organization’s zero-accident vision. A systematic review of the Scopus and Web of Science databases revealed 25 related studies using the PRISMA statement (preferred reporting items for systematic reviews and meta-analyses) review method. Following a thorough review of these articles, seven main themes emerged: the occupational safety and health management system, organizational leadership, safety culture, training, communication, risk, and legislation. These seven themes resulted in a total of 28 sub-themes. Several recommendations are emphasized, including the use of a specific and standard systematic review method to guide research synthesis in the frame of reference of variables impacting the organization’s zero-accident vision and to practice complementary searching techniques, such as citation tracking, reference searching, snowballing, and contacting experts. information needs, focusing primarily on the healthcare context. We analyse the literature to identify key challenges and issues and explore appropriate solutions and workarounds. From this analysis we propose a way forward to facilitate trust and to aid explainability and transparency, reproducibility and replicability through a set of key design principles for tools to support the development of search strategies in systematic literature reviews. 31% of total articles available for review. Conclusions We believe this iterative method can help overcome bias in initial ML model training by having humans reinforce ML models with new and relevant information, and is an applied step towards transfer learning for ML in SR. research is required to investigate the potential for combining this approach with crowdsourcing or machine learning methodologies. identify human error. This needs to be confirmed in other reviews, , but represents a promising approach to integrating human decisions and automation in systematic review methodology. more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2022
DA  - 2022-06-21
JO  - {'id': 'https://openalex.org/S10134376', 'issn_l': '2071-1050', 'issn': ['2071-1050'], 'display_name': 'Sustainability', 'publisher': 'MDPI', 'type': 'journal', 'url': 'https://www.mdpi.com/2071-1050/14/13/7523/pdf?version=1655794435', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Mohamad Nadzlen Ahamad
AU  - Kadir Arifin
AU  - Azlan Abas
AU  - Mahfudz Mahfudz
AU  - Muhammad Basir Cyio
AU  - Muhammad Khairil
AU  - Muhammad Ali
AU  - Ilyas Lampe
AU  - Muhammad Ahsan Samad
ER  - 

151.
TY  - book-chapter
ID  - https://openalex.org/W2791201782
DO  - https://doi.org/10.1007/978-3-319-78105-1_40
TI  - Opportunities for Computer Support for Systematic Reviewing - A Gap Analysis
AB  - Systematic review is a type of literature review designed to synthesize all available evidence on a given question. Systematic reviews require significant time and effort, which has led to the continuing development of computer support. This paper seeks to identify the gaps and opportunities for computer support. By interviewing experienced systematic reviewers from diverse fields, we identify the technical problems and challenges reviewers face in conducting a systematic review and their current uses of computer support. We propose potential research directions for how computer support could help to speed the systematic review process while retaining or improving review quality. themes emerged: the occupational safety and health management system, organizational leadership, safety culture, training, communication, risk, and legislation. These seven themes resulted in a total of 28 sub-themes. Several recommendations are emphasized, including the use of a specific and standard systematic review method to guide research synthesis in the frame of reference of variables impacting the organization’s zero-accident vision and to practice complementary searching techniques, such as citation tracking, reference searching, snowballing, and contacting experts. information needs, focusing primarily on the healthcare context. We analyse the literature to identify key challenges and issues and explore appropriate solutions and workarounds. From this analysis we propose a way forward to facilitate trust and to aid explainability and transparency, reproducibility and replicability through a set of key design principles for tools to support the development of search strategies in systematic literature reviews. 31% of total articles available for review. Conclusions We believe this iterative method can help overcome bias in initial ML model training by having humans reinforce ML models with new and relevant information, and is an applied step towards transfer learning for ML in SR. research is required to investigate the potential for combining this approach with crowdsourcing or machine learning methodologies. identify human error. This needs to be confirmed in other reviews, , but represents a promising approach to integrating human decisions and automation in systematic review methodology. more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2018
DA  - 2018-03-25
JO  - {'id': 'https://openalex.org/S106296714', 'issn_l': '0302-9743', 'issn': ['1611-3349', '0302-9743'], 'display_name': 'Lecture Notes in Computer Science', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Linh Cao Hoang
AU  - Jodi Schneider
ER  - 

152.
TY  - journal-article
ID  - https://openalex.org/W2951697674
DO  - https://doi.org/10.1016/j.jclinepi.2019.06.010
TI  - Rapid network meta-analysis using data from Food and Drug Administration approval packages is feasible but with limitations
AB  - To test rapid approaches that use Drugs@FDA (a public database of approved drugs) and ClinicalTrials.gov to identify trials and to compare these two sources with bibliographic databases as an evidence base for a systematic review and network meta-analysis (NMA).We searched bibliographic databases, Drugs@FDA, and ClinicalTrials.gov for eligible trials on first-line glaucoma medications. We extracted data, assessed risk of bias, and examined the completeness and consistency of information provided by different sources. We fitted random-effects NMA models separately for trials identified from each source and for all unique trials from three sources.We identified 138 unique trials including 29,394 participants on 15 first-line glaucoma medications. For a given trial, information reported was sometimes inconsistent across data sources. Journal articles provided the most information needed for a systematic review; trial registrations provided the least. Compared to an NMA including all unique trials, we were able to generate reasonably precise effect estimates and similar relative rankings for available interventions using trials from Drugs@FDA alone (but not ClinicalTrials.gov).A rapid NMA approach using data from Drugs@FDA is feasible but has its own limitations. Reporting of trial design and results can be improved in both the drug approval packages and on ClinicalTrials.gov. solutions and workarounds. From this analysis we propose a way forward to facilitate trust and to aid explainability and transparency, reproducibility and replicability through a set of key design principles for tools to support the development of search strategies in systematic literature reviews. 31% of total articles available for review. Conclusions We believe this iterative method can help overcome bias in initial ML model training by having humans reinforce ML models with new and relevant information, and is an applied step towards transfer learning for ML in SR. research is required to investigate the potential for combining this approach with crowdsourcing or machine learning methodologies. identify human error. This needs to be confirmed in other reviews, , but represents a promising approach to integrating human decisions and automation in systematic review methodology. more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2019
DA  - 2019-10-01
JO  - {'id': 'https://openalex.org/S64418186', 'issn_l': '0895-4356', 'issn': ['1878-5921', '0895-4356'], 'display_name': 'Journal of Clinical Epidemiology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Lin Wang
AU  - Benjamin Rouse
AU  - Arielle Marks-Anglin
AU  - Rui Duan
AU  - Shi Qiyuan
AU  - Kevin Quach
AU  - Yong Chen
AU  - Christopher B. Cameron
AU  - Christopher H. Schmid
AU  - Tianjing Li
ER  - 

153.
TY  - journal-article
ID  - https://openalex.org/W2982622858
DO  - https://doi.org/10.3233/isu-190062
TI  - Applying artificial intelligence in the science & technology cycle
AB  - No Abstract Found
PY  - 2020
DA  - 2020-02-06
JO  - {'id': 'https://openalex.org/V2764781207', 'issn_l': '0167-5265', 'issn': ['1875-8789', '0167-5265'], 'display_name': 'Information services & use', 'publisher': 'IOS Press', 'type': 'journal', 'url': 'https://content.iospress.com:443/download/information-services-and-use/isu190062?id=information-services-and-use%2Fisu190062', 'is_oa': True, 'version': 'publishedVersion', 'license': 'implied-oa'}
DP  - OpenAlex
AU  - Rosina O. Weber
ER  - 

154.
TY  - other
ID  - https://openalex.org/W3015418106
DO  - https://doi.org/10.1002/9781119602927.ch2
TI  - The Machine‐Learning Approach
AB  - For past several years, microarray technology has attracted tremendous interest for both scientific community and industry. Recently, the applications of microarrays include gene discovery, disease diagnosis and prognosis, drug discovery, etc. High dimensional data with small sample size is the main problem that generate the application of dimension reduction in microarray data analysis. It is seen that SVM, ANN and NB have recently gained wide popularity for cancer classification problems. An efficient and reliable method of dimension reduction plays an important role to improve the performance of SVM, ANN and NB, when applied for classification of high dimensional microarray data. In this book, we applied different combinations of feature selection / extraction methods, as a novel hybrid dimension reduction method for SVM, ANN and NB classifiers. The obtained results are compared with other popular published dimension reduction methods for SVM, NB and ANN classifiers. reasonably precise effect estimates and similar relative rankings for available interventions using trials from Drugs@FDA alone (but not ClinicalTrials.gov).A rapid NMA approach using data from Drugs@FDA is feasible but has its own limitations. Reporting of trial design and results can be improved in both the drug approval packages and on ClinicalTrials.gov. solutions and workarounds. From this analysis we propose a way forward to facilitate trust and to aid explainability and transparency, reproducibility and replicability through a set of key design principles for tools to support the development of search strategies in systematic literature reviews. 31% of total articles available for review. Conclusions We believe this iterative method can help overcome bias in initial ML model training by having humans reinforce ML models with new and relevant information, and is an applied step towards transfer learning for ML in SR. research is required to investigate the potential for combining this approach with crowdsourcing or machine learning methodologies. identify human error. This needs to be confirmed in other reviews, , but represents a promising approach to integrating human decisions and automation in systematic review methodology. more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2020
DA  - 2020-02-20
JO  - {'id': None, 'issn_l': None, 'issn': None, 'display_name': 'Machine Learning for iOS Developers', 'publisher': None, 'type': None, 'url': 'https://doi.org/10.1002/9781119602927.ch2', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Namita Srivastava
AU  - C. K. Verma
AU  - Rabia Aziz
ER  - 

155.
TY  - journal-article
ID  - https://openalex.org/W3105442727
DO  - https://doi.org/10.1049/iet-sen.2020.0109
TI  - Retrieving and mining professional experience of software practice from grey literature: an exploratory review
AB  - © 2020 Institution of Engineering and Technology. All rights reserved. Retrieving and mining practitioners' self-reports of their professional experience of software practice could provide valuable evidence for research. The authors are, however, unaware of any existing reviews of research conducted in this area. The authors reviewed and classified previous research, and identified insights into the challenges research confronts when retrieving and mining practitioners' self-reports of their experience of software practice. They conducted an exploratory review to identify and classify 42 studies. They analysed a selection of those studies for insights on challenges to mining professional experience. They identified only one directly relevant study. Even then this study concerns the software professional's emotional experiences rather than the professional's reporting of behaviour and events occurring during software practice. They discussed the challenges concerning: the prevalence of professional experience; definitions, models and theories; the sparseness of data; units of discourse analysis; annotator agreement; evaluation of the performance of algorithms; and the lack of replications. No directly relevant prior research appears to have been conducted in this area. They discussed the value of reporting negative results in secondary studies. There are a range of research opportunities but also considerable challenges. They formulated a set of guiding questions for further research in this area. and to aid explainability and transparency, reproducibility and replicability through a set of key design principles for tools to support the development of search strategies in systematic literature reviews. 31% of total articles available for review. Conclusions We believe this iterative method can help overcome bias in initial ML model training by having humans reinforce ML models with new and relevant information, and is an applied step towards transfer learning for ML in SR. research is required to investigate the potential for combining this approach with crowdsourcing or machine learning methodologies. identify human error. This needs to be confirmed in other reviews, , but represents a promising approach to integrating human decisions and automation in systematic review methodology. more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2020
DA  - 2020-10-14
JO  - {'id': 'https://openalex.org/S164201770', 'issn_l': '1751-8806', 'issn': ['1751-8806', '1751-8814'], 'display_name': 'IET Software', 'publisher': 'Institution of Engineering and Technology', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Austen Rainer
AU  - Ashley J. Williams
AU  - Vahid Garousi
AU  - Michael Felderer
ER  - 

156.
TY  - journal-article
ID  - https://openalex.org/W3115545833
DO  - https://doi.org/10.1002/cl2.1128
TI  - Editorial: Evidence synthesis for accelerated learning on climate solutions
AB  - No Abstract Found
PY  - 2020
DA  - 2020-12-01
JO  - {'id': 'https://openalex.org/V2739193000', 'issn_l': '1891-1803', 'issn': ['1891-1803'], 'display_name': 'Campbell Systematic Reviews', 'publisher': 'The Campbell Collaboration', 'type': 'journal', 'url': 'https://doi.org/10.1002/cl2.1128', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Lea Berrang-Ford
AU  - Friederike C. Döbbe
AU  - Ruth Garside
AU  - Neal R. Haddaway
AU  - William F. Lamb
AU  - Jan C. Minx
AU  - Wolfgang Viechtbauer
AU  - Vivian Welch
AU  - Howard White
ER  - 

157.
TY  - journal-article
ID  - https://openalex.org/W3164471952
DO  - https://doi.org/10.1002/jat.4204
TI  - Toxic effects of nanomaterials for health applications: How automation can support a systematic review of the literature?
AB  - Systematic reviews of the scientific literature can be an important source of information supporting the daily work of the regulators in their decision making, particularly in areas of innovative technologies where the regulatory experience is still limited. Significant research activities in the field of nanotechnology resulted in a huge number of publications in the last decades. However, even if the published data can provide relevant information, scientific articles are often of diverse quality, and it is nearly impossible to manually process and evaluate such amount of data in a systematic manner. In this feasibility study, we investigated to what extent open-access automation tools can support a systematic review of toxic effects of nanomaterials for health applications reported in the scientific literature. In this study, we used a battery of available tools to perform the initial steps of a systematic review such as targeted searches, data curation and abstract screening. This work was complemented with an in-house developed tool that allowed us to extract specific sections of the articles such as the materials and methods part or the results section where we could perform subsequent text analysis. We ranked the articles according to quality criteria based on the reported nanomaterial characterisation and extracted most frequently described toxic effects induced by different types of nanomaterials. Even if further demonstration of the reliability and applicability of automation tools is necessary, this study demonstrated the potential to leverage information from the scientific literature by using automation systems in a tiered strategy. believe this iterative method can help overcome bias in initial ML model training by having humans reinforce ML models with new and relevant information, and is an applied step towards transfer learning for ML in SR. research is required to investigate the potential for combining this approach with crowdsourcing or machine learning methodologies. identify human error. This needs to be confirmed in other reviews, , but represents a promising approach to integrating human decisions and automation in systematic review methodology. more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2022
DA  - 2022-01-01
JO  - {'id': 'https://openalex.org/S81851855', 'issn_l': '0260-437X', 'issn': ['1099-1263', '0260-437X'], 'display_name': 'Journal of Applied Toxicology', 'publisher': 'Wiley', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Blanka Halamoda-Kenzaoui
AU  - Etienne Rolland
AU  - Jacopo Piovesan
AU  - Antonio Gallardo
AU  - Susanne Bremer-Hoffmann
ER  - 

158.
TY  - journal-article
ID  - https://openalex.org/W3192015009
DO  - https://doi.org/10.1002/jrsm.1518
TI  - Training sample selection: Impact on screening automation in diagnostic test accuracy reviews
AB  - When performing a systematic review, researchers screen the articles retrieved after a broad search strategy one by one, which is time-consuming. Computerised support of this screening process has been applied with varying success. This is partly due to the dependency on large amounts of data to develop models that predict inclusion. In this paper, we present an approach to choose which data to use in model training and compare it with established approaches. We used a dataset of 50 Cochrane diagnostic test accuracy reviews, and each was used as a target review. From the remaining 49 reviews, we selected those that most closely resembled the target review's clinical topic using the cosine similarity metric. Included and excluded studies from these selected reviews were then used to develop our prediction models. The performance of models trained on the selected reviews was compared against models trained on studies from all available reviews. The prediction models performed best with a larger number of reviews in the training set and on target reviews that had a research subject similar to other reviews in the dataset. Our approach using cosine similarity may reduce computational costs for model training and the duration of the screening process. and extracted most frequently described toxic effects induced by different types of nanomaterials. Even if further demonstration of the reliability and applicability of automation tools is necessary, this study demonstrated the potential to leverage information from the scientific literature by using automation systems in a tiered strategy. believe this iterative method can help overcome bias in initial ML model training by having humans reinforce ML models with new and relevant information, and is an applied step towards transfer learning for ML in SR. research is required to investigate the potential for combining this approach with crowdsourcing or machine learning methodologies. identify human error. This needs to be confirmed in other reviews, , but represents a promising approach to integrating human decisions and automation in systematic review methodology. more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2021
DA  - 2021-11-01
JO  - {'id': 'https://openalex.org/S205768342', 'issn_l': '1759-2879', 'issn': ['1759-2879', '1759-2887'], 'display_name': 'Research Synthesis Methods', 'publisher': 'Wiley-Blackwell', 'type': 'journal', 'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/jrsm.1518', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc'}
DP  - OpenAlex
AU  - Allard J. van Altena
AU  - René Spijker
AU  - Mariska M.G. Leeflang
AU  - Silvia D. Olabarriaga
ER  - 

159.
TY  - journal-article
ID  - https://openalex.org/W3200778630
DO  - https://doi.org/10.1002/jrsm.1528
TI  - Making the case for librarian expertise to support evidence synthesis for the sustainable development goals
AB  - Evidence syntheses that engage librarians as co-authors produce higher-quality results than those that do not. Trained as teachers, researchers, and information managers, librarians possess expert knowledge on research methodologies and information retrieval approaches that are critical for evidence synthesis. Researchers are under increasing pressure to produce evidence syntheses to inform practice and policymaking. Many fields outside of health science and medicine, however, do not have established guidelines, processes, or methodologies. This article describes how librarians led the creation of an interdisciplinary toolkit for researchers new to evidence synthesis. The implementation of the tools, including a protocol, supported eight evidence syntheses focused on effective agricultural interventions published in a special collection in Nature Research in October 2020. This article is a step-by-step overview of the tools and process. We advocate that librarian collaboration in evidence synthesis must become the norm, not the exception. Evidence synthesis project leads without access to a qualified librarian may use this toolkit as a point of entry for production of transparent, reproducible reviews. target reviews that had a research subject similar to other reviews in the dataset. Our approach using cosine similarity may reduce computational costs for model training and the duration of the screening process. and extracted most frequently described toxic effects induced by different types of nanomaterials. Even if further demonstration of the reliability and applicability of automation tools is necessary, this study demonstrated the potential to leverage information from the scientific literature by using automation systems in a tiered strategy. believe this iterative method can help overcome bias in initial ML model training by having humans reinforce ML models with new and relevant information, and is an applied step towards transfer learning for ML in SR. research is required to investigate the potential for combining this approach with crowdsourcing or machine learning methodologies. identify human error. This needs to be confirmed in other reviews, , but represents a promising approach to integrating human decisions and automation in systematic review methodology. more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2022
DA  - 2022-01-01
JO  - {'id': 'https://openalex.org/S205768342', 'issn_l': '1759-2879', 'issn': ['1759-2879', '1759-2887'], 'display_name': 'Research Synthesis Methods', 'publisher': 'Wiley-Blackwell', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Kristine M. Alpi
AU  - Jessica Ault
AU  - Gracian Chimwaza
AU  - Florian Diekmann
AU  - Erin R. B. Eldermire
AU  - Nasra Gathoni
AU  - Julia A. Kelly
AU  - Alison Annet Kinengyere
AU  - Megan Kocher
AU  - Edda Tandi Lwoga
AU  - Jessica M. Page
AU  - Sarah Young
AU  - Jaron Porciello
ER  - 

160.
TY  - journal-article
ID  - https://openalex.org/W4239128715
DO  - https://doi.org/10.12688/wellcomeopenres.14738.2
TI  - The development and evaluation of an online application to assist in the extraction of data from graphs for use in systematic reviews
AB  - <ns4:p><ns4:bold>Background:</ns4:bold> The extraction of data from the reports of primary studies, on which the results of systematic reviews depend, needs to be carried out accurately. To aid reliability, it is recommended that two researchers carry out data extraction independently. The extraction of statistical data from graphs in PDF files is particularly challenging, as the process is usually completely manual, and reviewers need sometimes to revert to holding a ruler against the page to read off values: an inherently time-consuming and error-prone process.</ns4:p><ns4:p> <ns4:bold>Methods:</ns4:bold> To mitigate some of the above problems we integrated and customised two existing JavaScript libraries to create a new web-based graphical data extraction tool to assist reviewers in extracting data from graphs. This tool aims to facilitate more accurate and timely data extraction through a user interface which can be used to extract data through mouse clicks. We carried out a non-inferiority evaluation to examine its performance in comparison to standard practice.</ns4:p><ns4:p> <ns4:bold>Results:</ns4:bold> We found that the customised graphical data extraction tool is not inferior to users’ prior preferred current approaches. Our study was not designed to show superiority, but suggests that there may be a saving in time of around 6 minutes per graph, accompanied by a substantial increase in accuracy.</ns4:p><ns4:p> <ns4:italic><ns4:bold>Conclusions:</ns4:bold> Our study suggests that the incorporation of this type of tool in online systematic review software would be beneficial in facilitating the production of accurate and timely evidence synthesis to improve decision-making.</ns4:italic></ns4:p> literature by using automation systems in a tiered strategy. believe this iterative method can help overcome bias in initial ML model training by having humans reinforce ML models with new and relevant information, and is an applied step towards transfer learning for ML in SR. research is required to investigate the potential for combining this approach with crowdsourcing or machine learning methodologies. identify human error. This needs to be confirmed in other reviews, , but represents a promising approach to integrating human decisions and automation in systematic review methodology. more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2019
DA  - 2019-01-25
JO  - {'id': 'https://openalex.org/S4210218052', 'issn_l': '2398-502X', 'issn': ['2398-502X'], 'display_name': 'Wellcome open research', 'publisher': 'Wellcome', 'type': 'journal', 'url': 'https://doi.org/10.12688/wellcomeopenres.14738.2', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Fala Cramond
AU  - Alison O'Mara-Eves
AU  - Lee Doran-Constant
AU  - Andrew S.C. Rice
AU  - Malcolm R. Macleod
AU  - James D. Thomas
ER  - 

161.
TY  - proceedings-article
ID  - https://openalex.org/W2212174283
DO  - https://doi.org/10.1109/bibm.2015.7359733
TI  - Supporting HIV literature screening with data sampling and supervised learning
AB  - This paper presents a supervised learning approach to support the screening of HIV literature. The manual screening of biomedical literature is an important task in the process of systematic reviews. Researchers and curators have the very demanding, time-consuming and error-prone task of manually identifying documents that must be included in a systematic review concerning a specific problem. We implemented a supervised learning approach to support screening tasks, by automatically flagging potentially selected documents in a list retrieved by a literature database search. To overcome the main issues associated with the automatic literature screening task, we evaluated the use of data sampling, feature combinations, and feature selection methods, generating a total of 105 classification models. The models yielding best results were composed by the Logistic Model Trees classifier, a fairly balanced training set, and feature combination of Bag-Of-Words and MeSH terms. According to our results, the system correctly labels the great majority of relevant documents, and it could be used to support HIV systematic reviews to allow researchers to assess a greater number of documents in less time. not designed to show superiority, but suggests that there may be a saving in time of around 6 minutes per graph, accompanied by a substantial increase in accuracy.</ns4:p><ns4:p> <ns4:italic><ns4:bold>Conclusions:</ns4:bold> Our study suggests that the incorporation of this type of tool in online systematic review software would be beneficial in facilitating the production of accurate and timely evidence synthesis to improve decision-making.</ns4:italic></ns4:p> literature by using automation systems in a tiered strategy. believe this iterative method can help overcome bias in initial ML model training by having humans reinforce ML models with new and relevant information, and is an applied step towards transfer learning for ML in SR. research is required to investigate the potential for combining this approach with crowdsourcing or machine learning methodologies. identify human error. This needs to be confirmed in other reviews, , but represents a promising approach to integrating human decisions and automation in systematic review methodology. more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2015
DA  - 2015-11-09
JO  - {'id': 'https://openalex.org/S4306417836', 'issn_l': None, 'issn': None, 'display_name': 'Bioinformatics and Biomedicine', 'publisher': None, 'type': 'conference', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Hayda Almeida
AU  - Marie-Jean Meurs
AU  - Leila Kosseim
AU  - Adrian Tsang
ER  - 

162.
TY  - posted-content
ID  - https://openalex.org/W2466116446
DO  - nan
TI  - A Novel Framework to Expedite Systematic Reviews by Automatically Building Information Extraction Training Corpora.
AB  - A systematic review identifies and collates various clinical studies and compares data elements and results in order to provide an evidence based answer for a particular clinical question. The process is manual and involves lot of time. A tool to automate this process is lacking. The aim of this work is to develop a framework using natural language processing and machine learning to build information extraction algorithms to identify data elements in a new primary publication, without having to go through the expensive task of manual annotation to build gold standards for each data element type. The system is developed in two stages. Initially, it uses information contained in existing systematic reviews to identify the sentences from the PDF files of the included references that contain specific data elements of interest using a modified Jaccard similarity measure. These sentences have been treated as labeled data.A Support Vector Machine (SVM) classifier is trained on this labeled data to extract data elements of interests from a new article. We conducted experiments on Cochrane Database systematic reviews related to congestive heart failure using inclusion criteria as an example data element. The empirical results show that the proposed system automatically identifies sentences containing the data element of interest with a high recall (93.75%) and reasonable precision (27.05% - which means the reviewers have to read only 3.7 sentences on average). The empirical results suggest that the tool is retrieving valuable information from the reference articles, even when it is time-consuming to identify them manually. Thus we hope that the tool will be useful for automatic data extraction from biomedical research publications. The future scope of this work is to generalize this information framework for all types of systematic reviews. required to investigate the potential for combining this approach with crowdsourcing or machine learning methodologies. identify human error. This needs to be confirmed in other reviews, , but represents a promising approach to integrating human decisions and automation in systematic review methodology. more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2016
DA  - 2016-06-21
JO  - {'id': 'https://openalex.org/S2597136632', 'issn_l': None, 'issn': None, 'display_name': 'arXiv: Information Retrieval', 'publisher': None, 'type': 'journal', 'url': 'https://arxiv.org/pdf/1606.06424.pdf', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Tanmay Basu
AU  - Shraman Kumar
AU  - Abhishek Kalyan
AU  - Pawan Kumar Jayaswal
AU  - Pawan Goyal
AU  - Stephen Pettifer
AU  - Siddhartha Jonnalagadda
ER  - 

163.
TY  - journal-article
ID  - https://openalex.org/W2468146373
DO  - https://doi.org/10.1186/s13643-016-0276-7
TI  - Publication of reviews synthesizing child health evidence (PORSCHE): a survey of authors to identify factors associated with publication in Cochrane and non-Cochrane sources
AB  - Cochrane Child Health maintains a register of child-relevant Cochrane systematic reviews (SRs) to provide a comprehensive source of high-quality evidence. However, a large number of SRs are published outside of The Cochrane Collaboration (Cochrane), impacting the comprehensiveness of the Cochrane Database of Systematic Reviews (CDSR). We surveyed authors who published child-relevant SRs with Cochrane and elsewhere in the medical literature to (1) understand their experiences in preparing and publishing SRs and (2) identify factors influencing choice of publication venue.We identified SRs published in the CDSR for the most recent complete year prior to our study (2013; n = 145). We searched the medical literature and randomly selected the same number of SRs published the same year. We developed an internet-based survey and contacted the corresponding author of each review via email. Data were analyzed descriptively. Qualitative analysis elicited common themes from open-ended questions.Seventy-six (26 %) responded: 41 % Cochrane, 42 % non-Cochrane, and 17 % published in both venues. Among respondents who published their SR in both venues (n = 13), 46 % found it easier to publish in a non-Cochrane journal, 15 % easier with Cochrane, and 31 % similar. Main reasons for conducting SRs with Cochrane (n = 44) were Cochrane's positive reputation (82 %) and good impact factor (66 %). Among respondents who published their SR in a non-Cochrane journal (n = 32), most frequent reasons for not conducting their SR with Cochrane were time required to follow Cochrane processes (25 %), lack of knowledge about how to conduct an SR with Cochrane (19 %), administrative processes (16 %), and perception that non-Cochrane journals yielded more interest (16 %). Among respondents who published their SR in a non-Cochrane journal (n = 32), 78 % did not register their review and 22 % did not prepare a protocol.Key reasons for publishing in Cochrane are its positive reputation and impact factor. Reasons for publishing in non-Cochrane sources include lack of familiarity or challenges with the Cochrane processes and desire to publish in a source more directly relevant to the topic of interest. End users looking for evidence in the form of SRs need to be aware that there is a vast number of SRs published across the medical literature. Efforts to optimize the identification of SRs in non-Cochrane sources (e.g., through effective labeling or protocol/review registration) and their content will help end users find the necessary synthesized evidence to support clinical practice. was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2016
DA  - 2016-06-21
JO  - {'id': 'https://openalex.org/V82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://systematicreviewsjournal.biomedcentral.com/track/pdf/10.1186/s13643-016-0276-7', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Lisa Hartling
AU  - Kassi Shave
AU  - Denise Thomson
AU  - Ricardo J. Fernandes
AU  - Aireen Wingert
AU  - Katrina Williams
ER  - 

164.
TY  - proceedings-article
ID  - https://openalex.org/W2782772655
DO  - https://doi.org/10.1145/3127526.3127533
TI  - Rapid Tagging and Reporting for Functional Language Extraction in Scientific Articles
AB  - This paper describes the development of a web-based application for tagging scientific articles, in part to create machine learning training datasets for automated functional language identification and extraction (AFLEX). The initial intent for this work was to provide a new member of the ecosystem of tools that facilitate the structured automation of systematic reviews, an area of work that typically requires critical analysis of multiple research studies and provides an exhaustive summary of literature related to a research question. However, the tool's modular interface allows use across disciplines. A user may upload PDF or text documents and quickly tag selected parts of the document with a customizable set of discipline-specific tags, and export results to CSV or JSON formats. An integrated back-end database stores tagging data for comparison between taggers or visual display of results on the web browser. While other discipline-specific text tagging tools exist, the authors have not encountered a cloud-based customizable tool for PDF and text annotation as flexible as the AFLEX Tag Tool developed by the authors. 46 % found it easier to publish in a non-Cochrane journal, 15 % easier with Cochrane, and 31 % similar. Main reasons for conducting SRs with Cochrane (n = 44) were Cochrane's positive reputation (82 %) and good impact factor (66 %). Among respondents who published their SR in a non-Cochrane journal (n = 32), most frequent reasons for not conducting their SR with Cochrane were time required to follow Cochrane processes (25 %), lack of knowledge about how to conduct an SR with Cochrane (19 %), administrative processes (16 %), and perception that non-Cochrane journals yielded more interest (16 %). Among respondents who published their SR in a non-Cochrane journal (n = 32), 78 % did not register their review and 22 % did not prepare a protocol.Key reasons for publishing in Cochrane are its positive reputation and impact factor. Reasons for publishing in non-Cochrane sources include lack of familiarity or challenges with the Cochrane processes and desire to publish in a source more directly relevant to the topic of interest. End users looking for evidence in the form of SRs need to be aware that there is a vast number of SRs published across the medical literature. Efforts to optimize the identification of SRs in non-Cochrane sources (e.g., through effective labeling or protocol/review registration) and their content will help end users find the necessary synthesized evidence to support clinical practice. was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2017
DA  - 2017-12-15
JO  - {'id': None, 'issn_l': None, 'issn': None, 'display_name': 'Proceedings of the 6th International Workshop on Mining Scientific Publications', 'publisher': None, 'type': None, 'url': 'https://doi.org/10.1145/3127526.3127533', 'is_oa': True, 'version': 'publishedVersion', 'license': None}
DP  - OpenAlex
AU  - Mahmood Ramezani
AU  - Vijay Kalivarapu
AU  - Stephen B. Gilbert
AU  - Sarah Rebecca Huffman
AU  - Elena Cotos
AU  - A. O'Conner
ER  - 

165.
TY  - proceedings-article
ID  - https://openalex.org/W2962722156
DO  - https://doi.org/10.18653/v1/w18-5609
TI  - Unsupervised Identification of Study Descriptors in Toxicology Research: An Experimental Study
AB  - Identifying and extracting data elements such as study descriptors in publication full texts is a critical yet manual and labor-intensive step required in a number of tasks. In this paper we address the question of identifying data elements in an unsupervised manner. Specifically, provided a set of criteria describing specific study parameters, such as species, route of administration, and dosing regimen, we develop an unsupervised approach to identify text segments (sentences) relevant to the criteria. A binary classifier trained to identify publications that met the criteria performs better when trained on the candidate sentences than when trained on sentences randomly picked from the text, supporting the intuition that our method is able to accurately identify study descriptors. JSON formats. An integrated back-end database stores tagging data for comparison between taggers or visual display of results on the web browser. While other discipline-specific text tagging tools exist, the authors have not encountered a cloud-based customizable tool for PDF and text annotation as flexible as the AFLEX Tag Tool developed by the authors. 46 % found it easier to publish in a non-Cochrane journal, 15 % easier with Cochrane, and 31 % similar. Main reasons for conducting SRs with Cochrane (n = 44) were Cochrane's positive reputation (82 %) and good impact factor (66 %). Among respondents who published their SR in a non-Cochrane journal (n = 32), most frequent reasons for not conducting their SR with Cochrane were time required to follow Cochrane processes (25 %), lack of knowledge about how to conduct an SR with Cochrane (19 %), administrative processes (16 %), and perception that non-Cochrane journals yielded more interest (16 %). Among respondents who published their SR in a non-Cochrane journal (n = 32), 78 % did not register their review and 22 % did not prepare a protocol.Key reasons for publishing in Cochrane are its positive reputation and impact factor. Reasons for publishing in non-Cochrane sources include lack of familiarity or challenges with the Cochrane processes and desire to publish in a source more directly relevant to the topic of interest. End users looking for evidence in the form of SRs need to be aware that there is a vast number of SRs published across the medical literature. Efforts to optimize the identification of SRs in non-Cochrane sources (e.g., through effective labeling or protocol/review registration) and their content will help end users find the necessary synthesized evidence to support clinical practice. was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2018
DA  - 2018-10-01
JO  - {'id': 'https://openalex.org/S4306418267', 'issn_l': None, 'issn': None, 'display_name': 'Empirical Methods in Natural Language Processing', 'publisher': None, 'type': 'conference', 'url': 'https://www.aclweb.org/anthology/W18-5609.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Drahomira Herrmannova
AU  - Steven L. Young
AU  - Robert M. Patton
AU  - Christopher C. Stahl
AU  - Nicole Kleinstreuer
AU  - Mary Leigh Wolfe
ER  - 

166.
TY  - journal-article
ID  - https://openalex.org/W3164676482
DO  - https://doi.org/10.1186/s12874-021-01354-2
TI  - Creating efficiencies in the extraction of data from randomized trials: a prospective evaluation of a machine learning and text mining tool
AB  - Abstract Background Machine learning tools that semi-automate data extraction may create efficiencies in systematic review production. We evaluated a machine learning and text mining tool’s ability to (a) automatically extract data elements from randomized trials, and (b) save time compared with manual extraction and verification. Methods For 75 randomized trials, we manually extracted and verified data for 21 data elements. We uploaded the randomized trials to an online machine learning and text mining tool, and quantified performance by evaluating its ability to identify the reporting of data elements (reported or not reported), and the relevance of the extracted sentences, fragments, and overall solutions. For each randomized trial, we measured the time to complete manual extraction and verification, and to review and amend the data extracted by the tool. We calculated the median (interquartile range [IQR]) time for manual and semi-automated data extraction, and overall time savings. Results The tool identified the reporting (reported or not reported) of data elements with median (IQR) 91% (75% to 99%) accuracy. Among the top five sentences for each data element at least one sentence was relevant in a median (IQR) 88% (83% to 99%) of cases. Among a median (IQR) 90% (86% to 97%) of relevant sentences, pertinent fragments had been highlighted by the tool; exact matches were unreliable (median (IQR) 52% [33% to 73%]). A median 48% of solutions were fully correct, but performance varied greatly across data elements (IQR 21% to 71%). Using ExaCT to assist the first reviewer resulted in a modest time savings compared with manual extraction by a single reviewer (17.9 vs. 21.6 h total extraction time across 75 randomized trials). Conclusions Using ExaCT to assist with data extraction resulted in modest gains in efficiency compared with manual extraction. The tool was reliable for identifying the reporting of most data elements. The tool’s ability to identify at least one relevant sentence and highlight pertinent fragments was generally good, but changes to sentence selection and/or highlighting were often required. Protocol https://doi.org/10.7939/DVN/RQPJKS publish in a source more directly relevant to the topic of interest. End users looking for evidence in the form of SRs need to be aware that there is a vast number of SRs published across the medical literature. Efforts to optimize the identification of SRs in non-Cochrane sources (e.g., through effective labeling or protocol/review registration) and their content will help end users find the necessary synthesized evidence to support clinical practice. was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2021
DA  - 2021-08-16
JO  - {'id': 'https://openalex.org/S185874209', 'issn_l': '1471-2288', 'issn': ['1471-2288'], 'display_name': 'BMC Medical Research Methodology', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://bmcmedresmethodol.biomedcentral.com/track/pdf/10.1186/s12874-021-01354-2', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Allison Gates
AU  - Michelle Gates
AU  - Shannon Sim
AU  - Sarah A. Elliott
AU  - Jennifer Pillay
AU  - Lisa Hartling
ER  - 

167.
TY  - book-chapter
ID  - https://openalex.org/W3170008619
DO  - https://doi.org/10.1007/978-3-030-77417-2_17
TI  - A Roadmap for Composing Automatic Literature Reviews: A Text Mining Approach
AB  - Due to accelerated growth in the number of scientific papers, writing literature reviews has become an increasingly costly activity. Therefore, the search for computational tools to assist in this process has been gaining ground in recent years. This work presents an overview of the current scenario of development of artificial intelligence tools aimed to assist in the production of systematic literature reviews. The process of creating a literature review is both creative and technical. The technical part of this process is liable to automation. For the purpose of organization, we divide this technical part into four steps: searching, screening, extraction, and synthesis. For each of these steps, we present artificial intelligence techniques that can be useful to its realization. In addition, we also present the obstacles encountered for the application of each technique. Finally, we propose a pipeline for the automatic creation of systematic literature reviews, by combining and placing existing techniques in stages where they possess the greatest potential to be useful.KeywordsSystematic reviewText miningAutomation 99%) accuracy. Among the top five sentences for each data element at least one sentence was relevant in a median (IQR) 88% (83% to 99%) of cases. Among a median (IQR) 90% (86% to 97%) of relevant sentences, pertinent fragments had been highlighted by the tool; exact matches were unreliable (median (IQR) 52% [33% to 73%]). A median 48% of solutions were fully correct, but performance varied greatly across data elements (IQR 21% to 71%). Using ExaCT to assist the first reviewer resulted in a modest time savings compared with manual extraction by a single reviewer (17.9 vs. 21.6 h total extraction time across 75 randomized trials). Conclusions Using ExaCT to assist with data extraction resulted in modest gains in efficiency compared with manual extraction. The tool was reliable for identifying the reporting of most data elements. The tool’s ability to identify at least one relevant sentence and highlight pertinent fragments was generally good, but changes to sentence selection and/or highlighting were often required. Protocol https://doi.org/10.7939/DVN/RQPJKS publish in a source more directly relevant to the topic of interest. End users looking for evidence in the form of SRs need to be aware that there is a vast number of SRs published across the medical literature. Efforts to optimize the identification of SRs in non-Cochrane sources (e.g., through effective labeling or protocol/review registration) and their content will help end users find the necessary synthesized evidence to support clinical practice. was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2021
DA  - 2021-03-10
JO  - {'id': 'https://openalex.org/V4210216221', 'issn_l': '1867-8211', 'issn': ['1867-8211', '1867-822X'], 'display_name': 'Lecture notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Eugênio Monteiro da Silva Júnior
AU  - Moisés Lima Dutra
ER  - 

168.
TY  - journal-article
ID  - https://openalex.org/W3179704152
DO  - https://doi.org/10.1097/eja.0000000000001535
TI  - Adapt or perish
AB  - No Abstract Found
PY  - 2021
DA  - 2021-08-01
JO  - {'id': 'https://openalex.org/S108768312', 'issn_l': '0265-0215', 'issn': ['1365-2346', '0265-0215'], 'display_name': 'European Journal of Anaesthesiology', 'publisher': 'Lippincott Williams & Wilkins', 'type': 'journal', 'url': 'https://journals.lww.com/ejanaesthesiology/Fulltext/2021/08000/Adapt_or_perish__Introducing_focused_guidelines.1.aspx', 'is_oa': True, 'version': 'publishedVersion', 'license': None}
DP  - OpenAlex
AU  - Carolina Romero
AU  - Arash Afshari
AU  - Peter Kranke
ER  - 

169.
TY  - journal-article
ID  - https://openalex.org/W3184058630
DO  - https://doi.org/10.47909/ijsmc.52
TI  - A roadmap toward the automatic composition of systematic literature reviews
AB  - Objective. This paper presents an overview of existing artificial intelligence tools to produce systematic literature reviews. Furthermore, we propose a general framework resulting from combining these techniques to highlight the challenges and possibilities currently existing in this research area. Design/Methodology/Approach. We undertook a scoping review on the systematic literature review steps to automate them via computational techniques. Results/Discussion. The process of creating a literature review is both creative and technical. The technical part of this process is liable to automation. Based on the literature, we chose to divide this technical part into four steps: searching, screening, extraction, and synthesis. For each one of these steps, we presented practical artificial intelligence techniques to carry them out. In addition, we presented the obstacles encountered in the application of each technique. Conclusion. We proposed a framework for automatically creating systematic literature reviews by combining and placing existing techniques in stages where they possess the greatest potential to be useful. Despite still lacking practical assessment in different areas of knowledge, this proposal indicates ways with the potential to reduce the time-consuming and repetitive work embedded in the systematic literature review process. Originality/Value. The paper presents the current possibilities for automating systematic literature reviews and how they can work together to reduce researchers’ operational workload. tool; exact matches were unreliable (median (IQR) 52% [33% to 73%]). A median 48% of solutions were fully correct, but performance varied greatly across data elements (IQR 21% to 71%). Using ExaCT to assist the first reviewer resulted in a modest time savings compared with manual extraction by a single reviewer (17.9 vs. 21.6 h total extraction time across 75 randomized trials). Conclusions Using ExaCT to assist with data extraction resulted in modest gains in efficiency compared with manual extraction. The tool was reliable for identifying the reporting of most data elements. The tool’s ability to identify at least one relevant sentence and highlight pertinent fragments was generally good, but changes to sentence selection and/or highlighting were often required. Protocol https://doi.org/10.7939/DVN/RQPJKS publish in a source more directly relevant to the topic of interest. End users looking for evidence in the form of SRs need to be aware that there is a vast number of SRs published across the medical literature. Efforts to optimize the identification of SRs in non-Cochrane sources (e.g., through effective labeling or protocol/review registration) and their content will help end users find the necessary synthesized evidence to support clinical practice. was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2021
DA  - 2021-07-27
JO  - {'id': 'https://openalex.org/V4210199169', 'issn_l': '2709-3158', 'issn': ['2709-7595', '2709-3158'], 'display_name': 'Iberoamerican journal of science measurement and communication', 'publisher': 'ColNes', 'type': 'journal', 'url': 'https://pub.colnes.org/index.php/ijsmc/article/download/52/88', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc'}
DP  - OpenAlex
AU  - Eugênio Monteiro da Silva Júnior
AU  - Moisés Lima Dutra
ER  - 

170.
TY  - journal-article
ID  - https://openalex.org/W3189477168
DO  - https://doi.org/10.3390/jpm11080790
TI  - Personalized and Self-Management: Systematic Search and Evaluation Quality Factors and User Preference of Drug Reference Apps in Taiwan
AB  - Background: Drug reference apps promote self-management and improve the efficiency and quality of work for physicians, nurses, pharmacists, and patients. This study aimed to describe a systematic and stepwise process to identify drug reference apps in Taiwan, assess the quality of these apps, and analyze the influential factors for user ratings. Methods: A two-step algorithm (KESS) consisting of keyword growing and systematic search was proposed. Seven independent reviewers were trained to evaluate these apps using Mobile App Rating Scale (MARS). A logistic regression model was fitted and average marginal effects (AME) were calculated to identify the effects of factors for higher user ratings. Results: A total of 23 drug reference apps in Taiwan were identified and analyzed. Generally, these drug reference apps were evaluated as acceptable quality with an average MARS score of 3.23. Higher user engagement, more functionality, better aesthetics, and more information associated with higher user ratings. Navigation is the most influential factor on higher user ratings (AME: 13.15%) followed by performance (AME: 11.03%), visual appeal (AME: 10.87%), credibility (AME: 10.67%), and quantity of information (AME: 10.42%). Conclusions: User experience and information clearly affect user ratings of drug reference apps. Five key factors should be considered when designing drug reference apps. work together to reduce researchers’ operational workload. tool; exact matches were unreliable (median (IQR) 52% [33% to 73%]). A median 48% of solutions were fully correct, but performance varied greatly across data elements (IQR 21% to 71%). Using ExaCT to assist the first reviewer resulted in a modest time savings compared with manual extraction by a single reviewer (17.9 vs. 21.6 h total extraction time across 75 randomized trials). Conclusions Using ExaCT to assist with data extraction resulted in modest gains in efficiency compared with manual extraction. The tool was reliable for identifying the reporting of most data elements. The tool’s ability to identify at least one relevant sentence and highlight pertinent fragments was generally good, but changes to sentence selection and/or highlighting were often required. Protocol https://doi.org/10.7939/DVN/RQPJKS publish in a source more directly relevant to the topic of interest. End users looking for evidence in the form of SRs need to be aware that there is a vast number of SRs published across the medical literature. Efforts to optimize the identification of SRs in non-Cochrane sources (e.g., through effective labeling or protocol/review registration) and their content will help end users find the necessary synthesized evidence to support clinical practice. was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2021
DA  - 2021-08-12
JO  - {'id': 'https://openalex.org/S2736780684', 'issn_l': '2075-4426', 'issn': ['2075-4426'], 'display_name': 'Journal of Personalized Medicine', 'publisher': 'MDPI', 'type': 'journal', 'url': 'https://www.mdpi.com/2075-4426/11/8/790/pdf?version=1628775582', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Yu Chen
AU  - Wei Liao
AU  - Mei Su
AU  - Yen Ting Lin
ER  - 

171.
TY  - journal-article
ID  - https://openalex.org/W3215072578
DO  - https://doi.org/10.5195/jmla.2021.1221
TI  - Adopting a toolkit to manage time, resources, and expectations in the systematic review process: a case report
AB  - The proliferation of systematic reviews has impacted library operations and activities as librarians support, collaborate, and perform more tasks in the systematic review process. This case report describes a toolkit that librarians with extensive experience in supporting multiple review teams use to manage time, resources, and expectations in the systematic review process.The toolkit is a compilation of documents that we use to effectively communicate with and help review teams understand and navigate each stage of the systematic review process. Elements included in the toolkit and discussed in this case report are intake forms, communication templates and memoranda, a process flow diagram, library guides on tools for retrieval and data appraisal, and established standards for guidance during the write-up stage. We describe the use of the toolkit for both education and project management, with a focus on its use in helping manage team time, resources, and expectations.The systematic review toolkit helps librarians connect systematic review steps and tasks to actionable items. The content facilitates and supports discussion and learning by both librarians and team members. This toolkit helps librarians share important information and resources for each stage of the process. drug reference apps. Five key factors should be considered when designing drug reference apps. work together to reduce researchers’ operational workload. tool; exact matches were unreliable (median (IQR) 52% [33% to 73%]). A median 48% of solutions were fully correct, but performance varied greatly across data elements (IQR 21% to 71%). Using ExaCT to assist the first reviewer resulted in a modest time savings compared with manual extraction by a single reviewer (17.9 vs. 21.6 h total extraction time across 75 randomized trials). Conclusions Using ExaCT to assist with data extraction resulted in modest gains in efficiency compared with manual extraction. The tool was reliable for identifying the reporting of most data elements. The tool’s ability to identify at least one relevant sentence and highlight pertinent fragments was generally good, but changes to sentence selection and/or highlighting were often required. Protocol https://doi.org/10.7939/DVN/RQPJKS publish in a source more directly relevant to the topic of interest. End users looking for evidence in the form of SRs need to be aware that there is a vast number of SRs published across the medical literature. Efforts to optimize the identification of SRs in non-Cochrane sources (e.g., through effective labeling or protocol/review registration) and their content will help end users find the necessary synthesized evidence to support clinical practice. was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2021
DA  - 2021-11-22
JO  - {'id': 'https://openalex.org/V146304353', 'issn_l': '1536-5050', 'issn': ['1536-5050', '1558-9439'], 'display_name': 'Journal of The Medical Library Association', 'publisher': 'University Library System, University of Pittsburgh', 'type': 'journal', 'url': 'https://jmla.pitt.edu/ojs/jmla/article/download/1221/1378', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Q. Eileen Wafford
AU  - Lucia Helena O’Dwyer
ER  - 

172.
TY  - journal-article
ID  - https://openalex.org/W3217415402
DO  - https://doi.org/10.5195/jmla.2021.1222
TI  - Addressing challenges with systematic review teams through effective communication: a case report
AB  - Every step in the systematic review process has challenges, ranging from resistance by review teams to adherence to standard methodology to low-energy commitment to full participation. These challenges can derail the project and result in significant delays, duplication of work, and failure to complete the review. Communication during the systematic review process is key to ensuring it runs smoothly and is identified as a core competency for librarians involved in systematic reviews.This case report presents effective communication approaches that our librarians employ to address challenges encountered while working with systematic review teams. The communication strategies we describe engage teams through information, questions, and action items and lead to productive collaborations with publishable systematic reviews.Effective communication with review teams keeps systematic review projects moving forward. The techniques covered in this case study strive to minimize misunderstandings, educate collaborators, and, in our experience, have led to multiple successful collaborations and publications. Librarians working in the systematic review space will recognize these challenges and can adapt these techniques to their own environments. both librarians and team members. This toolkit helps librarians share important information and resources for each stage of the process. drug reference apps. Five key factors should be considered when designing drug reference apps. work together to reduce researchers’ operational workload. tool; exact matches were unreliable (median (IQR) 52% [33% to 73%]). A median 48% of solutions were fully correct, but performance varied greatly across data elements (IQR 21% to 71%). Using ExaCT to assist the first reviewer resulted in a modest time savings compared with manual extraction by a single reviewer (17.9 vs. 21.6 h total extraction time across 75 randomized trials). Conclusions Using ExaCT to assist with data extraction resulted in modest gains in efficiency compared with manual extraction. The tool was reliable for identifying the reporting of most data elements. The tool’s ability to identify at least one relevant sentence and highlight pertinent fragments was generally good, but changes to sentence selection and/or highlighting were often required. Protocol https://doi.org/10.7939/DVN/RQPJKS publish in a source more directly relevant to the topic of interest. End users looking for evidence in the form of SRs need to be aware that there is a vast number of SRs published across the medical literature. Efforts to optimize the identification of SRs in non-Cochrane sources (e.g., through effective labeling or protocol/review registration) and their content will help end users find the necessary synthesized evidence to support clinical practice. was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2021
DA  - 2021-11-22
JO  - {'id': 'https://openalex.org/V146304353', 'issn_l': '1536-5050', 'issn': ['1536-5050', '1558-9439'], 'display_name': 'Journal of The Medical Library Association', 'publisher': 'University Library System, University of Pittsburgh', 'type': 'journal', 'url': 'https://jmla.pitt.edu/ojs/jmla/article/download/1222/1379', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Lucia Helena O’Dwyer
AU  - Q. Eileen Wafford
ER  - 

173.
TY  - journal-article
ID  - https://openalex.org/W4205109317
DO  - https://doi.org/10.1002/jrsm.1545
TI  - Identifying unreported links between ClinicalTrials.gov trial registrations and their published results
AB  - A substantial proportion of trial registrations are not linked to corresponding published articles, limiting analyses and new tools. Our aim was to develop a method for finding articles reporting the results of trials that are registered on ClinicalTrials.gov when they do not include metadata links. We used a set of 27,280 trial registration and article pairs to train and evaluate methods for identifying missing links in both directions-from articles to registrations and from registrations to articles. We trained a classifier with six distance metrics as feature representations to rank the correct article or registration, using recall@K to evaluate performance and compare to baseline methods. When identifying links from registrations to published articles, the classifier ranked the correct article first (recall@1) among 378,048 articles in 80.8% of evaluation cases and 34.9% in the baseline method. Recall@10 was 85.1% compared to 60.7% in the baseline. When predicting links from articles to registrations, recall@1 was 83.4% for the classifier and 39.8% in the baseline. Recall@10 was 89.5% compared to 65.8% in the baseline. The proposed method improves on our baseline document similarity method to be feasible for identifying missing links in practice. Given a ClinicalTrials.gov registration, a user checking 10 ranked articles can expect to identify the matching article in at least 85% of cases, if the trial has been published. The proposed method can be used to improve the coupling of ClinicalTrials.gov and PubMed, with applications related to automating systematic review and evidence synthesis processes. assist the first reviewer resulted in a modest time savings compared with manual extraction by a single reviewer (17.9 vs. 21.6 h total extraction time across 75 randomized trials). Conclusions Using ExaCT to assist with data extraction resulted in modest gains in efficiency compared with manual extraction. The tool was reliable for identifying the reporting of most data elements. The tool’s ability to identify at least one relevant sentence and highlight pertinent fragments was generally good, but changes to sentence selection and/or highlighting were often required. Protocol https://doi.org/10.7939/DVN/RQPJKS publish in a source more directly relevant to the topic of interest. End users looking for evidence in the form of SRs need to be aware that there is a vast number of SRs published across the medical literature. Efforts to optimize the identification of SRs in non-Cochrane sources (e.g., through effective labeling or protocol/review registration) and their content will help end users find the necessary synthesized evidence to support clinical practice. was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2021
DA  - 2021-12-30
JO  - {'id': 'https://openalex.org/V205768342', 'issn_l': '1759-2879', 'issn': ['1759-2879', '1759-2887'], 'display_name': 'Research Synthesis Methods', 'publisher': 'Wiley-Blackwell', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Shifeng Liu
AU  - Florence T. Bourgeois
AU  - Adam G. Dunn
ER  - 

174.
TY  - journal-article
ID  - https://openalex.org/W4220842251
DO  - https://doi.org/10.1093/jamiaopen/ooac015
TI  - Evaluation of publication type tagging as a strategy to screen randomized controlled trial articles in preparing systematic reviews
AB  - To produce a systematic review (SR), reviewers typically screen thousands of titles and abstracts of articles manually to find a small number which are read in full text to find relevant articles included in the final SR. Here, we evaluate a proposed automated probabilistic publication type screening strategy applied to the randomized controlled trial (RCT) articles (i.e., those which present clinical outcome results of RCT studies) included in a corpus of previously published Cochrane reviews.We selected a random subset of 558 published Cochrane reviews that specified RCT study only inclusion criteria, containing 7113 included articles which could be matched to PubMed identifiers. These were processed by our automated RCT Tagger tool to estimate the probability that each article reports clinical outcomes of a RCT.Removing articles with low predictive scores P < 0.01 eliminated 288 included articles, of which only 22 were actually typical RCT articles, and only 18 were actually typical RCT articles that MEDLINE indexed as such. Based on our sample set, this screening strategy led to fewer than 0.05 relevant RCT articles being missed on average per Cochrane SR.This scenario, based on real SRs, demonstrates that automated tagging can identify RCT articles accurately while maintaining very high recall. However, we also found that even SRs whose inclusion criteria are restricted to RCT studies include not only clinical outcome articles per se, but a variety of ancillary article types as well.This encourages further studies learning how best to incorporate automated tagging of additional publication types into SR triage workflows. modest time savings compared with manual extraction by a single reviewer (17.9 vs. 21.6 h total extraction time across 75 randomized trials). Conclusions Using ExaCT to assist with data extraction resulted in modest gains in efficiency compared with manual extraction. The tool was reliable for identifying the reporting of most data elements. The tool’s ability to identify at least one relevant sentence and highlight pertinent fragments was generally good, but changes to sentence selection and/or highlighting were often required. Protocol https://doi.org/10.7939/DVN/RQPJKS publish in a source more directly relevant to the topic of interest. End users looking for evidence in the form of SRs need to be aware that there is a vast number of SRs published across the medical literature. Efforts to optimize the identification of SRs in non-Cochrane sources (e.g., through effective labeling or protocol/review registration) and their content will help end users find the necessary synthesized evidence to support clinical practice. was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2022
DA  - 2022-01-07
JO  - {'id': 'https://openalex.org/S4210237468', 'issn_l': '2574-2531', 'issn': ['2574-2531'], 'display_name': 'JAMIA open', 'publisher': 'University of Oxford', 'type': 'journal', 'url': 'https://academic.oup.com/jamiaopen/article-pdf/5/1/ooac015/43291122/ooac015.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Jodi Schneider
AU  - , Linh Hoang
AU  - , Yogeshwar Kansara
AU  - Aaron Cohen
AU  - Neil R. Smalheiser
ER  - 

175.
TY  - journal-article
ID  - https://openalex.org/W4225297356
DO  - https://doi.org/10.2196/33219
TI  - Web-Based Software Tools for Systematic Literature Review in Medicine: Systematic Search and Feature Analysis
AB  - Background Systematic reviews (SRs) are central to evaluating therapies but have high costs in terms of both time and money. Many software tools exist to assist with SRs, but most tools do not support the full process, and transparency and replicability of SR depend on performing and presenting evidence according to established best practices. Objective This study aims to provide a basis for comparing and selecting between web-based software tools that support SR, by conducting a feature-by-feature comparison of SR tools. Methods We searched for SR tools by reviewing any such tool listed in the SR Toolbox, previous reviews of SR tools, and qualitative Google searching. We included all SR tools that were currently functional and required no coding, and excluded reference managers, desktop applications, and statistical software. The list of features to assess was populated by combining all features assessed in 4 previous reviews of SR tools; we also added 5 features (manual addition, screening automation, dual extraction, living review, and public outputs) that were independently noted as best practices or enhancements of transparency and replicability. Then, 2 reviewers assigned binary present or absent assessments to all SR tools with respect to all features, and a third reviewer adjudicated all disagreements. Results Of the 53 SR tools found, 55% (29/53) were excluded, leaving 45% (24/53) for assessment. In total, 30 features were assessed across 6 classes, and the interobserver agreement was 86.46%. Giotto Compliance (27/30, 90%), DistillerSR (26/30, 87%), and Nested Knowledge (26/30, 87%) support the most features, followed by EPPI-Reviewer Web (25/30, 83%), LitStream (23/30, 77%), JBI SUMARI (21/30, 70%), and SRDB.PRO (VTS Software) (21/30, 70%). Fewer than half of all the features assessed are supported by 7 tools: RobotAnalyst (National Centre for Text Mining), SRDR (Agency for Healthcare Research and Quality), SyRF (Systematic Review Facility), Data Abstraction Assistant (Center for Evidence Synthesis in Health), SR Accelerator (Institute for Evidence-Based Healthcare), RobotReviewer (RobotReviewer), and COVID-NMA (COVID-NMA). Notably, of the 24 tools, only 10 (42%) support direct search, only 7 (29%) offer dual extraction, and only 13 (54%) offer living/updatable reviews. Conclusions DistillerSR, Nested Knowledge, and EPPI-Reviewer Web each offer a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. end users find the necessary synthesized evidence to support clinical practice. was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2022
DA  - 2022-05-02
JO  - {'id': 'https://openalex.org/S2764650051', 'issn_l': '2291-9694', 'issn': ['2291-9694'], 'display_name': 'JMIR medical informatics', 'publisher': 'JMIR Publications', 'type': 'journal', 'url': 'https://medinform.jmir.org/2022/5/e33219/PDF', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Kathryn Cowie
AU  - Asad Rahmatullah
AU  - Nicole Hardy
AU  - Kevin M. Kallmes
AU  - Kevin M. Kallmes
ER  - 

176.
TY  - book-chapter
ID  - https://openalex.org/W4225658850
DO  - https://doi.org/10.1007/978-3-030-99736-6_39
TI  - Automation of Citation Screening for Systematic Literature Reviews Using Neural Networks: A Replicability Study
AB  - AbstractIn the process of Systematic Literature Review, citation screening is estimated to be one of the most time-consuming steps. Multiple approaches to automate it using various machine learning techniques have been proposed. The first research papers that apply deep neural networks to this problem were published in the last two years. In this work, we conduct a replicability study of the first two deep learning papers for citation screening [8, 16] and evaluate their performance on 23 publicly available datasets. While we succeeded in replicating the results of one of the papers, we were unable to replicate the results of the other. We summarise the challenges involved in the replication, including difficulties in obtaining the datasets to match the experimental setup of the original papers and problems with executing the original source code. Motivated by this experience, we subsequently present a simpler model based on averaging word embeddings that outperforms one of the models on 18 out of 23 datasets and is, on average, 72 times faster than the second replicated approach. Finally, we measure the training time and the invariance of the models when exposed to a variety of input features and random initialisations, demonstrating differences in the robustness of these approaches.KeywordsCitation screeningStudy selectionSystematic literature review (SLR)Document retrievalReplicability 55% (29/53) were excluded, leaving 45% (24/53) for assessment. In total, 30 features were assessed across 6 classes, and the interobserver agreement was 86.46%. Giotto Compliance (27/30, 90%), DistillerSR (26/30, 87%), and Nested Knowledge (26/30, 87%) support the most features, followed by EPPI-Reviewer Web (25/30, 83%), LitStream (23/30, 77%), JBI SUMARI (21/30, 70%), and SRDB.PRO (VTS Software) (21/30, 70%). Fewer than half of all the features assessed are supported by 7 tools: RobotAnalyst (National Centre for Text Mining), SRDR (Agency for Healthcare Research and Quality), SyRF (Systematic Review Facility), Data Abstraction Assistant (Center for Evidence Synthesis in Health), SR Accelerator (Institute for Evidence-Based Healthcare), RobotReviewer (RobotReviewer), and COVID-NMA (COVID-NMA). Notably, of the 24 tools, only 10 (42%) support direct search, only 7 (29%) offer dual extraction, and only 13 (54%) offer living/updatable reviews. Conclusions DistillerSR, Nested Knowledge, and EPPI-Reviewer Web each offer a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. end users find the necessary synthesized evidence to support clinical practice. was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2022
DA  - 2022-01-01
JO  - {'id': 'https://openalex.org/S4306463941', 'issn_l': None, 'issn': None, 'display_name': 'Springer International Publishing eBooks', 'publisher': 'Springer Nature', 'type': 'ebook platform', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Wojciech Kusa
AU  - Allan Hanbury
AU  - Petr Knoth
ER  - 

177.
TY  - journal-article
ID  - https://openalex.org/W4251645445
DO  - https://doi.org/10.12688/f1000research.22781.1
TI  - Data extraction methods for systematic review (semi)automation: A living review protocol
AB  - <ns4:p><ns4:bold>Background:</ns4:bold> Researchers in evidence-based medicine cannot keep up with the amounts of both old and newly published primary research articles. Conducting and updating of systematic reviews is time-consuming. In practice, data extraction is one of the most complex tasks in this process. Exponential improvements in computational processing speed and data storage are fostering the development of data extraction models and algorithms. This, in combination with quicker pathways to publication, led to a large landscape of tools and methods for data extraction tasks.</ns4:p><ns4:p> <ns4:bold>Objective</ns4:bold>: To review published methods and tools for data extraction to (semi)automate the systematic reviewing process.</ns4:p><ns4:p> <ns4:bold>Methods</ns4:bold>: We propose to conduct a living review. With this methodology we aim to do monthly search updates, as well as bi-annual review updates if new evidence permits it. In a cross-sectional analysis we will extract methodological characteristics and assess the quality of reporting in our included papers.</ns4:p><ns4:p> <ns4:bold>Conclusions</ns4:bold>: We aim to increase transparency in the reporting and assessment of machine learning technologies to the benefit of data scientists, systematic reviewers and funders of health research. This living review will help to reduce duplicate efforts by data scientists who develop data extraction methods. It will also serve to inform systematic reviewers about possibilities to support their data extraction.</ns4:p> review (SLR)Document retrievalReplicability 55% (29/53) were excluded, leaving 45% (24/53) for assessment. In total, 30 features were assessed across 6 classes, and the interobserver agreement was 86.46%. Giotto Compliance (27/30, 90%), DistillerSR (26/30, 87%), and Nested Knowledge (26/30, 87%) support the most features, followed by EPPI-Reviewer Web (25/30, 83%), LitStream (23/30, 77%), JBI SUMARI (21/30, 70%), and SRDB.PRO (VTS Software) (21/30, 70%). Fewer than half of all the features assessed are supported by 7 tools: RobotAnalyst (National Centre for Text Mining), SRDR (Agency for Healthcare Research and Quality), SyRF (Systematic Review Facility), Data Abstraction Assistant (Center for Evidence Synthesis in Health), SR Accelerator (Institute for Evidence-Based Healthcare), RobotReviewer (RobotReviewer), and COVID-NMA (COVID-NMA). Notably, of the 24 tools, only 10 (42%) support direct search, only 7 (29%) offer dual extraction, and only 13 (54%) offer living/updatable reviews. Conclusions DistillerSR, Nested Knowledge, and EPPI-Reviewer Web each offer a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. end users find the necessary synthesized evidence to support clinical practice. was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2020
DA  - 2020-03-25
JO  - {'id': 'https://openalex.org/S4210239046', 'issn_l': '2046-1402', 'issn': ['2046-1402'], 'display_name': 'F1000Research', 'publisher': 'Faculty of 1000', 'type': 'journal', 'url': 'https://f1000research.com/articles/9-210/v1/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Lena Schmidt
AU  - Babatunde K. Olorisade
AU  - Adrian M. Price-Whelan
AU  - Julian P T Higgins
ER  - 

178.
TY  - journal-article
ID  - https://openalex.org/W4281620438
DO  - https://doi.org/10.1186/s13326-022-00270-8
TI  - Synthesizing evidence from clinical trials with dynamic interactive argument trees
AB  - Evidence-based medicine propagates that medical/clinical decisions are made by taking into account high-quality evidence, most notably in the form of randomized clinical trials. Evidence-based decision-making requires aggregating the evidence available in multiple trials to reach -by means of systematic reviews- a conclusive recommendation on which treatment is best suited for a given patient population. However, it is challenging to produce systematic reviews to keep up with the ever-growing number of published clinical trials. Therefore, new computational approaches are necessary to support the creation of systematic reviews that include the most up-to-date evidence.We propose a method to synthesize the evidence available in clinical trials in an ad-hoc and on-demand manner by automatically arranging such evidence in the form of a hierarchical argument that recommends a therapy as being superior to some other therapy along a number of key dimensions corresponding to the clinical endpoints of interest. The method has also been implemented as a web tool that allows users to explore the effects of excluding different points of evidence, and indicating relative preferences on the endpoints.Through two use cases, our method was shown to be able to generate conclusions similar to the ones of published systematic reviews. To evaluate our method implemented as a web tool, we carried out a survey and usability analysis with medical professionals. The results show that the tool was perceived as being valuable, acknowledging its potential to inform clinical decision-making and to complement the information from existing medical guidelines.The method presented is a simple but yet effective argumentation-based method that contributes to support the synthesis of clinical trial evidence. A current limitation of the method is that it relies on a manually populated knowledge base. This problem could be alleviated by deploying natural language processing methods to extract the relevant information from publications. Facility), Data Abstraction Assistant (Center for Evidence Synthesis in Health), SR Accelerator (Institute for Evidence-Based Healthcare), RobotReviewer (RobotReviewer), and COVID-NMA (COVID-NMA). Notably, of the 24 tools, only 10 (42%) support direct search, only 7 (29%) offer dual extraction, and only 13 (54%) offer living/updatable reviews. Conclusions DistillerSR, Nested Knowledge, and EPPI-Reviewer Web each offer a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. end users find the necessary synthesized evidence to support clinical practice. was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2022
DA  - 2022-06-03
JO  - {'id': 'https://openalex.org/S172276550', 'issn_l': '2041-1480', 'issn': ['2041-1480'], 'display_name': 'Journal of Biomedical Semantics', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://jbiomedsem.biomedcentral.com/counter/pdf/10.1186/s13326-022-00270-8', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Olivia Sanchez-Graillet
AU  - C. Witte
AU  - Frank Grimm
AU  - Steffen Grautoff
AU  - Basil Ell
AU  - Philipp Cimiano
ER  - 

179.
TY  - journal-article
ID  - https://openalex.org/W4282937925
DO  - https://doi.org/10.1093/jamia/ocac066
TI  - Automated medical literature screening using artificial intelligence: a systematic review and meta-analysis
AB  - Abstract Objective We aim to investigate the application and accuracy of artificial intelligence (AI) methods for automated medical literature screening for systematic reviews. Materials and Methods We systematically searched PubMed, Embase, and IEEE Xplore Digital Library to identify potentially relevant studies. We included studies in automated literature screening that reported study question, source of dataset, and developed algorithm models for literature screening. The literature screening results by human investigators were considered to be the reference standard. Quantitative synthesis of the accuracy was conducted using a bivariate model. Results Eighty-six studies were included in our systematic review and 17 studies were further included for meta-analysis. The combined recall, specificity, and precision were 0.928 [95% confidence interval (CI), 0.878–0.958], 0.647 (95% CI, 0.442–0.809), and 0.200 (95% CI, 0.135–0.287) when achieving maximized recall, but were 0.708 (95% CI, 0.570–0.816), 0.921 (95% CI, 0.824–0.967), and 0.461 (95% CI, 0.375–0.549) when achieving maximized precision in the AI models. No significant difference was found in recall among subgroup analyses including the algorithms, the number of screened literatures, and the fraction of included literatures. Discussion and Conclusion This systematic review and meta-analysis study showed that the recall is more important than the specificity or precision in literature screening, and a recall over 0.95 should be prioritized. We recommend to report the effectiveness indices of automatic algorithms separately. At the current stage manual literature screening is still indispensable for medical systematic reviews. and to complement the information from existing medical guidelines.The method presented is a simple but yet effective argumentation-based method that contributes to support the synthesis of clinical trial evidence. A current limitation of the method is that it relies on a manually populated knowledge base. This problem could be alleviated by deploying natural language processing methods to extract the relevant information from publications. Facility), Data Abstraction Assistant (Center for Evidence Synthesis in Health), SR Accelerator (Institute for Evidence-Based Healthcare), RobotReviewer (RobotReviewer), and COVID-NMA (COVID-NMA). Notably, of the 24 tools, only 10 (42%) support direct search, only 7 (29%) offer dual extraction, and only 13 (54%) offer living/updatable reviews. Conclusions DistillerSR, Nested Knowledge, and EPPI-Reviewer Web each offer a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. end users find the necessary synthesized evidence to support clinical practice. was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2022
DA  - 2022-05-31
JO  - {'id': 'https://openalex.org/V129839026', 'issn_l': '1067-5027', 'issn': ['1067-5027', '1527-974X'], 'display_name': 'Journal of the American Medical Informatics Association', 'publisher': 'Oxford University Press', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Yunying Feng
AU  - Siyu Liang
AU  - Yuelun Zhang
AU  - Shi Chen
AU  - Qing Wang
AU  - Tianze Huang
AU  - Feng Sun
AU  - Xiaoqing Liu
AU  - Huijuan Zhu
AU  - Hui Pan
ER  - 

180.
TY  - journal-article
ID  - https://openalex.org/W4283078815
DO  - https://doi.org/10.1016/j.knosys.2022.109266
TI  - slr-kit: A semi-supervised machine learning framework for systematic literature reviews
AB  - Systematic Literature Review (SLR) is nowadays a challenging task due to the large number of papers that typically compose the scientific material of the topic to review. Recently, a lot of research effort has been devoted to automate, even partially, the stages of an SLR. This paper proposes the design and implementation of a workflow and a set of tools – called slr-kit – to support key tasks in an SLR. The proposed approach leverages a semi-supervised strategy, in which time-consuming processes are carried out using automatic tools, whereas manual tasks have been optimized by carefully designed support tools to reduce the overall required effort. Important parts of the workflow include the extraction of key terms directly from the abstracts of the papers to survey, and the subsequent topic modeling that allows for a thematic clustering of the corpus of papers. In the proposed workflow, the former task is carried out by exploiting a novel tool, called FAst WOrd Classifier (FAWOC). The latter, instead, is designed to be automatically carried out by leveraging an ad-hoc solution based on the application of the Latent Dirichlet Allocation (LDA) algorithm. The result of the process consists in a set of statistics regarding the relationship among papers, topics, and their trend of publication on journals and conference proceedings. The validity of the method is demonstrated with an application to a dataset related to the scientific field of NLP, while its accuracy is assessed by the manual examination of the results by domain experts. yet effective argumentation-based method that contributes to support the synthesis of clinical trial evidence. A current limitation of the method is that it relies on a manually populated knowledge base. This problem could be alleviated by deploying natural language processing methods to extract the relevant information from publications. Facility), Data Abstraction Assistant (Center for Evidence Synthesis in Health), SR Accelerator (Institute for Evidence-Based Healthcare), RobotReviewer (RobotReviewer), and COVID-NMA (COVID-NMA). Notably, of the 24 tools, only 10 (42%) support direct search, only 7 (29%) offer dual extraction, and only 13 (54%) offer living/updatable reviews. Conclusions DistillerSR, Nested Knowledge, and EPPI-Reviewer Web each offer a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. end users find the necessary synthesized evidence to support clinical practice. was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2022
DA  - 2022-06-01
JO  - {'id': 'https://openalex.org/S10169007', 'issn_l': '0950-7051', 'issn': ['1872-7409', '0950-7051'], 'display_name': 'Knowledge Based Systems', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Tullio Facchinetti
AU  - Guido Benetti
AU  - Davide Giuffrida
AU  - Antonino Nocera
ER  - 

181.
TY  - journal-article
ID  - https://openalex.org/W4296930504
DO  - https://doi.org/10.3390/biomedinformatics2030032
TI  - Machine Learning Tools and Platforms in Clinical Trial Outputs to Support Evidence-Based Health Informatics: A Rapid Review of the Literature
AB  - Background: The application of machine learning (ML) tools (MLTs) to support clinical trials outputs in evidence-based health informatics can be an effective, useful, feasible, and acceptable way to advance medical research and provide precision medicine. Methods: In this study, the author used the rapid review approach and snowballing methods. The review was conducted in the following databases: PubMed, Scopus, COCHRANE LIBRARY, clinicaltrials.gov, Semantic Scholar, and the first six pages of Google Scholar from the 10 July–15 August 2022 period. Results: Here, 49 articles met the required criteria and were included in this review. Accordingly, 32 MLTs and platforms were identified in this study that applied the automatic extraction of knowledge from clinical trial outputs. Specifically, the initial use of automated tools resulted in modest to satisfactory time savings compared with the manual management. In addition, the evaluation of performance, functionality, usability, user interface, and system requirements also yielded positive results. Moreover, the evaluation of some tools in terms of acceptance, feasibility, precision, accuracy, efficiency, efficacy, and reliability was also positive. Conclusions: In summary, design based on the application of clinical trial results in ML is a promising approach to apply more reliable solutions. Future studies are needed to propose common standards for the assessment of MLTs and to clinically validate the performance in specific healthcare and technical domains. method is demonstrated with an application to a dataset related to the scientific field of NLP, while its accuracy is assessed by the manual examination of the results by domain experts. yet effective argumentation-based method that contributes to support the synthesis of clinical trial evidence. A current limitation of the method is that it relies on a manually populated knowledge base. This problem could be alleviated by deploying natural language processing methods to extract the relevant information from publications. Facility), Data Abstraction Assistant (Center for Evidence Synthesis in Health), SR Accelerator (Institute for Evidence-Based Healthcare), RobotReviewer (RobotReviewer), and COVID-NMA (COVID-NMA). Notably, of the 24 tools, only 10 (42%) support direct search, only 7 (29%) offer dual extraction, and only 13 (54%) offer living/updatable reviews. Conclusions DistillerSR, Nested Knowledge, and EPPI-Reviewer Web each offer a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. end users find the necessary synthesized evidence to support clinical practice. was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2022
DA  - 2022-09-14
JO  - {'id': 'https://openalex.org/S4210213753', 'issn_l': '2673-7426', 'issn': ['2673-7426'], 'display_name': 'BioMedInformatics', 'publisher': 'MDPI AG', 'type': 'journal', 'url': 'https://www.mdpi.com/2673-7426/2/3/32/pdf?version=1663163045', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Stella C. Christopoulou
ER  - 

182.
TY  - journal-article
ID  - https://openalex.org/W2147775447
DO  - https://doi.org/10.1053/j.ajkd.2014.09.003
TI  - Finding CKD Studies—Automated Searching and Screening
AB  - No Abstract Found
PY  - 2015
DA  - 2015-01-01
JO  - {'id': 'https://openalex.org/V18197459', 'issn_l': '0272-6386', 'issn': ['1523-6838', '0272-6386'], 'display_name': 'American Journal of Kidney Diseases', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Katrin Uhlig
ER  - 

183.
TY  - book-chapter
ID  - https://openalex.org/W2265427618
DO  - https://doi.org/10.1007/978-1-4899-7600-0_22
TI  - New Statistical Methods of Combining Results in Comparative Effectiveness Research
AB  - No Abstract Found
PY  - 2016
DA  - 2016-01-01
JO  - {'id': None, 'issn_l': None, 'issn': None, 'display_name': None, 'publisher': None, 'type': None, 'url': 'https://doi.org/10.1007/978-1-4899-7600-0_22', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Chris Cameron
AU  - Robert W. Platt
ER  - 

184.
TY  - proceedings-article
ID  - https://openalex.org/W2442869382
DO  - https://doi.org/10.1145/2934732.2934752
TI  - Search Strategy Formulation
AB  - Healthcare information professionals perform systematic literature reviews to gather the evidence needed to answer specific research questions and formulate policy. However, performing a systematic review is a resource-intensive and time consuming undertaking, often taking years to complete. Moreover, the output relies heavily on the quality of the initial search strategy in ensuring that the scope is sufficiently exhaustive and not biased by easily accessible studies. In this paper we introduce a structured methodology and a framework for learning which together aim to embody best practices from the community and provide support for many of the common issues in search strategy development. this study that applied the automatic extraction of knowledge from clinical trial outputs. Specifically, the initial use of automated tools resulted in modest to satisfactory time savings compared with the manual management. In addition, the evaluation of performance, functionality, usability, user interface, and system requirements also yielded positive results. Moreover, the evaluation of some tools in terms of acceptance, feasibility, precision, accuracy, efficiency, efficacy, and reliability was also positive. Conclusions: In summary, design based on the application of clinical trial results in ML is a promising approach to apply more reliable solutions. Future studies are needed to propose common standards for the assessment of MLTs and to clinically validate the performance in specific healthcare and technical domains. method is demonstrated with an application to a dataset related to the scientific field of NLP, while its accuracy is assessed by the manual examination of the results by domain experts. yet effective argumentation-based method that contributes to support the synthesis of clinical trial evidence. A current limitation of the method is that it relies on a manually populated knowledge base. This problem could be alleviated by deploying natural language processing methods to extract the relevant information from publications. Facility), Data Abstraction Assistant (Center for Evidence Synthesis in Health), SR Accelerator (Institute for Evidence-Based Healthcare), RobotReviewer (RobotReviewer), and COVID-NMA (COVID-NMA). Notably, of the 24 tools, only 10 (42%) support direct search, only 7 (29%) offer dual extraction, and only 13 (54%) offer living/updatable reviews. Conclusions DistillerSR, Nested Knowledge, and EPPI-Reviewer Web each offer a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. end users find the necessary synthesized evidence to support clinical practice. was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2016
DA  - 2016-06-14
JO  - {'id': None, 'issn_l': None, 'issn': None, 'display_name': 'Proceedings of the 4th Spanish Conference on Information Retrieval', 'publisher': None, 'type': None, 'url': 'https://doi.org/10.1145/2934732.2934752', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Andrew MacFarlane
AU  - Tony Russell-Rose
ER  - 

185.
TY  - proceedings-article
ID  - https://openalex.org/W2517705328
DO  - nan
TI  - Automating Meta-Analyses of Randomized Clinical Trials: A First Look
AB  - A “meta-study” or “meta-analysis” analyzes multiple medical studies related to the same disease, treatment protocol, and outcome measurement to identify if there is an overall effect or not (e.g., treatment induces remission or causes adverse effects). It’s advantage lies in the pooling and analysis of results across independent studies, which increases the population size, mitigates some experimental bias or inconsistent results from a single study, etc. Meta-studies are important for understanding the effectiveness (or not) of treatment, influencing clinical guidelines and for spurring new research directions. However, meta-studies are extremely time consuming to construct by hand and keep updated with the latest results. This limits both their breadth of coverage (since researchers will only invest the time for diseases they are interested in) and their practically. Yet, high-quality medical research is increasing at a staggering rate, and there is an opportunity to apply automation to this increasing body of knowledge, thereby expanding the benefits of meta-studies to (theoretically) all diseases and treatment, as they are published. That is, we envision, long term an automatic process for creating meta-studies across all diseases and treatments, and keeping those meta-studies up-to-date automatically. In this paper we demonstrate that there is potential to perform this task, point out future research directions to make this so, and, hopefully, spur significant interest in this compelling and important research direction at the intersection of medical research and machine learning. of NLP, while its accuracy is assessed by the manual examination of the results by domain experts. yet effective argumentation-based method that contributes to support the synthesis of clinical trial evidence. A current limitation of the method is that it relies on a manually populated knowledge base. This problem could be alleviated by deploying natural language processing methods to extract the relevant information from publications. Facility), Data Abstraction Assistant (Center for Evidence Synthesis in Health), SR Accelerator (Institute for Evidence-Based Healthcare), RobotReviewer (RobotReviewer), and COVID-NMA (COVID-NMA). Notably, of the 24 tools, only 10 (42%) support direct search, only 7 (29%) offer dual extraction, and only 13 (54%) offer living/updatable reviews. Conclusions DistillerSR, Nested Knowledge, and EPPI-Reviewer Web each offer a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. end users find the necessary synthesized evidence to support clinical practice. was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2014
DA  - 2014-01-01
JO  - {'id': 'https://openalex.org/S4306420577', 'issn_l': None, 'issn': None, 'display_name': 'National Conference on Artificial Intelligence', 'publisher': None, 'type': 'conference', 'url': 'http://www.mmichelson.com/paps/HIAI_metaStudies.pdf', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Matthew Michelson
ER  - 

186.
TY  - dissertation
ID  - https://openalex.org/W2603784858
DO  - https://doi.org/10.14264/uql.2017.167
TI  - A framework for developing knowledge bases of scientific artefacts in the biomedical domain
AB  - The volume of scientific papers published annually in the biomedical domain is continuously increasing. Streamlining the process of identifying the most critical and significant nuggets of information (such as hypotheses, observations, interventions, findings) in a given research publication is a challenging but worthwhile task. This essential information, known as scientific artefacts, underpins the knowledge used by many health professionals in the decision-making process or researchers in creating systematic reviews; however most of today’s search engines are unable to identify these artefacts. Evidence Based Medicine (EBM) represents a framework that encompasses decision-making in the healthcare domain, based on providing medical practitioners with the best available evidence so they can choose the optimum treatment for individual patients. In order to provide patients with the best treatment, health professionals need access to current, timely and reliable evidence retrieved from relevant published medical research or previously synthesised evidence. Hence, devising mechanisms that can automatically identify, retrieve, consolidate and present scientific artefacts, based on a given query, has the potential to greatly facilitate collating related evidence and ultimately streamline medical decision-making. This thesis represents an attempt to define a comprehensive framework for acquiring and managing scientific artefacts in the EBM domain – by transforming unstructured publications into structured, consolidated, pertinent knowledge. There have been previous attempts to model such information (e.g., supporting and contradicting statements), however these approaches have primarily focused on providing users with conceptual high-level frameworks and associated manual annotation services. The approach proposed in this thesis employs novel, sets of low-level features to uniquely identify key scientific information in EBM, and enable knowledge extraction and retrieval. This will also lead to automatic creation of networks of scientific artefacts, and eventually the detection of effects across diverse artefacts (i.e., new potential drug treatments). This goal will be attained by firstly modelling and extracting scientific artefacts from publications (more specifically, abstracts) and then consolidating and linking them using Linked Data approaches. The first step for pinpointing the best evidence in the published research is to formulate clinical queries and their answers. Hence, a comprehensive and fine-grained model is essential to formulate key factors of evidence-based decision making according to various medical cases. The Problem/Population, Intervention, Comparison, and Outcome (PICO) framework is a specialised model to frame and answer a clinical or health care related question. An extension of PICO formalises this fundamental information by classifying it into six classes: Population, Intervention, Background, Outcome, Study Design, and Other (called the PIBOSO model). The PIBOSO model has been used as the underlying model throughout this thesis for defining the scientific artefacts in publications. Once modelled, the challenge then shifts towards automatically recognising such scientific artefacts within a published abstract and detecting similar occurrences across multiple abstracts. Machine Learning techniques have been widely applied in this context, especially since the recognition task can be formulated as a sentence classification task, and therefore can be addressed using classification techniques. This thesis presents a scientific artefact classifier that is trained on a novel set of discriminative features. The results indicate that this approach represents a marked improvement compared to the state of the art. In order to be able to find those related scientific artefacts (or evidence) extracted from a large number of published abstracts and then consolidate those that are conceptually similar, this thesis proposes an improved semantic similarity quantification approach. A unique set of similarity measures, which examines similarity of sentences from different syntactic, structural, and semantic features, is presented and then used to train an ensemble regressor. This ensemble can accurately predict the semantic similarity of both generic and domain-specific English sentences. The quantified similarities of scientific artefacts are then employed to consolidate and link those that are highly similar. The resulting Knowledge Base comprises a network of semantically related scientific artefacts, abstracts and publications. The holistic framework described in this thesis, has the potential to transform large corpuses of unstructured text into an enriched, consolidated and linked network of scientific artefacts. The resulting Knowledge Base (which will evolve, improve and expand over time) enables one to quickly gain a broad and deep understanding of the current state of evidence (PIBOSO scientific artefacts) related to a medical topic.
PY  - 2017
DA  - 2017-01-30
JO  - {'id': None, 'issn_l': None, 'issn': None, 'display_name': None, 'publisher': None, 'type': None, 'url': 'https://doi.org/10.14264/uql.2017.167', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Hamed Hassanzadeh
ER  - 

187.
TY  - nan
ID  - https://openalex.org/W2612407091
DO  - nan
TI  - Industrial and Manufacturing Systems Engineering Conference Proceedings and Posters Industrial and Manufacturing Systems Engineering
AB  - No Abstract Found
PY  - 2014
DA  - 2014-01-01
JO  - {'id': None, 'issn_l': None, 'issn': None, 'display_name': None, 'publisher': None, 'type': None, 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Kelly Kalvelage
AU  - Michael C. Dorneich
ER  - 

188.
TY  - journal-article
ID  - https://openalex.org/W2787252755
DO  - nan
TI  - A Knowledge-based System for Intelligent Support in Pharmacogenomics Evidence Assessment: Ontology-driven Evidence Representation and Retrieval.
AB  - Pharmacogenomics holds promise as a critical component of precision medicine. Yet, the use of pharmacogenomics in routine clinical care is minimal, partly due to the lack of efficient and effective use of existing evidence. This paper describes the design, development, implementation and evaluation of a knowledge-based system that fulfills three critical features: a) providing clinically relevant evidence, b) applying an evidence-based approach, and c) using semantically computable formalism, to facilitate efficient evidence assessment to support timely decisions on adoption of pharmacogenomics in clinical care. To illustrate functionality, the system was piloted in the context of clopidogrel and warfarin pharmacogenomics. In contrast to existing pharmacogenomics knowledge bases, the developed system is the first to exploit the expressivity and reasoning power of logic-based representation formalism to enable unambiguous expression and automatic retrieval of pharmacogenomics evidence to support systematic review with meta-analysis. research or previously synthesised evidence. Hence, devising mechanisms that can automatically identify, retrieve, consolidate and present scientific artefacts, based on a given query, has the potential to greatly facilitate collating related evidence and ultimately streamline medical decision-making. This thesis represents an attempt to define a comprehensive framework for acquiring and managing scientific artefacts in the EBM domain – by transforming unstructured publications into structured, consolidated, pertinent knowledge. There have been previous attempts to model such information (e.g., supporting and contradicting statements), however these approaches have primarily focused on providing users with conceptual high-level frameworks and associated manual annotation services. The approach proposed in this thesis employs novel, sets of low-level features to uniquely identify key scientific information in EBM, and enable knowledge extraction and retrieval. This will also lead to automatic creation of networks of scientific artefacts, and eventually the detection of effects across diverse artefacts (i.e., new potential drug treatments). This goal will be attained by firstly modelling and extracting scientific artefacts from publications (more specifically, abstracts) and then consolidating and linking them using Linked Data approaches. The first step for pinpointing the best evidence in the published research is to formulate clinical queries and their answers. Hence, a comprehensive and fine-grained model is essential to formulate key factors of evidence-based decision making according to various medical cases. The Problem/Population, Intervention, Comparison, and Outcome (PICO) framework is a specialised model to frame and answer a clinical or health care related question. An extension of PICO formalises this fundamental information by classifying it into six classes: Population, Intervention, Background, Outcome, Study Design, and Other (called the PIBOSO model). The PIBOSO model has been used as the underlying model throughout this thesis for defining the scientific artefacts in publications. Once modelled, the challenge then shifts towards automatically recognising such scientific artefacts within a published abstract and detecting similar occurrences across multiple abstracts. Machine Learning techniques have been widely applied in this context, especially since the recognition task can be formulated as a sentence classification task, and therefore can be addressed using classification techniques. This thesis presents a scientific artefact classifier that is trained on a novel set of discriminative features. The results indicate that this approach represents a marked improvement compared to the state of the art. In order to be able to find those related scientific artefacts (or evidence) extracted from a large number of published abstracts and then consolidate those that are conceptually similar, this thesis proposes an improved semantic similarity quantification approach. A unique set of similarity measures, which examines similarity of sentences from different syntactic, structural, and semantic features, is presented and then used to train an ensemble regressor. This ensemble can accurately predict the semantic similarity of both generic and domain-specific English sentences. The quantified similarities of scientific artefacts are then employed to consolidate and link those that are highly similar. The resulting Knowledge Base comprises a network of semantically related scientific artefacts, abstracts and publications. The holistic framework described in this thesis, has the potential to transform large corpuses of unstructured text into an enriched, consolidated and linked network of scientific artefacts. The resulting Knowledge Base (which will evolve, improve and expand over time) enables one to quickly gain a broad and deep understanding of the current state of evidence (PIBOSO scientific artefacts) related to a medical topic.
PY  - 2017
DA  - 2017-01-01
JO  - {'id': 'https://openalex.org/S4306501627', 'issn_l': '2153-4063', 'issn': ['2153-4063'], 'display_name': 'AMIA Joint Summits on Translational Science proceedings. AMIA Joint Summits on Translational Science', 'publisher': None, 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Chia-Ju Lee
AU  - Beth Devine
AU  - Peter Tarczy-Hornoch
ER  - 

189.
TY  - proceedings-article
ID  - https://openalex.org/W2807461675
DO  - https://doi.org/10.5281/zenodo.1173076
TI  - Automating Document Discovery in the Systematic Review Process: How to Use Chaff to Extract Wheat.
AB  - Systematic reviews in e.g. empirical medicine address research questions by comprehensively examining the entire published literature. Conventionally, manual literature surveys decide inclusion in two steps, first based on abstracts and title, then by full text, yet current
methods to automate the process make no distinction between gold data from these two stages. features: In this work we compare the impact different schemes for choosing positive and negative examples from the different screening stages have on the training of automated systems. of We train a ranker using logistic regression and evaluate it on a new gold standard dataset for clinical NLP, and on an existing gold standard dataset for drug class efficacy. The classification and ranking achieves an average AUC of 0.803 and 0.768 when relying on gold standard decisions based on title and abstracts of articles, and an AUC of 0.625 and 0.839 when relying on gold standard decisions based on full text. consolidate Our results suggest that it makes little difference which screening stage the gold standard decisions are drawn from, and that the decisions need not be based on the full text. The results further suggest that common-off-the-shelf algorithms can reduce the amount of work required to retrieve relevant literature. into structured, consolidated, pertinent knowledge. There have been previous attempts to model such information (e.g., supporting and contradicting statements), however these approaches have primarily focused on providing users with conceptual high-level frameworks and associated manual annotation services. The approach proposed in this thesis employs novel, sets of low-level features to uniquely identify key scientific information in EBM, and enable knowledge extraction and retrieval. This will also lead to automatic creation of networks of scientific artefacts, and eventually the detection of effects across diverse artefacts (i.e., new potential drug treatments). This goal will be attained by firstly modelling and extracting scientific artefacts from publications (more specifically, abstracts) and then consolidating and linking them using Linked Data approaches. The first step for pinpointing the best evidence in the published research is to formulate clinical queries and their answers. Hence, a comprehensive and fine-grained model is essential to formulate key factors of evidence-based decision making according to various medical cases. The Problem/Population, Intervention, Comparison, and Outcome (PICO) framework is a specialised model to frame and answer a clinical or health care related question. An extension of PICO formalises this fundamental information by classifying it into six classes: Population, Intervention, Background, Outcome, Study Design, and Other (called the PIBOSO model). The PIBOSO model has been used as the underlying model throughout this thesis for defining the scientific artefacts in publications. Once modelled, the challenge then shifts towards automatically recognising such scientific artefacts within a published abstract and detecting similar occurrences across multiple abstracts. Machine Learning techniques have been widely applied in this context, especially since the recognition task can be formulated as a sentence classification task, and therefore can be addressed using classification techniques. This thesis presents a scientific artefact classifier that is trained on a novel set of discriminative features. The results indicate that this approach represents a marked improvement compared to the state of the art. In order to be able to find those related scientific artefacts (or evidence) extracted from a large number of published abstracts and then consolidate those that are conceptually similar, this thesis proposes an improved semantic similarity quantification approach. A unique set of similarity measures, which examines similarity of sentences from different syntactic, structural, and semantic features, is presented and then used to train an ensemble regressor. This ensemble can accurately predict the semantic similarity of both generic and domain-specific English sentences. The quantified similarities of scientific artefacts are then employed to consolidate and link those that are highly similar. The resulting Knowledge Base comprises a network of semantically related scientific artefacts, abstracts and publications. The holistic framework described in this thesis, has the potential to transform large corpuses of unstructured text into an enriched, consolidated and linked network of scientific artefacts. The resulting Knowledge Base (which will evolve, improve and expand over time) enables one to quickly gain a broad and deep understanding of the current state of evidence (PIBOSO scientific artefacts) related to a medical topic.
PY  - 2018
DA  - 2018-05-01
JO  - {'id': 'https://openalex.org/S4306401953', 'issn_l': None, 'issn': None, 'display_name': 'HAL (Le Centre pour la Communication Scientifique Directe)', 'publisher': 'Le Centre pour la Communication Scientifique Directe', 'type': 'repository', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Christopher R. Norman
AU  - Mariska M.G. Leeflang
AU  - Pierre Zweigenbaum
AU  - Aurélie Névéol
ER  - 

190.
TY  - posted-content
ID  - https://openalex.org/W2896116428
DO  - https://doi.org/10.48550/arxiv.1706.00933
TI  - Evolution of statistical analysis in empirical software engineering
  research: Current state and steps forward
AB  - Software engineering research is evolving and papers are increasingly based on empirical data from a multitude of sources, using statistical tests to determine if and to what degree empirical evidence supports their hypotheses. To investigate the practices and trends of statistical analysis in empirical software engineering (ESE), this paper presents a review of a large pool of papers from top-ranked software engineering journals. First, we manually reviewed 161 papers and in the second phase of our method, we conducted a more extensive semi-automatic classification of papers spanning the years 2001--2015 and 5,196 papers. Results from both review steps was used to: i) identify and analyze the predominant practices in ESE (e.g., using t-test or ANOVA), as well as relevant trends in usage of specific statistical methods (e.g., nonparametric tests and effect size measures) and, ii) develop a conceptual model for a statistical analysis workflow with suggestions on how to apply different statistical methods as well as guidelines to avoid pitfalls. Lastly, we confirm existing claims that current ESE practices lack a standard to report practical significance of results. We illustrate how practical significance can be discussed in terms of both the statistical analysis and in the practitioner's context. retrieve relevant literature. into structured, consolidated, pertinent knowledge. There have been previous attempts to model such information (e.g., supporting and contradicting statements), however these approaches have primarily focused on providing users with conceptual high-level frameworks and associated manual annotation services. The approach proposed in this thesis employs novel, sets of low-level features to uniquely identify key scientific information in EBM, and enable knowledge extraction and retrieval. This will also lead to automatic creation of networks of scientific artefacts, and eventually the detection of effects across diverse artefacts (i.e., new potential drug treatments). This goal will be attained by firstly modelling and extracting scientific artefacts from publications (more specifically, abstracts) and then consolidating and linking them using Linked Data approaches. The first step for pinpointing the best evidence in the published research is to formulate clinical queries and their answers. Hence, a comprehensive and fine-grained model is essential to formulate key factors of evidence-based decision making according to various medical cases. The Problem/Population, Intervention, Comparison, and Outcome (PICO) framework is a specialised model to frame and answer a clinical or health care related question. An extension of PICO formalises this fundamental information by classifying it into six classes: Population, Intervention, Background, Outcome, Study Design, and Other (called the PIBOSO model). The PIBOSO model has been used as the underlying model throughout this thesis for defining the scientific artefacts in publications. Once modelled, the challenge then shifts towards automatically recognising such scientific artefacts within a published abstract and detecting similar occurrences across multiple abstracts. Machine Learning techniques have been widely applied in this context, especially since the recognition task can be formulated as a sentence classification task, and therefore can be addressed using classification techniques. This thesis presents a scientific artefact classifier that is trained on a novel set of discriminative features. The results indicate that this approach represents a marked improvement compared to the state of the art. In order to be able to find those related scientific artefacts (or evidence) extracted from a large number of published abstracts and then consolidate those that are conceptually similar, this thesis proposes an improved semantic similarity quantification approach. A unique set of similarity measures, which examines similarity of sentences from different syntactic, structural, and semantic features, is presented and then used to train an ensemble regressor. This ensemble can accurately predict the semantic similarity of both generic and domain-specific English sentences. The quantified similarities of scientific artefacts are then employed to consolidate and link those that are highly similar. The resulting Knowledge Base comprises a network of semantically related scientific artefacts, abstracts and publications. The holistic framework described in this thesis, has the potential to transform large corpuses of unstructured text into an enriched, consolidated and linked network of scientific artefacts. The resulting Knowledge Base (which will evolve, improve and expand over time) enables one to quickly gain a broad and deep understanding of the current state of evidence (PIBOSO scientific artefacts) related to a medical topic.
PY  - 2017
DA  - 2017-06-03
JO  - {'id': 'https://openalex.org/S4306400194', 'issn_l': None, 'issn': None, 'display_name': 'arXiv (Cornell University)', 'publisher': 'Cornell University', 'type': 'repository', 'url': 'http://arxiv.org/pdf/1706.00933', 'is_oa': True, 'version': 'submittedVersion', 'license': None}
DP  - OpenAlex
AU  - Francisco Gomes de Oliveira Neto
AU  - Richard Torkar
AU  - Robert Feldt
AU  - Lucas Gren
AU  - Carlo A. Furia
AU  - Ziwei Huang
ER  - 

191.
TY  - journal-article
ID  - https://openalex.org/W2964036488
DO  - https://doi.org/10.1136/bmjebm-2019-111206
TI  - Automatic extraction of quantitative data from ClinicalTrials.gov to conduct meta-analyses
AB  - Increasing the speed for completing a systematic review is needed to keep up to date with the literature. Could automatic data extraction from ClinicalTrials.gov provide an important step in speeding up the process of evidence synthesis? 

How can we conduct systematic reviews more quickly? An assessment of information in the PROSPERO registry (International prospective register of systematic reviews) to 2014, Borah et al 1 estimated the average time to carry out a systematic review to be over a year. This time frame has remained broadly unchanged in comparison with an estimate published 18 years earlier.2 Because of the speed with which some clinical disciplines generate new evidence, there is a danger that new systematic reviews become out of date within the time taken for them to be completed and published, and as a consequence their findings appear too slowly to influence practice.

Lifting data from electronic articles or data repositories automatically using computer software, rather than extracting it painstakingly by hand, has been gradually growing in popularity among systematic reviewers.3 The move to automation seems appealing and … of results. We illustrate how practical significance can be discussed in terms of both the statistical analysis and in the practitioner's context. retrieve relevant literature. into structured, consolidated, pertinent knowledge. There have been previous attempts to model such information (e.g., supporting and contradicting statements), however these approaches have primarily focused on providing users with conceptual high-level frameworks and associated manual annotation services. The approach proposed in this thesis employs novel, sets of low-level features to uniquely identify key scientific information in EBM, and enable knowledge extraction and retrieval. This will also lead to automatic creation of networks of scientific artefacts, and eventually the detection of effects across diverse artefacts (i.e., new potential drug treatments). This goal will be attained by firstly modelling and extracting scientific artefacts from publications (more specifically, abstracts) and then consolidating and linking them using Linked Data approaches. The first step for pinpointing the best evidence in the published research is to formulate clinical queries and their answers. Hence, a comprehensive and fine-grained model is essential to formulate key factors of evidence-based decision making according to various medical cases. The Problem/Population, Intervention, Comparison, and Outcome (PICO) framework is a specialised model to frame and answer a clinical or health care related question. An extension of PICO formalises this fundamental information by classifying it into six classes: Population, Intervention, Background, Outcome, Study Design, and Other (called the PIBOSO model). The PIBOSO model has been used as the underlying model throughout this thesis for defining the scientific artefacts in publications. Once modelled, the challenge then shifts towards automatically recognising such scientific artefacts within a published abstract and detecting similar occurrences across multiple abstracts. Machine Learning techniques have been widely applied in this context, especially since the recognition task can be formulated as a sentence classification task, and therefore can be addressed using classification techniques. This thesis presents a scientific artefact classifier that is trained on a novel set of discriminative features. The results indicate that this approach represents a marked improvement compared to the state of the art. In order to be able to find those related scientific artefacts (or evidence) extracted from a large number of published abstracts and then consolidate those that are conceptually similar, this thesis proposes an improved semantic similarity quantification approach. A unique set of similarity measures, which examines similarity of sentences from different syntactic, structural, and semantic features, is presented and then used to train an ensemble regressor. This ensemble can accurately predict the semantic similarity of both generic and domain-specific English sentences. The quantified similarities of scientific artefacts are then employed to consolidate and link those that are highly similar. The resulting Knowledge Base comprises a network of semantically related scientific artefacts, abstracts and publications. The holistic framework described in this thesis, has the potential to transform large corpuses of unstructured text into an enriched, consolidated and linked network of scientific artefacts. The resulting Knowledge Base (which will evolve, improve and expand over time) enables one to quickly gain a broad and deep understanding of the current state of evidence (PIBOSO scientific artefacts) related to a medical topic.
PY  - 2020
DA  - 2020-06-01
JO  - {'id': 'https://openalex.org/S4210227606', 'issn_l': '2515-446X', 'issn': ['2515-446X', '2515-4478'], 'display_name': 'BMJ evidence-based medicine', 'publisher': 'BMJ', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Thomas R. Fanshawe
AU  - Rafael Perera
ER  - 

192.
TY  - dissertation
ID  - https://openalex.org/W2981319994
DO  - nan
TI  - Understanding in vivo modelling of depression
AB  - No Abstract Found
PY  - 2019
DA  - 2019-11-25
JO  - {'id': None, 'issn_l': None, 'issn': None, 'display_name': None, 'publisher': None, 'type': None, 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Alexandra Bannach-Brown
ER  - 

193.
TY  - book-chapter
ID  - https://openalex.org/W2986030491
DO  - https://doi.org/10.1007/978-3-030-34980-6_25
TI  - Towards an Aspect-Based Ranking Model for Clinical Trial Search
AB  - Clinical Trials are crucial for the practice of evidence-based medicine. It provides updated and essential health-related information for the patients. Sometimes, Clinical trials are the first source of information about new drugs and treatments. Different stakeholders, such as trial volunteers, trial investigators, and meta-analyses researchers often need to search for trials. In this paper, we propose an automated method to retrieve relevant trials based on the overlap of UMLS concepts between the user query and clinical trials. However, different stakeholders may have different information needs, and accordingly, we rank the retrieved clinical trials based on the following four aspects – Relevancy, Adversity, Recency, and Popularity. We aim to develop a clinical trial search system which covers multiple disease classes, instead of only focusing on retrieval of oncology-based clinical trials. We follow a rigorous annotation scheme and create an annotated retrieval set for 25 queries, across five disease categories. Our proposed method performs better than the baseline model in almost \(90\%\) cases. We also measure the correlation between the different aspect-based ranking lists and observe a high negative Spearman rank’s correlation coefficient between popularity and recency. discussed in terms of both the statistical analysis and in the practitioner's context. retrieve relevant literature. into structured, consolidated, pertinent knowledge. There have been previous attempts to model such information (e.g., supporting and contradicting statements), however these approaches have primarily focused on providing users with conceptual high-level frameworks and associated manual annotation services. The approach proposed in this thesis employs novel, sets of low-level features to uniquely identify key scientific information in EBM, and enable knowledge extraction and retrieval. This will also lead to automatic creation of networks of scientific artefacts, and eventually the detection of effects across diverse artefacts (i.e., new potential drug treatments). This goal will be attained by firstly modelling and extracting scientific artefacts from publications (more specifically, abstracts) and then consolidating and linking them using Linked Data approaches. The first step for pinpointing the best evidence in the published research is to formulate clinical queries and their answers. Hence, a comprehensive and fine-grained model is essential to formulate key factors of evidence-based decision making according to various medical cases. The Problem/Population, Intervention, Comparison, and Outcome (PICO) framework is a specialised model to frame and answer a clinical or health care related question. An extension of PICO formalises this fundamental information by classifying it into six classes: Population, Intervention, Background, Outcome, Study Design, and Other (called the PIBOSO model). The PIBOSO model has been used as the underlying model throughout this thesis for defining the scientific artefacts in publications. Once modelled, the challenge then shifts towards automatically recognising such scientific artefacts within a published abstract and detecting similar occurrences across multiple abstracts. Machine Learning techniques have been widely applied in this context, especially since the recognition task can be formulated as a sentence classification task, and therefore can be addressed using classification techniques. This thesis presents a scientific artefact classifier that is trained on a novel set of discriminative features. The results indicate that this approach represents a marked improvement compared to the state of the art. In order to be able to find those related scientific artefacts (or evidence) extracted from a large number of published abstracts and then consolidate those that are conceptually similar, this thesis proposes an improved semantic similarity quantification approach. A unique set of similarity measures, which examines similarity of sentences from different syntactic, structural, and semantic features, is presented and then used to train an ensemble regressor. This ensemble can accurately predict the semantic similarity of both generic and domain-specific English sentences. The quantified similarities of scientific artefacts are then employed to consolidate and link those that are highly similar. The resulting Knowledge Base comprises a network of semantically related scientific artefacts, abstracts and publications. The holistic framework described in this thesis, has the potential to transform large corpuses of unstructured text into an enriched, consolidated and linked network of scientific artefacts. The resulting Knowledge Base (which will evolve, improve and expand over time) enables one to quickly gain a broad and deep understanding of the current state of evidence (PIBOSO scientific artefacts) related to a medical topic.
PY  - 2019
DA  - 2019-11-18
JO  - {'id': 'https://openalex.org/S106296714', 'issn_l': '0302-9743', 'issn': ['1611-3349', '0302-9743'], 'display_name': 'Lecture Notes in Computer Science', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Soumyadeep Roy
AU  - Koustav Rudra
AU  - Nikhil Agrawal
AU  - Shamik Sural
AU  - Niloy Ganguly
ER  - 

194.
TY  - dissertation
ID  - https://openalex.org/W3000960569
DO  - nan
TI  - Simplifying, reading, and machine translating health content: an empirical investigation of usability
AB  - Text simplification, through plain language (PL) or controlled language (CL), is adopted to increase readability, comprehension and machine translatability of (health) content. Cochrane is a non-profit organisation where volunteer authors summarise and simplify health-related English texts on the impact of treatments and interventions into plain language summaries (PLS), which are then disseminated online to the lay audience and translated. Cochrane’s simplification approach is non-automated, and involves the manual checking and implementation of different sets of PL guidelines, which can be an unsatisfactory, challenging and time-consuming task.
This thesis examined if using the Acrolinx CL checker to automatically and consistently check PLS for readability and translatability issues would increase the usability of Cochrane’s simplification approach and, more precisely: (i) authors’ satisfaction; and (ii) authors’ effectiveness in terms of readability, comprehensibility, and machine translatability into Spanish.
Data on satisfaction were collected from twelve Cochrane authors by means of the System Usability Scale and follow-up preference questions. Readability was analysed through the computational tool Coh-Metrix. Evidence on comprehensibility was gathered through ratings and recall protocols produced by lay readers, both native and non-native speakers of English. Machine translatability was assessed in terms of adequacy and fluency with forty-one Cochrane contributors, all native speakers of Spanish.
Authors seemed to welcome the introduction of Acrolinx, and the adoption of this CL checker reduced word length, sentence length, and syntactic complexity. No significant impact on comprehensibility and machine translatability was identified. We observed that reading skills and characteristics other than simplified language (e.g. formatting) might influence comprehension. Machine translation quality was relatively high, with mainly style issues.
This thesis presented an environment that could boost volunteer authors’ satisfaction and foster their adoption of simple language. We also discussed strategies to increase the accessibility of online health content among lay readers with different skills and language backgrounds. firstly modelling and extracting scientific artefacts from publications (more specifically, abstracts) and then consolidating and linking them using Linked Data approaches. The first step for pinpointing the best evidence in the published research is to formulate clinical queries and their answers. Hence, a comprehensive and fine-grained model is essential to formulate key factors of evidence-based decision making according to various medical cases. The Problem/Population, Intervention, Comparison, and Outcome (PICO) framework is a specialised model to frame and answer a clinical or health care related question. An extension of PICO formalises this fundamental information by classifying it into six classes: Population, Intervention, Background, Outcome, Study Design, and Other (called the PIBOSO model). The PIBOSO model has been used as the underlying model throughout this thesis for defining the scientific artefacts in publications. Once modelled, the challenge then shifts towards automatically recognising such scientific artefacts within a published abstract and detecting similar occurrences across multiple abstracts. Machine Learning techniques have been widely applied in this context, especially since the recognition task can be formulated as a sentence classification task, and therefore can be addressed using classification techniques. This thesis presents a scientific artefact classifier that is trained on a novel set of discriminative features. The results indicate that this approach represents a marked improvement compared to the state of the art. In order to be able to find those related scientific artefacts (or evidence) extracted from a large number of published abstracts and then consolidate those that are conceptually similar, this thesis proposes an improved semantic similarity quantification approach. A unique set of similarity measures, which examines similarity of sentences from different syntactic, structural, and semantic features, is presented and then used to train an ensemble regressor. This ensemble can accurately predict the semantic similarity of both generic and domain-specific English sentences. The quantified similarities of scientific artefacts are then employed to consolidate and link those that are highly similar. The resulting Knowledge Base comprises a network of semantically related scientific artefacts, abstracts and publications. The holistic framework described in this thesis, has the potential to transform large corpuses of unstructured text into an enriched, consolidated and linked network of scientific artefacts. The resulting Knowledge Base (which will evolve, improve and expand over time) enables one to quickly gain a broad and deep understanding of the current state of evidence (PIBOSO scientific artefacts) related to a medical topic.
PY  - 2019
DA  - 2019-11-01
JO  - {'id': None, 'issn_l': None, 'issn': None, 'display_name': 'Rossetti, Alessandra ORCID: 0000-0002-2162-9639 <https://orcid.org/0000-0002-2162-9639>  (2019) Simplifying, reading, and machine translating health content: an empirical investigation of usability.  PhD thesis, Dublin City University.', 'publisher': None, 'type': None, 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Alessandra Rossetti
ER  - 

195.
TY  - posted-content
ID  - https://openalex.org/W3021651687
DO  - https://doi.org/10.1101/2020.04.28.20083378
TI  - Ocular toxicity and Hydroxychloroquine: A Rapid Meta-Analysis
AB  - Abstract Rapid access to evidence is crucial in times of evolving clinical crisis. To that end, we propose a novel mechanism to answer clinical queries: Rapid Meta-Analysis (RMA). Unlike traditional meta-analysis, RMA balances quick time-to-production with reasonable data quality assurances, leveraging Artificial Intelligence to strike this balance. This article presents an example RMA to a currently relevant clinical question: Is ocular toxicity and vision compromise a side effect with hydroxychloroquine therapy? As of this writing, hydroxychloroquine is a leading candidate in the treatment of COVID-19. By combining AI with human analysis, our RMA identified 11 studies looking at ocular toxicity as a side effect and estimated the incidence to be 3.4% (95% CI: 1.11-9.96%). The heterogeneity across the individual study findings was high, and interpretation of the result should take this into account. Importantly, this RMA, from search to screen to analysis, took less than 30 minutes to produce. follow-up preference questions. Readability was analysed through the computational tool Coh-Metrix. Evidence on comprehensibility was gathered through ratings and recall protocols produced by lay readers, both native and non-native speakers of English. Machine translatability was assessed in terms of adequacy and fluency with forty-one Cochrane contributors, all native speakers of Spanish.
Authors seemed to welcome the introduction of Acrolinx, and the adoption of this CL checker reduced word length, sentence length, and syntactic complexity. No significant impact on comprehensibility and machine translatability was identified. We observed that reading skills and characteristics other than simplified language (e.g. formatting) might influence comprehension. Machine translation quality was relatively high, with mainly style issues.
This thesis presented an environment that could boost volunteer authors’ satisfaction and foster their adoption of simple language. We also discussed strategies to increase the accessibility of online health content among lay readers with different skills and language backgrounds. firstly modelling and extracting scientific artefacts from publications (more specifically, abstracts) and then consolidating and linking them using Linked Data approaches. The first step for pinpointing the best evidence in the published research is to formulate clinical queries and their answers. Hence, a comprehensive and fine-grained model is essential to formulate key factors of evidence-based decision making according to various medical cases. The Problem/Population, Intervention, Comparison, and Outcome (PICO) framework is a specialised model to frame and answer a clinical or health care related question. An extension of PICO formalises this fundamental information by classifying it into six classes: Population, Intervention, Background, Outcome, Study Design, and Other (called the PIBOSO model). The PIBOSO model has been used as the underlying model throughout this thesis for defining the scientific artefacts in publications. Once modelled, the challenge then shifts towards automatically recognising such scientific artefacts within a published abstract and detecting similar occurrences across multiple abstracts. Machine Learning techniques have been widely applied in this context, especially since the recognition task can be formulated as a sentence classification task, and therefore can be addressed using classification techniques. This thesis presents a scientific artefact classifier that is trained on a novel set of discriminative features. The results indicate that this approach represents a marked improvement compared to the state of the art. In order to be able to find those related scientific artefacts (or evidence) extracted from a large number of published abstracts and then consolidate those that are conceptually similar, this thesis proposes an improved semantic similarity quantification approach. A unique set of similarity measures, which examines similarity of sentences from different syntactic, structural, and semantic features, is presented and then used to train an ensemble regressor. This ensemble can accurately predict the semantic similarity of both generic and domain-specific English sentences. The quantified similarities of scientific artefacts are then employed to consolidate and link those that are highly similar. The resulting Knowledge Base comprises a network of semantically related scientific artefacts, abstracts and publications. The holistic framework described in this thesis, has the potential to transform large corpuses of unstructured text into an enriched, consolidated and linked network of scientific artefacts. The resulting Knowledge Base (which will evolve, improve and expand over time) enables one to quickly gain a broad and deep understanding of the current state of evidence (PIBOSO scientific artefacts) related to a medical topic.
PY  - 2020
DA  - 2020-05-03
JO  - {'id': 'https://openalex.org/S3005729997', 'issn_l': None, 'issn': None, 'display_name': 'medRxiv', 'publisher': 'Cold Spring Harbor Laboratory Press', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Matthew Michelson
AU  - Tiffany W. Chow
AU  - Neil A. Martin
AU  - M. Ross
AU  - Abi Tee
AU  - Steven Minton
ER  - 

196.
TY  - proceedings-article
ID  - https://openalex.org/W3081749182
DO  - https://doi.org/10.1109/icabcd49160.2020.9183816
TI  - Identifying Recent Telemedicine Research Trends Using a Natural Language Processing Approach
AB  - Conventional literature review processes undertaken by human experts require considerable effort. Automating them is elusive due to subtlety of concepts and complexity of interrelationships implicit in text semantics. However, when assessing topics relating to current trends, these factors are less important as there is inherent breadth and diversity in the text which countermands the need for expertise. This paper presents an approach for trend topic analysis using simple bibliometrics of Term Frequency and Keyword Selection, extracted with natural language processing tools NLTK and AntConc. This approach is applied to a case study of identifying trends in Telemedicine research in South Africa based on 2019 publications included in PubMed. Lists of topics generated by the analysis methods show consistency in identified trends and suggest their suitability to categorise small focussed corpora. this into account. Importantly, this RMA, from search to screen to analysis, took less than 30 minutes to produce. follow-up preference questions. Readability was analysed through the computational tool Coh-Metrix. Evidence on comprehensibility was gathered through ratings and recall protocols produced by lay readers, both native and non-native speakers of English. Machine translatability was assessed in terms of adequacy and fluency with forty-one Cochrane contributors, all native speakers of Spanish.
Authors seemed to welcome the introduction of Acrolinx, and the adoption of this CL checker reduced word length, sentence length, and syntactic complexity. No significant impact on comprehensibility and machine translatability was identified. We observed that reading skills and characteristics other than simplified language (e.g. formatting) might influence comprehension. Machine translation quality was relatively high, with mainly style issues.
This thesis presented an environment that could boost volunteer authors’ satisfaction and foster their adoption of simple language. We also discussed strategies to increase the accessibility of online health content among lay readers with different skills and language backgrounds. firstly modelling and extracting scientific artefacts from publications (more specifically, abstracts) and then consolidating and linking them using Linked Data approaches. The first step for pinpointing the best evidence in the published research is to formulate clinical queries and their answers. Hence, a comprehensive and fine-grained model is essential to formulate key factors of evidence-based decision making according to various medical cases. The Problem/Population, Intervention, Comparison, and Outcome (PICO) framework is a specialised model to frame and answer a clinical or health care related question. An extension of PICO formalises this fundamental information by classifying it into six classes: Population, Intervention, Background, Outcome, Study Design, and Other (called the PIBOSO model). The PIBOSO model has been used as the underlying model throughout this thesis for defining the scientific artefacts in publications. Once modelled, the challenge then shifts towards automatically recognising such scientific artefacts within a published abstract and detecting similar occurrences across multiple abstracts. Machine Learning techniques have been widely applied in this context, especially since the recognition task can be formulated as a sentence classification task, and therefore can be addressed using classification techniques. This thesis presents a scientific artefact classifier that is trained on a novel set of discriminative features. The results indicate that this approach represents a marked improvement compared to the state of the art. In order to be able to find those related scientific artefacts (or evidence) extracted from a large number of published abstracts and then consolidate those that are conceptually similar, this thesis proposes an improved semantic similarity quantification approach. A unique set of similarity measures, which examines similarity of sentences from different syntactic, structural, and semantic features, is presented and then used to train an ensemble regressor. This ensemble can accurately predict the semantic similarity of both generic and domain-specific English sentences. The quantified similarities of scientific artefacts are then employed to consolidate and link those that are highly similar. The resulting Knowledge Base comprises a network of semantically related scientific artefacts, abstracts and publications. The holistic framework described in this thesis, has the potential to transform large corpuses of unstructured text into an enriched, consolidated and linked network of scientific artefacts. The resulting Knowledge Base (which will evolve, improve and expand over time) enables one to quickly gain a broad and deep understanding of the current state of evidence (PIBOSO scientific artefacts) related to a medical topic.
PY  - 2020
DA  - 2020-08-01
JO  - {'id': 'https://openalex.org/S4306419142', 'issn_l': None, 'issn': None, 'display_name': 'International Conference on Artificial Intelligence', 'publisher': None, 'type': 'conference', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Anthony Maeder
AU  - Martyn George
AU  - Bertha Naveda
ER  - 

197.
TY  - posted-content
ID  - https://openalex.org/W3089842510
DO  - nan
TI  - Retrieving and mining professional experience of software practice from grey literature: an exploratory review
AB  - Background: Retrieving and mining practitioners' self--reports of their professional experience of software practice could provide valuable evidence for research. We are, however, unaware of any existing reviews of research conducted in this area. Objective: To review and classify previous research, and to identify insights into the challenges research confronts when retrieving and mining practitioners' self-reports of their experience of software practice. Method: We conduct an exploratory review to identify and classify 42 articles. We analyse a selection of those articles for insights on challenges to mining professional experience. Results: We identify only one directly relevant article. Even then this article concerns the software professional's emotional experiences rather than the professional's reporting of behaviour and events occurring during software practice. We discuss challenges concerning: the prevalence of professional experience; definitions, models and theories; the sparseness of data; units of discourse analysis; annotator agreement; evaluation of the performance of algorithms; and the lack of replications. Conclusion: No directly relevant prior research appears to have been conducted in this area. We discuss the value of reporting negative results in secondary studies. There are a range of research opportunities but also considerable challenges. We formulate a set of guiding questions for further research in this area. welcome the introduction of Acrolinx, and the adoption of this CL checker reduced word length, sentence length, and syntactic complexity. No significant impact on comprehensibility and machine translatability was identified. We observed that reading skills and characteristics other than simplified language (e.g. formatting) might influence comprehension. Machine translation quality was relatively high, with mainly style issues.
This thesis presented an environment that could boost volunteer authors’ satisfaction and foster their adoption of simple language. We also discussed strategies to increase the accessibility of online health content among lay readers with different skills and language backgrounds. firstly modelling and extracting scientific artefacts from publications (more specifically, abstracts) and then consolidating and linking them using Linked Data approaches. The first step for pinpointing the best evidence in the published research is to formulate clinical queries and their answers. Hence, a comprehensive and fine-grained model is essential to formulate key factors of evidence-based decision making according to various medical cases. The Problem/Population, Intervention, Comparison, and Outcome (PICO) framework is a specialised model to frame and answer a clinical or health care related question. An extension of PICO formalises this fundamental information by classifying it into six classes: Population, Intervention, Background, Outcome, Study Design, and Other (called the PIBOSO model). The PIBOSO model has been used as the underlying model throughout this thesis for defining the scientific artefacts in publications. Once modelled, the challenge then shifts towards automatically recognising such scientific artefacts within a published abstract and detecting similar occurrences across multiple abstracts. Machine Learning techniques have been widely applied in this context, especially since the recognition task can be formulated as a sentence classification task, and therefore can be addressed using classification techniques. This thesis presents a scientific artefact classifier that is trained on a novel set of discriminative features. The results indicate that this approach represents a marked improvement compared to the state of the art. In order to be able to find those related scientific artefacts (or evidence) extracted from a large number of published abstracts and then consolidate those that are conceptually similar, this thesis proposes an improved semantic similarity quantification approach. A unique set of similarity measures, which examines similarity of sentences from different syntactic, structural, and semantic features, is presented and then used to train an ensemble regressor. This ensemble can accurately predict the semantic similarity of both generic and domain-specific English sentences. The quantified similarities of scientific artefacts are then employed to consolidate and link those that are highly similar. The resulting Knowledge Base comprises a network of semantically related scientific artefacts, abstracts and publications. The holistic framework described in this thesis, has the potential to transform large corpuses of unstructured text into an enriched, consolidated and linked network of scientific artefacts. The resulting Knowledge Base (which will evolve, improve and expand over time) enables one to quickly gain a broad and deep understanding of the current state of evidence (PIBOSO scientific artefacts) related to a medical topic.
PY  - 2020
DA  - 2020-09-30
JO  - {'id': 'https://openalex.org/S2595428313', 'issn_l': None, 'issn': None, 'display_name': 'arXiv: Software Engineering', 'publisher': None, 'type': 'journal', 'url': 'https://arxiv.org/pdf/2009.14740.pdf', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Austen Rainer
AU  - Ashley J. Williams
AU  - Vahid Garousi
AU  - Michael Felderer
ER  - 

198.
TY  - journal-article
ID  - https://openalex.org/W3114011205
DO  - https://doi.org/10.1002/jrsm.1473
TI  - A rule‐based approach for automatically extracting data from systematic reviews and their updates to model the risk of conclusion change
AB  - Few data-driven approaches are available to estimate the risk of conclusion change in systematic review updates. We developed a rule-based approach to automatically extract information from reviews and updates to be used as features for modelling conclusion change risk. Rules were developed to extract relevant information from published Cochrane reviews and used to construct four features: the number of included trials and participants in the reviews, a measure based on the number of participants, and the time elapsed between the search dates. We compared the performance of random forest, decision tree, and logistic regression to predict the conclusion change risk. The performance was measured by accuracy, precision, recall, F1 -score, and area under ROC (AU-ROC). One rule was developed to extract the conclusion change information (96% accuracy, 100 reviews), one for the search date (100% accuracy, 100 reviews), one for the number of included clinical trials (100% accuracy, 100 reviews), and 22 for the number of participants (97.3% accuracy, 200 reviews). For unseen reviews, the random forest classifier showed the highest accuracy (80.8%) and AU-ROC (0.80). All classifiers showed relatively similar performance with overlapping 95% confidence interval (CI). The coverage score was shown to be the most useful feature for predicting the conclusion change risk. Features mined from Cochrane reviews and updates can estimate conclusion change risk. If data from more published reviews and updates were made accessible, data-driven methods to predict the conclusion change risk may be a feasible way to support decisions about updating reviews. comprehension. Machine translation quality was relatively high, with mainly style issues.
This thesis presented an environment that could boost volunteer authors’ satisfaction and foster their adoption of simple language. We also discussed strategies to increase the accessibility of online health content among lay readers with different skills and language backgrounds. firstly modelling and extracting scientific artefacts from publications (more specifically, abstracts) and then consolidating and linking them using Linked Data approaches. The first step for pinpointing the best evidence in the published research is to formulate clinical queries and their answers. Hence, a comprehensive and fine-grained model is essential to formulate key factors of evidence-based decision making according to various medical cases. The Problem/Population, Intervention, Comparison, and Outcome (PICO) framework is a specialised model to frame and answer a clinical or health care related question. An extension of PICO formalises this fundamental information by classifying it into six classes: Population, Intervention, Background, Outcome, Study Design, and Other (called the PIBOSO model). The PIBOSO model has been used as the underlying model throughout this thesis for defining the scientific artefacts in publications. Once modelled, the challenge then shifts towards automatically recognising such scientific artefacts within a published abstract and detecting similar occurrences across multiple abstracts. Machine Learning techniques have been widely applied in this context, especially since the recognition task can be formulated as a sentence classification task, and therefore can be addressed using classification techniques. This thesis presents a scientific artefact classifier that is trained on a novel set of discriminative features. The results indicate that this approach represents a marked improvement compared to the state of the art. In order to be able to find those related scientific artefacts (or evidence) extracted from a large number of published abstracts and then consolidate those that are conceptually similar, this thesis proposes an improved semantic similarity quantification approach. A unique set of similarity measures, which examines similarity of sentences from different syntactic, structural, and semantic features, is presented and then used to train an ensemble regressor. This ensemble can accurately predict the semantic similarity of both generic and domain-specific English sentences. The quantified similarities of scientific artefacts are then employed to consolidate and link those that are highly similar. The resulting Knowledge Base comprises a network of semantically related scientific artefacts, abstracts and publications. The holistic framework described in this thesis, has the potential to transform large corpuses of unstructured text into an enriched, consolidated and linked network of scientific artefacts. The resulting Knowledge Base (which will evolve, improve and expand over time) enables one to quickly gain a broad and deep understanding of the current state of evidence (PIBOSO scientific artefacts) related to a medical topic.
PY  - 2021
DA  - 2021-01-04
JO  - {'id': 'https://openalex.org/V205768342', 'issn_l': '1759-2879', 'issn': ['1759-2879', '1759-2887'], 'display_name': 'Research Synthesis Methods', 'publisher': 'Wiley-Blackwell', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Rabia Bashir
AU  - Adam G. Dunn
AU  - Didi Surian
ER  - 

199.
TY  - proceedings-article
ID  - https://openalex.org/W3121323882
DO  - https://doi.org/10.24251/hicss.2021.095
TI  - Automated topic analysis for restricted scope health corpora: methodology and comparison with human performance
AB  - This paper addresses the problem of identifying topics which describe information content, in restricted size sets of scientific papers extracted from publication databases. Conventional computational approaches, based on natural language processing using unsupervised classification algorithms, typically require large numbers of papers to achieve adequate training. The approach presented here uses a simpler word-frequency-based approach coupled with context modeling. An example is provided of its application to corpora resulting from a curated literature search site for COVID-19 research publications. The results are compared with a conventional human-based approach, indicating partial overlap in the topics identified. The findings suggest that computational approaches may provide an alternative to human expert topic analysis, provided adequate contextual models are available. © 2021 IEEE Computer Society. All rights reserved. change information (96% accuracy, 100 reviews), one for the search date (100% accuracy, 100 reviews), one for the number of included clinical trials (100% accuracy, 100 reviews), and 22 for the number of participants (97.3% accuracy, 200 reviews). For unseen reviews, the random forest classifier showed the highest accuracy (80.8%) and AU-ROC (0.80). All classifiers showed relatively similar performance with overlapping 95% confidence interval (CI). The coverage score was shown to be the most useful feature for predicting the conclusion change risk. Features mined from Cochrane reviews and updates can estimate conclusion change risk. If data from more published reviews and updates were made accessible, data-driven methods to predict the conclusion change risk may be a feasible way to support decisions about updating reviews. comprehension. Machine translation quality was relatively high, with mainly style issues.
This thesis presented an environment that could boost volunteer authors’ satisfaction and foster their adoption of simple language. We also discussed strategies to increase the accessibility of online health content among lay readers with different skills and language backgrounds. firstly modelling and extracting scientific artefacts from publications (more specifically, abstracts) and then consolidating and linking them using Linked Data approaches. The first step for pinpointing the best evidence in the published research is to formulate clinical queries and their answers. Hence, a comprehensive and fine-grained model is essential to formulate key factors of evidence-based decision making according to various medical cases. The Problem/Population, Intervention, Comparison, and Outcome (PICO) framework is a specialised model to frame and answer a clinical or health care related question. An extension of PICO formalises this fundamental information by classifying it into six classes: Population, Intervention, Background, Outcome, Study Design, and Other (called the PIBOSO model). The PIBOSO model has been used as the underlying model throughout this thesis for defining the scientific artefacts in publications. Once modelled, the challenge then shifts towards automatically recognising such scientific artefacts within a published abstract and detecting similar occurrences across multiple abstracts. Machine Learning techniques have been widely applied in this context, especially since the recognition task can be formulated as a sentence classification task, and therefore can be addressed using classification techniques. This thesis presents a scientific artefact classifier that is trained on a novel set of discriminative features. The results indicate that this approach represents a marked improvement compared to the state of the art. In order to be able to find those related scientific artefacts (or evidence) extracted from a large number of published abstracts and then consolidate those that are conceptually similar, this thesis proposes an improved semantic similarity quantification approach. A unique set of similarity measures, which examines similarity of sentences from different syntactic, structural, and semantic features, is presented and then used to train an ensemble regressor. This ensemble can accurately predict the semantic similarity of both generic and domain-specific English sentences. The quantified similarities of scientific artefacts are then employed to consolidate and link those that are highly similar. The resulting Knowledge Base comprises a network of semantically related scientific artefacts, abstracts and publications. The holistic framework described in this thesis, has the potential to transform large corpuses of unstructured text into an enriched, consolidated and linked network of scientific artefacts. The resulting Knowledge Base (which will evolve, improve and expand over time) enables one to quickly gain a broad and deep understanding of the current state of evidence (PIBOSO scientific artefacts) related to a medical topic.
PY  - 2021
DA  - 2021-01-05
JO  - {'id': 'https://openalex.org/S4306418516', 'issn_l': None, 'issn': None, 'display_name': 'Hawaii International Conference on System Sciences', 'publisher': None, 'type': 'conference', 'url': 'http://scholarspace.manoa.hawaii.edu/bitstream/10125/70706/1/0077.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc-nd'}
DP  - OpenAlex
AU  - Anthony Maeder
AU  - Jennifer Tieman
AU  - Bertha Naveda
AU  - Stephanie Champion
AU  - Tamara Agnew
ER  - 

200.
TY  - book-chapter
ID  - https://openalex.org/W3185932187
DO  - https://doi.org/10.1007/978-3-030-71881-7_12
TI  - Machine Learning in Evidence Synthesis Research
AB  - No Abstract Found
PY  - 2021
DA  - 2021-01-01
JO  - {'id': 'https://openalex.org/V4306463941', 'issn_l': None, 'issn': None, 'display_name': 'Springer International Publishing eBooks', 'publisher': 'Springer Nature', 'type': 'ebook platform', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Alonso Carrasco-Labra
AU  - Olivia Urquhart
AU  - Heiko Spallek
ER  - 

201.
TY  - dissertation
ID  - https://openalex.org/W3185975465
DO  - nan
TI  - Study-based registers of randomised controlled trials: the premise and increasing sophistication of data supply for evidence synthesis
AB  - No Abstract Found
PY  - 2020
DA  - 2020-07-24
JO  - {'id': None, 'issn_l': None, 'issn': None, 'display_name': None, 'publisher': None, 'type': None, 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Farhad Shokraneh
ER  - 

202.
TY  - book-chapter
ID  - https://openalex.org/W3190720226
DO  - https://doi.org/10.1007/978-3-030-58080-3_43-1
TI  - Artificial Intelligence in Evidence-Based Medicine
AB  - No Abstract Found
PY  - 2021
DA  - 2021-01-01
JO  - {'id': 'https://openalex.org/S4306463941', 'issn_l': None, 'issn': None, 'display_name': 'Springer International Publishing eBooks', 'publisher': 'Springer Nature', 'type': 'ebook platform', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Artur Nowak
ER  - 

203.
TY  - journal-article
ID  - https://openalex.org/W3191919399
DO  - https://doi.org/10.20535/2410-8286.227831
TI  - STRATEGIES FOR ORGANISING AND MANAGING RESEARCH AT UNIVERSITIES: SYSTEMIC REVIEW
AB  - The purpose of the study was to identify and synthesise the interventions used to build the strategies for organising and managing research at universities that can be feasible in Ukraine. To achieve this purpose we provided a descriptive profile of the interventions and strategies used at universities to organise and manage research, rather than the detailed examination of substantive research results. The method of descriptive content analysis was applied to analyse empirical, experimental, review, conceptual, and commentary sources revealing strategies of organising and managing research at universities. The growth and corporate type strategies are dominant at universities, particularly in the USA and EU. The universities mainly seek cost-effective research opportunities that can help the institutions build a strong international brand. The policy of institutional strategic research management aimed at cooperation in research with other sectors seems to be the most feasible and appropriate for the Ukrainian research management context. Creating project management communities was found to be the second most feasible and appropriate strategy of organising and managing the university research in Ukraine. Financial criterion dominates in assessing the interventions for building a strategy of organising and managing research at universities. The university research can be stimulated at the state level through a demand-oriented reform that is aimed at reshaping the management of personnel, talent selection system, and personnel assessment.
PY  - 2021
DA  - 2021-07-31
JO  - {'id': 'https://openalex.org/V2764974745', 'issn_l': '2409-3351', 'issn': ['2409-3351', '2410-8286'], 'display_name': 'Advanced Education', 'publisher': 'The Center of Educational Literature, LTD', 'type': 'journal', 'url': 'http://ae.fl.kpi.ua/article/download/227831/236745', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Катерина Іванівна Шихненко
AU  - Alina Anatoliivna Sbruieva
ER  - 

204.
TY  - proceedings-article
ID  - https://openalex.org/W3198005027
DO  - https://doi.org/10.18653/v1/2021.findings-emnlp.147
TI  - Sent2Span: Span Detection for PICO Extraction in the Biomedical Text without Span Annotations
AB  - The rapid growth in published clinical trials makes it difficult to maintain up-to-date systematic reviews, which requires finding all relevant trials. This leads to policy and practice decisions based on out-of-date, incomplete, and biased subsets of available clinical evidence. Extracting and then normalising Population, Intervention, Comparator, and Outcome (PICO) information from clinical trial articles may be an effective way to automatically assign trials to systematic reviews and avoid searching and screening - the two most time-consuming systematic review processes. We propose and test a novel approach to PICO span detection. The major difference between our proposed method and previous approaches comes from detecting spans without needing annotated span data and using only crowdsourced sentence-level annotations. Experiments on two datasets show that PICO span detection results achieve much higher results for recall when compared to fully supervised methods with PICO sentence detection at least as good as human annotations. By removing the reliance on expert annotations for span detection, this work could be used in human-machine pipeline for turning low-quality crowdsourced, and sentence-level PICO annotations into structured information that can be used to quickly assign trials to relevant systematic reviews. at universities. The university research can be stimulated at the state level through a demand-oriented reform that is aimed at reshaping the management of personnel, talent selection system, and personnel assessment.
PY  - 2021
DA  - 2021-01-01
JO  - {'id': 'https://openalex.org/S2596401190', 'issn_l': None, 'issn': None, 'display_name': 'arXiv: Computation and Language', 'publisher': None, 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Shifeng Liu
AU  - Yifang Sun
AU  - Bing Li
AU  - Wei Wang
AU  - Florence T. Bourgeois
AU  - Adam G. Dunn
ER  - 

205.
TY  - journal-article
ID  - https://openalex.org/W3201443372
DO  - https://doi.org/10.6007/ijarafms/v11-i3/11052
TI  - A Systematic Review on Corporate Philanthropy Disclosure by Malaysian Companies
AB  - No Abstract Found
PY  - 2021
DA  - 2021-09-25
JO  - {'id': 'https://openalex.org/S4210192748', 'issn_l': '2225-8329', 'issn': ['2308-0337', '2225-8329'], 'display_name': 'International journal of academic research in accounting, finance and management sciences', 'publisher': 'Human Resource Management Academic Research Society', 'type': 'journal', 'url': 'https://doi.org/10.6007/ijarafms/v11-i3/11052', 'is_oa': True, 'version': 'publishedVersion', 'license': None}
DP  - OpenAlex
AU  - Nurul Arfiyanti Yusuf
AU  - Corina Joseph
ER  - 

206.
TY  - proceedings-article
ID  - https://openalex.org/W3212062532
DO  - nan
TI  - MS\^2: Multi-Document Summarization of Medical Studies.
AB  - To assess the effectiveness of any medical intervention, researchers must conduct a time-intensive and manual literature review. NLP systems can help to automate or assist in parts of this expensive process. In support of this goal, we release MSˆ2 (Multi-Document Summarization of Medical Studies), a dataset of over 470k documents and 20K summaries derived from the scientific literature. This dataset facilitates the development of systems that can assess and aggregate contradictory evidence across multiple studies, and is the first large-scale, publicly available multi-document summarization dataset in the biomedical domain. We experiment with a summarization system based on BART, with promising early results, though significant work remains to achieve higher summarization quality. We formulate our summarization inputs and targets in both free text and structured forms and modify a recently proposed metric to assess the quality of our system’s generated summaries. Data and models are available at https://github.com/allenai/ms2. annotations. By removing the reliance on expert annotations for span detection, this work could be used in human-machine pipeline for turning low-quality crowdsourced, and sentence-level PICO annotations into structured information that can be used to quickly assign trials to relevant systematic reviews. at universities. The university research can be stimulated at the state level through a demand-oriented reform that is aimed at reshaping the management of personnel, talent selection system, and personnel assessment.
PY  - 2021
DA  - 2021-11-01
JO  - {'id': 'https://openalex.org/S4306418267', 'issn_l': None, 'issn': None, 'display_name': 'Empirical Methods in Natural Language Processing', 'publisher': None, 'type': 'conference', 'url': 'https://arxiv.org/pdf/2104.06486', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Jay DeYoung
AU  - Iz Beltagy
AU  - Madeleine van Zuylen
AU  - Bailey Kuehl
AU  - Lucy Lu Wang
ER  - 

207.
TY  - posted-content
ID  - https://openalex.org/W3212218981
DO  - https://doi.org/10.48550/arxiv.2109.02254
TI  - Sent2Span: Span Detection for PICO Extraction in the Biomedical Text
  without Span Annotations
AB  - The rapid growth in published clinical trials makes it difficult to maintain up-to-date systematic reviews, which requires finding all relevant trials. This leads to policy and practice decisions based on out-of-date, incomplete, and biased subsets of available clinical evidence. Extracting and then normalising Population, Intervention, Comparator, and Outcome (PICO) information from clinical trial articles may be an effective way to automatically assign trials to systematic reviews and avoid searching and screening - the two most time-consuming systematic review processes. We propose and test a novel approach to PICO span detection. The major difference between our proposed method and previous approaches comes from detecting spans without needing annotated span data and using only crowdsourced sentence-level annotations. Experiments on two datasets show that PICO span detection results achieve much higher results for recall when compared to fully supervised methods with PICO sentence detection at least as good as human annotations. By removing the reliance on expert annotations for span detection, this work could be used in human-machine pipeline for turning low-quality crowdsourced, and sentence-level PICO annotations into structured information that can be used to quickly assign trials to relevant systematic reviews. at universities. The university research can be stimulated at the state level through a demand-oriented reform that is aimed at reshaping the management of personnel, talent selection system, and personnel assessment.
PY  - 2021
DA  - 2021-11-01
JO  - {'id': 'https://openalex.org/S4306400194', 'issn_l': None, 'issn': None, 'display_name': 'arXiv (Cornell University)', 'publisher': 'Cornell University', 'type': 'repository', 'url': 'http://arxiv.org/pdf/2109.02254', 'is_oa': True, 'version': 'submittedVersion', 'license': None}
DP  - OpenAlex
AU  - Shifeng Liu
AU  - Yifang Sun
AU  - Bing Li
AU  - Wei Wang
AU  - Florence T. Bourgeois
AU  - Adam G. Dunn
ER  - 

208.
TY  - journal-article
ID  - https://openalex.org/W4200536079
DO  - https://doi.org/10.1080/03007995.2021.2015160
TI  - Conducting and critically appraising a high-quality systematic review and Meta-analysis pertaining to COVID-19
AB  - With constantly emerging new information regarding the epidemiology, pathogenesis, diagnosis and management of Coronavirus Disease 2019 (COVID-19), reviewing literature related to it has become increasingly complicated and resource-intensive. In the setting of this global pandemic, clinical decisions are being guided by the results of multiple pertinent studies; however, it has been observed that these studies are often heterogenous in design and population characteristics and results of initial trials may not be replicated in subsequent studies. The resulting clinical conundrum can be resolved by high-quality systematic review and meta-analysis with a robust and reliable methodology, encapsulating and critically appraising all the available literature relevant to the clinical scenario under scrutiny. It can condense the large volume of scientific information available and can also identify the cause of differences in the degree of effect under consideration across different studies. It can identify optimal diagnostic algorithms, assess efficacy of treatment strategies, and analyze inherent factors influencing the efficacy of treatment for COVID-19. The current review aims to provide a basic guide to plan and conduct a high-quality systematic review and meta-analysis pertaining to COVID-19, describing the main steps and addressing the pitfalls commonly encountered at each step. Knowledge of the basic steps would also allow the reader to critically appraise published systematic review and meta-analysis and the quality of evidence provided therein. assessment.
PY  - 2021
DA  - 2021-12-06
JO  - {'id': 'https://openalex.org/S206643269', 'issn_l': '0300-7995', 'issn': ['0300-7995', '1473-4877'], 'display_name': 'Current Medical Research and Opinion', 'publisher': 'Informa', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Niraj Nirmal Pandey
AU  - Sanjiv Sharma
ER  - 

209.
TY  - journal-article
ID  - https://openalex.org/W4205767413
DO  - https://doi.org/10.1111/itor.13108
TI  - Shop scheduling in manufacturing environments: a review
AB  - We review the literature about shop scheduling problems in manufacturing systems, revealing the concepts and methodologies that most impact the usage of scheduling theory in manufacturing environments. We focus our attention on the job shop and flow shop problems and their variants. We emphasize the interactions between the scheduling functions and manufacturing paradigms such as Industry 4.0, Computer Integrated Manufacturing, Computer-Aided Process Planning, Advanced Planning and Scheduling, and Integrated Process Planning and Scheduling. We describe the main components and characteristics of the scheduling ecosystem, and we discuss how the scheduling interacts with the components that make it up and how it is affected by them. The metadata collected from the digital libraries on which the review was based (ScienceDirect, Scopus, and Elsevier) made it possible to characterize the historical evolution of the main concepts of the scheduling ecosystem in terms of scientific publications and research trends in the period 2000–2020. inherent factors influencing the efficacy of treatment for COVID-19. The current review aims to provide a basic guide to plan and conduct a high-quality systematic review and meta-analysis pertaining to COVID-19, describing the main steps and addressing the pitfalls commonly encountered at each step. Knowledge of the basic steps would also allow the reader to critically appraise published systematic review and meta-analysis and the quality of evidence provided therein. assessment.
PY  - 2022
DA  - 2022-01-15
JO  - {'id': 'https://openalex.org/S267729', 'issn_l': '0969-6016', 'issn': ['1475-3995', '0969-6016'], 'display_name': 'International Transactions in Operational Research', 'publisher': 'Wiley-Blackwell', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Carlos Francisco Nogales Márquez
AU  - Celso C. Ribeiro
ER  - 

210.
TY  - posted-content
ID  - https://openalex.org/W4206991029
DO  - https://doi.org/10.2196/preprints.31195
TI  - Assessing Quality Factors and User Preference of Drug Reference Apps in Taiwan: Systematic Search and Evaluation (Preprint)
AB  - <sec> <title>BACKGROUND</title> Drug reference apps play various distinct and vital roles through the medication use process. A drug reference app that carried out comprehensive localized drug information would greatly improve the efficiency and quality of work for physicians, nurses, pharmacists, and patients. </sec> <sec> <title>OBJECTIVE</title> This current study aimed to describe a systematic and stepwise process to identify drug reference apps with localized drug information in Taiwan. Moreover, we assessed the quality of these apps by using a reliable quality assessment tool and further analyzing the influential factors for user ratings. </sec> <sec> <title>METHODS</title> A two-step algorithm (KESS) consisting of keyword growing and systematic search was proposed. Apps were divided into two groups: higher user ratings and lower user ratings. Seven independent reviewers were trained to evaluate these apps using Mobile App Rating Scale (MARS). A logistic regression model was fitted, and average marginal effects (AME) were calculated to identify the effects of factors for higher user ratings. A p-value&lt; 0.05 was considered statistically significant. </sec> <sec> <title>RESULTS</title> A total of 23 drug reference apps in Taiwan had been identified and analyzed. Ten apps had higher user star ratings (&gt;=4 stars), and 13 apps had lower user star ratings ( &lt; 4 stars). These drug reference apps had acceptable quality with an average MARS score of 3.23. Apps with higher user star ratings had higher MARS scores than the lowers (engagement (2.70 v.s. 2.50, P= .005), functionality (3.85 v.s. 3.49, P= .003), aesthetics (3.39 v.s. 2.98, P &lt; .001), and information (3.55 v.s. 3.25, P= .005)). The regression model showed five influential factors for higher user ratings (navigation, AME, 13.15%; performance, AME, 11.03%; visual appeal, AME, 10.87%; credibility, AME, 10.67%; quantity of information, AME, 10.42%). </sec> <sec> <title>CONCLUSIONS</title> The proposed KESS algorithm could be a valuable and unbiased framework for systematic search for app. While the higher engagement, more functionality, better aesthetics, and more information associated with higher user ratings, there are five most influential factors, navigation, performance, visual appeal, credibility, and quantity of information among the four elements. </sec>
PY  - 2021
DA  - 2021-06-12
JO  - {'id': None, 'issn_l': None, 'issn': None, 'display_name': None, 'publisher': None, 'type': None, 'url': 'https://doi.org/10.2196/preprints.31195', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Yuchun Chen
AU  - Wei-Wei Liao
AU  - Mei-Chin Su
AU  - Yen-Hsi Lin
ER  - 

211.
TY  - book-chapter
ID  - https://openalex.org/W4213379757
DO  - https://doi.org/10.1007/978-3-030-64573-1_43
TI  - Artificial Intelligence in Evidence-Based Medicine
AB  - No Abstract Found
PY  - 2022
DA  - 2022-01-01
JO  - {'id': 'https://openalex.org/S4306463941', 'issn_l': None, 'issn': None, 'display_name': 'Springer International Publishing eBooks', 'publisher': 'Springer Nature', 'type': 'ebook platform', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Artur Nowak
ER  - 

212.
TY  - journal-article
ID  - https://openalex.org/W4220860813
DO  - https://doi.org/10.1016/j.heliyon.2022.e09095
TI  - Assessing author willingness to enter study information into structured data templates as part of the manuscript submission process: A pilot study
AB  - Environmental health and other researchers can benefit from automated or semi-automated summaries of data within published studies as summarizing study methods and results is time and resource intensive. Automated summaries can be designed to identify and extract details of interest pertaining to the study design, population, testing agent/intervention, or outcome (etc.). Much of the data reported across existing publications lack unified structure, standardization and machine-readable formats or may be presented in complex tables which serve as barriers that impede the development of automated data extraction methodologies.As full automation of data extraction seems unlikely soon, encouraging investigators to submit structured summaries of methods and results in standardized formats with meta-data tagging of content may be of value during the publication process. This would produce machine-readable content to facilitate automated data extraction, establish sharable data repositories, help make research data FAIR, and could improve reporting quality.A pilot study was conducted to assess the feasibility of asking participants to summarize study methods and results using a structured, web-based data extraction model as a potential workflow that could be implemented during the manuscript submission process.Eight participants entered study details and data into the Health Assessment Workplace Collaborative (HAWC). Participants were surveyed after the extraction exercise to ascertain 1) whether this extraction exercise will impact their conducting and reporting of future research, 2) the ease of data extraction, including which fields were easiest and relatively more problematic to extract and 3) the amount of time taken to perform data extractions and other related tasks. Investigators then presented participants the potential benefits of providing structured data in the format they were extracting. After this, participants were surveyed about 1) their willingness to provide structured data during the publication process and 2) whether they felt the potential application of structured data entry approaches and their implementation during the journal submission process should continue to be further explored.Routine provision of structured data that summarizes key information from research studies could reduce the amount of effort required for reusing that data in the future, such as in systematic reviews or agency scientific assessments. Our pilot study suggests that directly asking authors to provide that data, via structured templates, may be a viable approach to achieving this: participants were willing to do so, and the overall process was not prohibitively arduous. We also found some support for the hypothesis that use of study templates may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken.
PY  - 2022
DA  - 2022-03-01
JO  - {'id': 'https://openalex.org/S2898612692', 'issn_l': '2405-8440', 'issn': ['2405-8440'], 'display_name': 'Heliyon', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'http://www.cell.com/article/S2405844022003838/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc-nd'}
DP  - OpenAlex
AU  - A. Amina Wilkins
AU  - Amanda S. Persad
AU  - Ingrid L. Druwe
AU  - Janice C. Lee
AU  - Paul Whaley
AU  - M. Taylor
AU  - Andrew A. Shapiro
AU  - Natalie Blanton
AU  - Courtney Lemeris
AU  - Kristina A. Thayer
ER  - 

213.
TY  - journal-article
ID  - https://openalex.org/W4224303202
DO  - https://doi.org/10.1080/17565529.2022.2062284
TI  - Spatial overview of climate change impacts in Bangladesh: a systematic review
AB  - No Abstract Found
PY  - 2022
DA  - 2022-04-18
JO  - {'id': 'https://openalex.org/S43379938', 'issn_l': '1756-5529', 'issn': ['1756-5537', '1756-5529'], 'display_name': 'Climate and Development', 'publisher': 'Taylor & Francis', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Shabbir Ahmed
AU  - Md. Ayatullah Khan
ER  - 

214.
TY  - posted-content
ID  - https://openalex.org/W4230661095
DO  - https://doi.org/10.2196/preprints.24418
TI  - The Impact of Systematic Review Automation Tools on Methodological Quality and Time Taken to Complete Systematic Review Tasks: Case Study (Preprint)
AB  - <sec> <title>BACKGROUND</title> Systematic reviews (SRs) are considered the highest level of evidence to answer research questions; however, they are time and resource intensive. </sec> <sec> <title>OBJECTIVE</title> When comparing SR tasks done manually, using standard methods, versus those same SR tasks done using automated tools, (1) what is the difference in time to complete the SR task and (2) what is the impact on the error rate of the SR task? </sec> <sec> <title>METHODS</title> A case study compared specific tasks done during the conduct of an SR on prebiotic, probiotic, and synbiotic supplementation in chronic kidney disease. Two participants (manual team) conducted the SR using current methods, comprising a total of 16 tasks. Another two participants (automation team) conducted the tasks where a systematic review automation (SRA) tool was available, comprising of a total of six tasks. The time taken and error rate of the six tasks that were completed by both teams were compared. </sec> <sec> <title>RESULTS</title> The approximate time for the manual team to produce a draft of the background, methods, and results sections of the SR was 126 hours. For the six tasks in which times were compared, the manual team spent 2493 minutes (42 hours) on the tasks, compared to 708 minutes (12 hours) spent by the automation team. The manual team had a higher error rate in two of the six tasks—regarding &lt;i&gt;Task 5: Run the systematic search&lt;/i&gt;, the manual team made eight errors versus three errors made by the automation team; regarding &lt;i&gt;Task 12: Assess the risk of bias&lt;/i&gt;, 25 assessments differed from a reference standard for the manual team compared to 20 differences for the automation team. The manual team had a lower error rate in one of the six tasks—regarding &lt;i&gt;Task 6: Deduplicate search results&lt;/i&gt;, the manual team removed one unique study and missed zero duplicates versus the automation team who removed two unique studies and missed seven duplicates. Error rates were similar for the two remaining compared tasks—regarding &lt;i&gt;Task 7: Screen the titles and abstracts&lt;/i&gt; and &lt;i&gt;Task 9: Screen the full text&lt;/i&gt;, zero relevant studies were excluded by both teams. One task could not be compared between groups—&lt;i&gt;Task 8: Find the full text&lt;/i&gt;. </sec> <sec> <title>CONCLUSIONS</title> For the majority of SR tasks where an SRA tool was used, the time required to complete that task was reduced for novice researchers while methodological quality was maintained. </sec> may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken.
PY  - 2020
DA  - 2020-09-18
JO  - {'id': None, 'issn_l': None, 'issn': None, 'display_name': None, 'publisher': None, 'type': None, 'url': 'https://doi.org/10.2196/preprints.24418', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Justin Clark
AU  - Catherine McFarlane
AU  - Gina Cleo
AU  - Christiane Ishikawa Ramos
AU  - Skye Marshall
ER  - 

215.
TY  - book-chapter
ID  - https://openalex.org/W4238892018
DO  - https://doi.org/10.1007/978-1-4899-7586-7_22-1
TI  - New Statistical Methods of Combining Results in Comparative Effectiveness Research
AB  - No Abstract Found
PY  - 2015
DA  - 2015-01-01
JO  - {'id': 'https://openalex.org/S4306463950', 'issn_l': None, 'issn': None, 'display_name': 'Springer US eBooks', 'publisher': 'Springer Nature', 'type': 'ebook platform', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Chris Cameron
AU  - Robert W. Platt
ER  - 

216.
TY  - posted-content
ID  - https://openalex.org/W4240818803
DO  - https://doi.org/10.2196/preprints.33219
TI  - Software Tools for Systematic Literature Review in Medicine: A Review and Feature Analysis (Preprint)
AB  - <sec> <title>BACKGROUND</title> Systematic reviews (SRs) are central to evaluating therapies but have high costs in terms of both time and money. Many software tools exist to assist with SRs, but most tools do not support the full process, and transparency and replicability of SR depends on performing and presenting evidence according to established best practices. </sec> <sec> <title>OBJECTIVE</title> In order to provide a basis for comparing and selecting between software tools that support SR, we performed a feature-by-feature comparison of SR tools. </sec> <sec> <title>METHODS</title> We searched for SR tools by reviewing any such tool listed the Systematic Review Toolbox, previous reviews of SR tools, and qualitative Google searching. We included all SR tools that were currently functional, and require no coding and excluded reference managers, desktop applications, and statistical software. The list of features to assess was populated by combining all features assessed in four previous reviews of SR tools; we also added five features (Manual Addition, Screening Automation, Dual Extraction, Living review, Public outputs) that were independently noted as best practices or enhancements of transparency/replicability. Then, two reviewers assigned binary “present/absent” assessments to all SR tools with respect to all features, and a third reviewer adjudicated all disagreements. </sec> <sec> <title>RESULTS</title> Of 49 SR tools found, 27 were excluded, leaving 22 for assessment. Twenty-eight features were assessed across 6 classes, and the inter-observer agreement was 86.46%. DistillerSR, EPPI-Reviewer Web, and Nested Knowledge support the most features (24/28, 86%), followed by Covidence, SRDB.PRO, SysRev (20/28, 71%). Six tools support fewer than half of all features assessed: SyRF, Data Abstraction Assistant, SWIFT-review, SR-Accelerator, RobotReviewer, and COVID-NMA. Notably, only 9 of 22 tools (41%) support direct search, only four (18%) offer dual extraction, and only 9 (41%) offer living/updatable reviews. </sec> <sec> <title>CONCLUSIONS</title> DistillerSR, EPPI-Reviewer Web, and Nested Knowledge each offer a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. </sec> studies were excluded by both teams. One task could not be compared between groups—&lt;i&gt;Task 8: Find the full text&lt;/i&gt;. </sec> <sec> <title>CONCLUSIONS</title> For the majority of SR tasks where an SRA tool was used, the time required to complete that task was reduced for novice researchers while methodological quality was maintained. </sec> may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken.
PY  - 2021
DA  - 2021-08-28
JO  - {'id': None, 'issn_l': None, 'issn': None, 'display_name': None, 'publisher': None, 'type': None, 'url': 'https://doi.org/10.2196/preprints.33219', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Kathryn Cowie
AU  - Asad Rahmatullah
AU  - Nicole Hardy
AU  - Kevin M. Kallmes
AU  - Kevin M. Kallmes
ER  - 

217.
TY  - posted-content
ID  - https://openalex.org/W4250827416
DO  - https://doi.org/10.2196/preprints.20007
TI  - Artificial Intelligence for Rapid Meta-Analysis: Case Study on Ocular Toxicity of Hydroxychloroquine (Preprint)
AB  - <sec> <title>BACKGROUND</title> Rapid access to evidence is crucial in times of an evolving clinical crisis. To that end, we propose a novel approach to answer clinical queries, termed rapid meta-analysis (RMA). Unlike traditional meta-analysis, RMA balances a quick time to production with reasonable data quality assurances, leveraging artificial intelligence (AI) to strike this balance. </sec> <sec> <title>OBJECTIVE</title> We aimed to evaluate whether RMA can generate meaningful clinical insights, but crucially, in a much faster processing time than traditional meta-analysis, using a relevant, real-world example. </sec> <sec> <title>METHODS</title> The development of our RMA approach was motivated by a currently relevant clinical question: is ocular toxicity and vision compromise a side effect of hydroxychloroquine therapy? At the time of designing this study, hydroxychloroquine was a leading candidate in the treatment of coronavirus disease (COVID-19). We then leveraged AI to pull and screen articles, automatically extract their results, review the studies, and analyze the data with standard statistical methods. </sec> <sec> <title>RESULTS</title> By combining AI with human analysis in our RMA, we generated a meaningful, clinical result in less than 30 minutes. The RMA identified 11 studies considering ocular toxicity as a side effect of hydroxychloroquine and estimated the incidence to be 3.4% (95% CI 1.11%-9.96%). The heterogeneity across individual study findings was high, which should be taken into account in interpretation of the result. </sec> <sec> <title>CONCLUSIONS</title> We demonstrate that a novel approach to meta-analysis using AI can generate meaningful clinical insights in a much shorter time period than traditional meta-analysis. </sec> fewer than half of all features assessed: SyRF, Data Abstraction Assistant, SWIFT-review, SR-Accelerator, RobotReviewer, and COVID-NMA. Notably, only 9 of 22 tools (41%) support direct search, only four (18%) offer dual extraction, and only 9 (41%) offer living/updatable reviews. </sec> <sec> <title>CONCLUSIONS</title> DistillerSR, EPPI-Reviewer Web, and Nested Knowledge each offer a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. </sec> studies were excluded by both teams. One task could not be compared between groups—&lt;i&gt;Task 8: Find the full text&lt;/i&gt;. </sec> <sec> <title>CONCLUSIONS</title> For the majority of SR tasks where an SRA tool was used, the time required to complete that task was reduced for novice researchers while methodological quality was maintained. </sec> may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken.
PY  - 2020
DA  - 2020-05-08
JO  - {'id': None, 'issn_l': None, 'issn': None, 'display_name': None, 'publisher': None, 'type': None, 'url': 'https://doi.org/10.2196/preprints.20007', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Matthew Michelson
AU  - Tiffany W. Chow
AU  - Neil A. Martin
AU  - Mike Ross
AU  - Amelia Tee Qiao Ying
AU  - Steven Minton
ER  - 

218.
TY  - book-chapter
ID  - https://openalex.org/W4252331751
DO  - https://doi.org/10.1007/978-3-030-12263-8_7
TI  - Data Extraction
AB  - No Abstract Found
PY  - 2019
DA  - 2019-01-01
JO  - {'id': 'https://openalex.org/S4306463941', 'issn_l': None, 'issn': None, 'display_name': 'Springer International Publishing eBooks', 'publisher': 'Springer Nature', 'type': 'ebook platform', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - David Tod
ER  - 

219.
TY  - other
ID  - https://openalex.org/W4280569825
DO  - https://doi.org/10.1002/9781119099369.ch6
TI  - Managing People and Data
AB  - No Abstract Found
PY  - 2022
DA  - 2022-04-22
JO  - {'id': None, 'issn_l': None, 'issn': None, 'display_name': 'Systematic Reviews in Health Research', 'publisher': None, 'type': None, 'url': 'https://doi.org/10.1002/9781119099369.ch6', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Eliane Rohner
AU  - Julia Bohlius
AU  - Bruno M. Costa
AU  - Sven Trelle
ER  - 

220.
TY  - other
ID  - https://openalex.org/W4280570258
DO  - https://doi.org/10.1002/9781119099369.ch23
TI  - Innovations in Systematic Review Production
AB  - No Abstract Found
PY  - 2022
DA  - 2022-04-22
JO  - {'id': None, 'issn_l': None, 'issn': None, 'display_name': 'Systematic Reviews in Health Research', 'publisher': None, 'type': None, 'url': 'https://doi.org/10.1002/9781119099369.ch23', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Julian Elliott
AU  - Tari Turner
ER  - 

221.
TY  - journal-article
ID  - https://openalex.org/W4280600737
DO  - https://doi.org/10.12688/openreseurope.14041.2
TI  - Implementing living evidence to inform health decisions: A strategy for building capacity in health sector (Protocol)
AB  - <ns4:p>Every day important healthcare decisions are made with incomplete or outdated information about the effects of the healthcare interventions available, what delivers the best value for the health system and where more research is needed. It is necessary to invest in strategies that allow access to reliable and updated evidence on which to base health decisions.</ns4:p><ns4:p> The objective is to develop and evaluate a strategy for building the capacity among different actors of a country’s health system to implement the model known as “Living Evidence” [LE] in the evidence synthesis and dissemination of knowledge transfer [KT] products to inform health decisions. The study will involve professional members of health system organizations in charge of developing KT products to inform health decisions.</ns4:p><ns4:p> The project will be developed in three complementary phases: 1) LE-implementation framework development through review of the literature, brainstorming meetings, user testing, and expert consultation; 2) training in LE tools and strategies; 3) developing LE synthesis for KT products by applying the framework to real-life diverse situations.</ns4:p><ns4:p> To achieve the capacity-building strategy assessment goal, several surveys and interviews will take place during the process to assess: 1) the LE-implementation framework for the incorporation of LE synthesis in the development of KT products; 2) the training workshops; 3) the whole capacity-building strategy used for health system organizations be able of implementing the LE as part of the KT products they regularly produce.</ns4:p><ns4:p> The expected results are an effective capacity-building strategy for health system organizations to implement the living evidence model in different KT products; a LE-implementation framework to be applicable to any country or region to incorporate LE in the KT products; LE synthesis for KT products directly applicable to the real-setting situations; integration of Epistemonikos-L.OVE platform for keeping the LE process in the development and updating of KT products.</ns4:p> a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. </sec> studies were excluded by both teams. One task could not be compared between groups—&lt;i&gt;Task 8: Find the full text&lt;/i&gt;. </sec> <sec> <title>CONCLUSIONS</title> For the majority of SR tasks where an SRA tool was used, the time required to complete that task was reduced for novice researchers while methodological quality was maintained. </sec> may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken.
PY  - 2022
DA  - 2022-05-20
JO  - {'id': 'https://openalex.org/S4210238080', 'issn_l': '2732-5121', 'issn': ['2732-5121'], 'display_name': 'Open research Europe', 'publisher': 'European Commission', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - María Ximena Rojas
AU  - Gerard Urrútia
AU  - Gabriel Rada
AU  - Pablo J. Alonso
AU  - David Comas
AU  - Ariadna Auladell-Rispau
ER  - 

222.
TY  - journal-article
ID  - https://openalex.org/W4281564843
DO  - https://doi.org/10.5304/jafscd.2022.113.010
TI  - Sustainability outcomes of the United States food system: A systematic review
AB  - Food systems literature has shifted towards interdisciplinarity and the use of systems lenses but can still be disjointed and unconnected. To bring together disciplinary knowledge and establish a common understanding of food systems, we conducted a systematic review to inventory sustainability outcomes of the U.S. food system. The literature search returned 2,866 articles, which was reduced to 49, reviewed here. A qualitative content analysis process identified 93 outcomes. These were split across three main themes of environmental, socio-economic, and health outcomes. This review also identified several trends in food systems literature, such as an underrepresentation of socio-economic outcomes and a lack of inclusion of social outcomes in natural science journals. The sustainability outcomes inventoried here may help to facilitate greater communication and collaboration in food systems research and situate current and future food systems studies within this inventory. literature, brainstorming meetings, user testing, and expert consultation; 2) training in LE tools and strategies; 3) developing LE synthesis for KT products by applying the framework to real-life diverse situations.</ns4:p><ns4:p> To achieve the capacity-building strategy assessment goal, several surveys and interviews will take place during the process to assess: 1) the LE-implementation framework for the incorporation of LE synthesis in the development of KT products; 2) the training workshops; 3) the whole capacity-building strategy used for health system organizations be able of implementing the LE as part of the KT products they regularly produce.</ns4:p><ns4:p> The expected results are an effective capacity-building strategy for health system organizations to implement the living evidence model in different KT products; a LE-implementation framework to be applicable to any country or region to incorporate LE in the KT products; LE synthesis for KT products directly applicable to the real-setting situations; integration of Epistemonikos-L.OVE platform for keeping the LE process in the development and updating of KT products.</ns4:p> a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. </sec> studies were excluded by both teams. One task could not be compared between groups—&lt;i&gt;Task 8: Find the full text&lt;/i&gt;. </sec> <sec> <title>CONCLUSIONS</title> For the majority of SR tasks where an SRA tool was used, the time required to complete that task was reduced for novice researchers while methodological quality was maintained. </sec> may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken.
PY  - 2022
DA  - 2022-05-25
JO  - {'id': 'https://openalex.org/V2764628096', 'issn_l': '2152-0801', 'issn': ['2152-0798', '2152-0801'], 'display_name': 'The Journal of Agriculture, Food Systems, and Community Development', 'publisher': 'Thomas A. Lyson Center for Civic Agriculture and Food Systems', 'type': 'journal', 'url': 'https://www.foodsystemsjournal.org/index.php/fsj/article/download/1078/1047', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - C. B. Knox
AU  - Shelie A. Miller
ER  - 

223.
TY  - journal-article
ID  - https://openalex.org/W4281782963
DO  - https://doi.org/10.1007/s10664-021-10084-4
TI  - SeSG: a search string generator for Secondary Studies with hybrid search strategies using text mining
AB  - No Abstract Found
PY  - 2022
DA  - 2022-05-30
JO  - {'id': 'https://openalex.org/S109852484', 'issn_l': '1382-3256', 'issn': ['1382-3256', '1573-7616'], 'display_name': 'Empirical Software Engineering', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Leonardo Alcântara Alves
AU  - Francisco J. S. Vasconcellos
AU  - Bruno Nogueira
ER  - 

224.
TY  - journal-article
ID  - https://openalex.org/W4287485772
DO  - nan
TI  - Controversial Trials First: Identifying Disagreement Between Clinical Guidelines and New Evidence.
AB  - Clinical guidelines integrate latest evidence to support clinical decision-making. As new research findings are published at an increasing rate, it would be helpful to detect when such results disagree with current guideline recommendations. In this work, we describe a software system for the automatic identification of disagreement between clinical guidelines and published research. A critical feature of the system is the extraction and cross-lingual normalization of information through natural language processing. The initial version focuses on the detection of cancer treatments in clinical trial reports that are not addressed in oncology guidelines. We evaluate the relevance of trials retrieved by our system retrospectively by comparison with historic guideline updates and also prospectively through manual evaluation by guideline experts. The system improves precision over state-of-the-art literature research strategies while maintaining near-total recall. Detailed error analysis highlights challenges for fine-grained clinical information extraction, in particular when extracting population definitions for tumor-agnostic therapies. tools and strategies; 3) developing LE synthesis for KT products by applying the framework to real-life diverse situations.</ns4:p><ns4:p> To achieve the capacity-building strategy assessment goal, several surveys and interviews will take place during the process to assess: 1) the LE-implementation framework for the incorporation of LE synthesis in the development of KT products; 2) the training workshops; 3) the whole capacity-building strategy used for health system organizations be able of implementing the LE as part of the KT products they regularly produce.</ns4:p><ns4:p> The expected results are an effective capacity-building strategy for health system organizations to implement the living evidence model in different KT products; a LE-implementation framework to be applicable to any country or region to incorporate LE in the KT products; LE synthesis for KT products directly applicable to the real-setting situations; integration of Epistemonikos-L.OVE platform for keeping the LE process in the development and updating of KT products.</ns4:p> a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. </sec> studies were excluded by both teams. One task could not be compared between groups—&lt;i&gt;Task 8: Find the full text&lt;/i&gt;. </sec> <sec> <title>CONCLUSIONS</title> For the majority of SR tasks where an SRA tool was used, the time required to complete that task was reduced for novice researchers while methodological quality was maintained. </sec> may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken.
PY  - 2021
DA  - 2021-01-01
JO  - {'id': None, 'issn_l': None, 'issn': None, 'display_name': 'AMIA ... Annual Symposium proceedings. AMIA Symposium', 'publisher': None, 'type': None, 'url': 'https://pubmed.ncbi.nlm.nih.gov/35308948/', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Florian Borchert
AU  - Laura Meister
AU  - Thomas Langer
AU  - Markus Follmann
AU  - Bert Arnrich
AU  - Matthieu-P. Schapranow
ER  - 

225.
TY  - journal-article
ID  - https://openalex.org/W4290973973
DO  - https://doi.org/10.1093/advances/nmac086
TI  - Orally Ingested Probiotics, Prebiotics, and Synbiotics as Countermeasures for Respiratory Tract Infections in Nonelderly Adults: A Systematic Review and Meta-Analysis
AB  - The impact of gut microbiota-targeted interventions on the incidence, duration, and severity of respiratory tract infections (RTIs) in nonelderly adults, and factors moderating any such effects, are unclear. This systematic review and meta-analysis aimed to determine the effects of orally ingested probiotics, prebiotics, and synbiotics compared with placebo on RTI incidence, duration, and severity in nonelderly adults, and to identify potential sources of heterogeneity. Studies were identified by searching CENTRAL, PubMed, Scopus, and Web of Science up to December 2021. English-language, peer-reviewed publications of randomized, placebo-controlled studies that tested an orally ingested probiotic, prebiotic, or synbiotic intervention of any dose for ≥1 wk in adults aged 18-65 y were included. Results were synthesized using intention-to-treat and per-protocol random-effects meta-analysis. Heterogeneity was explored by subgroup meta-analysis and meta-regression. Risk of bias was assessed using the Cochrane risk-of-bias assessment tool for randomized trials version 2 (RoB2). Forty-two manuscripts reporting effects of probiotics (n = 38), prebiotics (n = 2), synbiotics (n = 1) or multiple -biotic types (n = 1) were identified (n = 9179 subjects). Probiotics reduced the risk of experiencing ≥1 RTI (relative risk = 0.91; 95% CI: 0.84, 0.98; P = 0.01), and total days (rate ratio = 0.77; 95% CI: 0.71, 0.83; P < 0.001), duration (Hedges' g = -0.23; 95% CI: -0.39, -0.08; P = 0.004), and severity (Hedges' g = -0.16; 95% CI: -0.29, -0.03; P = 0.02) of RTIs. Effects were relatively consistent across different strain combinations, doses, and durations, although reductions in RTI duration were larger with fermented dairy as the delivery matrix, and beneficial effects of probiotics were not observed in physically active populations. Overall risk of bias was rated as "some concerns" for most studies. In conclusion, orally ingested probiotics, relative to placebo, modestly reduce the incidence, duration, and severity of RTIs in nonelderly adults. Physical activity and delivery matrix may moderate some of these effects. Whether prebiotic and synbiotic interventions confer similar protection remains unclear due to few relevant studies. This trial was registered at https://www.crd.york.ac.uk/prospero/ as CRD42020220213. support of living reviews. </sec> studies were excluded by both teams. One task could not be compared between groups—&lt;i&gt;Task 8: Find the full text&lt;/i&gt;. </sec> <sec> <title>CONCLUSIONS</title> For the majority of SR tasks where an SRA tool was used, the time required to complete that task was reduced for novice researchers while methodological quality was maintained. </sec> may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken.
PY  - 2022
DA  - 2022-08-10
JO  - {'id': 'https://openalex.org/S2491932416', 'issn_l': '2161-8313', 'issn': ['2161-8313', '2156-5376'], 'display_name': 'Advances in Nutrition', 'publisher': 'American Society for Nutrition', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Julie Coleman
AU  - Adrienne M. Hatch
AU  - Stephanie D Small
AU  - Jillian T. Allen
AU  - Elaine Sullo
AU  - Richard Agans
AU  - Heather S. Fagnant
AU  - Asma S Bukhari
AU  - J. Philip Karl
ER  - 

226.
TY  - journal-article
ID  - https://openalex.org/W4295814235
DO  - https://doi.org/10.3390/app12189156
TI  - Machine Learning Applications in Surface Transportation Systems: A Literature Review
AB  - Surface transportation has evolved through technology advancements using parallel knowledge areas such as machine learning (ML). However, the transportation industry has not yet taken full advantage of ML. To evaluate this gap, we utilized a literature review approach to locate, categorize, and synthesize the principal concepts of research papers regarding surface transportation systems using ML algorithms, and we then decomposed them into their fundamental elements. We explored more than 100 articles, literature review papers, and books. The results show that 74% of the papers concentrate on forecasting, while multilayer perceptions, long short-term memory, random forest, supporting vector machine, XGBoost, and deep convolutional neural networks are the most preferred ML algorithms. However, sophisticated ML algorithms have been minimally used. The root-cause analysis revealed a lack of effective collaboration between the ML and transportation experts, resulting in the most accessible transportation applications being used as a case study to test or enhance a given ML algorithm and not necessarily to enhance a mobility or safety issue. Additionally, the transportation community does not define transportation issues clearly and does not provide publicly available transportation datasets. The transportation sector must offer an open-source platform to showcase the sector’s concerns and build spatiotemporal datasets for ML experts to accelerate technology advancements. 0.001), duration (Hedges' g = -0.23; 95% CI: -0.39, -0.08; P = 0.004), and severity (Hedges' g = -0.16; 95% CI: -0.29, -0.03; P = 0.02) of RTIs. Effects were relatively consistent across different strain combinations, doses, and durations, although reductions in RTI duration were larger with fermented dairy as the delivery matrix, and beneficial effects of probiotics were not observed in physically active populations. Overall risk of bias was rated as "some concerns" for most studies. In conclusion, orally ingested probiotics, relative to placebo, modestly reduce the incidence, duration, and severity of RTIs in nonelderly adults. Physical activity and delivery matrix may moderate some of these effects. Whether prebiotic and synbiotic interventions confer similar protection remains unclear due to few relevant studies. This trial was registered at https://www.crd.york.ac.uk/prospero/ as CRD42020220213. support of living reviews. </sec> studies were excluded by both teams. One task could not be compared between groups—&lt;i&gt;Task 8: Find the full text&lt;/i&gt;. </sec> <sec> <title>CONCLUSIONS</title> For the majority of SR tasks where an SRA tool was used, the time required to complete that task was reduced for novice researchers while methodological quality was maintained. </sec> may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken.
PY  - 2022
DA  - 2022-09-13
JO  - {'id': 'https://openalex.org/S4210205812', 'issn_l': '2076-3417', 'issn': ['2076-3417'], 'display_name': 'Applied sciences', 'publisher': 'MDPI', 'type': 'journal', 'url': 'https://www.mdpi.com/2076-3417/12/18/9156/pdf?version=1663063043', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Hojat Behrooz
AU  - Yeganeh M. Hayeri
ER  - 

227.
TY  - journal-article
ID  - https://openalex.org/W4296546700
DO  - https://doi.org/10.12688/f1000research.125198.1
TI  - (Semi)automated approaches to data extraction for systematic reviews and meta-analyses in social sciences: A living review protocol
AB  - <ns3:p><ns3:bold>Background</ns3:bold>: An abundance of rapidly accumulating scientific evidence presents novel opportunities for researchers and practitioners alike, yet such advantages are often overshadowed by resource demands associated with finding and aggregating a continually expanding body of scientific information. Across social science disciplines, the use of automation technologies for timely and accurate knowledge synthesis can enhance research translation value, better inform key policy development, and expand the current understanding of human interactions, organizations, and systems. Ongoing developments surrounding automation are highly concentrated in research for evidence-based medicine with limited evidence surrounding tools and techniques applied outside of the clinical research community. Our objective is to conduct a living systematic review of automated data extraction techniques supporting systematic reviews and meta-analyses in the social sciences. The aim of this study is to extend the automation knowledge base by synthesizing current trends in the application of extraction technologies of key data elements of interest for social scientists.</ns3:p><ns3:p> <ns3:bold>Methods</ns3:bold>: The proposed study is a living systematic review employing a partial replication framework based on extant literature surrounding automation of data extraction for systematic reviews and meta-analyses. Protocol development, base review, and updates follow PRISMA standards for reporting systematic reviews. This protocol is preregistered in OSF: <ns3:ext-link xmlns:ns4="http://www.w3.org/1999/xlink" ext-link-type="uri" ns4:href="https://doi.org/10.17605/OSF.IO/YWTF9">(Semi)Automated Approaches to Data Extraction for Systematic Reviews and Meta-Analyses in Social Sciences: A Living Review Protocol</ns3:ext-link> on August 14, 2022.</ns3:p><ns3:p> <ns3:bold>Conclusions</ns3:bold>: Anticipated outcomes of this study include: (a) generate insights supporting advancement in transferring existing reliable methods to social science research; (b) provide a foundation for protocol development leading to enhancement of comparability and benchmarking standards across disciplines; and (c) uncover exigencies that spur continued value-adding innovation and interdisciplinary collaboration for the benefit of the collective systematic review community.</ns3:p> In conclusion, orally ingested probiotics, relative to placebo, modestly reduce the incidence, duration, and severity of RTIs in nonelderly adults. Physical activity and delivery matrix may moderate some of these effects. Whether prebiotic and synbiotic interventions confer similar protection remains unclear due to few relevant studies. This trial was registered at https://www.crd.york.ac.uk/prospero/ as CRD42020220213. support of living reviews. </sec> studies were excluded by both teams. One task could not be compared between groups—&lt;i&gt;Task 8: Find the full text&lt;/i&gt;. </sec> <sec> <title>CONCLUSIONS</title> For the majority of SR tasks where an SRA tool was used, the time required to complete that task was reduced for novice researchers while methodological quality was maintained. </sec> may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken.
PY  - 2022
DA  - 2022-09-12
JO  - {'id': 'https://openalex.org/S4210239046', 'issn_l': '2046-1402', 'issn': ['2046-1402'], 'display_name': 'F1000Research', 'publisher': 'Faculty of 1000', 'type': 'journal', 'url': 'https://f1000research.com/articles/11-1036/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Amanda Legate
AU  - Kim Nimon
ER  - 

228.
TY  - journal-article
ID  - https://openalex.org/W4297176019
DO  - https://doi.org/10.1007/s43440-022-00420-w
TI  - Effects of chronic fluoxetine treatment on anxiety- and depressive-like behaviors in adolescent rodents – systematic review and meta-analysis
AB  - Drugs prescribed for psychiatric disorders in adolescence should be studied very extensively since they can affect developing and thus highly plastic brain differently than they affect the adult brain. Therefore, we aimed to summarize animal studies reporting the behavioral consequences of chronic exposure to the most widely prescribed antidepressant drug among adolescents i.e., fluoxetine.Electronic databases (Medline via Pubmed, Web of Science Core Collection, ScienceDirect) were systematically searched until April 12, 2022, for published, peer-reviewed, controlled trials concerning the effects of chronic fluoxetine administration vs. vehicle on anxiety and depression measures in naïve and stress-exposed adolescent rodents. All of the relevant studies were selected and critically appraised, and a meta-analysis of eligible studies was performed.A total of 18 studies were included in the meta-analysis. In naïve animals, chronic adolescent fluoxetine administration showed dose-related anxiogenic-like effects, measured as a reduction in time spent in the open arms of the elevated plus maze. No significant effects of chronic adolescent fluoxetine on depression-like behavior were reported in naïve animals, while in stress-exposed rodents chronic adolescent fluoxetine significantly decreased immobility time in the forced swim test compared to vehicle.These results suggest that although chronic fluoxetine treatment proves positive effects in animal models of depression, it may simultaneously increase anxiety in adolescent animals in a dose-related manner. Although the clinical implications of the data should be interpreted with extreme caution, adolescent patients under fluoxetine treatment should be closely monitored. insights supporting advancement in transferring existing reliable methods to social science research; (b) provide a foundation for protocol development leading to enhancement of comparability and benchmarking standards across disciplines; and (c) uncover exigencies that spur continued value-adding innovation and interdisciplinary collaboration for the benefit of the collective systematic review community.</ns3:p> In conclusion, orally ingested probiotics, relative to placebo, modestly reduce the incidence, duration, and severity of RTIs in nonelderly adults. Physical activity and delivery matrix may moderate some of these effects. Whether prebiotic and synbiotic interventions confer similar protection remains unclear due to few relevant studies. This trial was registered at https://www.crd.york.ac.uk/prospero/ as CRD42020220213. support of living reviews. </sec> studies were excluded by both teams. One task could not be compared between groups—&lt;i&gt;Task 8: Find the full text&lt;/i&gt;. </sec> <sec> <title>CONCLUSIONS</title> For the majority of SR tasks where an SRA tool was used, the time required to complete that task was reduced for novice researchers while methodological quality was maintained. </sec> may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken.
PY  - 2022
DA  - 2022-09-24
JO  - {'id': 'https://openalex.org/S180401253', 'issn_l': '1734-1140', 'issn': ['1734-1140', '2299-5684'], 'display_name': 'Pharmacological Reports', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'https://link.springer.com/content/pdf/10.1007/s43440-022-00420-w.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Joanna Kryst
AU  - Iwona Majcher-Maślanka
AU  - Agnieszka Chocyk
ER  - 

229.
TY  - journal-article
ID  - https://openalex.org/W4297535932
DO  - https://doi.org/10.1016/j.jclinepi.2022.09.013
TI  - Commentary: collaborative systematic review may produce and share high-quality, comparative evidence more efficiently
AB  - <h2>Abstract</h2> Systematic reviews are necessary to synthesize available evidence and inform clinical practice and health policy decisions. There has been an explosion of evidence available in many fields; this makes it challenging to keep evidence syntheses up to date and useful. Comparative effectiveness systematic reviews are informative; however, producing these often-large reviews bring intense time and resource demands. This commentary describes the implementation of a systematic review using a collaborative model of evidence synthesis. We are implementing the collaborative review model to update a large Cochrane review investigating the efficacy and comparative effectiveness of the design, delivery, and type of exercise treatment for people with chronic low-back pain. Three key benefits of the collaborative review model for evidence synthesis are (1) team coordination and collaboration, (2) quality control measures, and (3) advanced comparative and other analyses. This new collaborative review model is developed and implemented to produce and share high-quality, comparative evidence more efficiently while building capacity and community within a research field. naïve animals, while in stress-exposed rodents chronic adolescent fluoxetine significantly decreased immobility time in the forced swim test compared to vehicle.These results suggest that although chronic fluoxetine treatment proves positive effects in animal models of depression, it may simultaneously increase anxiety in adolescent animals in a dose-related manner. Although the clinical implications of the data should be interpreted with extreme caution, adolescent patients under fluoxetine treatment should be closely monitored. insights supporting advancement in transferring existing reliable methods to social science research; (b) provide a foundation for protocol development leading to enhancement of comparability and benchmarking standards across disciplines; and (c) uncover exigencies that spur continued value-adding innovation and interdisciplinary collaboration for the benefit of the collective systematic review community.</ns3:p> In conclusion, orally ingested probiotics, relative to placebo, modestly reduce the incidence, duration, and severity of RTIs in nonelderly adults. Physical activity and delivery matrix may moderate some of these effects. Whether prebiotic and synbiotic interventions confer similar protection remains unclear due to few relevant studies. This trial was registered at https://www.crd.york.ac.uk/prospero/ as CRD42020220213. support of living reviews. </sec> studies were excluded by both teams. One task could not be compared between groups—&lt;i&gt;Task 8: Find the full text&lt;/i&gt;. </sec> <sec> <title>CONCLUSIONS</title> For the majority of SR tasks where an SRA tool was used, the time required to complete that task was reduced for novice researchers while methodological quality was maintained. </sec> may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken.
PY  - 2022
DA  - 2022-09-01
JO  - {'id': 'https://openalex.org/S64418186', 'issn_l': '0895-4356', 'issn': ['1878-5921', '0895-4356'], 'display_name': 'Journal of Clinical Epidemiology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Jill A. Hayden
AU  - Jill A. Hayden
AU  - Rachel Ogilvie
AU  - Sareen Singh
AU  - Shazia Kashif
AU  - Jan Hartvigsen
AU  - Chris G. Maher
AU  - Andrea D. Furlan
AU  - Toby Lasserson
AU  - Peter Tugwell
AU  - Maurits van Tulder
AU  - Amir Qaseem
AU  - Manuela L. Ferreira
AU  - Rachelle Buchbinder
AU  - L Susan Wieland
AU  - Fabianna R. Jesus-Moraleida
AU  - Bruno T. Saragiotto
AU  - Tie Parma Yamato
AU  - Annemarie de Zoete
AU  - Kasper Bülow
AU  - Lisandra Almeida de Oliveira
AU  - Geronimo Bejarano
AU  - Carol Cancelliere
ER  - 

230.
TY  - journal-article
ID  - https://openalex.org/W4304092662
DO  - https://doi.org/10.1016/j.arabjc.2022.104340
TI  - WITHDRAWN: Poly(caprolactone)-b-Poly(ethylene glycol)-based Polymeric Micelles as Drug Carrier for Efficient Breast Cancer Therapy: A Systematic Review
AB  - Recently, drug delivery systems based on nanoparticles for cancer treatment have become the centre of attention for researchers to design and fabricate drug carriers for anticancer drugs due to the conventional pharmaceuticals lacking tumour-targeting activity. Poly(caprolactone)- b -poly(ethylene glycol) (PCL-PEG)-based micelles have attracted significant attention as a potential drug carrier intended for human use. Since their first discovery, the Food and Drug Administration (FDA)-approved polymers have been studied extensively for various biomedical applications, specifically cancer therapy. The application of PCL-PEG micelles in different cancer therapy has been recorded in countless research for their efficacy as drug cargos. However, systematic studies on the effectiveness of PCL-PEG micelles of specific cancer for pharmaceutical applications are still lacking. As breast cancer is reported as the most prevalent cancer worldwide, we aim to systematically review all available literature that publishes research findings on the PCL-PEG-based micelles as drug cargo for the therapy. We further discussed the preparation method and the anti-tumour efficacy of the micelles. Using prearranged search string, Scopus and Science Direct were selected as the database for the systematic searching strategy. Only eight of the 314 articles met the inclusion requirements and were used for data synthesis. From the review, all studies reported the efficiency of PCL-PEG-based micelles, which act as drug cargo for breast cancer therapy. of the data should be interpreted with extreme caution, adolescent patients under fluoxetine treatment should be closely monitored. insights supporting advancement in transferring existing reliable methods to social science research; (b) provide a foundation for protocol development leading to enhancement of comparability and benchmarking standards across disciplines; and (c) uncover exigencies that spur continued value-adding innovation and interdisciplinary collaboration for the benefit of the collective systematic review community.</ns3:p> In conclusion, orally ingested probiotics, relative to placebo, modestly reduce the incidence, duration, and severity of RTIs in nonelderly adults. Physical activity and delivery matrix may moderate some of these effects. Whether prebiotic and synbiotic interventions confer similar protection remains unclear due to few relevant studies. This trial was registered at https://www.crd.york.ac.uk/prospero/ as CRD42020220213. support of living reviews. </sec> studies were excluded by both teams. One task could not be compared between groups—&lt;i&gt;Task 8: Find the full text&lt;/i&gt;. </sec> <sec> <title>CONCLUSIONS</title> For the majority of SR tasks where an SRA tool was used, the time required to complete that task was reduced for novice researchers while methodological quality was maintained. </sec> may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken.
PY  - 2022
DA  - 2022-10-01
JO  - {'id': 'https://openalex.org/S2357026', 'issn_l': '1878-5352', 'issn': ['1878-5379', '1878-5352'], 'display_name': 'Arabian Journal of Chemistry', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'https://doi.org/10.1016/j.arabjc.2022.104340', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc-nd'}
DP  - OpenAlex
AU  - Siti Hajar Ahmad Shariff
AU  - Wan Khartini Wan Abdul Khodir
AU  - Shafida Abd Hamid
AU  - Muhammad Salahuddin Haris
AU  - Mohamad Wafiuddin Ismail
ER  - 

231.
TY  - journal-article
ID  - https://openalex.org/W4307947811
DO  - https://doi.org/10.3390/data7110147
TI  - Thematic Analysis of Indonesian Physics Education Research Literature Using Machine Learning
AB  - Abundant physics education research (PER) literature has been disseminated through academic publications. Over the years, the growing body of literature challenges Indonesian PER scholars to understand how the research community has progressed and possible future work that should be encouraged. Nevertheless, the previous traditional method of thematic analysis possesses limitations when the amount of PER literature exponentially increases. In order to deal with this plethora of publications, one of the machine learning (ML) algorithms from natural language processing (NLP) studies was employed in this paper to automate a thematic analysis of Indonesian PER literature that still needs to be explored within the community. One of the well-known NLP algorithms, latent Dirichlet allocation (LDA), was used in this study to extract Indonesian PER topics and their evolution between 2014 and 2021. A total of 852 papers (~4 to 8 pages each) were collectively downloaded from five international conference proceedings organized, peer reviewed, and published by Indonesian PER researchers. Before their topics were modeled through the LDA algorithm, our data corpus was preprocessed through several common procedures of established NLP studies. The findings revealed that LDA had thematically quantified Indonesian PER topics and described their distinct development over a certain period. The identified topics from this study recommended that the Indonesian PER community establish robust development in eight distinct topics to the present. Here, we commenced with an initial interest focusing on research on physics laboratories and followed the research-based instruction in late 2015. For the past few years, the Indonesian PER scholars have mostly studied 21st century skills which have given way to a focus on developing relevant educational technologies and promoting the interdisciplinary aspects of physics education. We suggest an open room for Indonesian PER scholars to address the qualitative aspects of physics teaching and learning that is still scant within the literature. Physical activity and delivery matrix may moderate some of these effects. Whether prebiotic and synbiotic interventions confer similar protection remains unclear due to few relevant studies. This trial was registered at https://www.crd.york.ac.uk/prospero/ as CRD42020220213. support of living reviews. </sec> studies were excluded by both teams. One task could not be compared between groups—&lt;i&gt;Task 8: Find the full text&lt;/i&gt;. </sec> <sec> <title>CONCLUSIONS</title> For the majority of SR tasks where an SRA tool was used, the time required to complete that task was reduced for novice researchers while methodological quality was maintained. </sec> may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken.
PY  - 2022
DA  - 2022-10-28
JO  - {'id': 'https://openalex.org/S4210226510', 'issn_l': '2306-5729', 'issn': ['2306-5729'], 'display_name': 'Data', 'publisher': 'MDPI', 'type': 'journal', 'url': 'https://www.mdpi.com/2306-5729/7/11/147/pdf?version=1668069334', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Purwoko Haryadi Santoso
AU  - Edi Istiyono
AU  - None Haryanto
AU  - Wahyu Hidayatulloh
ER  - 

232.
TY  - journal-article
ID  - https://openalex.org/W4308628131
DO  - https://doi.org/10.1016/j.iswa.2022.200150
TI  - Transferring knowledge between topics in systematic reviews
AB  - In the medical domain, a systematic review (SR) is a well-structured process aimed to review all available literature on a research question. This is however a laborious task, both in terms of money and time. As such, the automation of a SR with the aid of technology has received interest in several research communities, among which the Information Retrieval community. In this work, we experiment on the possibility of leveraging previously conducted systematic reviews to train a classifier/ranker which is later applied to a new SR. We also investigate on the possibility of pre-training Deep Learning models and eventually tuning them in an Active Learning process. Our results show that the pre-training of these models deliver a good zero-shot (i.e., with no fine-tuning) ranking, achieving an improvement of 79% for the MAP metric, with respect to a standard classifier trained on few in-domain documents. However, the pre-trained deep learning algorithms fail to deliver consistent results when continuously trained in an Active Learning scenario: our analysis shows that using smaller sized models and employing adapter modules might enable an effective active learning training. that LDA had thematically quantified Indonesian PER topics and described their distinct development over a certain period. The identified topics from this study recommended that the Indonesian PER community establish robust development in eight distinct topics to the present. Here, we commenced with an initial interest focusing on research on physics laboratories and followed the research-based instruction in late 2015. For the past few years, the Indonesian PER scholars have mostly studied 21st century skills which have given way to a focus on developing relevant educational technologies and promoting the interdisciplinary aspects of physics education. We suggest an open room for Indonesian PER scholars to address the qualitative aspects of physics teaching and learning that is still scant within the literature. Physical activity and delivery matrix may moderate some of these effects. Whether prebiotic and synbiotic interventions confer similar protection remains unclear due to few relevant studies. This trial was registered at https://www.crd.york.ac.uk/prospero/ as CRD42020220213. support of living reviews. </sec> studies were excluded by both teams. One task could not be compared between groups—&lt;i&gt;Task 8: Find the full text&lt;/i&gt;. </sec> <sec> <title>CONCLUSIONS</title> For the majority of SR tasks where an SRA tool was used, the time required to complete that task was reduced for novice researchers while methodological quality was maintained. </sec> may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken.
PY  - 2022
DA  - 2022-11-01
JO  - {'id': 'https://openalex.org/V4210234522', 'issn_l': '2667-3053', 'issn': ['2667-3053'], 'display_name': 'Intelligent systems with applications', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'https://doi.org/10.1016/j.iswa.2022.200150', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc-nd'}
DP  - OpenAlex
AU  - Alessio Molinari
AU  - Evangelos Kanoulas
ER  - 

233.
TY  - journal-article
ID  - https://openalex.org/W4309035201
DO  - https://doi.org/10.3390/polym14224847
TI  - Poly(caprolactone)-b-poly(ethylene glycol)-Based Polymeric Micelles as Drug Carriers for Efficient Breast Cancer Therapy: A Systematic Review
AB  - Recently, drug delivery systems based on nanoparticles for cancer treatment have become the centre of attention for researchers to design and fabricate drug carriers for anti-cancer drugs due to the lack of tumour-targeting activity in conventional pharmaceuticals. Poly(caprolactone)-b-poly(ethylene glycol) (PCL-PEG)-based micelles have attracted significant attention as a potential drug carrier intended for human use. Since their first discovery, the Food and Drug Administration (FDA)-approved polymers have been studied extensively for various biomedical applications, specifically cancer therapy. The application of PCL-PEG micelles in different cancer therapies has been recorded in countless research studies for their efficacy as drug cargos. However, systematic studies on the effectiveness of PCL-PEG micelles of specific cancers for pharmaceutical applications are still lacking. As breast cancer is reported as the most prevalent cancer worldwide, we aim to systematically review all available literature that has published research findings on the PCL-PEG-based micelles as drug cargo for therapy. We further discussed the preparation method and the anti-tumour efficacy of the micelles. Using a prearranged search string, Scopus and Science Direct were selected as the databases for the systematic searching strategy. Only eight of the 314 articles met the inclusion requirements and were used for data synthesis. From the review, all studies reported the efficiency of PCL-PEG-based micelles, which act as drug cargo for breast cancer therapy. topics to the present. Here, we commenced with an initial interest focusing on research on physics laboratories and followed the research-based instruction in late 2015. For the past few years, the Indonesian PER scholars have mostly studied 21st century skills which have given way to a focus on developing relevant educational technologies and promoting the interdisciplinary aspects of physics education. We suggest an open room for Indonesian PER scholars to address the qualitative aspects of physics teaching and learning that is still scant within the literature. Physical activity and delivery matrix may moderate some of these effects. Whether prebiotic and synbiotic interventions confer similar protection remains unclear due to few relevant studies. This trial was registered at https://www.crd.york.ac.uk/prospero/ as CRD42020220213. support of living reviews. </sec> studies were excluded by both teams. One task could not be compared between groups—&lt;i&gt;Task 8: Find the full text&lt;/i&gt;. </sec> <sec> <title>CONCLUSIONS</title> For the majority of SR tasks where an SRA tool was used, the time required to complete that task was reduced for novice researchers while methodological quality was maintained. </sec> may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken.
PY  - 2022
DA  - 2022-11-10
JO  - {'id': 'https://openalex.org/S123288148', 'issn_l': '2073-4360', 'issn': ['2073-4360'], 'display_name': 'Polymers', 'publisher': 'MDPI', 'type': 'journal', 'url': 'https://www.mdpi.com/2073-4360/14/22/4847/pdf?version=1668248465', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Siti Hajar Ahmad Shariff
AU  - Wan Khartini Wan Abdul Khodir
AU  - Shafida Abd Hamid
AU  - Muhammad Salahuddin Haris
AU  - Mohamad Wafiuddin Ismail
ER  - 

234.
TY  - journal-article
ID  - https://openalex.org/W4309308064
DO  - https://doi.org/10.3390/robotics11060126
TI  - Learning from Demonstrations in Human–Robot Collaborative Scenarios: A Survey
AB  - Human–Robot Collaboration (HRC) is an interdisciplinary research area that has gained attention within the smart manufacturing context. To address changes within manufacturing processes, HRC seeks to combine the impressive physical capabilities of robots with the cognitive abilities of humans to design tasks with high efficiency, repeatability, and adaptability. During the implementation of an HRC cell, a key activity is the robot programming that takes into account not only the robot restrictions and the working space, but also human interactions. One of the most promising techniques is the so-called Learning from Demonstration (LfD), this approach is based on a collection of learning algorithms, inspired by how humans imitate behaviors to learn and acquire new skills. In this way, the programming task could be simplified and provided by the shop floor operator. The aim of this work is to present a survey of this programming technique, with emphasis on collaborative scenarios rather than just an isolated task. The literature was classified and analyzed based on: the main algorithms employed for Skill/Task learning, and the human level of participation during the whole LfD process. Our analysis shows that human intervention has been poorly explored, and its implications have not been carefully considered. Among the different methods of data acquisition, the prevalent method is physical guidance. Regarding data modeling, techniques such as Dynamic Movement Primitives and Semantic Learning were the preferred methods for low-level and high-level task solving, respectively. This paper aims to provide guidance and insights for researchers looking for an introduction to LfD programming methods in collaborative robotics context and identify research opportunities. to a focus on developing relevant educational technologies and promoting the interdisciplinary aspects of physics education. We suggest an open room for Indonesian PER scholars to address the qualitative aspects of physics teaching and learning that is still scant within the literature. Physical activity and delivery matrix may moderate some of these effects. Whether prebiotic and synbiotic interventions confer similar protection remains unclear due to few relevant studies. This trial was registered at https://www.crd.york.ac.uk/prospero/ as CRD42020220213. support of living reviews. </sec> studies were excluded by both teams. One task could not be compared between groups—&lt;i&gt;Task 8: Find the full text&lt;/i&gt;. </sec> <sec> <title>CONCLUSIONS</title> For the majority of SR tasks where an SRA tool was used, the time required to complete that task was reduced for novice researchers while methodological quality was maintained. </sec> may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken.
PY  - 2022
DA  - 2022-11-15
JO  - {'id': 'https://openalex.org/V4210232487', 'issn_l': '2218-6581', 'issn': ['2218-6581'], 'display_name': 'Robotics', 'publisher': 'MDPI', 'type': 'journal', 'url': 'https://www.mdpi.com/2218-6581/11/6/126/pdf?version=1668504467', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Arturo Daniel Sosa-Ceron
AU  - Hugo G. Gonzalez-Hernandez
AU  - Jorge A. Reyes-Avendano
ER  - 

235.
TY  - journal-article
ID  - https://openalex.org/W4309811661
DO  - https://doi.org/10.1016/j.mex.2022.101935
TI  - An automated method for developing search strategies for systematic review using Natural Language Processing (NLP)
AB  - The design and implementation of systematic reviews and meta-analyses are often hampered by high financial costs, significant time commitment, and biases due to researchers' familiarity with studies. We proposed and implemented a fast and standardized method for search term selection using Natural Language Processing (NLP) and co-occurrence networks to identify relevant search terms to reduce biases in conducting systematic reviews and meta-analyses.•The method was implemented using Python packaged dubbed Ananse, which is benchmarked on the search terms strategy for naïve search proposed by Grames et al. (2019) written in "R". Ananse was applied to a case example towards finding search terms to implement a systematic literature review on cumulative effect studies on forest ecosystems.•The software automatically corrected and classified 100% of the duplicate articles identified by manual deduplication. Ananse was applied to the cumulative effects assessment case study, but it can serve as a general-purpose, open-source software system that can support extensive systematic reviews within a relatively short period with reduced biases.•Besides generating keywords, Ananse can act as middleware or a data converter for integrating multiple datasets into a database. process. Our analysis shows that human intervention has been poorly explored, and its implications have not been carefully considered. Among the different methods of data acquisition, the prevalent method is physical guidance. Regarding data modeling, techniques such as Dynamic Movement Primitives and Semantic Learning were the preferred methods for low-level and high-level task solving, respectively. This paper aims to provide guidance and insights for researchers looking for an introduction to LfD programming methods in collaborative robotics context and identify research opportunities. to a focus on developing relevant educational technologies and promoting the interdisciplinary aspects of physics education. We suggest an open room for Indonesian PER scholars to address the qualitative aspects of physics teaching and learning that is still scant within the literature. Physical activity and delivery matrix may moderate some of these effects. Whether prebiotic and synbiotic interventions confer similar protection remains unclear due to few relevant studies. This trial was registered at https://www.crd.york.ac.uk/prospero/ as CRD42020220213. support of living reviews. </sec> studies were excluded by both teams. One task could not be compared between groups—&lt;i&gt;Task 8: Find the full text&lt;/i&gt;. </sec> <sec> <title>CONCLUSIONS</title> For the majority of SR tasks where an SRA tool was used, the time required to complete that task was reduced for novice researchers while methodological quality was maintained. </sec> may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken.
PY  - 2022
DA  - 2022-11-01
JO  - {'id': 'https://openalex.org/S2898269294', 'issn_l': '2215-0161', 'issn': ['2215-0161'], 'display_name': 'MethodsX', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'http://methods-x.com/article/S2215016122003120/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Antwi Effah Kwabena
AU  - Owusu-Banahene Wiafe
AU  - Boakye-Danquah John
AU  - Asare Bernard
AU  - Frimpong A.F Boateng
ER  - 

236.
TY  - posted-content
ID  - https://openalex.org/W4309912626
DO  - https://doi.org/10.21203/rs.3.rs-2292464/v1
TI  - Automation of legal precedents retrieval: findings from a rapid literature review
AB  - Abstract Judges frequently rely their reasoning on precedents. In every circumstance, courts must preserve uniformity in case law and, depending on the legal system, previous cases compel rulings. The search for methods to accurately identify similar previous cases is not new and has been a vital input, for example, to case-based reasoning (CBR) methodologies. Innovations in language processing and machine learning (ML) brought momentum to identifying precedents while providing tools for automating this task. This rapid literature review investigated how research on the identification of legal precedents has evolved. It also examined the most promising automation strategies for this task and confirmed the growing interest in using artificial intelligence for legal precedents retrieval. The findings demonstrate that no artificial intelligence solution currently stands out as the most effective at finding past similar cases. Also, existing results require validation with statistically significant samples and ground truth provided by specialists. In addition, this work employed text mining (TM) to automate part of the literature review while still delivering an accurate picture of research in the field. Ultimately, this review suggests directions for future work, as more experimentation is required. has been poorly explored, and its implications have not been carefully considered. Among the different methods of data acquisition, the prevalent method is physical guidance. Regarding data modeling, techniques such as Dynamic Movement Primitives and Semantic Learning were the preferred methods for low-level and high-level task solving, respectively. This paper aims to provide guidance and insights for researchers looking for an introduction to LfD programming methods in collaborative robotics context and identify research opportunities. to a focus on developing relevant educational technologies and promoting the interdisciplinary aspects of physics education. We suggest an open room for Indonesian PER scholars to address the qualitative aspects of physics teaching and learning that is still scant within the literature. Physical activity and delivery matrix may moderate some of these effects. Whether prebiotic and synbiotic interventions confer similar protection remains unclear due to few relevant studies. This trial was registered at https://www.crd.york.ac.uk/prospero/ as CRD42020220213. support of living reviews. </sec> studies were excluded by both teams. One task could not be compared between groups—&lt;i&gt;Task 8: Find the full text&lt;/i&gt;. </sec> <sec> <title>CONCLUSIONS</title> For the majority of SR tasks where an SRA tool was used, the time required to complete that task was reduced for novice researchers while methodological quality was maintained. </sec> may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken.
PY  - 2022
DA  - 2022-11-23
JO  - {'id': 'https://openalex.org/S4306402450', 'issn_l': None, 'issn': None, 'display_name': 'Research Square (Research Square)', 'publisher': 'Research Square', 'type': 'repository', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Hugo Mentzingen
AU  - Fernando Bacao
AU  - Nuno António
ER  - 

237.
TY  - journal-article
ID  - https://openalex.org/W4310439492
DO  - https://doi.org/10.3310/udir6682
TI  - Increasing comprehensiveness and reducing workload in a systematic review of complex interventions using automated machine learning
AB  - As part of our ongoing systematic review of complex interventions for the primary prevention of cardiovascular diseases, we have developed and evaluated automated machine-learning classifiers for title and abstract screening. The aim was to develop a high-performing algorithm comparable to human screening.We followed a three-phase process to develop and test an automated machine learning-based classifier for screening potential studies on interventions for primary prevention of cardiovascular disease. We labelled a total of 16,611 articles during the first phase of the project. In the second phase, we used the labelled articles to develop a machine learning-based classifier. After that, we examined the performance of the classifiers in correctly labelling the papers. We evaluated the performance of the five deep-learning models [i.e. parallel convolutional neural network ( CNN ), stacked CNN , parallel-stacked CNN , recurrent neural network ( RNN ) and CNN-RNN]. The models were evaluated using recall, precision and work saved over sampling at no less than 95% recall.We labelled a total of 16,611 articles, of which 676 (4.0%) were tagged as 'relevant' and 15,935 (96%) were tagged as 'irrelevant'. The recall ranged from 51.9% to 96.6%. The precision ranged from 64.6% to 99.1%. The work saved over sampling ranged from 8.9% to as high as 92.1%. The best-performing model was parallel CNN , yielding a 96.4% recall, as well as 99.1% precision, and a potential workload reduction of 89.9%.We used words from the title and the abstract only. More work needs to be done to look into possible changes in performance, such as adding features such as full document text. The approach might also not be able to be used for other complex systematic reviews on different topics.Our study shows that machine learning has the potential to significantly aid the labour-intensive screening of abstracts in systematic reviews of complex interventions. Future research should concentrate on enhancing the classifier system and determining how it can be integrated into the systematic review workflow.This project was funded by the National Institute for Health and Care Research (NIHR) Health Technology Assessment programme and will be published in Health Technology Assessment. See the NIHR Journals Library website for further project information. Find the full text&lt;/i&gt;. </sec> <sec> <title>CONCLUSIONS</title> For the majority of SR tasks where an SRA tool was used, the time required to complete that task was reduced for novice researchers while methodological quality was maintained. </sec> may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken.
PY  - 2022
DA  - 2022-11-01
JO  - {'id': 'https://openalex.org/V191206091', 'issn_l': '1366-5278', 'issn': ['1366-5278', '2046-4924', '2046-4932'], 'display_name': 'Health Technology Assessment', 'publisher': 'NIHR Journals Library', 'type': 'journal', 'url': 'https://doi.org/10.3310/udir6682', 'is_oa': True, 'version': 'publishedVersion', 'license': 'publisher-specific license'}
DP  - OpenAlex
AU  - Olalekan A. Uthman
AU  - Rachel Court
AU  - Jodie Enderby
AU  - Lena Al-Khudairy
AU  - Chidozie U. Nduka
AU  - Hema Mistry
AU  - G. J. Melendez-Torres
AU  - Sian Taylor-Phillips
AU  - Aileen Clarke
ER  - 

238.
TY  - journal-article
ID  - https://openalex.org/W4310601443
DO  - https://doi.org/10.1097/md.0000000000031884
TI  - Nasal irrigation with various solutions for adults with allergic rhinitis: A protocol for systematic review and meta-analysis of randomized controlled trials
AB  - Nasal douching or irrigation has been recommended for adjunctive therapy of sinonasal diseases including allergic rhinitis (AR) for many years. Previous study reported large-volume high-pressure device as an effective standard application, but the solutions was remains controversy. This study systematically review the clinical efficacy of nasal irrigation with various solutions for adults with AR from medical literature.This research systematically asses clinical trial about nasal irrigation with various solutions for adults with AR from medical literature. The sources were PubMed, ProQuest, Scopus, Cochrane Register of Controlled Trials databases, and gray literature from google scholar and RAMA repository limited to English and Bahasa Indonesia language articles, published from January 2017 to July 2022. Only randomized controlled trials involving the human subjects studies will be included. The inclusion criteria research must be related to nasal irrigation for AR, and should be full texted available. Literature management, screening, data extraction will use Rayyan.ai tools. The quality assessment of qualified paper and risk of bias will be assessing independent conducted by 2 reviewer with risk of bias 2. We will use Review Manager (RevMan) [Computer program] Version 5.4. The Cochrane Collaboration, 2020 tools to produce the systematic review and meta-analysis.After completion of the study process, the data analysis and review will be reported. The results will be publicized through a peer-review journal publication.The results of the systematic review will summarize the efficacy of various nasal irrigation for adults with AR, so it can be used as clinician recommendation. be done to look into possible changes in performance, such as adding features such as full document text. The approach might also not be able to be used for other complex systematic reviews on different topics.Our study shows that machine learning has the potential to significantly aid the labour-intensive screening of abstracts in systematic reviews of complex interventions. Future research should concentrate on enhancing the classifier system and determining how it can be integrated into the systematic review workflow.This project was funded by the National Institute for Health and Care Research (NIHR) Health Technology Assessment programme and will be published in Health Technology Assessment. See the NIHR Journals Library website for further project information. Find the full text&lt;/i&gt;. </sec> <sec> <title>CONCLUSIONS</title> For the majority of SR tasks where an SRA tool was used, the time required to complete that task was reduced for novice researchers while methodological quality was maintained. </sec> may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken.
PY  - 2022
DA  - 2022-11-25
JO  - {'id': 'https://openalex.org/V28966261', 'issn_l': '0025-7974', 'issn': ['0025-7974', '1536-5964'], 'display_name': 'Medicine', 'publisher': 'Wolters Kluwer', 'type': 'journal', 'url': 'https://doi.org/10.1097/md.0000000000031884', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc'}
DP  - OpenAlex
AU  - Asti Widuri
AU  - Bambang Udji Djoko Rianto
AU  - Luh Putu Lusy Indrawati
AU  - Ranggaputra Nugraha
AU  - Abdul Wahab
ER  - 

239.
TY  - journal-article
ID  - https://openalex.org/W4311227946
DO  - https://doi.org/10.1016/j.xcrm.2022.100860
TI  - Evidence synthesis, digital scribes, and translational challenges for artificial intelligence in healthcare
AB  - <h2>Summary</h2> Healthcare has well-known challenges with safety, quality, and effectiveness, and many see artificial intelligence (AI) as essential to any solution. Emerging applications include the automated synthesis of best-practice research evidence including systematic reviews, which would ultimately see all clinical trial data published in a computational form for immediate synthesis. Digital scribes embed themselves in the process of care to detect, record, and summarize events and conversations for the electronic record. However, three persistent translational challenges must be addressed before AI is widely deployed. First, little effort is spent replicating AI trials, exposing patients to risks of methodological error and biases. Next, there is little reporting of patient harms from trials. Finally, AI built using machine learning may perform less effectively in different clinical settings. criteria research must be related to nasal irrigation for AR, and should be full texted available. Literature management, screening, data extraction will use Rayyan.ai tools. The quality assessment of qualified paper and risk of bias will be assessing independent conducted by 2 reviewer with risk of bias 2. We will use Review Manager (RevMan) [Computer program] Version 5.4. The Cochrane Collaboration, 2020 tools to produce the systematic review and meta-analysis.After completion of the study process, the data analysis and review will be reported. The results will be publicized through a peer-review journal publication.The results of the systematic review will summarize the efficacy of various nasal irrigation for adults with AR, so it can be used as clinician recommendation. be done to look into possible changes in performance, such as adding features such as full document text. The approach might also not be able to be used for other complex systematic reviews on different topics.Our study shows that machine learning has the potential to significantly aid the labour-intensive screening of abstracts in systematic reviews of complex interventions. Future research should concentrate on enhancing the classifier system and determining how it can be integrated into the systematic review workflow.This project was funded by the National Institute for Health and Care Research (NIHR) Health Technology Assessment programme and will be published in Health Technology Assessment. See the NIHR Journals Library website for further project information. Find the full text&lt;/i&gt;. </sec> <sec> <title>CONCLUSIONS</title> For the majority of SR tasks where an SRA tool was used, the time required to complete that task was reduced for novice researchers while methodological quality was maintained. </sec> may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken.
PY  - 2022
DA  - 2022-12-01
JO  - {'id': 'https://openalex.org/S4210207453', 'issn_l': '2666-3791', 'issn': ['2666-3791'], 'display_name': 'Cell reports medicine', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'http://www.cell.com/article/S2666379122004244/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Enrico Coiera
AU  - Sidong Liu
ER  - 

240.
TY  - journal-article
ID  - https://openalex.org/W4311625871
DO  - https://doi.org/10.12688/f1000research.127179.1
TI  - The role of open research in improving the standards of evidence synthesis: current challenges and potential solutions in systematic reviews
AB  - <ns3:p>Systematic reviews (SRs) and meta-analyses (MAs) are the cornerstone of evidence-based medicine and are placed at the top of the level-of-evidence pyramid. To date, there are several methodological resources available from international organizations such as the Cochrane Collaboration that aim to aid researchers in conducting high-quality secondary research and promoting reproducibility, transparency and scientific rigour. Nevertheless, researchers still face challenges in most stages of evidence synthesis. Open research and the FAIR (findability, accessibility, interoperability, and reusability) principles are rising initiatives being increasingly implemented in primary research. However, their beneficial role in secondary research is less emphasized. This article addresses how the challenges commonly faced during evidence synthesis research could be overcome using open research practices and currently available open research tools. Despite the phenomenally simple SR workflow, researchers still find tasks such as framing the SR research question, search strategy development, data extraction, and assessing for bias, challenging. The implementation of FAIR practices, including prospective registration at the PROSPERO database, abiding with the PRISMA guidelines, and making all SR data openly available could have significant benefits in avoiding duplication of effort and reducing research waste while improving the reporting standards of SRs. Additionally, this article highlights the need for further education in open research culture to overcome ethical and motivational barriers in implementing open research practices in evidence synthesis. Finally, in the era of technological breakthroughs, artificial intelligence may eventually be incorporated into the process of SRs and should abide by the FAIR standards for open research.</ns3:p> into possible changes in performance, such as adding features such as full document text. The approach might also not be able to be used for other complex systematic reviews on different topics.Our study shows that machine learning has the potential to significantly aid the labour-intensive screening of abstracts in systematic reviews of complex interventions. Future research should concentrate on enhancing the classifier system and determining how it can be integrated into the systematic review workflow.This project was funded by the National Institute for Health and Care Research (NIHR) Health Technology Assessment programme and will be published in Health Technology Assessment. See the NIHR Journals Library website for further project information. Find the full text&lt;/i&gt;. </sec> <sec> <title>CONCLUSIONS</title> For the majority of SR tasks where an SRA tool was used, the time required to complete that task was reduced for novice researchers while methodological quality was maintained. </sec> may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken.
PY  - 2022
DA  - 2022-12-05
JO  - {'id': 'https://openalex.org/S4210239046', 'issn_l': '2046-1402', 'issn': ['2046-1402'], 'display_name': 'F1000Research', 'publisher': 'Faculty of 1000', 'type': 'journal', 'url': 'https://f1000research.com/articles/11-1435/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Eirini Martinou
AU  - Angeliki Angelidi
ER  - 

241.
TY  - journal-article
ID  - https://openalex.org/W4312221385
DO  - https://doi.org/10.1016/j.infsof.2022.107145
TI  - Digital-twin-based testing for cyber–physical systems: A systematic literature review
AB  - No Abstract Found
PY  - 2022
DA  - 2022-12-01
JO  - {'id': 'https://openalex.org/S205010575', 'issn_l': '0950-5849', 'issn': ['0950-5849', '1873-6025'], 'display_name': 'Information & Software Technology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'https://doi.org/10.1016/j.infsof.2022.107145', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Richard J. Somers
AU  - James A. Douthwaite
AU  - David J. Wagg
AU  - Neil Walkinshaw
AU  - Robert M. Hierons
ER  - 

242.
TY  - journal-article
ID  - https://openalex.org/W4312310655
DO  - https://doi.org/10.19053/01211129.v31.n60.2022.14189
TI  - Semi-Automatic Mapping Technique Using Snowballing to Support Massive Literature Searches in Software Engineering
AB  - Systematic literature reviews represent an important methodology in Evidence-Based Software Engineering. To define the methodological route in these type of studies, in which a review of quantitative and qualitative aspects of primary studies is carried out to summarize the existing information regarding a particular topic, researchers use protocols that guide the construction of knowledge from research questions. This article presents a process that uses forward Snowballing, which identifies the articles cited in the paper under study and the number of citations as inclusion criteria to complement systematic literature reviews. A process that relies on software tools was designed to apply the Snowballing strategy and to identify the most cited works and those who cite them. To validate the process, a review identified in the literature was used. After comparing the results, new works that were not taken into account but made contributions to the subject of study emerged. The citation index represents the number of times a publication has been referenced in other documents and is used as a mechanism to analyze, measure, or quantitatively assess the impact of said publication on the scientific community. The present study showed how applying Snowballing along with other strategies enables the emergence of works that may be relevant for an investigation given the citations rate. That is, implementing this proposal will allow updating or expanding systematic literature studies through the new works evidenced. be incorporated into the process of SRs and should abide by the FAIR standards for open research.</ns3:p> into possible changes in performance, such as adding features such as full document text. The approach might also not be able to be used for other complex systematic reviews on different topics.Our study shows that machine learning has the potential to significantly aid the labour-intensive screening of abstracts in systematic reviews of complex interventions. Future research should concentrate on enhancing the classifier system and determining how it can be integrated into the systematic review workflow.This project was funded by the National Institute for Health and Care Research (NIHR) Health Technology Assessment programme and will be published in Health Technology Assessment. See the NIHR Journals Library website for further project information. Find the full text&lt;/i&gt;. </sec> <sec> <title>CONCLUSIONS</title> For the majority of SR tasks where an SRA tool was used, the time required to complete that task was reduced for novice researchers while methodological quality was maintained. </sec> may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken.
PY  - 2022
DA  - 2022-05-21
JO  - {'id': 'https://openalex.org/S4210234188', 'issn_l': '0121-1129', 'issn': ['2357-5328', '0121-1129'], 'display_name': 'Revista Facultad de Ingeniería', 'publisher': 'Pedagogical and Technological University of Colombia', 'type': 'journal', 'url': 'https://revistas.uptc.edu.co/index.php/ingenieria/article/download/14189/11721', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Elizabeth Suescún
AU  - Julio-Cesar Sampaio-do-Prado-Leite
AU  - César Pardo
ER  - 

243.
TY  - journal-article
ID  - https://openalex.org/W4313446661
DO  - https://doi.org/10.1186/s13643-022-02163-4
TI  - Unsupervised title and abstract screening for systematic review: a retrospective case-study using topic modelling methodology
AB  - Abstract Background The importance of systematic reviews in collating and summarising available research output on a particular topic cannot be over-emphasized. However, initial screening of retrieved literature is significantly time and labour intensive. Attempts at automating parts of the systematic review process have been made with varying degree of success partly due to being domain-specific, requiring vendor-specific software or manually labelled training data. Our primary objective was to develop statistical methodology for performing automated title and abstract screening for systematic reviews. Secondary objectives included (1) to retrospectively apply the automated screening methodology to previously manually screened systematic reviews and (2) to characterize the performance of the automated screening methodology scoring algorithm in a simulation study. Methods We implemented a Latent Dirichlet Allocation-based topic model to derive representative topics from the retrieved documents’ title and abstract. The second step involves defining a score threshold for classifying the documents as relevant for full-text review or not. The score is derived based on a set of search keywords (often the database retrieval search terms). Two systematic review studies were retrospectively used to illustrate the methodology. Results In one case study (helminth dataset), $$69.83\%$$ <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"> <mml:mrow> <mml:mn>69.83</mml:mn> <mml:mo>%</mml:mo> </mml:mrow> </mml:math> sensitivity compared to manual title and abstract screening was achieved. This is against a false positive rate of $$22.63\%$$ <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"> <mml:mrow> <mml:mn>22.63</mml:mn> <mml:mo>%</mml:mo> </mml:mrow> </mml:math> . For the second case study (Wilson disease dataset), a sensitivity of $$54.02\%$$ <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"> <mml:mrow> <mml:mn>54.02</mml:mn> <mml:mo>%</mml:mo> </mml:mrow> </mml:math> and specificity of $$67.03\%$$ <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"> <mml:mrow> <mml:mn>67.03</mml:mn> <mml:mo>%</mml:mo> </mml:mrow> </mml:math> were achieved. Conclusions Unsupervised title and abstract screening has the potential to reduce the workload involved in conducting systematic review. While sensitivity of the methodology on the tested data is low, approximately $$70\%$$ <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"> <mml:mrow> <mml:mn>70</mml:mn> <mml:mo>%</mml:mo> </mml:mrow> </mml:math> specificity was achieved. Users ought to keep in mind that potentially low sensitivity might occur. One approach to mitigate this might be to incorporate additional targeted search keywords such as the indexing databases terms into the search term copora. Moreover, automated screening can be used as an additional screener to the manual screeners. See the NIHR Journals Library website for further project information. Find the full text&lt;/i&gt;. </sec> <sec> <title>CONCLUSIONS</title> For the majority of SR tasks where an SRA tool was used, the time required to complete that task was reduced for novice researchers while methodological quality was maintained. </sec> may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken.
PY  - 2023
DA  - 2023-01-03
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://systematicreviewsjournal.biomedcentral.com/counter/pdf/10.1186/s13643-022-02163-4', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Leacky Muchene
AU  - Leacky K Muchene
ER  - 

244.
TY  - journal-article
ID  - https://openalex.org/W4318225126
DO  - https://doi.org/10.12688/f1000research.125198.2
TI  - (Semi)automated approaches to data extraction for systematic reviews and meta-analyses in social sciences: A living review protocol
AB  - <ns3:p><ns3:bold>Background</ns3:bold>: An abundance of rapidly accumulating scientific evidence presents novel opportunities for researchers and practitioners alike, yet such advantages are often overshadowed by resource demands associated with finding and aggregating a continually expanding body of scientific information. Across social science disciplines, the use of automation technologies for timely and accurate knowledge synthesis can enhance research translation value, better inform key policy development, and expand the current understanding of human interactions, organizations, and systems. Ongoing developments surrounding automation are highly concentrated in research for evidence-based medicine with limited evidence surrounding tools and techniques applied outside of the clinical research community. Our objective is to conduct a living systematic review of automated data extraction techniques supporting systematic reviews and meta-analyses in the social sciences. The aim of this study is to extend the automation knowledge base by synthesizing current trends in the application of extraction technologies of key data elements of interest for social scientists.</ns3:p><ns3:p> <ns3:bold>Methods</ns3:bold>: The proposed study is a living systematic review employing a partial replication framework based on extant literature surrounding automation of data extraction for systematic reviews and meta-analyses. Protocol development, base review, and updates follow PRISMA standards for reporting systematic reviews. This protocol is preregistered in OSF: <ns3:ext-link xmlns:ns4="http://www.w3.org/1999/xlink" ext-link-type="uri" ns4:href="https://doi.org/10.17605/OSF.IO/YWTF9">(Semi)Automated Approaches to Data Extraction for Systematic Reviews and Meta-Analyses in Social Sciences: A Living Review Protocol</ns3:ext-link> on August 14, 2022.</ns3:p><ns3:p> <ns3:bold>Conclusions</ns3:bold>: Anticipated outcomes of this study include: (a) generate insights supporting advancement in transferring existing reliable methods to social science research; (b) provide a foundation for protocol development leading to enhancement of comparability and benchmarking standards across disciplines; and (c) uncover exigencies that spur continued value-adding innovation and interdisciplinary collaboration for the benefit of the collective systematic review community.</ns3:p> is low, approximately $$70\%$$ <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"> <mml:mrow> <mml:mn>70</mml:mn> <mml:mo>%</mml:mo> </mml:mrow> </mml:math> specificity was achieved. Users ought to keep in mind that potentially low sensitivity might occur. One approach to mitigate this might be to incorporate additional targeted search keywords such as the indexing databases terms into the search term copora. Moreover, automated screening can be used as an additional screener to the manual screeners. See the NIHR Journals Library website for further project information. Find the full text&lt;/i&gt;. </sec> <sec> <title>CONCLUSIONS</title> For the majority of SR tasks where an SRA tool was used, the time required to complete that task was reduced for novice researchers while methodological quality was maintained. </sec> may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken.
PY  - 2023
DA  - 2023-01-27
JO  - {'id': 'https://openalex.org/S4210239046', 'issn_l': '2046-1402', 'issn': ['2046-1402'], 'display_name': 'F1000Research', 'publisher': 'Faculty of 1000', 'type': 'journal', 'url': 'https://f1000research.com/articles/11-1036/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Amanda Legate
AU  - Kim Nimon
ER  - 

245.
TY  - journal-article
ID  - https://openalex.org/W4318664208
DO  - https://doi.org/10.2196/35568
TI  - Automating Quality Assessment of Medical Evidence in Systematic Reviews (Preprint)
AB  - Assessment of the quality of medical evidence available online is a critical step in the systematic review of clinical evidence. Existing tools that automate parts of this task validate the quality of individual studies but not of entire bodies of evidence, and focus on a restricted set of quality criteria.We propose a quality assessment task that consists of providing an overall quality rating for each outcome, as well as finer-grained justification for different quality criteria according to the GRADE formalisation framework. For this, we construct a new dataset and develop a machine-learning baseline system (EvidenceGRADEr). Our goal is to work towards evaluating the quality of a body of evidence (BoE) for a specific clinical question, rather than assessing the quality of individual primary studies.We algorithmically extracted quality-related data from all summaries of findings found in the Cochrane Database of Systematic Reviews (CDSR). Each BoE is defined by a set of PICO criteria (population-intervention-comparison-outcome) and assigned a quality grade (high/moderate/low/very low) together with quality criteria (justification) that influenced that decision. Different statistical data, metadata about the review, and parts of review text are extracted as support for grading each BoE. After pruning the resulting dataset with various quality checks, we used it to train several variants of a feature-rich neural model. The predictions were compared against the labels originally assigned by the authors of the systematic reviews.Our quality assessment dataset, CDSR-QoE, contains 13,440 instances, or BoEs labelled for quality, originating from 2,252 systematic reviews published on the Internet in the years 2002--2020. Based on 10-fold cross-validation, the best neural binary classifiers for quality criteria detect risk of bias at .78 F1 (P: .68, R: .92) and imprecision at .75 F1 (P: .66, R: .86), while the performance on inconsistency, indirectness and publication bias criteria is lower (F1 in the range of .3-.4). The prediction of the overall quality grade into one of the four levels results in 0.5 F1. When casting the task as a binary problem by merging the GRADE classes (high+moderate vs. low+very low quality evidence), we attain .74 F1. We also find that the results vary depending on what supporting information is provided as input to the models.There are different factors affecting the quality of evidence in the context of systematic reviews of medical evidence. Some of them (risk of bias and imprecision) can be automated with reasonable accuracy. Other quality dimensions such as indirectness, inconsistency, and publication bias prove more challenging for machine learning, largely because they are much rarer. This technology could substantially reduce reviewer workload in the future and expedite quality assessment as part of evidence synthesis. such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken.
PY  - 2021
DA  - 2021-12-12
JO  - {'id': 'https://openalex.org/V17147534', 'issn_l': '1438-8871', 'issn': ['1439-4456', '1438-8871'], 'display_name': 'Journal of Medical Internet Research', 'publisher': 'JMIR Publications', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Simon Šuster
AU  - Timothy Baldwin
AU  - Jey Han Lau
AU  - Antonio Jimeno Yepes
AU  - David Martinez Iraola
AU  - Yulia Otmakhova
AU  - Karin Verspoor
ER  - 

246.
TY  - journal-article
ID  - https://openalex.org/W4319785800
DO  - https://doi.org/10.1080/01441647.2023.2175275
TI  - A meta-evaluation of climate policy evaluations: findings from the freight transport sector
AB  - No Abstract Found
PY  - 2023
DA  - 2023-02-08
JO  - {'id': 'https://openalex.org/S194388667', 'issn_l': '0144-1647', 'issn': ['0144-1647', '1464-5327'], 'display_name': 'Transport Reviews', 'publisher': 'Taylor & Francis', 'type': 'journal', 'url': 'https://doi.org/10.1080/01441647.2023.2175275', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc-nd'}
DP  - OpenAlex
AU  - Lina Trosvik
AU  - Johanna Takman
AU  - Lisa Björk
AU  - Jenny Norrman
AU  - Yvonne Andersson-Sköld
ER  - 

247.
TY  - journal-article
ID  - https://openalex.org/W4320485868
DO  - https://doi.org/10.28982/josam.7709
TI  - Orthopedic surgeons’ attitudes and expectations toward artificial intelligence: A national survey study
AB  - Background/Aim: There is a lack of understanding of artificial intelligence (AI) among orthopedic surgeons regarding how it can be used in their clinical practices. This study aimed to evaluate the attitudes of orthopedic surgeons regarding the application of AI in their practices. Methods: A cross-sectional study was conducted in Turkey among 189 orthopedic surgeons between November 2021 and February 2022. An electronic survey was designed using the SurveyMonkey platform. The questionnaire included six subsections related to AI usefulness in clinical practice and participants’ knowledge about the topic. It also surveyed their acceptance level of learning, concerns about the potential risks of AI, and implementation of this technology into their daily practice Results: A total of 33.9% of the participants indicated that they were familiar with the concept of AI, while 82.5% planned to learn about artificial intelligence in the coming years. Most of the surgeons (68.3%) reported not using AI in their daily practice. The activities of orthopedic associations focused on AI were insufficient according to 77.2% of participants. Orthopedic surgeons expressed concern over AI involvement in the future regarding an insensitive and nonempathic attitude toward the patient (53.5%). A majority of respondents (80.4%) indicated that AI was most feasible in extremity reconstruction. Pelvis fractures were found in the region where the AI system is most needed in the fracture classification (68.7%). Conclusion: Most of the respondents did not use AI in their daily clinical practice; however, almost all surgeons had plans to learn about artificial intelligence in the future. There was a need to improve orthopedic associations’ activities focusing on artificial intelligence. Furthermore, new research including the medical ethics issues of the field will be needed to allay the surgeons’ worries. The classification system of pelvic fractures and sub-branches of orthopedic extremity reconstruction were the most feasible areas for AI systems. We believe that this study will serve as a guide for all branches of orthopedic medicine. When casting the task as a binary problem by merging the GRADE classes (high+moderate vs. low+very low quality evidence), we attain .74 F1. We also find that the results vary depending on what supporting information is provided as input to the models.There are different factors affecting the quality of evidence in the context of systematic reviews of medical evidence. Some of them (risk of bias and imprecision) can be automated with reasonable accuracy. Other quality dimensions such as indirectness, inconsistency, and publication bias prove more challenging for machine learning, largely because they are much rarer. This technology could substantially reduce reviewer workload in the future and expedite quality assessment as part of evidence synthesis. such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken.
PY  - 2023
DA  - 2023-02-13
JO  - {'id': 'https://openalex.org/S4210219070', 'issn_l': '2602-2079', 'issn': ['2602-2079'], 'display_name': 'Journal of surgery and medicine', 'publisher': 'Journal of Surgery and Medicine', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Ertuğrul Şahin
AU  - Haluk Berk
ER  - 

248.
TY  - journal-article
ID  - https://openalex.org/W3118615836
DO  - https://doi.org/10.1136/bmj.n71
TI  - The PRISMA 2020 statement: an updated guideline for reporting systematic reviews
AB  - The Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) statement, published in 2009, was designed to help systematic reviewers transparently report why the review was done, what the authors did, and what they found. Over the past decade, advances in systematic review methodology and terminology have necessitated an update to the guideline. The PRISMA 2020 statement replaces the 2009 statement and includes new reporting guidance that reflects advances in methods to identify, select, appraise, and synthesise studies. The structure and presentation of the items have been modified to facilitate implementation. In this article, we present the PRISMA 2020 27-item checklist, an expanded checklist that details reporting recommendations for each item, the PRISMA 2020 abstract checklist, and the revised flow diagrams for original and updated reviews.
PY  - 2021
DA  - 2021-03-29
JO  - {'id': 'https://openalex.org/S4210185579', 'issn_l': '1756-1833', 'issn': ['1756-1833'], 'display_name': 'BMJ', 'publisher': 'BMJ', 'type': 'journal', 'url': 'https://www.bmj.com/content/bmj/372/bmj.n71.full.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Matthew J. Page
AU  - Joanne E. McKenzie
AU  - Patrick M.M. Bossuyt
AU  - Isabelle Boutron
AU  - Tammy Hoffmann
AU  - Cynthia D. Mulrow
AU  - Larissa Shamseer
AU  - Jennifer Tetzlaff
AU  - Elie A. Akl
AU  - Sue E. Brennan
AU  - Roger Chou
AU  - Julie Glanville
AU  - Jeremy M. Grimshaw
AU  - Asbjørn Hróbjartsson
AU  - Manoj M. Lalu
AU  - Tianjing Li
AU  - Elizabeth Loder
AU  - Evan Mayo-Wilson
AU  - Steve McDonald
AU  - Adrian M. Price-Whelan
AU  - Lesley A. Stewart
AU  - James D. Thomas
AU  - Andrea C. Tricco
AU  - Vivian Welch
AU  - Penny Whiting
AU  - David Moher
ER  - 

249.
TY  - journal-article
ID  - https://openalex.org/W3123893780
DO  - https://doi.org/10.1136/bmj.n160
TI  - PRISMA 2020 explanation and elaboration: updated guidance and exemplars for reporting systematic reviews
AB  - The methods and results of systematic reviews should be reported in sufficient detail to allow users to assess the trustworthiness and applicability of the review findings. The Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) statement was developed to facilitate transparent and complete reporting of systematic reviews and has been updated (to PRISMA 2020) to reflect recent advances in systematic review methodology and terminology. Here, we present the explanation and elaboration paper for PRISMA 2020, where we explain why reporting of each item is recommended, present bullet points that detail the reporting recommendations, and present examples from published reviews. We hope that changes to the content and structure of PRISMA 2020 will facilitate uptake of the guideline and lead to more transparent, complete, and accurate reporting of systematic reviews.
PY  - 2021
DA  - 2021-03-29
JO  - {'id': 'https://openalex.org/S4210185579', 'issn_l': '1756-1833', 'issn': ['1756-1833'], 'display_name': 'BMJ', 'publisher': 'BMJ', 'type': 'journal', 'url': 'https://www.bmj.com/content/bmj/372/bmj.n160.full.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Matthew J. Page
AU  - David Moher
AU  - Patrick M.M. Bossuyt
AU  - Isabelle Boutron
AU  - Tammy Hoffmann
AU  - Cynthia D. Mulrow
AU  - Larissa Shamseer
AU  - Jennifer Tetzlaff
AU  - Elie A. Akl
AU  - Sue E. Brennan
AU  - Roger Chou
AU  - Julie Glanville
AU  - Jeremy M. Grimshaw
AU  - Asbjørn Hróbjartsson
AU  - Manoj M. Lalu
AU  - Tianjing Li
AU  - Elizabeth Loder
AU  - Evan Mayo-Wilson
AU  - Steve McDonald
AU  - Adrian M. Price-Whelan
AU  - Lesley A. Stewart
AU  - James D. Thomas
AU  - Andrea C. Tricco
AU  - Vivian Welch
AU  - Penny Whiting
AU  - Joanne E. McKenzie
ER  - 

250.
TY  - journal-article
ID  - https://openalex.org/W3144543375
DO  - https://doi.org/10.1186/s13643-021-01626-4
TI  - The PRISMA 2020 statement: an updated guideline for reporting systematic reviews
AB  - The Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) statement, published in 2009, was designed to help systematic reviewers transparently report why the review was done, what the authors did, and what they found. Over the past decade, advances in systematic review methodology and terminology have necessitated an update to the guideline. The PRISMA 2020 statement replaces the 2009 statement and includes new reporting guidance that reflects advances in methods to identify, select, appraise, and synthesise studies. The structure and presentation of the items have been modified to facilitate implementation. In this article, we present the PRISMA 2020 27-item checklist, an expanded checklist that details reporting recommendations for each item, the PRISMA 2020 abstract checklist, and the revised flow diagrams for original and updated reviews. reporting of systematic reviews.
PY  - 2021
DA  - 2021-03-29
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://systematicreviewsjournal.biomedcentral.com/track/pdf/10.1186/s13643-021-01626-4', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Matthew J. Page
AU  - Joanne E. McKenzie
AU  - Patrick M.M. Bossuyt
AU  - Isabelle Boutron
AU  - Tammy Hoffmann
AU  - Cynthia D. Mulrow
AU  - Larissa Shamseer
AU  - Jennifer Tetzlaff
AU  - Elie A. Akl
AU  - Sue E. Brennan
AU  - Roger Chou
AU  - Julie Glanville
AU  - Jeremy M. Grimshaw
AU  - Asbjørn Hróbjartsson
AU  - Manoj M. Lalu
AU  - Tianjing Li
AU  - Elizabeth Loder
AU  - Evan Mayo-Wilson
AU  - Steve McDonald
AU  - Adrian M. Price-Whelan
AU  - Lesley A. Stewart
AU  - James D. Thomas
AU  - Andrea C. Tricco
AU  - Vivian Welch
AU  - Penny Whiting
AU  - David Moher
ER  - 

251.
TY  - journal-article
ID  - https://openalex.org/W3146142859
DO  - https://doi.org/10.1016/j.ijsu.2021.105906
TI  - The PRISMA 2020 statement: An updated guideline for reporting systematic reviews
AB  - The Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) statement, published in 2009, was designed to help systematic reviewers transparently report why the review was done, what the authors did, and what they found. Over the past decade, advances in systematic review methodology and terminology have necessitated an update to the guideline. The PRISMA 2020 statement replaces the 2009 statement and includes new reporting guidance that reflects advances in methods to identify, select, appraise, and synthesise studies. The structure and presentation of the items have been modified to facilitate implementation. In this article, we present the PRISMA 2020 27-item checklist, an expanded checklist that details reporting recommendations for each item, the PRISMA 2020 abstract checklist, and the revised flow diagrams for original and updated reviews. reporting of systematic reviews.
PY  - 2021
DA  - 2021-03-29
JO  - {'id': 'https://openalex.org/S67965910', 'issn_l': '1743-9159', 'issn': ['1743-9191', '1743-9159'], 'display_name': 'International Journal of Surgery', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Matthew J. Page
AU  - Joanne E. McKenzie
AU  - Patrick M.M. Bossuyt
AU  - Isabelle Boutron
AU  - Tammy Hoffmann
AU  - Cynthia D. Mulrow
AU  - Larissa Shamseer
AU  - Jennifer Tetzlaff
AU  - Elie A. Akl
AU  - Sue E. Brennan
AU  - Roger Chou
AU  - Julie Glanville
AU  - Jeremy M. Grimshaw
AU  - Asbjørn Hróbjartsson
AU  - Manoj M. Lalu
AU  - Tianjing Li
AU  - Elizabeth Loder
AU  - Evan Mayo-Wilson
AU  - Steve McDonald
AU  - Adrian M. Price-Whelan
AU  - Lesley A. Stewart
AU  - James D. Thomas
AU  - Andrea C. Tricco
AU  - Vivian Welch
AU  - Penny Whiting
AU  - David Moher
ER  - 

252.
TY  - journal-article
ID  - https://openalex.org/W3148962211
DO  - https://doi.org/10.1371/journal.pmed.1003583
TI  - The PRISMA 2020 statement: An updated guideline for reporting systematic reviews
AB  - Matthew Page and co-authors describe PRISMA 2020, an updated reporting guideline for systematic reviews and meta-analyses. to help systematic reviewers transparently report why the review was done, what the authors did, and what they found. Over the past decade, advances in systematic review methodology and terminology have necessitated an update to the guideline. The PRISMA 2020 statement replaces the 2009 statement and includes new reporting guidance that reflects advances in methods to identify, select, appraise, and synthesise studies. The structure and presentation of the items have been modified to facilitate implementation. In this article, we present the PRISMA 2020 27-item checklist, an expanded checklist that details reporting recommendations for each item, the PRISMA 2020 abstract checklist, and the revised flow diagrams for original and updated reviews. reporting of systematic reviews.
PY  - 2021
DA  - 2021-03-29
JO  - {'id': 'https://openalex.org/S197939330', 'issn_l': '1549-1277', 'issn': ['1549-1676', '1549-1277'], 'display_name': 'PLOS Medicine', 'publisher': 'Public Library of Science', 'type': 'journal', 'url': 'https://journals.plos.org/plosmedicine/article/file?id=10.1371/journal.pmed.1003583&type=printable', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Matthew J. Page
AU  - Joanne E. McKenzie
AU  - Patrick M.M. Bossuyt
AU  - Isabelle Boutron
AU  - Tammy Hoffmann
AU  - Cynthia D. Mulrow
AU  - Larissa Shamseer
AU  - Jennifer Tetzlaff
AU  - Elie A. Akl
AU  - Sue E. Brennan
AU  - Roger Chou
AU  - Julie Glanville
AU  - Jeremy M. Grimshaw
AU  - Asbjørn Hróbjartsson
AU  - Manoj M. Lalu
AU  - Tianjing Li
AU  - Elizabeth Loder
AU  - Evan Mayo-Wilson
AU  - Steve McDonald
AU  - Adrian M. Price-Whelan
AU  - Lesley A. Stewart
AU  - James D. Thomas
AU  - Andrea C. Tricco
AU  - Vivian Welch
AU  - Penny Whiting
AU  - David Moher
ER  - 

253.
TY  - journal-article
ID  - https://openalex.org/W3141256924
DO  - https://doi.org/10.1016/j.jclinepi.2021.03.001
TI  - The PRISMA 2020 statement: An updated guideline for reporting systematic reviews
AB  - <h2>Abstract</h2> The Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) statement, published in 2009, was designed to help systematic reviewers transparently report why the review was done, what the authors did, and what they found. Over the past decade, advances in systematic review methodology and terminology have necessitated an update to the guideline. The PRISMA 2020 statement replaces the 2009 statement and includes new reporting guidance that reflects advances in methods to identify, select, appraise, and synthesise studies. The structure and presentation of the items have been modified to facilitate implementation. In this article, we present the PRISMA 2020 27-item checklist, an expanded checklist that details reporting recommendations for each item, the PRISMA 2020 abstract checklist, and the revised flow diagrams for original and updated reviews. of systematic reviews.
PY  - 2021
DA  - 2021-06-01
JO  - {'id': 'https://openalex.org/S64418186', 'issn_l': '0895-4356', 'issn': ['1878-5921', '0895-4356'], 'display_name': 'Journal of Clinical Epidemiology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'http://www.jclinepi.com/article/S0895435621000731/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Matthew J. Page
AU  - Joanne E. McKenzie
AU  - Patrick M.M. Bossuyt
AU  - Isabelle Boutron
AU  - Tammy Hoffmann
AU  - Cynthia D. Mulrow
AU  - Larissa Shamseer
AU  - Jennifer Tetzlaff
AU  - Elie A. Akl
AU  - Sue E. Brennan
AU  - Roger Chou
AU  - Julie Glanville
AU  - Jeremy M. Grimshaw
AU  - Asbjørn Hróbjartsson
AU  - Manoj M. Lalu
AU  - Tianjing Li
AU  - Elizabeth Loder
AU  - Evan Mayo-Wilson
AU  - Steve McDonald
AU  - Adrian M. Price-Whelan
AU  - Lesley A. Stewart
AU  - James D. Thomas
AU  - Andrea C. Tricco
AU  - Vivian Welch
AU  - Penny Whiting
AU  - David Moher
ER  - 

254.
TY  - journal-article
ID  - https://openalex.org/W3191480438
DO  - https://doi.org/10.1016/j.recesp.2021.06.016
TI  - Declaración PRISMA 2020: una guía actualizada para la publicación de revisiones sistemáticas
AB  - La declaración PRISMA ( Preferred Reporting Items for Systematic reviews and Meta-Analyses ), publicada en 2009, se diseñó para ayudar a los autores de revisiones sistemáticas a documentar de manera transparente el porqué de la revisión, qué hicieron los autores y qué encontraron. Durante la última década, ha habido muchos avances en la metodología y terminología de las revisiones sistemáticas, lo que ha requerido una actualización de esta guía. La declaración prisma 2020 sustituye a la declaración de 2009 e incluye una nueva guía de presentación de las publicaciones que refleja los avances en los métodos para identificar, seleccionar, evaluar y sintetizar estudios. La estructura y la presentación de los ítems ha sido modificada para facilitar su implementación. En este artículo, presentamos la lista de verificación PRISMA 2020 con 27 ítems, y una lista de verificación ampliada que detalla las recomendaciones en la publicación de cada ítem, la lista de verificación del resumen estructurado PRISMA 2020 y el diagrama de flujo revisado para revisiones sistemáticas. The Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) statement, published in 2009, was designed to help systematic reviewers transparently report why the review was done, what the authors did, and what they found. Over the past decade, advances in systematic review methodology and terminology have necessitated an update to the guideline. The PRISMA 2020 statement replaces the 2009 statement and includes new reporting guidance that reflects advances in methods to identify, select, appraise, and synthesise studies. The structure and presentation of the items have been modified to facilitate implementation. In this article, we present the PRISMA 2020 27-item checklist, an expanded checklist that details reporting recommendations for each item, the PRISMA 2020 abstract checklist, and the revised flow diagrams for original and updated reviews. Full English text available from : www.revespcardiol.org/en
PY  - 2021
DA  - 2021-09-01
JO  - {'id': 'https://openalex.org/S69770752', 'issn_l': '0300-8932', 'issn': ['1579-2242', '0300-8932', '1577-3698'], 'display_name': 'Revista Espanola De Cardiologia', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'https://doi.org/10.1016/j.recesp.2021.06.016', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc-nd'}
DP  - OpenAlex
AU  - Juan José Yepes-Nuñez
AU  - Gerard Urrútia
AU  - Marta Romero-García
AU  - Sergio Alonso-Fernández
ER  - 

255.
TY  - journal-article
ID  - https://openalex.org/W3193329895
DO  - https://doi.org/10.1016/j.rec.2021.07.010
TI  - Declaración PRISMA 2020: una guía actualizada para la publicación de revisiones sistemáticas
AB  - The Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) statement, published in 2009, was designed to help systematic reviewers transparently report why the review was done, what the authors did, and what they found. Over the past decade, advances in systematic review methodology and terminology have necessitated an update to the guideline. The PRISMA 2020 statement replaces the 2009 statement and includes new reporting guidance that reflects advances in methods to identify, select, appraise, and synthesise studies. The structure and presentation of the items have been modified to facilitate implementation. In this article, we present the PRISMA 2020 27-item checklist, an expanded checklist that details reporting recommendations for each item, the PRISMA 2020 abstract checklist, and the revised flow diagrams for original and updated reviews. Full English text available from:www.revespcardiol.org/en. y una lista de verificación ampliada que detalla las recomendaciones en la publicación de cada ítem, la lista de verificación del resumen estructurado PRISMA 2020 y el diagrama de flujo revisado para revisiones sistemáticas. The Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) statement, published in 2009, was designed to help systematic reviewers transparently report why the review was done, what the authors did, and what they found. Over the past decade, advances in systematic review methodology and terminology have necessitated an update to the guideline. The PRISMA 2020 statement replaces the 2009 statement and includes new reporting guidance that reflects advances in methods to identify, select, appraise, and synthesise studies. The structure and presentation of the items have been modified to facilitate implementation. In this article, we present the PRISMA 2020 27-item checklist, an expanded checklist that details reporting recommendations for each item, the PRISMA 2020 abstract checklist, and the revised flow diagrams for original and updated reviews. Full English text available from : www.revespcardiol.org/en
PY  - 2021
DA  - 2021-09-01
JO  - {'id': 'https://openalex.org/S4210221393', 'issn_l': '1885-5857', 'issn': ['1885-5857'], 'display_name': 'Revista española de cardiología', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'https://doi.org/10.1016/j.rec.2021.07.010', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc-nd'}
DP  - OpenAlex
AU  - Juan José Yepes-Nuñez
AU  - Gerard Urrútia
AU  - Marta Romero-García
AU  - Sergio Alonso-Fernández
ER  - 

256.
TY  - proceedings-article
ID  - https://openalex.org/W3099977667
DO  - https://doi.org/10.18653/v1/2020.emnlp-main.609
TI  - Fact or Fiction: Verifying Scientific Claims
AB  - We introduce scientific claim verification, a new task to select abstracts from the research literature containing evidence that SUPPORTS or REFUTES a given scientific claim, and to identify rationales justifying each decision. To study this task, we construct SciFact, a dataset of 1.4K expert-written scientific claims paired with evidence-containing abstracts annotated with labels and rationales. We develop baseline models for SciFact, and demonstrate that simple domain adaptation techniques substantially improve performance compared to models trained on Wikipedia or political news. We show that our system is able to verify claims related to COVID-19 by identifying evidence from the CORD-19 corpus. Our experiments indicate that SciFact will provide a challenging testbed for the development of new systems designed to retrieve and reason over corpora containing specialized domain knowledge. Data and code for this new task are publicly available at https://github.com/allenai/scifact. A leaderboard and COVID-19 fact-checking demo are available at https://scifact.apps.allenai.org. de verificación del resumen estructurado PRISMA 2020 y el diagrama de flujo revisado para revisiones sistemáticas. The Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) statement, published in 2009, was designed to help systematic reviewers transparently report why the review was done, what the authors did, and what they found. Over the past decade, advances in systematic review methodology and terminology have necessitated an update to the guideline. The PRISMA 2020 statement replaces the 2009 statement and includes new reporting guidance that reflects advances in methods to identify, select, appraise, and synthesise studies. The structure and presentation of the items have been modified to facilitate implementation. In this article, we present the PRISMA 2020 27-item checklist, an expanded checklist that details reporting recommendations for each item, the PRISMA 2020 abstract checklist, and the revised flow diagrams for original and updated reviews. Full English text available from : www.revespcardiol.org/en
PY  - 2020
DA  - 2020-04-30
JO  - {'id': 'https://openalex.org/V4306418267', 'issn_l': None, 'issn': None, 'display_name': 'Empirical Methods in Natural Language Processing', 'publisher': None, 'type': 'conference', 'url': 'https://www.aclweb.org/anthology/2020.emnlp-main.609.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - David Wadden
AU  - Shanchuan Lin
AU  - Kyle Lo
AU  - Lucy Lu Wang
AU  - Madeleine van Zuylen
AU  - Arman Cohan
AU  - Hannaneh Hajishirzi
ER  - 

257.
TY  - journal-article
ID  - https://openalex.org/W3128349626
DO  - https://doi.org/10.1038/s42256-020-00287-7
TI  - An open source machine learning framework for efficient and transparent systematic reviews
AB  - To help researchers conduct a systematic review or meta-analysis as efficiently and transparently as possible, we designed a tool (ASReview) to accelerate the step of screening titles and abstracts. For many tasks - including but not limited to systematic reviews and meta-analyses - the scientific literature needs to be checked systematically. Currently, scholars and practitioners screen thousands of studies by hand to determine which studies to include in their review or meta-analysis. This is error prone and inefficient because of extremely imbalanced data: only a fraction of the screened studies is relevant. The future of systematic reviewing will be an interaction with machine learning algorithms to deal with the enormous increase of available text. We therefore developed an open source machine learning-aided pipeline applying active learning: ASReview. We demonstrate by means of simulation studies that ASReview can yield far more efficient reviewing than manual reviewing, while providing high quality. Furthermore, we describe the options of the free and open source research software and present the results from user experience tests. We invite the community to contribute to open source projects such as our own that provide measurable and reproducible improvements over current practice. the authors did, and what they found. Over the past decade, advances in systematic review methodology and terminology have necessitated an update to the guideline. The PRISMA 2020 statement replaces the 2009 statement and includes new reporting guidance that reflects advances in methods to identify, select, appraise, and synthesise studies. The structure and presentation of the items have been modified to facilitate implementation. In this article, we present the PRISMA 2020 27-item checklist, an expanded checklist that details reporting recommendations for each item, the PRISMA 2020 abstract checklist, and the revised flow diagrams for original and updated reviews. Full English text available from : www.revespcardiol.org/en
PY  - 2021
DA  - 2021-02-01
JO  - {'id': 'https://openalex.org/S2912241403', 'issn_l': '2522-5839', 'issn': ['2522-5839'], 'display_name': 'Nature Machine Intelligence', 'publisher': 'Nature Portfolio', 'type': 'journal', 'url': 'https://www.nature.com/articles/s42256-020-00287-7.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Rens van de Schoot
AU  - Jonathan de Bruin
AU  - Raoul D. Schram
AU  - Parisa Zahedi
AU  - Jan de Boer
AU  - Felix Weijdema
AU  - Bianca Kramer
AU  - Martijn Huijts
AU  - Maarten Hoogerwerf
AU  - Gerbrich Ferdinands
AU  - Albert Harkema
AU  - Joukje Willemsen
AU  - Yongchao Ma
AU  - Qixiang Fang
AU  - Sybren Hindriks
AU  - Lars Tummers
AU  - Daniel L. Oberski
ER  - 

258.
TY  - journal-article
ID  - https://openalex.org/W3139045587
DO  - https://doi.org/10.1016/j.nedt.2021.104868
TI  - Virtual reality simulations in nurse education: A systematic mapping review
AB  - Simulation-based learning is widely used in nurse education, including virtual reality (VR) methods which have experienced a major growth lately. Virtual reality offers risk free and contactless learning. Currently, little is known about what topics of nursing are adopted for VR simulations and how their design meets various educational goals. This review aims to scope existing articles on educational VR nursing simulations, and to analyse approaches from didactic and technical perspectives. A systematic mapping review following the PRISMA-ScR guideline and PICo search strategy was conducted. Peer reviewed articles in English and German were searched across Scopus, CINAHL, PsycINFO, PSYNDEX, PsycARTICLES, PubMed, ERIC and The Cochrane Library. Studies had to include at least one immersive head-mounted display VR simulation in the field of nursing education. Data extraction and analysis was performed in a narrative, graphical and tabular way. Twenty-two articles were identified. There is a large variety in the use and definition of VR simulation for educational purposes. Simulations were classified into four main educational objectives: procedural skills training to improve technical knowledge and proficiency; emergency response training that focusses on confidence; soft skills training that teaches empathy; and finally, psychomotor skills training. Various approaches and simulation designs were implemented to achieve these educational outcomes. A few of them were highly innovative in providing an immersive experience to learn complex tasks, e.g. auscultation, or foster empathy by mimicking life with dementia. Despite an increase in the use of state-of-the-art VR nursing simulations, there is still a paucity of studies on immersive HMD based VR scenarios. Researchers designing educational VR packages need to be clear on terminology. In order to make full use of VR, designers should consider including haptic devices to practise psychomotor skills and include social interaction to teach soft skills. • A systematic mapping review was performed. • Virtual reality (VR) in nurse education has experienced a major growth lately. • Researchers designing educational VR packages need to be clear on terminology. • The effectivity of VR as a learning method in nursing requires further research. • Special haptic devices can be included to teach psychomotor skills.
PY  - 2021
DA  - 2021-03-23
JO  - {'id': 'https://openalex.org/S62565178', 'issn_l': '0260-6917', 'issn': ['0260-6917', '1532-2793'], 'display_name': 'Nurse Education Today', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Christian Plotzky
AU  - Ulrike Lindwedel
AU  - Michaela Sorber
AU  - Barbara Loessl
AU  - Peter König
AU  - Christophe Kunze
AU  - Christiane Kugler
AU  - Michael Meng
ER  - 

259.
TY  - journal-article
ID  - https://openalex.org/W3000482183
DO  - https://doi.org/10.3389/fvets.2020.00011
TI  - Scoping Reviews, Systematic Reviews, and Meta-Analysis: Applications in Veterinary Medicine
AB  - Evidence-based decision making is a hallmark of effective veterinary clinical practice. Scoping reviews, systematic reviews, and meta-analyses all are methods intended to provide transparent and replicable ways of summarizing a body of research to address an important clinical or public health issue. As these methods increasingly are being used by researchers and read by practitioners, it is important to understand the distinction between these techniques and to understand what research questions they can, and cannot, address. This review provides an overview of scoping reviews, systematic reviews, and meta-analysis, including a discussion of the method and uses. A sample dataset and coding to conduct a simple meta-analysis in the statistical program R also are provided. Scoping reviews are a descriptive approach, designed to chart the literature around a particular topic. The approach involves an extensive literature search, following by a structured mapping, or charting, of the literature. The results of scoping reviews can help to inform future research by identifying gaps in the existing literature and also can be used to identify areas where there may be a sufficient depth of literature to warrant a systematic review. Systematic reviews are intended to address a specific question by identifying and summarizing all of the available research that has addressed the review question. Questions types that can be addressed by a systematic review include prevalence/incidence questions, and questions related to etiology, intervention efficacy, and diagnostic test accuracy. The systematic review process follows structured steps with multiple reviewers working in parallel to reduce the potential for bias. An extensive literature search is undertaken and, for each relevant study identified by the search, a formal extraction of data, including the effect size, and assessment of the risk of bias is performed. The results from multiple studies can be combined using meta-analysis. Meta-analysis provides a summary effect size, and allows heterogeneity of effect among studies to be quantified and explored. These evidence synthesis approaches can provide scientific input to evidence-based clinical decision-making for veterinarians and regulatory bodies, and also can be useful for identifying gaps in the literature to enhance the efficiency of future research in a topic area.
PY  - 2020
DA  - 2020-01-28
JO  - {'id': 'https://openalex.org/S2594976040', 'issn_l': '2297-1769', 'issn': ['2297-1769'], 'display_name': 'Frontiers in Veterinary Science', 'publisher': 'Frontiers Media', 'type': 'journal', 'url': 'https://doi.org/10.3389/fvets.2020.00011', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Jan M. Sargeant
AU  - Annette M. O'Connor
ER  - 

260.
TY  - journal-article
ID  - https://openalex.org/W3119755789
DO  - https://doi.org/10.1057/s41267-020-00385-z
TI  - The anatomy of an award-winning meta-analysis: Recommendations for authors, reviewers, and readers of meta-analytic reviews
AB  - Abstract Meta-analyses summarize a field’s research base and are therefore highly influential. Despite their value, the standards for an excellent meta-analysis, one that is potentially award-winning, have changed in the last decade. Each step of a meta-analysis is now more formalized, from the identification of relevant articles to coding, moderator analysis, and reporting of results. What was exemplary a decade ago can be somewhat dated today. Using the award-winning meta-analysis by Stahl et al. (Unraveling the effects of cultural diversity in teams: A meta-analysis of research on multicultural work groups. Journal of International Business Studies, 41(4):690–709, 2010) as an exemplar, we adopted a multi-disciplinary approach (e.g., management, psychology, health sciences) to summarize the anatomy (i.e., fundamental components) of a modern meta-analysis, focusing on: (1) data collection (i.e., literature search and screening, coding), (2) data preparation (i.e., treatment of multiple effect sizes, outlier identification and management, publication bias), (3) data analysis (i.e., average effect sizes, heterogeneity of effect sizes, moderator search), and (4) reporting (i.e., transparency and reproducibility, future research directions). In addition, we provide guidelines and a decision-making tree for when even foundational and highly cited meta-analyses should be updated. Based on the latest evidence, we summarize what journal editors and reviewers should expect, authors should provide, and readers (i.e., other researchers, practitioners, and policymakers) should consider about meta-analytic reviews. include prevalence/incidence questions, and questions related to etiology, intervention efficacy, and diagnostic test accuracy. The systematic review process follows structured steps with multiple reviewers working in parallel to reduce the potential for bias. An extensive literature search is undertaken and, for each relevant study identified by the search, a formal extraction of data, including the effect size, and assessment of the risk of bias is performed. The results from multiple studies can be combined using meta-analysis. Meta-analysis provides a summary effect size, and allows heterogeneity of effect among studies to be quantified and explored. These evidence synthesis approaches can provide scientific input to evidence-based clinical decision-making for veterinarians and regulatory bodies, and also can be useful for identifying gaps in the literature to enhance the efficiency of future research in a topic area.
PY  - 2021
DA  - 2021-01-05
JO  - {'id': 'https://openalex.org/S38024979', 'issn_l': '0047-2506', 'issn': ['0047-2506', '1478-6990'], 'display_name': 'Journal of International Business Studies', 'publisher': 'Palgrave Macmillan', 'type': 'journal', 'url': 'https://link.springer.com/content/pdf/10.1057/s41267-020-00385-z.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Piers Steel
AU  - Sjoerd Beugelsdijk
AU  - Herman Aguinis
ER  - 

261.
TY  - journal-article
ID  - https://openalex.org/W3149778443
DO  - https://doi.org/10.1016/j.infsof.2021.106589
TI  - Automation of systematic literature reviews: A systematic literature review
AB  - Systematic Literature Review (SLR) studies aim to identify relevant primary papers, extract the required data, analyze, and synthesize results to gain further and broader insight into the investigated domain. Multiple SLR studies have been conducted in several domains, such as software engineering, medicine, and pharmacy. Conducting an SLR is a time-consuming, laborious, and costly effort. As such, several researchers developed different techniques to automate the SLR process. However, a systematic overview of the current state-of-the-art in SLR automation seems to be lacking. This study aims to collect and synthesize the studies that focus on the automation of SLR to pave the way for further research. A systematic literature review is conducted on published primary studies on the automation of SLR studies, in which 41 primary studies have been analyzed. This SLR identifies the objectives of automation studies, application domains, automated steps of the SLR, automation techniques, and challenges and solution directions. According to our study, the leading automated step is the Selection of Primary Studies . Although many studies have provided automation approaches for systematic literature reviews, no study has been found to apply automation techniques in the planning and reporting phase. Further research is needed to support the automation of the other activities of the SLR process. readers (i.e., other researchers, practitioners, and policymakers) should consider about meta-analytic reviews. include prevalence/incidence questions, and questions related to etiology, intervention efficacy, and diagnostic test accuracy. The systematic review process follows structured steps with multiple reviewers working in parallel to reduce the potential for bias. An extensive literature search is undertaken and, for each relevant study identified by the search, a formal extraction of data, including the effect size, and assessment of the risk of bias is performed. The results from multiple studies can be combined using meta-analysis. Meta-analysis provides a summary effect size, and allows heterogeneity of effect among studies to be quantified and explored. These evidence synthesis approaches can provide scientific input to evidence-based clinical decision-making for veterinarians and regulatory bodies, and also can be useful for identifying gaps in the literature to enhance the efficiency of future research in a topic area.
PY  - 2021
DA  - 2021-08-01
JO  - {'id': 'https://openalex.org/S205010575', 'issn_l': '0950-5849', 'issn': ['0950-5849', '1873-6025'], 'display_name': 'Information & Software Technology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Raymon van Dinter
AU  - Bedir Tekinerdogan
AU  - Daniel Rodriguez
ER  - 

262.
TY  - journal-article
ID  - https://openalex.org/W2982683456
DO  - https://doi.org/10.1186/s13643-019-1222-2
TI  - Performance and usability of machine learning for screening in systematic reviews: a comparative evaluation of three tools
AB  - Abstract Background We explored the performance of three machine learning tools designed to facilitate title and abstract screening in systematic reviews (SRs) when used to (a) eliminate irrelevant records (automated simulation) and (b) complement the work of a single reviewer (semi-automated simulation). We evaluated user experiences for each tool. Methods We subjected three SRs to two retrospective screening simulations. In each tool (Abstrackr, DistillerSR, RobotAnalyst), we screened a 200-record training set and downloaded the predicted relevance of the remaining records. We calculated the proportion missed and workload and time savings compared to dual independent screening. To test user experiences, eight research staff tried each tool and completed a survey. Results Using Abstrackr, DistillerSR, and RobotAnalyst, respectively, the median (range) proportion missed was 5 (0 to 28) percent, 97 (96 to 100) percent, and 70 (23 to 100) percent for the automated simulation and 1 (0 to 2) percent, 2 (0 to 7) percent, and 2 (0 to 4) percent for the semi-automated simulation. The median (range) workload savings was 90 (82 to 93) percent, 99 (98 to 99) percent, and 85 (85 to 88) percent for the automated simulation and 40 (32 to 43) percent, 49 (48 to 49) percent, and 35 (34 to 38) percent for the semi-automated simulation. The median (range) time savings was 154 (91 to 183), 185 (95 to 201), and 157 (86 to 172) hours for the automated simulation and 61 (42 to 82), 92 (46 to 100), and 64 (37 to 71) hours for the semi-automated simulation. Abstrackr identified 33–90% of records missed by a single reviewer. RobotAnalyst performed less well and DistillerSR provided no relative advantage. User experiences depended on user friendliness, qualities of the user interface, features and functions, trustworthiness, ease and speed of obtaining predictions, and practicality of the export file(s). Conclusions The workload savings afforded in the automated simulation came with increased risk of missing relevant records. Supplementing a single reviewer’s decisions with relevance predictions (semi-automated simulation) sometimes reduced the proportion missed, but performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable.
PY  - 2019
DA  - 2019-11-15
JO  - {'id': 'https://openalex.org/V82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://doi.org/10.1186/s13643-019-1222-2', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Allison Gates
AU  - Samantha Guitard
AU  - Jennifer Pillay
AU  - Sarah A. Elliott
AU  - Michele P Dyson
AU  - Amanda S Newton
AU  - Lisa Hartling
ER  - 

263.
TY  - journal-article
ID  - https://openalex.org/W3033190121
DO  - https://doi.org/10.14745/ccdr.v46i06a02
TI  - Challenges and opportunities for public health made possible by advances in natural language processing
AB  - Natural language processing (NLP) is a subfield of artificial intelligence devoted to understanding and generation of language. The recent advances in NLP technologies are enabling rapid analysis of vast amounts of text, thereby creating opportunities for health research and evidence-informed decision making. The analysis and data extraction from scientific literature, technical reports, health records, social media, surveys, registries and other documents can support core public health functions including the enhancement of existing surveillance systems (e.g. through faster identification of diseases and risk factors/at-risk populations), disease prevention strategies (e.g. through more efficient evaluation of the safety and effectiveness of interventions) and health promotion efforts (e.g. by providing the ability to obtain expert-level answers to any health related question). NLP is emerging as an important tool that can assist public health authorities in decreasing the burden of health inequality/inequity in the population. The purpose of this paper is to provide some notable examples of both the potential applications and challenges of NLP use in public health. median (range) workload savings was 90 (82 to 93) percent, 99 (98 to 99) percent, and 85 (85 to 88) percent for the automated simulation and 40 (32 to 43) percent, 49 (48 to 49) percent, and 35 (34 to 38) percent for the semi-automated simulation. The median (range) time savings was 154 (91 to 183), 185 (95 to 201), and 157 (86 to 172) hours for the automated simulation and 61 (42 to 82), 92 (46 to 100), and 64 (37 to 71) hours for the semi-automated simulation. Abstrackr identified 33–90% of records missed by a single reviewer. RobotAnalyst performed less well and DistillerSR provided no relative advantage. User experiences depended on user friendliness, qualities of the user interface, features and functions, trustworthiness, ease and speed of obtaining predictions, and practicality of the export file(s). Conclusions The workload savings afforded in the automated simulation came with increased risk of missing relevant records. Supplementing a single reviewer’s decisions with relevance predictions (semi-automated simulation) sometimes reduced the proportion missed, but performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable.
PY  - 2020
DA  - 2020-06-04
JO  - {'id': 'https://openalex.org/S4210218640', 'issn_l': '1188-4169', 'issn': ['1188-4169', '1481-8531'], 'display_name': 'Canada communicable disease report', 'publisher': 'Health Canada', 'type': 'journal', 'url': 'https://doi.org/10.14745/ccdr.v46i06a02', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Oliver Baclic
AU  - Matthew Tunis
AU  - Kelsey Young
AU  - Coraline Doan
AU  - Howard Swerdfeger
AU  - Justin Schonfeld
ER  - 

264.
TY  - journal-article
ID  - https://openalex.org/W3093336514
DO  - https://doi.org/10.1186/s12874-020-01129-1
TI  - An evaluation of DistillerSR’s machine learning-based prioritization tool for title/abstract screening – impact on reviewer-relevant outcomes
AB  - Abstract Background Systematic reviews often require substantial resources, partially due to the large number of records identified during searching. Although artificial intelligence may not be ready to fully replace human reviewers, it may accelerate and reduce the screening burden. Using DistillerSR (May 2020 release), we evaluated the performance of the prioritization simulation tool to determine the reduction in screening burden and time savings. Methods Using a true recall @ 95%, response sets from 10 completed systematic reviews were used to evaluate: (i) the reduction of screening burden; (ii) the accuracy of the prioritization algorithm; and (iii) the hours saved when a modified screening approach was implemented. To account for variation in the simulations, and to introduce randomness (through shuffling the references), 10 simulations were run for each review. Means, standard deviations, medians and interquartile ranges (IQR) are presented. Results Among the 10 systematic reviews, using true recall @ 95% there was a median reduction in screening burden of 47.1% (IQR: 37.5 to 58.0%). A median of 41.2% (IQR: 33.4 to 46.9%) of the excluded records needed to be screened to achieve true recall @ 95%. The median title/abstract screening hours saved using a modified screening approach at a true recall @ 95% was 29.8 h (IQR: 28.1 to 74.7 h). This was increased to a median of 36 h (IQR: 32.2 to 79.7 h) when considering the time saved not retrieving and screening full texts of the remaining 5% of records not yet identified as included at title/abstract. Among the 100 simulations (10 simulations per review), none of these 5% of records were a final included study in the systematic review. The reduction in screening burden to achieve true recall @ 95% compared to @ 100% resulted in a reduced screening burden median of 40.6% (IQR: 38.3 to 54.2%). Conclusions The prioritization tool in DistillerSR can reduce screening burden. A modified or stop screening approach once a true recall @ 95% is achieved appears to be a valid method for rapid reviews, and perhaps systematic reviews. This needs to be further evaluated in prospective reviews using the estimated recall. compatibility with present workflows. Systematic review registration Not applicable.
PY  - 2020
DA  - 2020-10-15
JO  - {'id': 'https://openalex.org/S185874209', 'issn_l': '1471-2288', 'issn': ['1471-2288'], 'display_name': 'BMC Medical Research Methodology', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://doi.org/10.1186/s12874-020-01129-1', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Candyce Hamel
AU  - Shannon Kelly
AU  - Walter P. Wodchis
AU  - Danielle B. Rice
AU  - George A. Wells
AU  - Brian Hutton
ER  - 

265.
TY  - journal-article
ID  - https://openalex.org/W3081040615
DO  - https://doi.org/10.1002/ijc.33260
TI  - The International Collaboration for Cancer Classification and Research
AB  - Gaps in the translation of research findings to clinical management have been recognised for decades. They exist for the diagnosis as well as the management of cancer. The international standards for cancer diagnosis are contained within the World Health Organization (WHO) Classification of Tumours, published by the International Agency for Research on Cancer (IARC) and known worldwide as the WHO Blue Books. In addition to their relevance to individual patients, these volumes provide a valuable contribution to cancer research and surveillance, fulfilling an important role in scientific evidence synthesis and international standard-setting. However, the multidimensional nature of cancer classification, the way in which the WHO Classification of Tumours is constructed, and the scientific information overload in the field pose important challenges for the translation of research findings to tumour classification and hence cancer diagnosis. To help address these challenges, we have established the International Collaboration for Cancer Classification and Research (IC3 R) to provide a forum for the coordination of efforts in evidence generation, standard-setting, and best practice recommendations in the field of tumour classification. The first IC3 R meeting, held in Lyon, France, in February 2019, gathered representatives of major institutions involved in tumour classification and related fields to identify and discuss translational challenges in data comparability, standard-setting, quality management, evidence evaluation, and copyright, as well as to develop a collaborative plan for addressing these challenges. This article is protected by copyright. All rights reserved. the remaining 5% of records not yet identified as included at title/abstract. Among the 100 simulations (10 simulations per review), none of these 5% of records were a final included study in the systematic review. The reduction in screening burden to achieve true recall @ 95% compared to @ 100% resulted in a reduced screening burden median of 40.6% (IQR: 38.3 to 54.2%). Conclusions The prioritization tool in DistillerSR can reduce screening burden. A modified or stop screening approach once a true recall @ 95% is achieved appears to be a valid method for rapid reviews, and perhaps systematic reviews. This needs to be further evaluated in prospective reviews using the estimated recall. compatibility with present workflows. Systematic review registration Not applicable.
PY  - 2021
DA  - 2021-02-01
JO  - {'id': 'https://openalex.org/S5382288', 'issn_l': '0020-7136', 'issn': ['1097-0215', '0020-7136'], 'display_name': 'International Journal of Cancer', 'publisher': 'Wiley', 'type': 'journal', 'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/ijc.33260', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc'}
DP  - OpenAlex
AU  - Ian A. Cree
AU  - Blanca Iciar Indave
AU  - Jiri Zavadil
AU  - James McKay
AU  - Magali Olivier
AU  - Zisis Kozlakidis
AU  - Alexander J. Lazar
AU  - Chris Hyde
AU  - Stefan Holdenrieder
AU  - Ros Hastings
AU  - Nasir M. Rajpoot
AU  - Arnaud de la Fouchardiere
AU  - Brian Rous
AU  - Jean C. Zenklusen
AU  - Nicola Normanno
AU  - Richard L. Schilsky
ER  - 

266.
TY  - journal-article
ID  - https://openalex.org/W3094241221
DO  - https://doi.org/10.1038/s41893-020-00623-0
TI  - A scoping review of research funding for small-scale farmers in water scarce regions
AB  - Abstract Water scarcity is a global issue that disproportionately affects small-scale farmers in low- and middle-income countries (LMICs). Through geospatial analysis, we estimated that less than 37% of small-scale farms probably have irrigation in water scarce regions across LMICs, compared with 42% of non-small-scale farms. Through a literature synthesis assisted by machine learning, we then systematically mapped the existing research for on-farm interventions that improve the incomes or yields of small-scale farmers in water scarce regions. We mapped over 888 on-farm interventions used to combat water scarcity from 560 publications and showed a research bias towards yields rather than livelihoods. We found gaps in evidence for many commonly proposed solutions, including livestock management, digital technology and solutions to protect natural resources at the farm-level, such as buffer strips. Our findings can be used to set a funding agenda for research on the geographies that are most at risk of water scarcity and the interventions that most lack evidence. coordination of efforts in evidence generation, standard-setting, and best practice recommendations in the field of tumour classification. The first IC3 R meeting, held in Lyon, France, in February 2019, gathered representatives of major institutions involved in tumour classification and related fields to identify and discuss translational challenges in data comparability, standard-setting, quality management, evidence evaluation, and copyright, as well as to develop a collaborative plan for addressing these challenges. This article is protected by copyright. All rights reserved. the remaining 5% of records not yet identified as included at title/abstract. Among the 100 simulations (10 simulations per review), none of these 5% of records were a final included study in the systematic review. The reduction in screening burden to achieve true recall @ 95% compared to @ 100% resulted in a reduced screening burden median of 40.6% (IQR: 38.3 to 54.2%). Conclusions The prioritization tool in DistillerSR can reduce screening burden. A modified or stop screening approach once a true recall @ 95% is achieved appears to be a valid method for rapid reviews, and perhaps systematic reviews. This needs to be further evaluated in prospective reviews using the estimated recall. compatibility with present workflows. Systematic review registration Not applicable.
PY  - 2020
DA  - 2020-10-12
JO  - {'id': 'https://openalex.org/S4210188283', 'issn_l': '2398-9629', 'issn': ['2398-9629'], 'display_name': 'Nature sustainability', 'publisher': 'Springer Nature', 'type': 'journal', 'url': 'https://www.nature.com/articles/s41893-020-00623-0.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Vincent Ricciardi
AU  - Abdrahmane Wane
AU  - Balsher Singh Sidhu
AU  - Cecile Godde
AU  - Divya Solomon
AU  - Ellen B. McCullough
AU  - Florian Diekmann
AU  - Jaron Porciello
AU  - Meha Jain
AU  - Nicola Randall
AU  - Zia Mehrabi
ER  - 

267.
TY  - journal-article
ID  - https://openalex.org/W3187581061
DO  - https://doi.org/10.1161/circoutcomes.121.007858
TI  - External Validations of Cardiovascular Clinical Prediction Models: A Large-Scale Review of the Literature
AB  - There are many clinical prediction models (CPMs) available to inform treatment decisions for patients with cardiovascular disease. However, the extent to which they have been externally tested, and how well they generally perform has not been broadly evaluated.A SCOPUS citation search was run on March 22, 2017 to identify external validations of cardiovascular CPMs in the Tufts Predictive Analytics and Comparative Effectiveness CPM Registry. We assessed the extent of external validation, performance heterogeneity across databases, and explored factors associated with model performance, including a global assessment of the clinical relatedness between the derivation and validation data.We identified 2030 external validations of 1382 CPMs. Eight hundred seven (58%) of the CPMs in the Registry have never been externally validated. On average, there were 1.5 validations per CPM (range, 0-94). The median external validation area under the receiver operating characteristic curve was 0.73 (25th-75th percentile [interquartile range (IQR)], 0.66-0.79), representing a median percent decrease in discrimination of -11.1% (IQR, -32.4% to +2.7%) compared with performance on derivation data. 81% (n=1333) of validations reporting area under the receiver operating characteristic curve showed discrimination below that reported in the derivation dataset. 53% (n=983) of the validations report some measure of CPM calibration. For CPMs evaluated more than once, there was typically a large range of performance. Of 1702 validations classified by relatedness, the percent change in discrimination was -3.7% (IQR, -13.2 to 3.1) for closely related validations (n=123), -9.0 (IQR, -27.6 to 3.9) for related validations (n=862), and -17.2% (IQR, -42.3 to 0) for distantly related validations (n=717; P<0.001).Many published cardiovascular CPMs have never been externally validated, and for those that have, apparent performance during development is often overly optimistic. A single external validation appears insufficient to broadly understand the performance heterogeneity across different settings. burden median of 40.6% (IQR: 38.3 to 54.2%). Conclusions The prioritization tool in DistillerSR can reduce screening burden. A modified or stop screening approach once a true recall @ 95% is achieved appears to be a valid method for rapid reviews, and perhaps systematic reviews. This needs to be further evaluated in prospective reviews using the estimated recall. compatibility with present workflows. Systematic review registration Not applicable.
PY  - 2021
DA  - 2021-08-01
JO  - {'id': 'https://openalex.org/S52278559', 'issn_l': '1941-7713', 'issn': ['1941-7705', '1941-7713'], 'display_name': 'Circulation-cardiovascular Quality and Outcomes', 'publisher': 'Lippincott Williams & Wilkins', 'type': 'journal', 'url': 'https://www.ahajournals.org/doi/pdf/10.1161/CIRCOUTCOMES.121.007858', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc-nd'}
DP  - OpenAlex
AU  - Benjamin S. Wessler
AU  - Jason M. Nelson
AU  - Jinny Park
AU  - Hannah L. McGinnes
AU  - Gaurav Gulati
AU  - Riley Brazil
AU  - Ben Van Calster
AU  - David van Klaveren
AU  - Esmee Venema
AU  - Ewout W. Steyerberg
AU  - Jessica K. Paulus
AU  - David M. Kent
ER  - 

268.
TY  - journal-article
ID  - https://openalex.org/W4221103032
DO  - https://doi.org/10.1002/mar.21657
TI  - Meta‐analysis and traditional systematic literature reviews—What, why, when, where, and how?
AB  - Meta-analysis is a research method for systematically combining and synthesizing findings from multiple quantitative studies in a research domain. Despite its importance, most literature evaluating meta-analyses are based on data analysis and statistical discussions. This paper takes a holistic view, comparing meta-analyses to traditional systematic literature reviews. We described steps of the meta-analytic process including question definition, data collection, data analysis, and reporting results. For each step, we explain the primary purpose, the tasks required of the meta-analyst, and recommendations for best practice. Finally, we discuss recent developments in meta-analytic techniques, which increase its effectiveness in business research. external validations of 1382 CPMs. Eight hundred seven (58%) of the CPMs in the Registry have never been externally validated. On average, there were 1.5 validations per CPM (range, 0-94). The median external validation area under the receiver operating characteristic curve was 0.73 (25th-75th percentile [interquartile range (IQR)], 0.66-0.79), representing a median percent decrease in discrimination of -11.1% (IQR, -32.4% to +2.7%) compared with performance on derivation data. 81% (n=1333) of validations reporting area under the receiver operating characteristic curve showed discrimination below that reported in the derivation dataset. 53% (n=983) of the validations report some measure of CPM calibration. For CPMs evaluated more than once, there was typically a large range of performance. Of 1702 validations classified by relatedness, the percent change in discrimination was -3.7% (IQR, -13.2 to 3.1) for closely related validations (n=123), -9.0 (IQR, -27.6 to 3.9) for related validations (n=862), and -17.2% (IQR, -42.3 to 0) for distantly related validations (n=717; P<0.001).Many published cardiovascular CPMs have never been externally validated, and for those that have, apparent performance during development is often overly optimistic. A single external validation appears insufficient to broadly understand the performance heterogeneity across different settings. burden median of 40.6% (IQR: 38.3 to 54.2%). Conclusions The prioritization tool in DistillerSR can reduce screening burden. A modified or stop screening approach once a true recall @ 95% is achieved appears to be a valid method for rapid reviews, and perhaps systematic reviews. This needs to be further evaluated in prospective reviews using the estimated recall. compatibility with present workflows. Systematic review registration Not applicable.
PY  - 2022
DA  - 2022-03-11
JO  - {'id': 'https://openalex.org/S102896891', 'issn_l': '0742-6046', 'issn': ['0742-6046', '1520-6793'], 'display_name': 'Psychology & Marketing', 'publisher': 'Wiley-Blackwell', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Justin Paul
AU  - Mojtaba Barari
ER  - 

269.
TY  - journal-article
ID  - https://openalex.org/W3045380424
DO  - https://doi.org/10.1111/hir.12318
TI  - How to keep up to date with medical information using web‐based resources: a systematised review and narrative synthesis
AB  - Background is Keeping up to date with the latest medical information using Web-based resources has been sparsely described, and a comprehensive up-to-date review is needed. meta-analyses Objectives based To summarise the Web-based 'channels' that may assist the actors of the health care system (clinicians, medical researchers and students) to keep up to date with medical information. definition, Methods collection, We searched PubMed and Scopus for English language articles published between January 1990 and February 2019 that investigated ways for keeping up with medical information. We used the results from our search and relevant information from other sources to conduct a narrative synthesis. CPMs. Results hundred We found that resources that push information (e.g. web alerts, medical newsletters, listservs), resources that rely on the active information seeking (e.g. access to health librarians and electronic databases, podcasts, mobile apps), collaborative resources (e.g. web conferences, online journal clubs, web social media) and resources that synthesise information (e.g. bibliometrics, living systematic reviews) can contribute in keeping up with new findings and can enhance evidence-based medicine. Clinicians, medical researchers and students can benefit from the proper use of such Internet-based technological innovations. 53% Conclusion of Internet provides many resources that can help the actors of the health care system stay up to date with the latest scientific findings. 1702 validations classified by relatedness, the percent change in discrimination was -3.7% (IQR, -13.2 to 3.1) for closely related validations (n=123), -9.0 (IQR, -27.6 to 3.9) for related validations (n=862), and -17.2% (IQR, -42.3 to 0) for distantly related validations (n=717; P<0.001).Many published cardiovascular CPMs have never been externally validated, and for those that have, apparent performance during development is often overly optimistic. A single external validation appears insufficient to broadly understand the performance heterogeneity across different settings. burden median of 40.6% (IQR: 38.3 to 54.2%). Conclusions The prioritization tool in DistillerSR can reduce screening burden. A modified or stop screening approach once a true recall @ 95% is achieved appears to be a valid method for rapid reviews, and perhaps systematic reviews. This needs to be further evaluated in prospective reviews using the estimated recall. compatibility with present workflows. Systematic review registration Not applicable.
PY  - 2020
DA  - 2020-07-21
JO  - {'id': 'https://openalex.org/S66051165', 'issn_l': '1471-1834', 'issn': ['1365-2532', '1471-1842', '0265-6647', '1471-1834'], 'display_name': 'Health Information and Libraries Journal', 'publisher': 'Wiley-Blackwell', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Konstantinos I. Bougioukas
AU  - Emmanouil Bouras
AU  - Konstantinos N. Syrigos
AU  - Theodore Dardavessis
AU  - Anna-Bettina Haidich
ER  - 

270.
TY  - journal-article
ID  - https://openalex.org/W3131967293
DO  - https://doi.org/10.1038/s42256-020-00235-5
TI  - Accelerating evidence-informed decision-making for the Sustainable Development Goals using machine learning
AB  - No Abstract Found
PY  - 2020
DA  - 2020-10-01
JO  - {'id': 'https://openalex.org/S2912241403', 'issn_l': '2522-5839', 'issn': ['2522-5839'], 'display_name': 'Nature Machine Intelligence', 'publisher': 'Nature Portfolio', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Jaron Porciello
AU  - Maryia Ivanina
AU  - Maidul Islam
AU  - Stefan Einarson
AU  - Haym Hirsh
ER  - 

271.
TY  - journal-article
ID  - https://openalex.org/W3025308134
DO  - https://doi.org/10.1186/s13040-020-00213-y
TI  - Ideas for how informaticians can get involved with COVID-19 research
AB  - Abstract The coronavirus disease 2019 (COVID-19) pandemic has had a significant impact on population health and wellbeing. Biomedical informatics is central to COVID-19 research efforts and for the delivery of healthcare for COVID-19 patients. Critical to this effort is the participation of informaticians who typically work on other basic science or clinical problems. The goal of this editorial is to highlight some examples of COVID-19 research areas that could benefit from informatics expertise. Each research idea summarizes the COVID-19 application area, followed by an informatics methodology, approach, or technology that could make a contribution. It is our hope that this piece will motivate and make it easy for some informaticians to adopt COVID-19 research projects. medical newsletters, listservs), resources that rely on the active information seeking (e.g. access to health librarians and electronic databases, podcasts, mobile apps), collaborative resources (e.g. web conferences, online journal clubs, web social media) and resources that synthesise information (e.g. bibliometrics, living systematic reviews) can contribute in keeping up with new findings and can enhance evidence-based medicine. Clinicians, medical researchers and students can benefit from the proper use of such Internet-based technological innovations. 53% Conclusion of Internet provides many resources that can help the actors of the health care system stay up to date with the latest scientific findings. 1702 validations classified by relatedness, the percent change in discrimination was -3.7% (IQR, -13.2 to 3.1) for closely related validations (n=123), -9.0 (IQR, -27.6 to 3.9) for related validations (n=862), and -17.2% (IQR, -42.3 to 0) for distantly related validations (n=717; P<0.001).Many published cardiovascular CPMs have never been externally validated, and for those that have, apparent performance during development is often overly optimistic. A single external validation appears insufficient to broadly understand the performance heterogeneity across different settings. burden median of 40.6% (IQR: 38.3 to 54.2%). Conclusions The prioritization tool in DistillerSR can reduce screening burden. A modified or stop screening approach once a true recall @ 95% is achieved appears to be a valid method for rapid reviews, and perhaps systematic reviews. This needs to be further evaluated in prospective reviews using the estimated recall. compatibility with present workflows. Systematic review registration Not applicable.
PY  - 2020
DA  - 2020-05-12
JO  - {'id': 'https://openalex.org/S84409260', 'issn_l': '1756-0381', 'issn': ['1756-0381'], 'display_name': 'Biodata Mining', 'publisher': 'BioMed Central', 'type': 'journal', 'url': 'https://biodatamining.biomedcentral.com/counter/pdf/10.1186/s13040-020-00213-y', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Jason H. Moore
AU  - Ian Barnett
AU  - Mary Regina Boland
AU  - Yong Chen
AU  - George Demiris
AU  - Graciela Gonzalez
AU  - Daniel C. Herman
AU  - Blanca E. Himes
AU  - Rebecca A. Hubbard
AU  - Dokyoon Kim
AU  - Jeffrey S. Morris
AU  - Danielle L. Mowery
AU  - Marylyn D. Ritchie
AU  - Li Shen
AU  - Ryan J. Urbanowicz
AU  - John Holmes
ER  - 

272.
TY  - journal-article
ID  - https://openalex.org/W3117197087
DO  - https://doi.org/10.1289/ehp6994
TI  - Knowledge Organization Systems for Systematic Chemical Assessments
AB  - Background: Although the implementation of systematic review and evidence mapping methods stands to improve the transparency and accuracy of chemical assessments, they also accentuate the challenge... for the delivery of healthcare for COVID-19 patients. Critical to this effort is the participation of informaticians who typically work on other basic science or clinical problems. The goal of this editorial is to highlight some examples of COVID-19 research areas that could benefit from informatics expertise. Each research idea summarizes the COVID-19 application area, followed by an informatics methodology, approach, or technology that could make a contribution. It is our hope that this piece will motivate and make it easy for some informaticians to adopt COVID-19 research projects. medical newsletters, listservs), resources that rely on the active information seeking (e.g. access to health librarians and electronic databases, podcasts, mobile apps), collaborative resources (e.g. web conferences, online journal clubs, web social media) and resources that synthesise information (e.g. bibliometrics, living systematic reviews) can contribute in keeping up with new findings and can enhance evidence-based medicine. Clinicians, medical researchers and students can benefit from the proper use of such Internet-based technological innovations. 53% Conclusion of Internet provides many resources that can help the actors of the health care system stay up to date with the latest scientific findings. 1702 validations classified by relatedness, the percent change in discrimination was -3.7% (IQR, -13.2 to 3.1) for closely related validations (n=123), -9.0 (IQR, -27.6 to 3.9) for related validations (n=862), and -17.2% (IQR, -42.3 to 0) for distantly related validations (n=717; P<0.001).Many published cardiovascular CPMs have never been externally validated, and for those that have, apparent performance during development is often overly optimistic. A single external validation appears insufficient to broadly understand the performance heterogeneity across different settings. burden median of 40.6% (IQR: 38.3 to 54.2%). Conclusions The prioritization tool in DistillerSR can reduce screening burden. A modified or stop screening approach once a true recall @ 95% is achieved appears to be a valid method for rapid reviews, and perhaps systematic reviews. This needs to be further evaluated in prospective reviews using the estimated recall. compatibility with present workflows. Systematic review registration Not applicable.
PY  - 2020
DA  - 2020-12-24
JO  - {'id': 'https://openalex.org/S10446503', 'issn_l': '0091-6765', 'issn': ['0091-6765', '1552-9924'], 'display_name': 'Environmental Health Perspectives', 'publisher': 'National Institute of Environmental Health Sciences', 'type': 'journal', 'url': 'https://ehp.niehs.nih.gov/doi/pdf/10.1289/EHP6994', 'is_oa': True, 'version': 'publishedVersion', 'license': 'pd'}
DP  - OpenAlex
AU  - Paul Whaley
AU  - Stephen H. Edwards
AU  - Andrew S. Kraft
AU  - Kate Nyhan
AU  - Andrew A. Shapiro
AU  - Sean Watford
AU  - Steve Wattam
AU  - Taylor Wolffe
AU  - Michelle M. Angrish
ER  - 

273.
TY  - journal-article
ID  - https://openalex.org/W2932069670
DO  - https://doi.org/10.1186/s13643-019-0974-z
TI  - Editorial: Systematic review automation thematic series
AB  - No Abstract Found
PY  - 2019
DA  - 2019-03-11
JO  - {'id': 'https://openalex.org/V82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://doi.org/10.1186/s13643-019-0974-z', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Joseph Lau
ER  - 

274.
TY  - journal-article
ID  - https://openalex.org/W3048803772
DO  - https://doi.org/10.1186/s13023-020-01493-7
TI  - A guide to writing systematic reviews of rare disease treatments to generate FAIR-compliant datasets: building a Treatabolome
AB  - Rare diseases are individually rare but globally affect around 6% of the population, and in over 70% of cases are genetically determined. Their rarity translates into a delayed diagnosis, with 25% of patients waiting 5 to 30 years for one. It is essential to raise awareness of patients and clinicians of existing gene and variant-specific therapeutics at the time of diagnosis to avoid that treatment delays add up to the diagnostic odyssey of rare diseases' patients and their families.This paper aims to provide guidance and give detailed instructions on how to write homogeneous systematic reviews of rare diseases' treatments in a manner that allows the capture of the results in a computer-accessible form. The published results need to comply with the FAIR guiding principles for scientific data management and stewardship to facilitate the extraction of datasets that are easily transposable into machine-actionable information. The ultimate purpose is the creation of a database of rare disease treatments ("Treatabolome") at gene and variant levels as part of the H2020 research project Solve-RD.Each systematic review follows a written protocol to address one or more rare diseases in which the authors are experts. The bibliographic search strategy requires detailed documentation to allow its replication. Data capture forms should be built to facilitate the filling of a data capture spreadsheet and to record the application of the inclusion and exclusion criteria to each search result. A PRISMA flowchart is required to provide an overview of the processes of search and selection of papers. A separate table condenses the data collected during the Systematic Review, appraised according to their level of evidence.This paper provides a template that includes the instructions for writing FAIR-compliant systematic reviews of rare diseases' treatments that enables the assembly of a Treatabolome database that complement existing diagnostic and management support tools with treatment awareness data. in DistillerSR can reduce screening burden. A modified or stop screening approach once a true recall @ 95% is achieved appears to be a valid method for rapid reviews, and perhaps systematic reviews. This needs to be further evaluated in prospective reviews using the estimated recall. compatibility with present workflows. Systematic review registration Not applicable.
PY  - 2020
DA  - 2020-08-12
JO  - {'id': 'https://openalex.org/S71291065', 'issn_l': '1750-1172', 'issn': ['1750-1172'], 'display_name': 'Orphanet Journal of Rare Diseases', 'publisher': 'BioMed Central', 'type': 'journal', 'url': 'https://doi.org/10.1186/s13023-020-01493-7', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - A. Atalaia
AU  - Rachel Thompson
AU  - Alberto Corvo
AU  - Leigh C. Carmody
AU  - Davide Piscia
AU  - Leslie Matalonga
AU  - Alfons Macaya
AU  - Angela Lochmüller
AU  - Bertrand Fontaine
AU  - Birte Zurek
AU  - Carles Hernandez-Ferrer
AU  - Carola Reinhard
AU  - David Gómez-Andrés
AU  - Jean-François Desaphy
AU  - Katherine Schon
AU  - Katja Lohmann
AU  - Matthew Jennings
AU  - Matthis Synofzik
AU  - Olaf Riess
AU  - Rabah Ben Yaou
AU  - Teresinha Evangelista
AU  - Thiloka Ratnaike
AU  - Virginie Bros-Facer
AU  - Gulcin Gumus
AU  - Rita Horvath
AU  - Patrick F. Chinnery
AU  - Steven S. Laurie
AU  - Holm Graessner
AU  - Peter N. Robinson
AU  - Hanns Lochmüller
AU  - Sergi Beltran
AU  - Gisèle Bonne
ER  - 

275.
TY  - journal-article
ID  - https://openalex.org/W3178695691
DO  - https://doi.org/10.1016/j.jclinepi.2021.06.030
TI  - Systematic review automation tools improve efficiency but lack of knowledge impedes their adoption: a survey
AB  - <h2>Abstract</h2><h3>Objective</h3> We investigated systematic review automation tool use by systematic reviewers, health technology assessors and clinical guideline developerst. <h3>Study design and setting</h3> An online, 16-question survey was distributed across several evidence synthesis, health technology assessment and guideline development organizations. We asked the respondents what tools they use and abandon, how often and when do they use the tools, their perceived time savings and accuracy, and desired new tools. Descriptive statistics were used to report the results. <h3>Results</h3> A total of 253 respondents completed the survey; 89% have used systematic review automation tools – most frequently whilst screening (79%). Respondents' "top 3" tools included: Covidence (45%), RevMan (35%), Rayyan and GRADEPro (both 22%); most commonly abandoned were Rayyan (19%), Covidence (15%), DistillerSR (14%) and RevMan (13%). Tools saved time (80%) and increased accuracy (54%). Respondents taught themselves to how to use the tools (72%); lack of knowledge was the most frequent barrier to tool adoption (51%). New tool development was suggested for the searching and data extraction stages. <h3>Conclusion</h3> Automation tools will likely have an increasingly important role in high-quality and timely reviews. Further work is required in training and dissemination of automation tools and ensuring they meet the desirable features of those conducting systematic reviews. built to facilitate the filling of a data capture spreadsheet and to record the application of the inclusion and exclusion criteria to each search result. A PRISMA flowchart is required to provide an overview of the processes of search and selection of papers. A separate table condenses the data collected during the Systematic Review, appraised according to their level of evidence.This paper provides a template that includes the instructions for writing FAIR-compliant systematic reviews of rare diseases' treatments that enables the assembly of a Treatabolome database that complement existing diagnostic and management support tools with treatment awareness data. in DistillerSR can reduce screening burden. A modified or stop screening approach once a true recall @ 95% is achieved appears to be a valid method for rapid reviews, and perhaps systematic reviews. This needs to be further evaluated in prospective reviews using the estimated recall. compatibility with present workflows. Systematic review registration Not applicable.
PY  - 2021
DA  - 2021-07-07
JO  - {'id': 'https://openalex.org/S64418186', 'issn_l': '0895-4356', 'issn': ['1878-5921', '0895-4356'], 'display_name': 'Journal of Clinical Epidemiology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Anna Mae Scott
AU  - Connor M. Forbes
AU  - Justin Clark
AU  - Matt Carter
AU  - Paul Glasziou
AU  - Zachary Munn
ER  - 

276.
TY  - journal-article
ID  - https://openalex.org/W2999105954
DO  - https://doi.org/10.1080/17437199.2020.1716198
TI  - Semi-Automated evidence synthesis in health psychology: current methods and future prospects
AB  - The evidence base in health psychology is vast and growing rapidly. These factors make it difficult (and sometimes practically impossible) to consider all available evidence when making decisions about the state of knowledge on a given phenomenon (e.g., associations of variables, effects of interventions on particular outcomes). Systematic reviews, meta-analyses, and other rigorous syntheses of the research mitigate this problem by providing concise, actionable summaries of knowledge in a given area of study. Yet, conducting these syntheses has grown increasingly laborious owing to the fast accumulation of new evidence; existing, manual methods for synthesis do not scale well. In this article, we discuss how semi-automation via machine learning and natural language processing methods may help researchers and practitioners to review evidence more efficiently. We outline concrete examples in health psychology, highlighting practical, open-source technologies available now. We indicate the potential of more advanced methods and discuss how to avoid the pitfalls of automated reviews. (51%). New tool development was suggested for the searching and data extraction stages. <h3>Conclusion</h3> Automation tools will likely have an increasingly important role in high-quality and timely reviews. Further work is required in training and dissemination of automation tools and ensuring they meet the desirable features of those conducting systematic reviews. built to facilitate the filling of a data capture spreadsheet and to record the application of the inclusion and exclusion criteria to each search result. A PRISMA flowchart is required to provide an overview of the processes of search and selection of papers. A separate table condenses the data collected during the Systematic Review, appraised according to their level of evidence.This paper provides a template that includes the instructions for writing FAIR-compliant systematic reviews of rare diseases' treatments that enables the assembly of a Treatabolome database that complement existing diagnostic and management support tools with treatment awareness data. in DistillerSR can reduce screening burden. A modified or stop screening approach once a true recall @ 95% is achieved appears to be a valid method for rapid reviews, and perhaps systematic reviews. This needs to be further evaluated in prospective reviews using the estimated recall. compatibility with present workflows. Systematic review registration Not applicable.
PY  - 2020
DA  - 2020-01-29
JO  - {'id': 'https://openalex.org/S111502347', 'issn_l': '1743-7199', 'issn': ['1743-7199', '1743-7202'], 'display_name': 'Health Psychology Review', 'publisher': 'Taylor & Francis', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Iain J. Marshall
AU  - Blair T. Johnson
AU  - Zigeng Wang
AU  - Sanguthevar Rajasekaran
AU  - Byron C. Wallace
ER  - 

277.
TY  - journal-article
ID  - https://openalex.org/W3087185831
DO  - https://doi.org/10.1093/jamia/ocaa163
TI  - Trialstreamer: A living, automatically updated database of clinical trial reports
AB  - Abstract Objective Randomized controlled trials (RCTs) are the gold standard method for evaluating whether a treatment works in health care but can be difficult to find and make use of. We describe the development and evaluation of a system to automatically find and categorize all new RCT reports. Materials and Methods Trialstreamer continuously monitors PubMed and the World Health Organization International Clinical Trials Registry Platform, looking for new RCTs in humans using a validated classifier. We combine machine learning and rule-based methods to extract information from the RCT abstracts, including free-text descriptions of trial PICO (populations, interventions/comparators, and outcomes) elements and map these snippets to normalized MeSH (Medical Subject Headings) vocabulary terms. We additionally identify sample sizes, predict the risk of bias, and extract text conveying key findings. We store all extracted data in a database, which we make freely available for download, and via a search portal, which allows users to enter structured clinical queries. Results are ranked automatically to prioritize larger and higher-quality studies. Results As of early June 2020, we have indexed 673 191 publications of RCTs, of which 22 363 were published in the first 5 months of 2020 (142 per day). We additionally include 304 111 trial registrations from the International Clinical Trials Registry Platform. The median trial sample size was 66. Conclusions We present an automated system for finding and categorizing RCTs. This yields a novel resource: a database of structured information automatically extracted for all published RCTs in humans. We make daily updates of this database available on our website (https://trialstreamer.robotreviewer.net). Review, appraised according to their level of evidence.This paper provides a template that includes the instructions for writing FAIR-compliant systematic reviews of rare diseases' treatments that enables the assembly of a Treatabolome database that complement existing diagnostic and management support tools with treatment awareness data. in DistillerSR can reduce screening burden. A modified or stop screening approach once a true recall @ 95% is achieved appears to be a valid method for rapid reviews, and perhaps systematic reviews. This needs to be further evaluated in prospective reviews using the estimated recall. compatibility with present workflows. Systematic review registration Not applicable.
PY  - 2020
DA  - 2020-12-09
JO  - {'id': 'https://openalex.org/S129839026', 'issn_l': '1067-5027', 'issn': ['1067-5027', '1527-974X'], 'display_name': 'Journal of the American Medical Informatics Association', 'publisher': 'Oxford University Press', 'type': 'journal', 'url': 'https://academic.oup.com/jamia/article-pdf/27/12/1903/34838541/ocaa163.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Iain J. Marshall
AU  - Benjamin D. Nye
AU  - Joël Kuiper
AU  - Anna H Noel-Storr
AU  - Rachel Marshall
AU  - Rory MacLean
AU  - Frank Soboczenski
AU  - Ani Nenkova
AU  - James D. Thomas
AU  - Byron C. Wallace
ER  - 

278.
TY  - journal-article
ID  - https://openalex.org/W3143985904
DO  - https://doi.org/10.1186/s13643-021-01635-3
TI  - Research Screener: a machine learning tool to semi-automate abstract screening for systematic reviews
AB  - Systematic reviews and meta-analyses provide the highest level of evidence to help inform policy and practice, yet their rigorous nature is associated with significant time and economic demands. The screening of titles and abstracts is the most time consuming part of the review process with analysts required review thousands of articles manually, taking on average 33 days. New technologies aimed at streamlining the screening process have provided initial promising findings, yet there are limitations with current approaches and barriers to the widespread use of these tools. In this paper, we introduce and report initial evidence on the utility of Research Screener, a semi-automated machine learning tool to facilitate abstract screening.Three sets of analyses (simulation, interactive and sensitivity) were conducted to provide evidence of the utility of the tool through both simulated and real-world examples.Research Screener delivered a workload saving of between 60 and 96% across nine systematic reviews and two scoping reviews. Findings from the real-world interactive analysis demonstrated a time saving of 12.53 days compared to the manual screening, which equates to a financial saving of USD 2444. Conservatively, our results suggest that analysts who scan 50% of the total pool of articles identified via a systematic search are highly likely to have identified 100% of eligible papers.In light of these findings, Research Screener is able to reduce the burden for researchers wishing to conduct a comprehensive systematic review without reducing the scientific rigour for which they strive to achieve. all published RCTs in humans. We make daily updates of this database available on our website (https://trialstreamer.robotreviewer.net). Review, appraised according to their level of evidence.This paper provides a template that includes the instructions for writing FAIR-compliant systematic reviews of rare diseases' treatments that enables the assembly of a Treatabolome database that complement existing diagnostic and management support tools with treatment awareness data. in DistillerSR can reduce screening burden. A modified or stop screening approach once a true recall @ 95% is achieved appears to be a valid method for rapid reviews, and perhaps systematic reviews. This needs to be further evaluated in prospective reviews using the estimated recall. compatibility with present workflows. Systematic review registration Not applicable.
PY  - 2021
DA  - 2021-04-01
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://systematicreviewsjournal.biomedcentral.com/counter/pdf/10.1186/s13643-021-01635-3', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Kevin Chai
AU  - Robin L. J. Lines
AU  - Daniel F. Gucciardi
AU  - Leo Ng
ER  - 

279.
TY  - journal-article
ID  - https://openalex.org/W3013835212
DO  - https://doi.org/10.12688/f1000research.22781.2
TI  - Data extraction methods for systematic review (semi)automation: A living review protocol
AB  - <ns4:p><ns4:bold>Background:</ns4:bold> Researchers in evidence-based medicine cannot keep up with the amounts of both old and newly published primary research articles. Support for the early stages of the systematic review process – searching and screening studies for eligibility – is necessary because it is currently impossible to search for relevant research with precision. Better automated data extraction may not only facilitate the stage of review traditionally labelled ‘data extraction’, but also change earlier phases of the review process by making it possible to identify relevant research. Exponential improvements in computational processing speed and data storage are fostering the development of data mining models and algorithms. This, in combination with quicker pathways to publication, led to a large landscape of tools and methods for data mining and extraction.</ns4:p><ns4:p> <ns4:bold>Objective:</ns4:bold> To review published methods and tools for data extraction to (semi)automate the systematic reviewing process.</ns4:p><ns4:p> <ns4:bold>Methods:</ns4:bold> We propose to conduct a living review. With this methodology we aim to do constant evidence surveillance, bi-monthly search updates, as well as review updates every 6 months if new evidence permits it. In a cross-sectional analysis we will extract methodological characteristics and assess the quality of reporting in our included papers.</ns4:p><ns4:p> <ns4:bold>Conclusions:</ns4:bold> We aim to increase transparency in the reporting and assessment of automation technologies to the benefit of data scientists, systematic reviewers and funders of health research. This living review will help to reduce duplicate efforts by data scientists who develop data mining methods. It will also serve to inform systematic reviewers about possibilities to support their data extraction.</ns4:p> on our website (https://trialstreamer.robotreviewer.net). Review, appraised according to their level of evidence.This paper provides a template that includes the instructions for writing FAIR-compliant systematic reviews of rare diseases' treatments that enables the assembly of a Treatabolome database that complement existing diagnostic and management support tools with treatment awareness data. in DistillerSR can reduce screening burden. A modified or stop screening approach once a true recall @ 95% is achieved appears to be a valid method for rapid reviews, and perhaps systematic reviews. This needs to be further evaluated in prospective reviews using the estimated recall. compatibility with present workflows. Systematic review registration Not applicable.
PY  - 2020
DA  - 2020-03-25
JO  - {'id': 'https://openalex.org/S4210239046', 'issn_l': '2046-1402', 'issn': ['2046-1402'], 'display_name': 'F1000Research', 'publisher': 'Faculty of 1000', 'type': 'journal', 'url': 'https://f1000research.com/articles/9-210/v2/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Lena Schmidt
AU  - Babatunde K. Olorisade
AU  - Adrian M. Price-Whelan
AU  - James D. Thomas
AU  - Julian P T Higgins
ER  - 

280.
TY  - journal-article
ID  - https://openalex.org/W3124993375
DO  - https://doi.org/10.1016/j.clinthera.2020.12.014
TI  - Artificial Intelligence in Pharmacovigilance: Scoping Points to Consider
AB  - <h2>Abstract</h2> Artificial intelligence (AI), a highly interdisciplinary science, is an increasing presence in pharmacovigilance (PV). A better understanding of the scope of artificial intelligence in pharmacovigilance (AIPV) may be advantageous to more sharply defining, for example, which terms, methods, tasks, and data sets are suitably subsumed under the application of AIPV. Accordingly, this article explores relevant points to consider regarding defining the scope of AIPV and offers a potential working definition of the scope of AIPV. process by making it possible to identify relevant research. Exponential improvements in computational processing speed and data storage are fostering the development of data mining models and algorithms. This, in combination with quicker pathways to publication, led to a large landscape of tools and methods for data mining and extraction.</ns4:p><ns4:p> <ns4:bold>Objective:</ns4:bold> To review published methods and tools for data extraction to (semi)automate the systematic reviewing process.</ns4:p><ns4:p> <ns4:bold>Methods:</ns4:bold> We propose to conduct a living review. With this methodology we aim to do constant evidence surveillance, bi-monthly search updates, as well as review updates every 6 months if new evidence permits it. In a cross-sectional analysis we will extract methodological characteristics and assess the quality of reporting in our included papers.</ns4:p><ns4:p> <ns4:bold>Conclusions:</ns4:bold> We aim to increase transparency in the reporting and assessment of automation technologies to the benefit of data scientists, systematic reviewers and funders of health research. This living review will help to reduce duplicate efforts by data scientists who develop data mining methods. It will also serve to inform systematic reviewers about possibilities to support their data extraction.</ns4:p> on our website (https://trialstreamer.robotreviewer.net). Review, appraised according to their level of evidence.This paper provides a template that includes the instructions for writing FAIR-compliant systematic reviews of rare diseases' treatments that enables the assembly of a Treatabolome database that complement existing diagnostic and management support tools with treatment awareness data. in DistillerSR can reduce screening burden. A modified or stop screening approach once a true recall @ 95% is achieved appears to be a valid method for rapid reviews, and perhaps systematic reviews. This needs to be further evaluated in prospective reviews using the estimated recall. compatibility with present workflows. Systematic review registration Not applicable.
PY  - 2021
DA  - 2021-01-18
JO  - {'id': 'https://openalex.org/S185879095', 'issn_l': '0149-2918', 'issn': ['0149-2918', '1879-114X'], 'display_name': 'Clinical Therapeutics', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Manfred Hauben
AU  - Craig G. Hartford
ER  - 

281.
TY  - journal-article
ID  - https://openalex.org/W4223614283
DO  - https://doi.org/10.1016/j.scitotenv.2022.155159
TI  - Assay of renewable energy transition: A systematic literature review
AB  - Issues of environmental degradation, finite quantity and uneven spatial distribution of fuels in nature, and growing demand accentuated by volatility of oil prices have led to the global clean renewable energy transition (RET). With an objective of examining the current knowledge-stock on RET, we reviewed 248 journal publications pooled from three databases (ScienceDirect, Web of Science and Scopus) using a Systematic Literature Review method. This study does not focus on the specifications of a particular energy technology or regress relations among a limited set of variables. Rather, the key contribution is the critical assessment of the factors that encourage and those that hinder the transition process to provide a wider perspective through seven broad lenses: technological, investment, market, environmental, government and institutional, policy and social. Research, development and implementation of technology is a direct outcome of policy investment. Developed countries are leading the RET research while the global south is far behind. Most of the studies were found to be donor-driven which faced a serious risk of being counter-welcomed in different settings of the world without compromising the objectives of the transition. A strong international collaboration among the rich and poor countries is urgently felt necessary to foster mutual benefits. Research, planning and implementation of the RET would be highly effective and sustainable through a participatory bottom-up approach promoting local technology instead of imposed expensive imported ones. The need for "demand-pull" and "technology-push" policy instruments is stringent for successful transition. We conclude that there is a unanimous agreement among all the studies on the future prospects of renewable energy in the electricity sector; however, some skepticism still exists regarding other high energy demanding areas. Our review recommends updating existing and designing new robust policy mixes to guide the modality and pace of the RET, adhering to local specificities. tools with treatment awareness data. in DistillerSR can reduce screening burden. A modified or stop screening approach once a true recall @ 95% is achieved appears to be a valid method for rapid reviews, and perhaps systematic reviews. This needs to be further evaluated in prospective reviews using the estimated recall. compatibility with present workflows. Systematic review registration Not applicable.
PY  - 2022
DA  - 2022-04-01
JO  - {'id': 'https://openalex.org/S86852077', 'issn_l': '0048-9697', 'issn': ['0048-9697', '1879-1026'], 'display_name': 'Science of The Total Environment', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Utsav Bhattarai
AU  - Tek Narayan Maraseni
AU  - Armando Apan
ER  - 

282.
TY  - journal-article
ID  - https://openalex.org/W3163124033
DO  - https://doi.org/10.12688/f1000research.51117.1
TI  - Data extraction methods for systematic review (semi)automation: A living systematic review
AB  - <ns3:p><ns3:bold>Background:</ns3:bold> The reliable and usable (semi)automation of data extraction can support the field of systematic review by reducing the workload required to gather information about the conduct and results of the included studies. This living systematic review examines published approaches for data extraction from reports of clinical studies.</ns3:p><ns3:p> <ns3:bold>Methods:</ns3:bold> We systematically and continually search MEDLINE, Institute of Electrical and Electronics Engineers (IEEE), arXiv, and the <ns3:italic>dblp computer science bibliography</ns3:italic> databases. Full text screening and data extraction are conducted within an open-source living systematic review application created for the purpose of this review. This iteration of the living review includes publications up to a cut-off date of 22 April 2020.</ns3:p><ns3:p> <ns3:bold>Results: </ns3:bold>In total, 53 publications are included in this version of our review. Of these, 41 (77%) of the publications addressed extraction of data from abstracts, while 14 (26%) used full texts. A total of 48 (90%) publications developed and evaluated classifiers that used randomised controlled trials as the main target texts. Over 30 entities were extracted, with PICOs (population, intervention, comparator, outcome) being the most frequently extracted. A description of their datasets was provided by 49 publications (94%), but only seven (13%) made the data publicly available. Code was made available by 10 (19%) publications, and five (9%) implemented publicly available tools.</ns3:p><ns3:p> <ns3:bold>Conclusions:</ns3:bold> This living systematic review presents an overview of (semi)automated data-extraction literature of interest to different types of systematic review. We identified a broad evidence base of publications describing data extraction for interventional reviews and a small number of publications extracting epidemiological or diagnostic accuracy data. The lack of publicly available gold-standard data for evaluation, and lack of application thereof, makes it difficult to draw conclusions on which is the best-performing system for each data extraction target. With this living review we aim to review the literature continually.</ns3:p> treatment awareness data. in DistillerSR can reduce screening burden. A modified or stop screening approach once a true recall @ 95% is achieved appears to be a valid method for rapid reviews, and perhaps systematic reviews. This needs to be further evaluated in prospective reviews using the estimated recall. compatibility with present workflows. Systematic review registration Not applicable.
PY  - 2021
DA  - 2021-05-19
JO  - {'id': 'https://openalex.org/S4210239046', 'issn_l': '2046-1402', 'issn': ['2046-1402'], 'display_name': 'F1000Research', 'publisher': 'Faculty of 1000', 'type': 'journal', 'url': 'https://f1000research.com/articles/10-401/v1/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Lena Schmidt
AU  - Babatunde K. Olorisade
AU  - Adrian M. Price-Whelan
AU  - James D. Thomas
AU  - Julian P T Higgins
ER  - 

283.
TY  - journal-article
ID  - https://openalex.org/W3093398320
DO  - https://doi.org/10.1111/bjhp.12479
TI  - Investigating which behaviour change techniques work for whom in which contexts delivered by what means: Proposal for an international collaboratory of Centres for Understanding Behaviour Change (CUBiC)
AB  - PURPOSE: Behaviour change techniques are fundamental to the development of any behaviour change intervention, but surprisingly little is known about their properties. Key questions include when, why, how, in which contexts, for which behaviours, in what combinations, compared with what, and for whom behaviour change techniques are typically effective. The aims of the present paper are to: (1) articulate the scope of the challenge in understanding the properties of behaviour change techniques, (2) propose means by which to tackle this problem, and (3) call scientists to action. METHODS: Iterative consensus (O'Connor et al., 2020, Br. J. Psychol., e12468) was used to elicit and distil the judgements of experts on how best to tackle the problem of understanding the nature and operation of behaviour change techniques. RESULTS: We propose a worldwide network of 'Centres for Understanding Behaviour Change' (CUBiC) simultaneously undertaking research to establish what are the single and combined properties of behaviour change techniques across multiple behaviours and populations. We additionally provide a first attempt to systematize an approach that CUBiC could use to understand behaviour change techniques and to begin to harness the efforts of researchers worldwide. CONCLUSION: Better understanding of behaviour change techniques is vital for improving behaviour change interventions to tackle global problems such as obesity and recovery from COVID-19. The CUBiC proposal is just one of many possible solutions to the problems that the world faces and is a call to action for scientists to work collaboratively to gain deeper understanding of the underpinnings of behaviour change interventions. extracting epidemiological or diagnostic accuracy data. The lack of publicly available gold-standard data for evaluation, and lack of application thereof, makes it difficult to draw conclusions on which is the best-performing system for each data extraction target. With this living review we aim to review the literature continually.</ns3:p> treatment awareness data. in DistillerSR can reduce screening burden. A modified or stop screening approach once a true recall @ 95% is achieved appears to be a valid method for rapid reviews, and perhaps systematic reviews. This needs to be further evaluated in prospective reviews using the estimated recall. compatibility with present workflows. Systematic review registration Not applicable.
PY  - 2021
DA  - 2021-02-01
JO  - {'id': 'https://openalex.org/S52059345', 'issn_l': '1359-107X', 'issn': ['1359-107X', '2044-8287'], 'display_name': 'British Journal of Health Psychology', 'publisher': 'British Psychological Society', 'type': 'journal', 'url': 'https://bpspsychub.onlinelibrary.wiley.com/doi/pdfdirect/10.1111/bjhp.12479', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc-nd'}
DP  - OpenAlex
AU  - Christopher J. Armitage
AU  - Mark Conner
AU  - Andrew Prestwich
AU  - Marijn de Bruin
AU  - Marie Johnston
AU  - Falko F. Sniehotta
AU  - Tracy Epton
ER  - 

284.
TY  - journal-article
ID  - https://openalex.org/W3120256265
DO  - https://doi.org/10.1186/s13643-020-01569-2
TI  - The views of health guideline developers on the use of automation in health evidence synthesis
AB  - Abstract Background The increasingly rapid rate of evidence publication has made it difficult for evidence synthesis—systematic reviews and health guidelines—to be continually kept up to date. One proposed solution for this is the use of automation in health evidence synthesis. Guideline developers are key gatekeepers in the acceptance and use of evidence, and therefore, their opinions on the potential use of automation are crucial. Methods The objective of this study was to analyze the attitudes of guideline developers towards the use of automation in health evidence synthesis. The Diffusion of Innovations framework was chosen as an initial analytical framework because it encapsulates some of the core issues which are thought to affect the adoption of new innovations in practice. This well-established theory posits five dimensions which affect the adoption of novel technologies: Relative Advantage , Compatibility , Complexity , Trialability , and Observability . Eighteen interviews were conducted with individuals who were currently working, or had previously worked, in guideline development. After transcription, a multiphase mixed deductive and grounded approach was used to analyze the data. First, transcripts were coded with a deductive approach using Rogers’ Diffusion of Innovation as the top-level themes. Second, sub-themes within the framework were identified using a grounded approach. Results Participants were consistently most concerned with the extent to which an innovation is in line with current values and practices (i.e., Compatibility in the Diffusion of Innovations framework). Participants were also concerned with Relative Advantage and Observability , which were discussed in approximately equal amounts. For the latter, participants expressed a desire for transparency in the methodology of automation software. Participants were noticeably less interested in Complexity and Trialability , which were discussed infrequently. These results were reasonably consistent across all participants. Conclusions If machine learning and other automation technologies are to be used more widely and to their full potential in systematic reviews and guideline development, it is crucial to ensure new technologies are in line with current values and practice. It will also be important to maximize the transparency of the methods of these technologies to address the concerns of guideline developers. compatibility with present workflows. Systematic review registration Not applicable.
PY  - 2021
DA  - 2021-01-08
JO  - {'id': 'https://openalex.org/V82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://doi.org/10.1186/s13643-020-01569-2', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Anneliese Arno
AU  - Julian Elliott
AU  - Byron C. Wallace
AU  - Tari Turner
AU  - James D. Thomas
ER  - 

285.
TY  - journal-article
ID  - https://openalex.org/W3149254289
DO  - https://doi.org/10.1155/2021/6680764
TI  - Meta-Analysis of Correlations between Altmetric Attention Score and Citations in Health Sciences
AB  - In recent years, several controversial reports of the correlation between altmetric score and citations have been published (range: -0.2 to 0.8). We conducted a meta-analysis to provide an in-depth statistical analysis of the correlation between altmetric score and number of citations in the field of health sciences.Three online databases (Web of Science, Scopus, and PubMed) were systematically searched, without language restrictions, from the earliest publication date available through February 29, 2020, using the keywords "altmetric," "citation," and "correlation." Grey literature was also searched via WorldCat, Open Grey, and Google Scholar (first 100 hits only). All studies in the field of health sciences that reported on this correlation were included. Effect sizes were calculated using Fisher's z transformation of correlations. Subgroup analyses based on citation source and sampling methods were performed.From 27 included articles, 8 articles comprise several independent studies. The total sample size was 9,943 articles comprised of 35 studies. The overall pooled effect size was 0.19 (95% confidence interval 0.13 to 0.26). Bivariate partial prediction of interaction between effect size, citation source, and sampling method showed a greater effect size with Web of Science compared with Scopus and Dimensions. Egger's regression showed a marginally nonsignificant publication bias (p = 0.055), and trim-and-fill analysis estimated one missing study in this meta-analysis.In health sciences, currently altmetric score has a positive but weak correlation with number of citations (pooled correlation = 0.19, 95% C.I 0.12 to 0.25). We emphasize on future examinations to assess changes of correlation pattern between altmetric score and citations over time. participants expressed a desire for transparency in the methodology of automation software. Participants were noticeably less interested in Complexity and Trialability , which were discussed infrequently. These results were reasonably consistent across all participants. Conclusions If machine learning and other automation technologies are to be used more widely and to their full potential in systematic reviews and guideline development, it is crucial to ensure new technologies are in line with current values and practice. It will also be important to maximize the transparency of the methods of these technologies to address the concerns of guideline developers. compatibility with present workflows. Systematic review registration Not applicable.
PY  - 2021
DA  - 2021-04-07
JO  - {'id': 'https://openalex.org/S1010394304', 'issn_l': '2314-6133', 'issn': ['2314-6133', '2314-6141'], 'display_name': 'BioMed Research International', 'publisher': 'Hindawi Publishing Corporation', 'type': 'journal', 'url': 'https://downloads.hindawi.com/journals/bmri/2021/6680764.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Jafar Kolahi
AU  - Saber Khazaei
AU  - Pedram Iranmanesh
AU  - Jeehyoung Kim
AU  - Heejung Bang
AU  - Abbasali Khademi
ER  - 

286.
TY  - journal-article
ID  - https://openalex.org/W3176858175
DO  - https://doi.org/10.1080/1750984x.2021.1946835
TI  - Handling effect size dependency in meta-analysis
AB  - The statistical synthesis of quantitative effects within primary studies via meta-analysis is an important analytical technique in the scientific toolkit of modern researchers. As with any scientif... an in-depth statistical analysis of the correlation between altmetric score and number of citations in the field of health sciences.Three online databases (Web of Science, Scopus, and PubMed) were systematically searched, without language restrictions, from the earliest publication date available through February 29, 2020, using the keywords "altmetric," "citation," and "correlation." Grey literature was also searched via WorldCat, Open Grey, and Google Scholar (first 100 hits only). All studies in the field of health sciences that reported on this correlation were included. Effect sizes were calculated using Fisher's z transformation of correlations. Subgroup analyses based on citation source and sampling methods were performed.From 27 included articles, 8 articles comprise several independent studies. The total sample size was 9,943 articles comprised of 35 studies. The overall pooled effect size was 0.19 (95% confidence interval 0.13 to 0.26). Bivariate partial prediction of interaction between effect size, citation source, and sampling method showed a greater effect size with Web of Science compared with Scopus and Dimensions. Egger's regression showed a marginally nonsignificant publication bias (p = 0.055), and trim-and-fill analysis estimated one missing study in this meta-analysis.In health sciences, currently altmetric score has a positive but weak correlation with number of citations (pooled correlation = 0.19, 95% C.I 0.12 to 0.25). We emphasize on future examinations to assess changes of correlation pattern between altmetric score and citations over time. participants expressed a desire for transparency in the methodology of automation software. Participants were noticeably less interested in Complexity and Trialability , which were discussed infrequently. These results were reasonably consistent across all participants. Conclusions If machine learning and other automation technologies are to be used more widely and to their full potential in systematic reviews and guideline development, it is crucial to ensure new technologies are in line with current values and practice. It will also be important to maximize the transparency of the methods of these technologies to address the concerns of guideline developers. compatibility with present workflows. Systematic review registration Not applicable.
PY  - 2021
DA  - 2021-06-30
JO  - {'id': 'https://openalex.org/S115649667', 'issn_l': '1750-984X', 'issn': ['1750-984X', '1750-9858'], 'display_name': 'International Review of Sport and Exercise Psychology', 'publisher': 'Taylor & Francis', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Daniel F. Gucciardi
AU  - Robin L. J. Lines
AU  - Nikos Ntoumanis
ER  - 

287.
TY  - journal-article
ID  - https://openalex.org/W3123245796
DO  - https://doi.org/10.3390/ijerph18020817
TI  - Safe Healthcare Facilities: A Systematic Review on the Costs of Establishing and Maintaining Environmental Health in Facilities in Low- and Middle-Income Countries
AB  - A hygienic environment is essential to provide quality patient care and prevent healthcare-acquired infections. Understanding costs is important to budget for service delivery, but costs evidence for environmental health services (EHS) in healthcare facilities (HCFs) is lacking. We present the first systematic review to evaluate the costs of establishing, operating, and maintaining EHS in HCFs in low- and middle-income countries (LMICs). We systematically searched for studies costing water, sanitation, hygiene, cleaning, waste management, personal protective equipment, vector control, laundry, and lighting in LMICs. Our search yielded 36 studies that reported costs for 51 EHS. There were 3 studies that reported costs for water, 3 for sanitation, 4 for hygiene, 13 for waste management, 16 for cleaning, 2 for personal protective equipment, 10 for laundry, and none for lighting or vector control. Quality of evidence was low. Reported costs were rarely representative of the total costs of EHS provision. Unit costs were infrequently reported. This review identifies opportunities to improve costing research through efforts to categorize and disaggregate EHS costs, greater dissemination of existing unpublished data, improvements to indicators to monitor EHS demand and quality necessary to contextualize costs, and development of frameworks to define EHS needs and essential inputs to guide future costing. analysis estimated one missing study in this meta-analysis.In health sciences, currently altmetric score has a positive but weak correlation with number of citations (pooled correlation = 0.19, 95% C.I 0.12 to 0.25). We emphasize on future examinations to assess changes of correlation pattern between altmetric score and citations over time. participants expressed a desire for transparency in the methodology of automation software. Participants were noticeably less interested in Complexity and Trialability , which were discussed infrequently. These results were reasonably consistent across all participants. Conclusions If machine learning and other automation technologies are to be used more widely and to their full potential in systematic reviews and guideline development, it is crucial to ensure new technologies are in line with current values and practice. It will also be important to maximize the transparency of the methods of these technologies to address the concerns of guideline developers. compatibility with present workflows. Systematic review registration Not applicable.
PY  - 2021
DA  - 2021-01-19
JO  - {'id': 'https://openalex.org/S15239247', 'issn_l': '1660-4601', 'issn': ['1661-7827', '1660-4601'], 'display_name': 'International Journal of Environmental Research and Public Health', 'publisher': 'MDPI', 'type': 'journal', 'url': 'https://www.mdpi.com/1660-4601/18/2/817/pdf?version=1611107750', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Darcy M. Anderson
AU  - Ryan Cronk
AU  - Donald Fejfar
AU  - Emily Pak
AU  - Michelle Cawley
AU  - Jamie Bartram
ER  - 

288.
TY  - journal-article
ID  - https://openalex.org/W3207456925
DO  - https://doi.org/10.1177/02683962211048201
TI  - Artificial intelligence and the conduct of literature reviews
AB  - Artificial intelligence (AI) is beginning to transform traditional research practices in many areas. In this context, literature reviews stand out because they operate on large and rapidly growing volumes of documents, that is, partially structured (meta)data, and pervade almost every type of paper published in information systems research or related social science disciplines. To familiarize researchers with some of the recent trends in this area, we outline how AI can expedite individual steps of the literature review process. Considering that the use of AI in this context is in an early stage of development, we propose a comprehensive research agenda for AI-based literature reviews (AILRs) in our field. With this agenda, we would like to encourage design science research and a broader constructive discourse on shaping the future of AILRs in research. of evidence was low. Reported costs were rarely representative of the total costs of EHS provision. Unit costs were infrequently reported. This review identifies opportunities to improve costing research through efforts to categorize and disaggregate EHS costs, greater dissemination of existing unpublished data, improvements to indicators to monitor EHS demand and quality necessary to contextualize costs, and development of frameworks to define EHS needs and essential inputs to guide future costing. analysis estimated one missing study in this meta-analysis.In health sciences, currently altmetric score has a positive but weak correlation with number of citations (pooled correlation = 0.19, 95% C.I 0.12 to 0.25). We emphasize on future examinations to assess changes of correlation pattern between altmetric score and citations over time. participants expressed a desire for transparency in the methodology of automation software. Participants were noticeably less interested in Complexity and Trialability , which were discussed infrequently. These results were reasonably consistent across all participants. Conclusions If machine learning and other automation technologies are to be used more widely and to their full potential in systematic reviews and guideline development, it is crucial to ensure new technologies are in line with current values and practice. It will also be important to maximize the transparency of the methods of these technologies to address the concerns of guideline developers. compatibility with present workflows. Systematic review registration Not applicable.
PY  - 2021
DA  - 2021-10-08
JO  - {'id': 'https://openalex.org/S135086714', 'issn_l': '0268-3962', 'issn': ['0268-3962', '1466-4437'], 'display_name': 'Journal of Information Technology', 'publisher': 'Macmillan Publishers', 'type': 'journal', 'url': 'https://journals.sagepub.com/doi/pdf/10.1177/02683962211048201', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Gerit Wagner
AU  - Roman Lukyanenko
AU  - Guy Paré
ER  - 

289.
TY  - journal-article
ID  - https://openalex.org/W3024831471
DO  - https://doi.org/10.1186/s12874-020-01004-z
TI  - Current methods for development of rapid reviews about diagnostic tests: an international survey
AB  - Abstract Background Rapid reviews (RRs) have emerged as an efficient alternative to time-consuming systematic reviews—they can help meet the demand for accelerated evidence synthesis to inform decision-making in healthcare. The synthesis of diagnostic evidence has important methodological challenges. Here, we performed an international survey to identify the current practice of producing RRs for diagnostic tests. Methods We developed and administered an online survey inviting institutions that perform RRs of diagnostic tests from all over the world. Results All participants ( N = 25) reported the implementation of one or more methods to define the scope of the RR; however, only one strategy (defining a structured question) was used by ≥90% of participants. All participants used at least one methodological shortcut including the use of a previous review as a starting point (92%) and the use of limits on the search (96%). Parallelization and automation of review tasks were not extensively used (48 and 20%, respectively). Conclusion Our survey indicates a greater use of shortcuts and limits for conducting diagnostic test RRs versus the results of a recent scoping review analyzing published RRs. Several shortcuts are used without knowing how their implementation affects the results of the evidence synthesis in the setting of diagnostic test reviews. Thus, a structured evaluation of the challenges and implications of the adoption of these RR methods is warranted. number of citations (pooled correlation = 0.19, 95% C.I 0.12 to 0.25). We emphasize on future examinations to assess changes of correlation pattern between altmetric score and citations over time. participants expressed a desire for transparency in the methodology of automation software. Participants were noticeably less interested in Complexity and Trialability , which were discussed infrequently. These results were reasonably consistent across all participants. Conclusions If machine learning and other automation technologies are to be used more widely and to their full potential in systematic reviews and guideline development, it is crucial to ensure new technologies are in line with current values and practice. It will also be important to maximize the transparency of the methods of these technologies to address the concerns of guideline developers. compatibility with present workflows. Systematic review registration Not applicable.
PY  - 2020
DA  - 2020-05-13
JO  - {'id': 'https://openalex.org/S185874209', 'issn_l': '1471-2288', 'issn': ['1471-2288'], 'display_name': 'BMC Medical Research Methodology', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://bmcmedresmethodol.biomedcentral.com/track/pdf/10.1186/s12874-020-01004-z', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Ingrid Arevalo-Rodriguez
AU  - Karen R Steingart
AU  - Andrea C. Tricco
AU  - Barbara Nussbaumer-Streit
AU  - David Kaunelis
AU  - Pablo Alonso-Coello
AU  - Susan Baxter
AU  - Patrick M.M. Bossuyt
AU  - Jose I. Emparanza
AU  - Javier Zamora
ER  - 

290.
TY  - journal-article
ID  - https://openalex.org/W3119889732
DO  - https://doi.org/10.5334/bc.67
TI  - Improving energy research practices: guidance for transparency, reproducibility and quality
AB  - Energy use is of crucial importance for the global challenge of climate change, and also is an essential part of daily life. Hence, research on energy needs to be robust and valid. Other scientific disciplines have experienced a reproducibility crisis, i.e. existing findings could not be reproduced in new studies. The ‘TReQ’ approach is recommended to improve research practices in the energy field and arrive at greater transparency, reproducibility and quality. A highly adaptable suite of tools is presented that can be applied to energy research approaches across this multidisciplinary and fast-changing field. In particular, the following tools are introduced – preregistration of studies, making data and code publicly available, using preprints, and employing reporting guidelines – to heighten the standard of research practices within the energy field. The wider adoption of these tools can facilitate greater trust in the findings of research used to inform evidence-based policy and practice in the energy field. <strong><em>Practice relevance</em></strong> <strong></strong>Concrete suggestions are provided for how and when to use preregistration, open data and code, preprints, and reporting guidelines, offering practical guidance for energy researchers for improving the TReQ of their research. The paper shows how employing tools around these concepts at appropriate stages of the research process can assure end-users of the research that good practices were followed. This will not only increase trust in research findings but also can deliver other co-benefits for researchers, e.g. more efficient processes and a more collaborative and open research culture. Increased TReQ can help remove barriers to accessing research both within and outside of academia, improving the visibility and impact of research findings. Finally, a checklist is presented that can be added to publications to show how the tools were used. all participants. Conclusions If machine learning and other automation technologies are to be used more widely and to their full potential in systematic reviews and guideline development, it is crucial to ensure new technologies are in line with current values and practice. It will also be important to maximize the transparency of the methods of these technologies to address the concerns of guideline developers. compatibility with present workflows. Systematic review registration Not applicable.
PY  - 2021
DA  - 2021-01-04
JO  - {'id': 'https://openalex.org/S4210169191', 'issn_l': '2632-6655', 'issn': ['2632-6655'], 'display_name': 'Buildings & cities', 'publisher': 'Ubiquity Press, Ltd.', 'type': 'journal', 'url': 'http://journal-buildingscities.org/articles/10.5334/bc.67/galley/86/download/', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Gesche M. Huebner
AU  - Michael J. Fell
AU  - Nicole Watson
ER  - 

291.
TY  - journal-article
ID  - https://openalex.org/W3168270921
DO  - https://doi.org/10.3389/frma.2021.685591
TI  - SYMBALS: A Systematic Review Methodology Blending Active Learning and Snowballing
AB  - Research output has grown significantly in recent years, often making it difficult to see the forest for the trees. Systematic reviews are the natural scientific tool to provide clarity in these situations. However, they are protracted processes that require expertise to execute. These are problematic characteristics in a constantly changing environment. To solve these challenges, we introduce an innovative systematic review methodology: SYMBALS. SYMBALS blends the traditional method of backward snowballing with the machine learning method of active learning. We applied our methodology in a case study, demonstrating its ability to swiftly yield broad research coverage. We proved the validity of our method using a replication study, where SYMBALS was shown to accelerate title and abstract screening by a factor of 6. Additionally, four benchmarking experiments demonstrated the ability of our methodology to outperform the state-of-the-art systematic review methodology FAST 2 . research used to inform evidence-based policy and practice in the energy field. <strong><em>Practice relevance</em></strong> <strong></strong>Concrete suggestions are provided for how and when to use preregistration, open data and code, preprints, and reporting guidelines, offering practical guidance for energy researchers for improving the TReQ of their research. The paper shows how employing tools around these concepts at appropriate stages of the research process can assure end-users of the research that good practices were followed. This will not only increase trust in research findings but also can deliver other co-benefits for researchers, e.g. more efficient processes and a more collaborative and open research culture. Increased TReQ can help remove barriers to accessing research both within and outside of academia, improving the visibility and impact of research findings. Finally, a checklist is presented that can be added to publications to show how the tools were used. all participants. Conclusions If machine learning and other automation technologies are to be used more widely and to their full potential in systematic reviews and guideline development, it is crucial to ensure new technologies are in line with current values and practice. It will also be important to maximize the transparency of the methods of these technologies to address the concerns of guideline developers. compatibility with present workflows. Systematic review registration Not applicable.
PY  - 2021
DA  - 2021-05-28
JO  - {'id': 'https://openalex.org/S2596295431', 'issn_l': '2504-0537', 'issn': ['2504-0537'], 'display_name': 'Frontiers in Research Metrics and Analytics', 'publisher': 'Frontiers Media', 'type': 'journal', 'url': 'https://www.frontiersin.org/articles/10.3389/frma.2021.685591/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Max van Haastrecht
AU  - Injy Sarhan
AU  - Bilge Yigit Ozkan
AU  - Matthieu J. S. Brinkhuis
AU  - Marco Spruit
ER  - 

292.
TY  - journal-article
ID  - https://openalex.org/W3004781512
DO  - https://doi.org/10.12688/f1000research.22032.2
TI  - Toolkit of methodological resources to conduct systematic reviews
AB  - <ns4:p><ns4:bold>Background: </ns4:bold>Systematic reviews (SR) can be classified by type depending on the research question they are based on. This work identifies and describes the most relevant methodological resources to conduct high-quality reviews that answer health care questions regarding prevalence, prognosis, diagnostic accuracy and effects of interventions.</ns4:p><ns4:p> <ns4:bold>Methods: </ns4:bold>Methodological resources have been identified from literature searches and consulting guidelines from institutions that develop SRs. The selected resources are organized by type of SR, and stage of development of the review (formulation of the research question, development of the protocol, literature search, risk of bias assessment, synthesis of findings, assessment of the quality of evidence, and report of SR results and conclusions).</ns4:p><ns4:p> <ns4:bold>Results: </ns4:bold>Although the different types of SRs are developed following the same steps, each SR type requires specific methods, differing in characteristics and complexity. The extent of methodological development varies by type of SR, with more solid guidelines available for diagnostic accuracy and effects of interventions SRs.</ns4:p><ns4:p> This methodological toolkit describes the most up-to-date risk of bias instruments: Quality in Prognostic Studies (QUIPS) tool and Prediction model study Risk Of Bias Assessment Tool (PROBAST) for prognostic SRs, Quality assessment of diagnostic accuracy studies tool (QUADAS-2) for diagnostic accuracy SRs, Cochrane risk of bias tool (ROB-2) and Risk of bias in non-randomised studies of interventions studies tool (ROBINS-I) for effects of interventions SRs, as well as the latest developments on the Grading of Recommendations Assessment, Development and Evaluation (GRADE) system.</ns4:p><ns4:p> <ns4:bold>Conclusions</ns4:bold>: This structured compilation of the best methodological resources for each type of SR may prove to be a very useful tool for those researchers that wish to develop SRs or conduct methodological research works on SRs</ns4:p> to publications to show how the tools were used. all participants. Conclusions If machine learning and other automation technologies are to be used more widely and to their full potential in systematic reviews and guideline development, it is crucial to ensure new technologies are in line with current values and practice. It will also be important to maximize the transparency of the methods of these technologies to address the concerns of guideline developers. compatibility with present workflows. Systematic review registration Not applicable.
PY  - 2020
DA  - 2020-02-04
JO  - {'id': 'https://openalex.org/V4210239046', 'issn_l': '2046-1402', 'issn': ['2046-1402'], 'display_name': 'F1000Research', 'publisher': 'Faculty of 1000', 'type': 'journal', 'url': 'https://f1000research.com/articles/9-82/v2/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Marta Roqué i Figuls
AU  - Laura B. Martínez-García
AU  - Ivan Solà
AU  - Pablo Alonso-Coello
AU  - Xavier Bonfill
AU  - Javier Zamora
ER  - 

293.
TY  - journal-article
ID  - https://openalex.org/W3093173351
DO  - https://doi.org/10.1186/s13643-020-01450-2
TI  - Comparison of a traditional systematic review approach with review-of-reviews and semi-automation as strategies to update the evidence
AB  - Abstract Background The exponential growth of the biomedical literature necessitates investigating strategies to reduce systematic reviewer burden while maintaining the high standards of systematic review validity and comprehensiveness. Methods We compared the traditional systematic review screening process with (1) a review-of-reviews (ROR) screening approach and (2) a semi-automation screening approach using two publicly available tools (RobotAnalyst and AbstrackR) and different types of training sets (randomly selected citations subjected to dual-review at the title-abstract stage, highly curated citations dually reviewed at the full-text stage, and a combination of the two). We evaluated performance measures of sensitivity, specificity, missed citations, and workload burden Results The ROR approach for treatments of early-stage prostate cancer had a poor sensitivity (0.54) and studies missed by the ROR approach tended to be of head-to-head comparisons of active treatments, observational studies, and outcomes of physical harms and quality of life. Title and abstract screening incorporating semi-automation only resulted in a sensitivity of 100% at high levels of reviewer burden (review of 99% of citations). A highly curated, smaller-sized, training set ( n = 125) performed similarly to a larger training set of random citations ( n = 938). Conclusion Two approaches to rapidly update SRs—review-of-reviews and semi-automation—failed to demonstrate reduced workload burden while maintaining an acceptable level of sensitivity. We suggest careful evaluation of the ROR approach through comparison of inclusion criteria and targeted searches to fill evidence gaps as well as further research of semi-automation use, including more study of highly curated training sets. for each type of SR may prove to be a very useful tool for those researchers that wish to develop SRs or conduct methodological research works on SRs</ns4:p> to publications to show how the tools were used. all participants. Conclusions If machine learning and other automation technologies are to be used more widely and to their full potential in systematic reviews and guideline development, it is crucial to ensure new technologies are in line with current values and practice. It will also be important to maximize the transparency of the methods of these technologies to address the concerns of guideline developers. compatibility with present workflows. Systematic review registration Not applicable.
PY  - 2020
DA  - 2020-10-19
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://systematicreviewsjournal.biomedcentral.com/track/pdf/10.1186/s13643-020-01450-2', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Shivani M. Reddy
AU  - Sheila K Patel
AU  - Meghan S Weyrich
AU  - Joshua J. Fenton
AU  - Meera Viswanathan
ER  - 

294.
TY  - journal-article
ID  - https://openalex.org/W3006853591
DO  - https://doi.org/10.1136/bmjopen-2019-034301
TI  - Effects of medical and non-medical cannabis use in older adults: protocol for a scoping review
AB  - Introduction With its legalisation and regulation in Canada in 2018, the proportion of Canadians reporting cannabis use in 2019 increased substantially over the previous year, with half of new users being aged 45+ years. While use in older adults has been low historically, as those born in the 1950s and 1960s continue to age, this demographic will progressively have more liberal attitudes, prior cannabis exposure and higher use rates. However, older adults experience slower metabolism, increased likelihood of polypharmacy, cognitive decline and chronic physical/mental health problems. There is a need to enhance knowledge of the effects of cannabis use in older adults. The following question will be addressed using a scoping review approach: what evidence exists regarding beneficial and harmful effects of medical and non-medical cannabis use in adults &gt;50 years of age? Given that beneficial and harmful effects of cannabis may be mediated by patient-level (eg, age, sex and race) and cannabis-related factors (eg, natural vs synthetic, consumption method), subgroup effects related to these and additional factors will be explored. Methods and analysis Methods for scoping reviews outlined by Arksey &amp; O’Malley and the Joanna Briggs Institute will be used. A librarian designed a systematic search of the literature from database inception to June 2019. Using the OVID platform, Ovid MEDLINE will be searched, including Epub Ahead of Print and In-Process and Other Non-Indexed Citations, Embase Classic+Embase, and PsycINFO for reviews, randomised trials, non-randomised trials and observational studies of cannabis use. The Cochrane Library on Wiley will also be searched. Eligibility criteria will be older adult participants, currently using cannabis (medical or non-medical), with studies required to report a cannabis-related health outcome to be eligible. Two reviewers will screen citations and full texts, with support from artificial intelligence. Two reviewers will chart data. Tables/graphics will be used to map evidence and identify evidence gaps. Ethics and dissemination This research will enhance awareness of existing evidence addressing the health effects of medical and non-medical cannabis use in older adults. Findings will be disseminated through a peer-reviewed publication, conference presentations and a stakeholder meeting. Trial registration number DOI 10.17605/OSF.IO/5JTAQ. developers. compatibility with present workflows. Systematic review registration Not applicable.
PY  - 2020
DA  - 2020-02-01
JO  - {'id': 'https://openalex.org/V79054089', 'issn_l': '2044-6055', 'issn': ['2044-6055'], 'display_name': 'BMJ Open', 'publisher': 'BMJ', 'type': 'journal', 'url': 'https://bmjopen.bmj.com/content/bmjopen/10/2/e034301.full.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc'}
DP  - OpenAlex
AU  - Dianna Wolfe
AU  - Kimberly Corace
AU  - Danielle B. Rice
AU  - Alexis M. S. Smith
AU  - Salmaan Kanji
AU  - David Bruce Conn
AU  - Melanie Willows
AU  - Gary Garber
AU  - John Puxty
AU  - Esther Moghadam
AU  - Becky Skidmore
AU  - Chantelle Garritty
AU  - Walter P. Wodchis
AU  - David Moher
AU  - Brian Hutton
ER  - 

295.
TY  - journal-article
ID  - https://openalex.org/W3097214169
DO  - https://doi.org/10.3390/educsci10110306
TI  - Developing a Task-Based Dialogue System for English Language Learning
AB  - This research involved the design of a task-based dialogue system and evaluation of its learning effectiveness. Dialogue training still heavily depends on human communication with instant feedback or correction. However, it is not possible to provide a personal tutor for every English learner. With the rapid development of information technology, digitized learning and voice communication is a possible solution. The goal of this research was to develop an innovative model to refine the task-based dialogue system, including natural language understanding, disassembly intention, and dialogue state tracking. To enable the dialogue system to find the corresponding sentence accurately, the dialogue system was designed with machine learning algorithms to allow users to communicate in a task-based fashion. Past research has pointed out that computer-assisted instruction has achieved remarkable results in language reading, writing, and listening. Therefore, the direction of the discussion is to use the task-oriented dialogue system as a speaking teaching assistant. To train the speaking ability, the proposed system provides a simulation environment with goal-oriented characteristics, allowing learners to continuously improve their language fluency in terms of speaking ability by simulating conversational situational exercises. To evaluate the possibility of replacing the traditional English speaking practice with the proposed system, a small English speaking class experiment was carried out to validate the effectiveness of the proposed system. Data of 28 students with three assigned tasks were collected and analyzed. The promising results of the collected students’ feedback confirm the positive perceptions toward the system regarding user interface, learning style, and the system’s effectiveness. criteria will be older adult participants, currently using cannabis (medical or non-medical), with studies required to report a cannabis-related health outcome to be eligible. Two reviewers will screen citations and full texts, with support from artificial intelligence. Two reviewers will chart data. Tables/graphics will be used to map evidence and identify evidence gaps. Ethics and dissemination This research will enhance awareness of existing evidence addressing the health effects of medical and non-medical cannabis use in older adults. Findings will be disseminated through a peer-reviewed publication, conference presentations and a stakeholder meeting. Trial registration number DOI 10.17605/OSF.IO/5JTAQ. developers. compatibility with present workflows. Systematic review registration Not applicable.
PY  - 2020
DA  - 2020-10-28
JO  - {'id': 'https://openalex.org/S2738008561', 'issn_l': '2227-7102', 'issn': ['2227-7102'], 'display_name': 'Education Sciences', 'publisher': 'MDPI', 'type': 'journal', 'url': 'https://www.mdpi.com/2227-7102/10/11/306/pdf?version=1603878387', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Kuo Li
AU  - Maiga Chang
AU  - Kuan Sheng Wu
ER  - 

296.
TY  - journal-article
ID  - https://openalex.org/W3104156511
DO  - https://doi.org/10.1186/s13643-020-01528-x
TI  - Decoding semi-automated title-abstract screening: findings from a convenience sample of reviews
AB  - Abstract Background We evaluated the benefits and risks of using the Abstrackr machine learning (ML) tool to semi-automate title-abstract screening and explored whether Abstrackr’s predictions varied by review or study-level characteristics. Methods For a convenience sample of 16 reviews for which adequate data were available to address our objectives (11 systematic reviews and 5 rapid reviews), we screened a 200-record training set in Abstrackr and downloaded the relevance (relevant or irrelevant) of the remaining records, as predicted by the tool. We retrospectively simulated the liberal-accelerated screening approach. We estimated the time savings and proportion missed compared with dual independent screening. For reviews with pairwise meta-analyses, we evaluated changes to the pooled effects after removing the missed studies. We explored whether the tool’s predictions varied by review and study-level characteristics. Results Using the ML-assisted liberal-accelerated approach, we wrongly excluded 0 to 3 (0 to 14%) records that were included in the final reports, but saved a median (IQR) 26 (9, 42) h of screening time. One missed study was included in eight pairwise meta-analyses in one systematic review. The pooled effect for just one of those meta-analyses changed considerably (from MD (95% CI) − 1.53 (− 2.92, − 0.15) to − 1.17 (− 2.70, 0.36)). Of 802 records in the final reports, 87% were correctly predicted as relevant. The correctness of the predictions did not differ by review (systematic or rapid, P = 0.37) or intervention type (simple or complex, P = 0.47). The predictions were more often correct in reviews with multiple (89%) vs. single (83%) research questions ( P = 0.01), or that included only trials (95%) vs. multiple designs (86%) ( P = 0.003). At the study level, trials (91%), mixed methods (100%), and qualitative (93%) studies were more often correctly predicted as relevant compared with observational studies (79%) or reviews (83%) ( P = 0.0006). Studies at high or unclear (88%) vs. low risk of bias (80%) ( P = 0.039), and those published more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2020
DA  - 2020-11-27
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://systematicreviewsjournal.biomedcentral.com/track/pdf/10.1186/s13643-020-01528-x', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Allison Gates
AU  - Michelle Gates
AU  - D. DaRosa
AU  - Sarah A. Elliott
AU  - Jennifer Pillay
AU  - Sholeh Rahman
AU  - Ben Vandermeer
AU  - Lisa Hartling
ER  - 

297.
TY  - journal-article
ID  - https://openalex.org/W3165198619
DO  - https://doi.org/10.1016/j.eswa.2021.115261
TI  - A decision support system for automating document retrieval and citation screening
AB  - • A Decision Support System for two steps in the Systematic Review process. • Automated document retrieval and citation screening. • Implementation of a Multi-Channel CNN model into the system. • A quantitative analysis of the effect of the system. • Our system is available at https://github.com/rvdinter/decision-support-system . The systematic literature review (SLR) process includes several steps to collect secondary data and analyze it to answer research questions. In this context, the document retrieval and primary study selection steps are heavily intertwined and known for their repetitiveness, high human workload, and difficulty identifying all relevant literature. This study aims to reduce human workload and error of the document retrieval and primary study selection processes using a decision support system (DSS). An open-source DSS is proposed that supports the document retrieval step, dataset preprocessing, and citation classification. The DSS is domain-independent, as it has proven to carefully select an article’s relevance based solely on the title and abstract. These features can be consistently retrieved from scientific database APIs. Additionally, the DSS is designed to run in the cloud without any required programming knowledge for reviewers. A Multi-Channel CNN architecture is implemented to support the citation screening process. With the provided DSS, reviewers can fill in their search strategy and manually label only a subset of the citations. The remaining unlabeled citations are automatically classified and sorted based on probability. It was shown that for four out of five review datasets, the DSS's use achieved significant workload savings of at least 10%. The cross-validation results show that the system provides consistent results up to 88.3% of work saved during citation screening. In two cases, our model yielded a better performance over the benchmark review datasets. As such, the proposed approach can assist the development of systematic literature reviews independent of the domain. The proposed DSS is effective and can substantially decrease the document retrieval and citation screening steps' workload and error rate. ( P = 0.039), and those published more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2021
DA  - 2021-11-15
JO  - {'id': 'https://openalex.org/S13144211', 'issn_l': '0957-4174', 'issn': ['1873-6793', '0957-4174'], 'display_name': 'Expert Systems With Applications', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'https://doi.org/10.1016/j.eswa.2021.115261', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Raymon van Dinter
AU  - Daniel Rodriguez
AU  - Bedir Tekinerdogan
ER  - 

298.
TY  - journal-article
ID  - https://openalex.org/W3201751808
DO  - https://doi.org/10.1186/s12911-021-01638-z
TI  - An informatics consult approach for generating clinical evidence for treatment decisions
AB  - An Informatics Consult has been proposed in which clinicians request novel evidence from large scale health data resources, tailored to the treatment of a specific patient. However, the availability of such consultations is lacking. We seek to provide an Informatics Consult for a situation where a treatment indication and contraindication coexist in the same patient, i.e., anti-coagulation use for stroke prevention in a patient with both atrial fibrillation (AF) and liver cirrhosis.We examined four sources of evidence for the effect of warfarin on stroke risk or all-cause mortality from: (1) randomised controlled trials (RCTs), (2) meta-analysis of prior observational studies, (3) trial emulation (using population electronic health records (N = 3,854,710) and (4) genetic evidence (Mendelian randomisation). We developed prototype forms to request an Informatics Consult and return of results in electronic health record systems.We found 0 RCT reports and 0 trials recruiting for patients with AF and cirrhosis. We found broad concordance across the three new sources of evidence we generated. Meta-analysis of prior observational studies showed that warfarin use was associated with lower stroke risk (hazard ratio [HR] = 0.71, CI 0.39-1.29). In a target trial emulation, warfarin was associated with lower all-cause mortality (HR = 0.61, CI 0.49-0.76) and ischaemic stroke (HR = 0.27, CI 0.08-0.91). Mendelian randomisation served as a drug target validation where we found that lower levels of vitamin K1 (warfarin is a vitamin K1 antagonist) are associated with lower stroke risk. A pilot survey with an independent sample of 34 clinicians revealed that 85% of clinicians found information on prognosis useful and that 79% thought that they should have access to the Informatics Consult as a service within their healthcare systems. We identified candidate steps for automation to scale evidence generation and to accelerate the return of results.We performed a proof-of-concept Informatics Consult for evidence generation, which may inform treatment decisions in situations where there is dearth of randomised trials. Patients are surprised to know that their clinicians are currently not able to learn in clinic from data on 'patients like me'. We identify the key challenges in offering such an Informatics Consult as a service. may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2021
DA  - 2021-10-12
JO  - {'id': 'https://openalex.org/S107516304', 'issn_l': '1472-6947', 'issn': ['1472-6947'], 'display_name': 'BMC Medical Informatics and Decision Making', 'publisher': 'BioMed Central', 'type': 'journal', 'url': 'https://doi.org/10.1186/s12911-021-01638-z', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Alvina G. Lai
AU  - Wai Hoong Chang
AU  - Constantinos A. Parisinos
AU  - Michail Katsoulis
AU  - Ruth Blackburn
AU  - Ajay M. Shah
AU  - Vincent Nguyen
AU  - Spiros Denaxas
AU  - George Davey Smith
AU  - Tom R. Gaunt
AU  - Krishnarajah Nirantharakumar
AU  - Murray P. Cox
AU  - Donall Forde
AU  - Folkert W. Asselbergs
AU  - Steve Harris
AU  - Sylvia Richardson
AU  - Reecha Sofat
AU  - Richard Dobson
AU  - Aroon D. Hingorani
AU  - Riyaz S. Patel
AU  - Jonathan A C Sterne
AU  - Amitava Banerjee
AU  - Alastair K Denniston
AU  - Simon Ball
AU  - Neil J. Sebire
AU  - Nigam H. Shah
AU  - Graham R. Foster
AU  - Bryan Williams
AU  - Harry Hemingway
ER  - 

299.
TY  - journal-article
ID  - https://openalex.org/W4200398992
DO  - https://doi.org/10.1016/j.jclinepi.2021.12.005
TI  - Tools to support the automation of systematic reviews: a scoping review
AB  - The objectives of this scoping review are to identify the reliability and validity of the available tools, their limitations and any recommendations to further improve the use of these tools.A scoping review methodology was followed to map the literature published on the challenges and solutions of conducting evidence synthesis using the JBI scoping review methodology.A total of 47 publications were included in the review. The current scoping review identified that LitSuggest, Rayyan, Abstractr, BIBOT, R software, RobotAnalyst, DistillerSR, ExaCT and NetMetaXL have potential to be used for the automation of systematic reviews. However, they are not without limitations. The review also identified other studies that employed algorithms that have not yet been developed into user friendly tools. Some of these algorithms showed high validity and reliability but their use is conditional on user knowledge of computer science and algorithms.Abstract screening has reached maturity; data extraction is still an active area. Developing methods to semi-automate different steps of evidence synthesis via machine learning remains an important research direction. Also, it is important to move from the research prototypes currently available to professionally maintained platforms. 0.39-1.29). In a target trial emulation, warfarin was associated with lower all-cause mortality (HR = 0.61, CI 0.49-0.76) and ischaemic stroke (HR = 0.27, CI 0.08-0.91). Mendelian randomisation served as a drug target validation where we found that lower levels of vitamin K1 (warfarin is a vitamin K1 antagonist) are associated with lower stroke risk. A pilot survey with an independent sample of 34 clinicians revealed that 85% of clinicians found information on prognosis useful and that 79% thought that they should have access to the Informatics Consult as a service within their healthcare systems. We identified candidate steps for automation to scale evidence generation and to accelerate the return of results.We performed a proof-of-concept Informatics Consult for evidence generation, which may inform treatment decisions in situations where there is dearth of randomised trials. Patients are surprised to know that their clinicians are currently not able to learn in clinic from data on 'patients like me'. We identify the key challenges in offering such an Informatics Consult as a service. may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2021
DA  - 2021-12-01
JO  - {'id': 'https://openalex.org/V64418186', 'issn_l': '0895-4356', 'issn': ['1878-5921', '0895-4356'], 'display_name': 'Journal of Clinical Epidemiology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - H. P. S. Abdul Khalil
AU  - D Ameen
AU  - Armita Zarnegar
ER  - 

300.
TY  - journal-article
ID  - https://openalex.org/W4225269224
DO  - https://doi.org/10.1016/j.jclinepi.2022.04.027
TI  - Artificial intelligence in COVID-19 evidence syntheses was underutilized, but impactful: a methodological study
AB  - A rapidly developing scenario like a pandemic requires the prompt production of high-quality systematic reviews, which can be automated using artificial intelligence (AI) techniques. We evaluated the application of AI tools in COVID-19 evidence syntheses.After prospective registration of the review protocol, we automated the download of all open-access COVID-19 systematic reviews in the COVID-19 Living Overview of Evidence database, indexed them for AI-related keywords, and located those that used AI tools. We compared their journals' JCR Impact Factor, citations per month, screening workloads, completion times (from pre-registration to preprint or submission to a journal) and AMSTAR-2 methodology assessments (maximum score 13 points) with a set of publication date matched control reviews without AI.Of the 3,999 COVID-19 reviews, 28 (0.7%, 95% CI 0.47-1.03%) made use of AI. On average, compared to controls (n = 64), AI reviews were published in journals with higher Impact Factors (median 8.9 vs. 3.5, P < 0.001), and screened more abstracts per author (302.2 vs. 140.3, P = 0.009) and per included study (189.0 vs. 365.8, P < 0.001) while inspecting less full texts per author (5.3 vs. 14.0, P = 0.005). No differences were found in citation counts (0.5 vs. 0.6, P = 0.600), inspected full texts per included study (3.8 vs. 3.4, P = 0.481), completion times (74.0 vs. 123.0, P = 0.205) or AMSTAR-2 (7.5 vs. 6.3, P = 0.119).AI was an underutilized tool in COVID-19 systematic reviews. Its usage, compared to reviews without AI, was associated with more efficient screening of literature and higher publication impact. There is scope for the application of AI in automating systematic reviews. access to the Informatics Consult as a service within their healthcare systems. We identified candidate steps for automation to scale evidence generation and to accelerate the return of results.We performed a proof-of-concept Informatics Consult for evidence generation, which may inform treatment decisions in situations where there is dearth of randomised trials. Patients are surprised to know that their clinicians are currently not able to learn in clinic from data on 'patients like me'. We identify the key challenges in offering such an Informatics Consult as a service. may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2022
DA  - 2022-05-01
JO  - {'id': 'https://openalex.org/S64418186', 'issn_l': '0895-4356', 'issn': ['1878-5921', '0895-4356'], 'display_name': 'Journal of Clinical Epidemiology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'http://www.jclinepi.com/article/S0895435622001160/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc-nd'}
DP  - OpenAlex
AU  - Juan R. Tercero-Hidalgo
AU  - Khalid Mohammed Khan
AU  - Aurora Bueno-Cavanillas
AU  - Rodrigo Fernández-López
AU  - Juan F. Huete
AU  - Carmen Amezcua-Prieto
AU  - Javier Zamora
AU  - Juan M. Fernández-Luna
ER  - 

301.
TY  - journal-article
ID  - https://openalex.org/W4280542232
DO  - https://doi.org/10.1177/17456916211053319
TI  - The Cooperation Databank: Machine-Readable Science Accelerates Research Synthesis
AB  - Publishing studies using standardized, machine-readable formats will enable machines to perform meta-analyses on demand. To build a semantically enhanced technology that embodies these functions, we developed the Cooperation Databank (CoDa)-a databank that contains 2,636 studies on human cooperation (1958-2017) conducted in 78 societies involving 356,283 participants. Experts annotated these studies along 312 variables, including the quantitative results (13,959 effects). We designed an ontology that defines and relates concepts in cooperation research and that can represent the relationships between results of correlational and experimental studies. We have created a research platform that, given the data set, enables users to retrieve studies that test the relation of variables with cooperation, visualize these study results, and perform (a) meta-analyses, (b) metaregressions, (c) estimates of publication bias, and (d) statistical power analyses for future studies. We leveraged the data set with visualization tools that allow users to explore the ontology of concepts in cooperation research and to plot a citation network of the history of studies. CoDa offers a vision of how publishing studies in a machine-readable format can establish institutions and tools that improve scientific practices and knowledge. 0.005). No differences were found in citation counts (0.5 vs. 0.6, P = 0.600), inspected full texts per included study (3.8 vs. 3.4, P = 0.481), completion times (74.0 vs. 123.0, P = 0.205) or AMSTAR-2 (7.5 vs. 6.3, P = 0.119).AI was an underutilized tool in COVID-19 systematic reviews. Its usage, compared to reviews without AI, was associated with more efficient screening of literature and higher publication impact. There is scope for the application of AI in automating systematic reviews. access to the Informatics Consult as a service within their healthcare systems. We identified candidate steps for automation to scale evidence generation and to accelerate the return of results.We performed a proof-of-concept Informatics Consult for evidence generation, which may inform treatment decisions in situations where there is dearth of randomised trials. Patients are surprised to know that their clinicians are currently not able to learn in clinic from data on 'patients like me'. We identify the key challenges in offering such an Informatics Consult as a service. may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2022
DA  - 2022-05-17
JO  - {'id': 'https://openalex.org/S27228949', 'issn_l': '1745-6916', 'issn': ['1745-6916', '1745-6924'], 'display_name': 'Perspectives on Psychological Science', 'publisher': 'SAGE Publishing', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Giuliana Spadaro
AU  - Ilaria Tiddi
AU  - Simon Columbus
AU  - Shu-Xian Jin
AU  - Annette ten Teije
AU  - Daniel Balliet
ER  - 

302.
TY  - journal-article
ID  - https://openalex.org/W3022462427
DO  - https://doi.org/10.1186/s13643-020-01366-x
TI  - Determining optimal strategies for primary prevention of cardiovascular disease: systematic review, cost-effectiveness review and network meta-analysis protocol
AB  - Abstract Background Despite recent improvements in the burden of cardiovascular disease (CVD) in the UK, deaths from CVD are relatively high compared with other high-income countries. An estimated 7 million people in the UK are living with CVD, and the healthcare cost is approximately £11 billion annually. In more than 90% of cases, the risk of a first heart attack is thought to be related to modifiable risk factors including smoking, poor diet, lipidemia, high blood pressure, inactivity, obesity and excess alcohol consumption. The aim of the study is to synthesise evidence for the comparative effectiveness and cost-effectiveness of different interventions for the primary prevention of CVD. Methods We will systematically search databases (for example, MEDLINE (Ovid), Embase (Ovid), Cochrane Library) and the reference lists of previous systematic reviews for randomised controlled trials that assess the effectiveness and cost-effectiveness of any form of intervention aimed at adult populations for the primary prevention of CVD, including but not limited to lipid lowering medications, blood pressure lowering medications, antiplatelet agents, nutritional supplements, dietary interventions, health promotion programmes, physical activity interventions or structural and policy interventions. Interventions may or may not be targeted at high-risk groups. Publications from any year will be considered for inclusion. The primary outcome will be all cause mortality. Secondary outcomes will be cardiovascular diseases related mortality, major cardiovascular events, coronary heart disease, incremental costs per quality-adjusted life years gained. If data permits, we will use network meta-analysis to compare and rank effectiveness of different interventions, and test effect modification of intervention effectiveness using subgroup analyses and meta-regression analyses. Discussion The results will be important for policymakers when making decisions between multiple possible alternative strategies to prevent CVD. Compared to results from existing multiple separate pairwise meta-analyses, this overarching synthesis of all relevant work will enhance decision-making. The findings will be crucial to inform evidence-based priorities and guidelines for policies and planning prevention strategies of CVD. Systematic review registration PROSPERO CRD42019123940 . their clinicians are currently not able to learn in clinic from data on 'patients like me'. We identify the key challenges in offering such an Informatics Consult as a service. may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2020
DA  - 2020-05-07
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://doi.org/10.1186/s13643-020-01366-x', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Olalekan A. Uthman
AU  - Lena Al-Khudairy
AU  - Chidozie U. Nduka
AU  - Rachel Court
AU  - Hema Mistry
AU  - G. J. Melendez-Torres
AU  - Sian Taylor-Phillips
AU  - Aileen Clarke
ER  - 

303.
TY  - journal-article
ID  - https://openalex.org/W3033427052
DO  - https://doi.org/10.1097/gco.0000000000000643
TI  - Artificial intelligence and automation of systematic reviews in women's health
AB  - Purpose of review recent Evidence-based women's healthcare is underpinned by systematic reviews and guidelines. Generating an evidence synthesis to support guidance for clinical practice is a time-consuming and labour-intensive activity that delays transfer of research into practice. Artificial intelligence has the potential to rapidly collate, combine, and update high-quality medical evidence with accuracy and precision, and without bias. heart Recent findings thought This article describes the main fields of artificial intelligence with examples of its application to systematic reviews. These include the capabilities of processing natural language texts, retrieving information, reasoning, and learning. The complementarity and interconnection of the various artificial intelligence techniques can be harnessed to solve difficult problems in automation of reviews. Computer science can advance evidence-based medicine through development, testing, and refinement of artificial intelligence tools to deploy automation, creating 'living' evidence syntheses. effectiveness Summary cost-effectiveness Groundbreaking, high-quality, and impactful artificial intelligence will accelerate the transfer of individual research studies seamlessly into evidence syntheses for contemporaneously improving the quality of healthcare. lowering medications, antiplatelet agents, nutritional supplements, dietary interventions, health promotion programmes, physical activity interventions or structural and policy interventions. Interventions may or may not be targeted at high-risk groups. Publications from any year will be considered for inclusion. The primary outcome will be all cause mortality. Secondary outcomes will be cardiovascular diseases related mortality, major cardiovascular events, coronary heart disease, incremental costs per quality-adjusted life years gained. If data permits, we will use network meta-analysis to compare and rank effectiveness of different interventions, and test effect modification of intervention effectiveness using subgroup analyses and meta-regression analyses. Discussion The results will be important for policymakers when making decisions between multiple possible alternative strategies to prevent CVD. Compared to results from existing multiple separate pairwise meta-analyses, this overarching synthesis of all relevant work will enhance decision-making. The findings will be crucial to inform evidence-based priorities and guidelines for policies and planning prevention strategies of CVD. Systematic review registration PROSPERO CRD42019123940 . their clinicians are currently not able to learn in clinic from data on 'patients like me'. We identify the key challenges in offering such an Informatics Consult as a service. may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2020
DA  - 2020-10-01
JO  - {'id': 'https://openalex.org/S203280300', 'issn_l': '1040-872X', 'issn': ['1080-8256', '1040-872X', '1473-656X'], 'display_name': 'Current Opinion in Obstetrics & Gynecology', 'publisher': 'Lippincott Williams & Wilkins', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Carmen Amezcua-Prieto
AU  - Juan M. Fernández-Luna
AU  - Juan F Huete-Guadix
AU  - Aurora Bueno-Cavanillas
AU  - Khalid Mohammed Khan
ER  - 

304.
TY  - journal-article
ID  - https://openalex.org/W3112337105
DO  - https://doi.org/10.1186/s13643-020-01520-5
TI  - Aligning text mining and machine learning algorithms with best practices for study selection in systematic literature reviews
AB  - Despite existing research on text mining and machine learning for title and abstract screening, the role of machine learning within systematic literature reviews (SLRs) for health technology assessment (HTA) remains unclear given lack of extensive testing and of guidance from HTA agencies. We sought to address two knowledge gaps: to extend ML algorithms to provide a reason for exclusion-to align with current practices-and to determine optimal parameter settings for feature-set generation and ML algorithms.We used abstract and full-text selection data from five large SLRs (n = 3089 to 12,769 abstracts) across a variety of disease areas. Each SLR was split into training and test sets. We developed a multi-step algorithm to categorize each citation into the following categories: included; excluded for each PICOS criterion; or unclassified. We used a bag-of-words approach for feature-set generation and compared machine learning algorithms using support vector machines (SVMs), naïve Bayes (NB), and bagged classification and regression trees (CART) for classification. We also compared alternative training set strategies: using full data versus downsampling (i.e., reducing excludes to balance includes/excludes because machine learning algorithms perform better with balanced data), and using inclusion/exclusion decisions from abstract versus full-text screening. Performance comparisons were in terms of specificity, sensitivity, accuracy, and matching the reason for exclusion.The best-fitting model (optimized sensitivity and specificity) was based on the SVM algorithm using training data based on full-text decisions, downsampling, and excluding words occurring fewer than five times. The sensitivity and specificity of this model ranged from 94 to 100%, and 54 to 89%, respectively, across the five SLRs. On average, 75% of excluded citations were excluded with a reason and 83% of these citations matched the reviewers' original reason for exclusion. Sensitivity significantly improved when both downsampling and abstract decisions were used.ML algorithms can improve the efficiency of the SLR process and the proposed algorithms could reduce the workload of a second reviewer by identifying exclusions with a relevant PICOS reason, thus aligning with HTA guidance. Downsampling can be used to improve study selection, and improvements using full-text exclusions have implications for a learn-as-you-go approach. challenges in offering such an Informatics Consult as a service. may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2020
DA  - 2020-12-13
JO  - {'id': 'https://openalex.org/V82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://doi.org/10.1186/s13643-020-01520-5', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Evan Popoff
AU  - M. Besada
AU  - John A. Jansen
AU  - Shannon Cope
AU  - Steve Kanters
ER  - 

305.
TY  - journal-article
ID  - https://openalex.org/W3144391370
DO  - https://doi.org/10.1186/s13643-021-01632-6
TI  - Successful incorporation of single reviewer assessments during systematic review screening: development and validation of sensitivity and work-saved of an algorithm that considers exclusion criteria and count.
AB  - Accepted systematic review (SR) methodology requires citation screening by two reviewers to maximise retrieval of eligible studies. We hypothesized that records could be excluded by a single reviewer without loss of sensitivity in two conditions; the record was ineligible for multiple reasons, or the record was ineligible for one or more specific reasons that could be reliably assessed.Twenty-four SRs performed at CHEO, a pediatric health care and research centre in Ottawa, Canada, were divided into derivation and validation sets. Exclusion criteria during abstract screening were sorted into 11 specific categories, with loss in sensitivity determined by individual category and by number of exclusion criteria endorsed. Five single reviewer algorithms that combined individual categories and multiple exclusion criteria were then tested on the derivation and validation sets, with success defined a priori as less than 5% loss of sensitivity.The 24 SRs included 930 eligible and 27390 ineligible citations. The reviews were mostly focused on pediatrics (70.8%, N=17/24), but covered various specialties. Using a single reviewer to exclude any citation led to an average loss of sensitivity of 8.6% (95%CI, 6.0-12.1%). Excluding citations with ≥2 exclusion criteria led to 1.2% average loss of sensitivity (95%CI, 0.5-3.1%). Five specific exclusion criteria performed with perfect sensitivity: conference abstract, ineligible age group, case report/series, not human research, and review article. In the derivation set, the five algorithms achieved a loss of sensitivity ranging from 0.0 to 1.9% and work-saved ranging from 14.8 to 39.1%. In the validation set, the loss of sensitivity for all 5 algorithms remained below 2.6%, with work-saved between 10.5% and 48.2%.Findings suggest that targeted application of single-reviewer screening, considering both type and number of exclusion criteria, could retain sensitivity and significantly decrease workload. Further research is required to investigate the potential for combining this approach with crowdsourcing or machine learning methodologies. the proposed algorithms could reduce the workload of a second reviewer by identifying exclusions with a relevant PICOS reason, thus aligning with HTA guidance. Downsampling can be used to improve study selection, and improvements using full-text exclusions have implications for a learn-as-you-go approach. challenges in offering such an Informatics Consult as a service. may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2021
DA  - 2021-04-05
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Nassr Nama
AU  - Mirna Hennawy
AU  - Nick Barrowman
AU  - Katie O’Hearn
AU  - Margaret Sampson
AU  - James G. McNally
ER  - 

306.
TY  - posted-content
ID  - https://openalex.org/W3153326066
DO  - nan
TI  - MS2: Multi-Document Summarization of Medical Studies.
AB  - To assess the effectiveness of any medical intervention, researchers must conduct a time-intensive and highly manual literature review. NLP systems can help to automate or assist in parts of this expensive process. In support of this goal, we release MS^2 (Multi-Document Summarization of Medical Studies), a dataset of over 470k documents and 20k summaries derived from the scientific literature. This dataset facilitates the development of systems that can assess and aggregate contradictory evidence across multiple studies, and is the first large-scale, publicly available multi-document summarization dataset in the biomedical domain. We experiment with a summarization system based on BART, with promising early results. We formulate our summarization inputs and targets in both free text and structured forms and modify a recently proposed metric to assess the quality of our system's generated summaries. Data and models are available at this https URL 930 eligible and 27390 ineligible citations. The reviews were mostly focused on pediatrics (70.8%, N=17/24), but covered various specialties. Using a single reviewer to exclude any citation led to an average loss of sensitivity of 8.6% (95%CI, 6.0-12.1%). Excluding citations with ≥2 exclusion criteria led to 1.2% average loss of sensitivity (95%CI, 0.5-3.1%). Five specific exclusion criteria performed with perfect sensitivity: conference abstract, ineligible age group, case report/series, not human research, and review article. In the derivation set, the five algorithms achieved a loss of sensitivity ranging from 0.0 to 1.9% and work-saved ranging from 14.8 to 39.1%. In the validation set, the loss of sensitivity for all 5 algorithms remained below 2.6%, with work-saved between 10.5% and 48.2%.Findings suggest that targeted application of single-reviewer screening, considering both type and number of exclusion criteria, could retain sensitivity and significantly decrease workload. Further research is required to investigate the potential for combining this approach with crowdsourcing or machine learning methodologies. the proposed algorithms could reduce the workload of a second reviewer by identifying exclusions with a relevant PICOS reason, thus aligning with HTA guidance. Downsampling can be used to improve study selection, and improvements using full-text exclusions have implications for a learn-as-you-go approach. challenges in offering such an Informatics Consult as a service. may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2021
DA  - 2021-04-13
JO  - {'id': 'https://openalex.org/V2596401190', 'issn_l': None, 'issn': None, 'display_name': 'arXiv: Computation and Language', 'publisher': None, 'type': 'journal', 'url': 'https://arxiv.org/pdf/2104.06486.pdf', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Jay DeYoung
AU  - Iz Beltagy
AU  - Madeleine van Zuylen
AU  - Bailey Kuehl
AU  - Lucy Lu Wang
ER  - 

307.
TY  - journal-article
ID  - https://openalex.org/W3163882992
DO  - https://doi.org/10.1111/aec.13052
TI  - What's hot and what's not – Identifying publication trends in insect ecology
AB  - Research disciplines in science have historically developed in silos but are increasingly multidisciplinary. Here, we assessed how the insect ecology literature published in ecological and entomological journals has developed over the last 20 years and which topics have crossed discipline boundaries. We used structural topic modelling to assess research trends from 34 304 articles published in six ecology journals and six entomology journals between 2000 and 2020. We then identified and compared topics that emerged from the entire body of literature, or corpus, with topics that emerged from a subsection of articles that focused only on insects (insect corpus). We found that, within the entire corpus, topics on ‘Community ecology’, ‘Traits, life history & physiology’ and ‘Ecological methods & theory’ became more prevalent over time (hot topics), whereas ‘Population modelling’, ‘Insect development’, ‘Reproduction & ontogeny’ and ‘Plant growth’ declined in prevalence over the 20 years we surveyed (cold topics). In the insect corpus, we found that hot topics included ‘Thermal tolerance’ and ‘Disease vectors’, whereas cold topics included ‘Herbivore phenology’, ‘Insect-plant interactions’ and ‘Parasitoids and parasites’. ‘Landscape ecology’ was a growth topic area for both corpora. Our findings suggest that insect-related research is a major component of the broader ecological discipline, and there are topics in ecology where insect research aligns with general ecological trends. However, specific topics unique to the insect corpora – such as insect taxonomy – are fundamental to both insect and ecology research. to 39.1%. In the validation set, the loss of sensitivity for all 5 algorithms remained below 2.6%, with work-saved between 10.5% and 48.2%.Findings suggest that targeted application of single-reviewer screening, considering both type and number of exclusion criteria, could retain sensitivity and significantly decrease workload. Further research is required to investigate the potential for combining this approach with crowdsourcing or machine learning methodologies. the proposed algorithms could reduce the workload of a second reviewer by identifying exclusions with a relevant PICOS reason, thus aligning with HTA guidance. Downsampling can be used to improve study selection, and improvements using full-text exclusions have implications for a learn-as-you-go approach. challenges in offering such an Informatics Consult as a service. may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2021
DA  - 2021-05-17
JO  - {'id': 'https://openalex.org/S38880878', 'issn_l': '1442-9985', 'issn': ['1442-9985', '1442-9993'], 'display_name': 'Austral Ecology', 'publisher': 'Wiley', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Nigel R. Andrew
AU  - Maldwyn J. Evans
AU  - Lauren N. Svejcar
AU  - Kit Prendegast
AU  - Luis Mata
AU  - Heloise Gibb
AU  - Marisa J. Stone
AU  - Philip S. Barton
ER  - 

308.
TY  - journal-article
ID  - https://openalex.org/W4200362342
DO  - https://doi.org/10.1186/s12874-021-01451-2
TI  - Guidance for using artificial intelligence for title and abstract screening while conducting knowledge syntheses
AB  - Systematic reviews are the cornerstone of evidence-based medicine. However, systematic reviews are time consuming and there is growing demand to produce evidence more quickly, while maintaining robust methods. In recent years, artificial intelligence and active-machine learning (AML) have been implemented into several SR software applications. As some of the barriers to adoption of new technologies are the challenges in set-up and how best to use these technologies, we have provided different situations and considerations for knowledge synthesis teams to consider when using artificial intelligence and AML for title and abstract screening.We retrospectively evaluated the implementation and performance of AML across a set of ten historically completed systematic reviews. Based upon the findings from this work and in consideration of the barriers we have encountered and navigated during the past 24 months in using these tools prospectively in our research, we discussed and developed a series of practical recommendations for research teams to consider in seeking to implement AML tools for citation screening into their workflow.We developed a seven-step framework and provide guidance for when and how to integrate artificial intelligence and AML into the title and abstract screening process. Steps include: (1) Consulting with Knowledge user/Expert Panel; (2) Developing the search strategy; (3) Preparing your review team; (4) Preparing your database; (5) Building the initial training set; (6) Ongoing screening; and (7) Truncating screening. During Step 6 and/or 7, you may also choose to optimize your team, by shifting some members to other review stages (e.g., full-text screening, data extraction).Artificial intelligence and, more specifically, AML are well-developed tools for title and abstract screening and can be integrated into the screening process in several ways. Regardless of the method chosen, transparent reporting of these methods is critical for future studies evaluating artificial intelligence and AML. with crowdsourcing or machine learning methodologies. the proposed algorithms could reduce the workload of a second reviewer by identifying exclusions with a relevant PICOS reason, thus aligning with HTA guidance. Downsampling can be used to improve study selection, and improvements using full-text exclusions have implications for a learn-as-you-go approach. challenges in offering such an Informatics Consult as a service. may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2021
DA  - 2021-12-01
JO  - {'id': 'https://openalex.org/S185874209', 'issn_l': '1471-2288', 'issn': ['1471-2288'], 'display_name': 'BMC Medical Research Methodology', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://bmcmedresmethodol.biomedcentral.com/track/pdf/10.1186/s12874-021-01451-2', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Candyce Hamel
AU  - Mona Hersi
AU  - Shannon Kelly
AU  - Andrea C. Tricco
AU  - Sharon E. Straus
AU  - George A. Wells
AU  - Ba' Pham
AU  - Brian Hutton
ER  - 

309.
TY  - journal-article
ID  - https://openalex.org/W4212778699
DO  - https://doi.org/10.1007/s11095-022-03201-5
TI  - Applications of Model-Based Meta-Analysis in Drug Development
AB  - Model-based meta-analysis (MBMA) is a quantitative approach that leverages published summary data along with internal data and can be applied to inform key drug development decisions, including the benefit-risk assessment of a treatment under investigation. These risk-benefit assessments may involve determining an optimal dose compared against historic external comparators of a particular disease indication. MBMA can provide a flexible framework for interpreting aggregated data from historic reference studies and therefore should be a standard tool for the model-informed drug development (MIDD) framework.In addition to pairwise and network meta-analyses, MBMA provides further contributions in the quantitative approaches with its ability to incorporate longitudinal data and the pharmacologic concept of dose-response relationship, as well as to combine individual- and summary-level data and routinely incorporate covariates in the analysis.A common application of MBMA is the selection of optimal dose and dosing regimen of the internal investigational molecule to evaluate external benchmarking and to support comparator selection. Two case studies provided examples in applications of MBMA in biologics (durvalumab + tremelimumab for safety) and small molecule (fenebrutinib for efficacy) to support drug development decision-making in two different but well-studied disease areas, i.e., oncology and rheumatoid arthritis, respectively.Important to the future directions of MBMA include additional recognition and engagement from drug development stakeholders for the MBMA approach, stronger collaboration between pharmacometrics and statistics, expanded data access, and the use of machine learning for database building. Timely, cost-effective, and successful application of MBMA should be part of providing an integrated view of MIDD. screening, data extraction).Artificial intelligence and, more specifically, AML are well-developed tools for title and abstract screening and can be integrated into the screening process in several ways. Regardless of the method chosen, transparent reporting of these methods is critical for future studies evaluating artificial intelligence and AML. with crowdsourcing or machine learning methodologies. the proposed algorithms could reduce the workload of a second reviewer by identifying exclusions with a relevant PICOS reason, thus aligning with HTA guidance. Downsampling can be used to improve study selection, and improvements using full-text exclusions have implications for a learn-as-you-go approach. challenges in offering such an Informatics Consult as a service. may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2022
DA  - 2022-02-16
JO  - {'id': 'https://openalex.org/S103865650', 'issn_l': '0724-8741', 'issn': ['0724-8741', '1573-904X'], 'display_name': 'Pharmaceutical Research', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://link.springer.com/content/pdf/10.1007/s11095-022-03201-5.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Phyllis Chan
AU  - Kirill Peskov
AU  - Xuyang Song
ER  - 

310.
TY  - journal-article
ID  - https://openalex.org/W4220880022
DO  - https://doi.org/10.14573/altex.2202141
TI  - Application of evidence-based methods to construct mechanism-driven chemical assessment frameworks
AB  - The workshop titled “Application of evidence-based methods to construct mechanism-driven chemical assessment frameworks” was co-organized by the Evidence-based Toxicology Collaboration and the European Food Safety Authority (EFSA) and hosted by EFSA at its headquarters in Parma, Italy on October 2 and 3, 2019. The goal was to explore integration of systematic review with mechanistic evidence evaluation. Participants were invited to work on concrete products to advance the exploration of how evidence-based approaches can support the development and application of adverse outcome pathways (AOP) in chemical risk assessment. The workshop discussions were centered around three related themes: 1) assessing certainty in AOPs, 2) literature-based AOP development, and 3) integrating certainty in AOPs and non-animal evidence into decision frameworks. Several challenges, mostly related to methodology, were identified and largely determined the workshop recommendations. The workshop recommendations included the comparison and potential alignment of processes used to develop AOP and systematic review methodology, including the translation of vocabulary of evidence-based methods to AOP and vice versa, the development and improvement of evidence mapping and text mining methods and tools, as well as a call for a fundamental change in chemical risk and uncertainty assessment methodology if to be conducted based on AOPs and new approach methodologies (NAM). The usefulness of evidence-based approaches for mechanism-based chemical risk assessments was stressed, particularly the potential contribution of the rigor and transparency inherent to such approaches in building stakeholders’ trust for implementation of NAM evidence and AOPs into chemical risk assessment. view of MIDD. screening, data extraction).Artificial intelligence and, more specifically, AML are well-developed tools for title and abstract screening and can be integrated into the screening process in several ways. Regardless of the method chosen, transparent reporting of these methods is critical for future studies evaluating artificial intelligence and AML. with crowdsourcing or machine learning methodologies. the proposed algorithms could reduce the workload of a second reviewer by identifying exclusions with a relevant PICOS reason, thus aligning with HTA guidance. Downsampling can be used to improve study selection, and improvements using full-text exclusions have implications for a learn-as-you-go approach. challenges in offering such an Informatics Consult as a service. may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2022
DA  - 2022-01-01
JO  - {'id': 'https://openalex.org/S4210171861', 'issn_l': '1868-596X', 'issn': ['1868-596X', '1868-8551'], 'display_name': 'Alternatives to animal experimentation', 'publisher': 'Spektrum Akademischer Verlag', 'type': 'journal', 'url': 'https://doi.org/10.14573/altex.2202141', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Sebastian Hoffmann
AU  - Elisa Aiassa
AU  - Michelle M. Angrish
AU  - Claire Beausoleil
AU  - Frédéric Y. Bois
AU  - Laura Ciccolallo
AU  - Peter Craig
AU  - Rob B. M. de Vries
AU  - Jean-Lou Dorne
AU  - Ingrid L. Druwe
AU  - Stephen H. Edwards
AU  - Chantra Eskes
AU  - Marios Georgiadis
AU  - Thomas Hartung
AU  - Aude Kienzler
AU  - Elisabeth Kristjansson
AU  - Juleen Lam
AU  - Laura Martino
AU  - Bette Meek
AU  - Rebecca L. Morgan
AU  - Irene Munoz-Guajardo
AU  - Pamela D. Noyes
AU  - Elena Parmelli
AU  - Aldert H. Piersma
AU  - Andrew A. Rooney
AU  - Emily S. Sena
AU  - Kristie Sullivan
AU  - Jose Tarazona
AU  - Andrea Terron
AU  - Kris Thayer
AU  - Jan Turner
AU  - Jos Verbeek
AU  - D. Verloo
AU  - Mathieu Vinken
AU  - Sean Watford
AU  - Paul Whaley
AU  - Daniele Wikoff
AU  - Kate M. Willett
AU  - Katya Tsaioun
ER  - 

311.
TY  - posted-content
ID  - https://openalex.org/W3023035014
DO  - nan
TI  - Fact or Fiction: Verifying Scientific Claims
AB  - We introduce scientific claim verification, a new task to select abstracts from the research literature containing evidence that supports or refutes a given scientific claim, and to identify rationales justifying each decision. To study this task, we construct SciFact, a dataset of 1.4K expert-written scientific claims paired with evidence-containing abstracts annotated with labels and rationales. We develop baseline models for SciFact, and demonstrate that these models benefit from combined training on a large dataset of claims about Wikipedia articles, together with the new SciFact data. We show that our claim verification system is able to identify plausible evidence for 23 / 36 claims relevant to COVID-19 on the CORD-19 corpus. Our results and experiments strongly suggest that our new task and data will support significant future research efforts. the workshop recommendations. The workshop recommendations included the comparison and potential alignment of processes used to develop AOP and systematic review methodology, including the translation of vocabulary of evidence-based methods to AOP and vice versa, the development and improvement of evidence mapping and text mining methods and tools, as well as a call for a fundamental change in chemical risk and uncertainty assessment methodology if to be conducted based on AOPs and new approach methodologies (NAM). The usefulness of evidence-based approaches for mechanism-based chemical risk assessments was stressed, particularly the potential contribution of the rigor and transparency inherent to such approaches in building stakeholders’ trust for implementation of NAM evidence and AOPs into chemical risk assessment. view of MIDD. screening, data extraction).Artificial intelligence and, more specifically, AML are well-developed tools for title and abstract screening and can be integrated into the screening process in several ways. Regardless of the method chosen, transparent reporting of these methods is critical for future studies evaluating artificial intelligence and AML. with crowdsourcing or machine learning methodologies. the proposed algorithms could reduce the workload of a second reviewer by identifying exclusions with a relevant PICOS reason, thus aligning with HTA guidance. Downsampling can be used to improve study selection, and improvements using full-text exclusions have implications for a learn-as-you-go approach. challenges in offering such an Informatics Consult as a service. may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2020
DA  - 2020-04-30
JO  - {'id': 'https://openalex.org/V2596401190', 'issn_l': None, 'issn': None, 'display_name': 'arXiv: Computation and Language', 'publisher': None, 'type': 'journal', 'url': 'http://export.arxiv.org/pdf/2004.14974', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - David Wadden
AU  - Shanchuan Lin
AU  - Kyle Lo
AU  - Lucy Lu Wang
AU  - Madeleine van Zuylen
AU  - Arman Cohan
AU  - Hannaneh Hajishirzi
ER  - 

312.
TY  - journal-article
ID  - https://openalex.org/W3035970239
DO  - https://doi.org/10.1136/bmjinnov-2019-000410
TI  - Deep learning for natural language processing of free-text pathology reports: a comparison of learning curves
AB  - Introduction Although clinically derived information could improve patient care, its full potential remains unrealised because most of it is stored in a format unsuitable for traditional methods of analysis, free-text clinical reports. Various studies have already demonstrated the utility of natural language processing algorithms for medical text analysis. Yet, evidence on their learning efficiency is still lacking. This study aimed to compare the learning curves of various algorithms and develop an open-source framework for text mining in healthcare. Methods Deep learning and regressions-based models were developed to determine the histopathological diagnosis of patients with brain tumour based on free-text pathology reports. For each model, we characterised the learning curve and the minimal required training examples to reach the area under the curve (AUC) performance thresholds of 0.95 and 0.98. Results In total, we retrieved 7000 reports on 5242 patients with brain tumour (2316 with glioma, 1412 with meningioma and 1514 with cerebral metastasis). Conventional regression and deep learning-based models required 200–400 and 800–1500 training examples to reach the AUC performance thresholds of 0.95 and 0.98, respectively. The deep learning architecture utilised in the current study required 100 and 200 examples, respectively, corresponding to a learning capacity that is two to eight times more efficient. Conclusions This open-source framework enables the development of high-performing and fast learning natural language processing models. The steep learning curve can be valuable for contexts with limited training examples (eg, rare diseases and events or institutions with lower patient volumes). The resultant models could accelerate retrospective chart review, assemble clinical registries and facilitate a rapid learning healthcare system. screening and can be integrated into the screening process in several ways. Regardless of the method chosen, transparent reporting of these methods is critical for future studies evaluating artificial intelligence and AML. with crowdsourcing or machine learning methodologies. the proposed algorithms could reduce the workload of a second reviewer by identifying exclusions with a relevant PICOS reason, thus aligning with HTA guidance. Downsampling can be used to improve study selection, and improvements using full-text exclusions have implications for a learn-as-you-go approach. challenges in offering such an Informatics Consult as a service. may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2020
DA  - 2020-06-23
JO  - {'id': 'https://openalex.org/S4210179384', 'issn_l': '2055-642X', 'issn': ['2055-642X', '2055-8074'], 'display_name': 'BMJ innovations', 'publisher': 'BMJ', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Joeky T. Senders
AU  - David J. Cote
AU  - Alireza Mehrtash
AU  - Robert Wiemann
AU  - William B. Gormley
AU  - Timothy W. Smith
AU  - Marike L. D. Broekman
AU  - Omar Arnaout
ER  - 

313.
TY  - journal-article
ID  - https://openalex.org/W3128307363
DO  - https://doi.org/10.1111/jnu.12628
TI  - Agreement in Risk of Bias Assessment Between RobotReviewer and Human Reviewers: An Evaluation Study on Randomised Controlled Trials in Nursing‐Related Cochrane Reviews
AB  - Purpose Although RobotReviewer is a machine learning system for semi-automated assistance in risk of bias assessment. The tools's performance in randomized controlled trials (RCTs) in the field of nursing remains unknown. We aimed therefore to evaluate the agreement in risk of bias assessment between RobotReviewer and human reviewers. Yet, Design on Evaluation study using a retrospective diagnostic design. study Methods to We used RobotReviewer as the index test and human reviewers' risk of bias assessment reported in Cochrane reviews as the reference test. A convenience sample of electronically available English-language full texts of RCTs included in Cochrane reviews with nurs* in the title were eligible for inclusion. In this context, we assessed random sequence generation, allocation concealment, and blinding (personnel or participants and assessors) corresponding to Cochrane risk of bias version 2011. Two independent research teams performed and double-checked data extraction and analysis. We calculated sensitivity, specificity, receiver operating characteristic (ROC) curve, the area under the ROC curve, predictive values, observed percentage of agreement, and Cohen's kappa (including confidence intervals, if applicable). 0.95 Findings 0.98, The selection process yielded 190 RCTs published between 1958 and 2016 in 23 Cochrane reviews published between 2000 and 2018. Missing assessments of risk of bias domains in Cochrane reviews or RobotReviewer yielded varying sample sizes per risk of bias domain. Sensitivity ranged from 0.44 to 0.88 and specificity from 0.48 to 0.95. Positive predictive value was highest for allocation concealment (0.79) and lowest for blinding assessors (0.25). Cohen's kappa was moderate for randomization (0.52), allocation concealment (0.60), and for blinding of personnel/patients (0.43). Blinding of outcome assessors had only slight agreement (0.04). the Conclusions process This is the first evaluation of risk of bias assessment by RobotReviewer in RCTs included in nursing-related Cochrane reviews. It yielded a moderate degree of agreement with human reviewers for randomization and allocation concealment, and an adequate sensitivity for detecting low risk of selection bias. relevant Clinical relevance thus Based on our results, using the RobotReviewer for risk of bias assessment in RCTs can be supportive in some risk of bias domains. However, human reviewers should supervise the semi-automated assessment process. service. may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2021
DA  - 2021-03-01
JO  - {'id': 'https://openalex.org/S205285807', 'issn_l': '1527-6546', 'issn': ['1547-5069', '1527-6546'], 'display_name': 'Journal of Nursing Scholarship', 'publisher': 'Wiley-Blackwell', 'type': 'journal', 'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/jnu.12628', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc-nd'}
DP  - OpenAlex
AU  - Julian Hirt
AU  - Jasmin Meichlinger
AU  - Petra B. Schumacher
AU  - Gerhard J. Mueller
ER  - 

314.
TY  - posted-content
ID  - https://openalex.org/W3159559669
DO  - https://doi.org/10.1101/2021.04.26.21255833
TI  - Systematic review automation tool use by systematic reviewers, health technology assessors and clinical guideline developers: tools used, abandoned, and desired
AB  - Abstract Objective We investigated the use of systematic review automation tools by systematic reviewers, health technology assessors and clinical guideline developers. Study design and settings An online, 16-question survey was distributed across several evidence synthesis, health technology assessment and guideline development organisations internationally. We asked the respondents what tools they use and abandon, how often and when they use the tools, their perceived time savings and accuracy, and desired new tools. Descriptive statistics were used to report the results. Results 253 respondents completed the survey; 89% have used systematic review automation tools – most frequently whilst screening (79%). Respondents’ ‘top 3’ tools include: Covidence (45%), RevMan (35%), Rayyan and GRADEPro (both 22%); most commonly abandoned were Rayyan (19%), Covidence (15%), DistillerSR (14%) and RevMan (13%). Majority thought tools saved time (80%) and increased accuracy (54%). Respondents taught themselves to how to use the tools (72%), and were most often prevented by lack of knowledge from their adoption (51%). Most new tool development was suggested for the searching and data extraction stages. Conclusion Automation tools are likely to take on an increasingly important role in high quality and timely reviews. Further work is required in training and dissemination of automation tools and ensuring they meet the desirable features of those conducting systematic reviews. risk of bias domain. Sensitivity ranged from 0.44 to 0.88 and specificity from 0.48 to 0.95. Positive predictive value was highest for allocation concealment (0.79) and lowest for blinding assessors (0.25). Cohen's kappa was moderate for randomization (0.52), allocation concealment (0.60), and for blinding of personnel/patients (0.43). Blinding of outcome assessors had only slight agreement (0.04). the Conclusions process This is the first evaluation of risk of bias assessment by RobotReviewer in RCTs included in nursing-related Cochrane reviews. It yielded a moderate degree of agreement with human reviewers for randomization and allocation concealment, and an adequate sensitivity for detecting low risk of selection bias. relevant Clinical relevance thus Based on our results, using the RobotReviewer for risk of bias assessment in RCTs can be supportive in some risk of bias domains. However, human reviewers should supervise the semi-automated assessment process. service. may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2021
DA  - 2021-04-30
JO  - {'id': 'https://openalex.org/S4306400573', 'issn_l': None, 'issn': None, 'display_name': 'medRxiv (Cold Spring Harbor Laboratory)', 'publisher': 'Cold Spring Harbor Laboratory', 'type': 'repository', 'url': 'https://doi.org/10.1101/2021.04.26.21255833', 'is_oa': True, 'version': 'submittedVersion', 'license': None}
DP  - OpenAlex
AU  - Andrew M. Scott
AU  - Connor Forbes
AU  - John W. Clark
AU  - Matt Carter
AU  - Paul Glasziou
AU  - Zachary Munn
ER  - 

315.
TY  - journal-article
ID  - https://openalex.org/W3203297670
DO  - https://doi.org/10.2196/33124
TI  - Toward Automated Data Extraction According to Tabular Data Structure: Cross-sectional Pilot Survey of the Comparative Clinical Literature
AB  - Systematic reviews depend on time-consuming extraction of data from the PDFs of underlying studies. To date, automation efforts have focused on extracting data from the text, and no approach has yet succeeded in fully automating ingestion of quantitative evidence. However, the majority of relevant data is generally presented in tables, and the tabular structure is more amenable to automated extraction than free text.The purpose of this study was to classify the structure and format of descriptive statistics reported in tables in the comparative medical literature.We sampled 100 published randomized controlled trials from 2019 based on a search in PubMed; these results were imported to the AutoLit platform. Studies were excluded if they were nonclinical, noncomparative, not in English, protocols, or not available in full text. In AutoLit, tables reporting baseline or outcome data in all studies were characterized based on reporting practices. Measurement context, meaning the structure in which the interventions of interest, patient arm breakdown, measurement time points, and data element descriptions were presented, was classified based on the number of contextual pieces and metadata reported. The statistic formats for reported metrics (specific instances of reporting of data elements) were then classified by location and broken down into reporting strategies for continuous, dichotomous, and categorical metrics.We included 78 of 100 sampled studies, one of which (1.3%) did not report data elements in tables. The remaining 77 studies reported baseline and outcome data in 174 tables, and 96% (69/72) of these tables broke down reporting by patient arms. Fifteen structures were found for the reporting of measurement context, which were broadly grouped into: 1×1 contexts, where two pieces of context are reported in total (eg, arms in columns, data elements in rows); 2×1 contexts, where two pieces of context are given on row headers (eg, time points in columns, arms nested in data elements on rows); and 1×2 contexts, where two pieces of context are given on column headers. The 1×1 contexts were present in 57% of tables (99/174), compared to 20% (34/174) for 2×1 contexts and 15% (26/174) for 1×2 contexts; the remaining 8% (15/174) used unique/other stratification methods. Statistic formats were reported in the headers or descriptions of 84% (65/74) of studies.In this cross-sectional pilot review, we found a high density of information in tables, but with major heterogeneity in presentation of measurement context. The highest-density studies reported both baseline and outcome measures in tables, with arm-level breakout, intervention labels, and arm sizes present, and reported both the statistic formats and units. The measurement context formats presented here, broadly classified into three classes that cover 92% (71/78) of studies, form a basis for understanding the frequency of different reporting styles, supporting automated detection of the data format for extraction of metrics. meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2021
DA  - 2021-11-24
JO  - {'id': 'https://openalex.org/V4210234749', 'issn_l': '2561-326X', 'issn': ['2561-326X'], 'display_name': 'JMIR formative research', 'publisher': 'JMIR Publications Inc.', 'type': 'journal', 'url': 'https://formative.jmir.org/2021/11/e33124/PDF', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Kevin M. Kallmes
AU  - Nicole Hardy
AU  - Kevin M. Kallmes
ER  - 

316.
TY  - journal-article
ID  - https://openalex.org/W3212337362
DO  - https://doi.org/10.1002/int.22748
TI  - A precision‐preferred comprehensive information extraction system for clinical articles in traditional Chinese Medicine
AB  - This study established a precision-preferred system specially designed for the data extraction of traditional Chinese medicine (TCM) articles, providing foundational data for subsequent clinical article analysis and synthesis of TCM clinical evidence. Information extraction is commonly used in many fields to identify relevant concepts and the relationship between pairs of concepts from the vast information sources. Previous studies that performed information extraction primarily focused on scattering targeted fields to achieve a balance between precision and recall. Therefore, this study aims to create a comprehensive information extraction system for TCM articles. This system will extract all relevant information from research articles on a broad research field, including the 11 diseases that can be efficiently treated with TCM, with high precision and efficient measurement to address bias in every study. It covers the most essential information related to patients, interventions, comparisons, outcomes, and study design (PICOS) principles in TCM clinical trials. This system covers 34 target fields on 14 topics. Impediments such as the various typesetting of TCM clinical articles were managed by a hybrid of machine vision and optical character recognition. Thus, TCM researchers can be spared of laborious, unscalable, and inefficient manual extraction processes. Our system could also enhance TCM researcher awareness of frequently missing information or TCM clinical trial design methods that could introduce bias, by analyzing the overall information integrity of TCM clinical articles, which is beneficial for future research designs. in 174 tables, and 96% (69/72) of these tables broke down reporting by patient arms. Fifteen structures were found for the reporting of measurement context, which were broadly grouped into: 1×1 contexts, where two pieces of context are reported in total (eg, arms in columns, data elements in rows); 2×1 contexts, where two pieces of context are given on row headers (eg, time points in columns, arms nested in data elements on rows); and 1×2 contexts, where two pieces of context are given on column headers. The 1×1 contexts were present in 57% of tables (99/174), compared to 20% (34/174) for 2×1 contexts and 15% (26/174) for 1×2 contexts; the remaining 8% (15/174) used unique/other stratification methods. Statistic formats were reported in the headers or descriptions of 84% (65/74) of studies.In this cross-sectional pilot review, we found a high density of information in tables, but with major heterogeneity in presentation of measurement context. The highest-density studies reported both baseline and outcome measures in tables, with arm-level breakout, intervention labels, and arm sizes present, and reported both the statistic formats and units. The measurement context formats presented here, broadly classified into three classes that cover 92% (71/78) of studies, form a basis for understanding the frequency of different reporting styles, supporting automated detection of the data format for extraction of metrics. meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2021
DA  - 2021-11-16
JO  - {'id': 'https://openalex.org/S57950554', 'issn_l': '0884-8173', 'issn': ['1098-111X', '0884-8173'], 'display_name': 'International Journal of Intelligent Systems', 'publisher': 'Wiley-Blackwell', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Ye Xia
AU  - Jianxiong Cai
AU  - Yizhen Li
AU  - Zhili Dou
AU  - Yunan Zhang
AU  - Lin Wu
AU  - Zhe Huang
AU  - Shujing Xu
AU  - Jiayi Sun
AU  - Yixing Liu
AU  - Darong Wu
AU  - Dongran Han
ER  - 

317.
TY  - journal-article
ID  - https://openalex.org/W4200331025
DO  - https://doi.org/10.1002/jrsm.1541
TI  - Machine learning in systematic reviews: Comparing automated text clustering with Lingo3G and human researcher categorization in a rapid review
AB  - Systematic reviews are resource-intensive. The machine learning tools being developed mostly focus on the study identification process, but tools to assist in analysis and categorization are also needed. One possibility is to use unsupervised automatic text clustering, in which each study is automatically assigned to one or more meaningful clusters. Our main aim was to assess the usefulness of an automated clustering method, Lingo3G, in categorizing studies in a simplified rapid review, then compare performance (precision and recall) of this method compared to manual categorization. We randomly assigned all 128 studies in a review to be coded by a human researcher blinded to cluster assignment (mimicking two independent researchers) or by a human researcher non-blinded to cluster assignment (mimicking one researcher checking another's work). We compared time use, precision and recall of manual categorization versus automated clustering. Automated clustering and manual categorization organized studies by population and intervention/context. Automated clustering failed to identify two manually identified categories but identified one additional category not identified by the human researcher. We estimate that automated clustering has similar precision to both blinded and non-blinded researchers (e.g., 88% vs. 89%), but higher recall (e.g., 89% vs. 84%). Manual categorization required 49% more time than automated clustering. Using a specific clustering algorithm, automated clustering can be helpful with categorization of and identifying patterns across studies in simpler systematic reviews. We found that the clustering was sensitive enough to group studies according to linguistic differences that often corresponded to the manual categories. patient arms. Fifteen structures were found for the reporting of measurement context, which were broadly grouped into: 1×1 contexts, where two pieces of context are reported in total (eg, arms in columns, data elements in rows); 2×1 contexts, where two pieces of context are given on row headers (eg, time points in columns, arms nested in data elements on rows); and 1×2 contexts, where two pieces of context are given on column headers. The 1×1 contexts were present in 57% of tables (99/174), compared to 20% (34/174) for 2×1 contexts and 15% (26/174) for 1×2 contexts; the remaining 8% (15/174) used unique/other stratification methods. Statistic formats were reported in the headers or descriptions of 84% (65/74) of studies.In this cross-sectional pilot review, we found a high density of information in tables, but with major heterogeneity in presentation of measurement context. The highest-density studies reported both baseline and outcome measures in tables, with arm-level breakout, intervention labels, and arm sizes present, and reported both the statistic formats and units. The measurement context formats presented here, broadly classified into three classes that cover 92% (71/78) of studies, form a basis for understanding the frequency of different reporting styles, supporting automated detection of the data format for extraction of metrics. meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2021
DA  - 2021-12-22
JO  - {'id': 'https://openalex.org/S205768342', 'issn_l': '1759-2879', 'issn': ['1759-2879', '1759-2887'], 'display_name': 'Research Synthesis Methods', 'publisher': 'Wiley-Blackwell', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Ashley Elizabeth Muller
AU  - Heather M. Ames
AU  - Patricia Sofia Jacobsen Jardim
AU  - Christopher F. Rose
ER  - 

318.
TY  - journal-article
ID  - https://openalex.org/W4214717426
DO  - https://doi.org/10.3390/info13030117
TI  - Semi-Automatic Systematic Literature Reviews and Information Extraction of COVID-19 Scientific Evidence: Description and Preliminary Results of the COKE Project
AB  - The COVID-19 pandemic highlighted the importance of validated and updated scientific information to help policy makers, healthcare professionals, and the public. The speed in disseminating reliable information and the subsequent guidelines and policy implementation are also essential to save as many lives as possible. Trustworthy guidelines should be based on a systematic evidence review which uses reproducible analytical methods to collect secondary data and analyse them. However, the guidelines’ drafting process is time consuming and requires a great deal of resources. This paper aims to highlight the importance of accelerating and streamlining the extraction and synthesis of scientific evidence, specifically within the systematic review process. To do so, this paper describes the COKE (COVID-19 Knowledge Extraction framework for next generation discovery science) Project, which involves the use of machine reading and deep learning to design and implement a semi-automated system that supports and enhances the systematic literature review and guideline drafting processes. Specifically, we propose a framework for aiding in the literature selection and navigation process that employs natural language processing and clustering techniques for selecting and organizing the literature for human consultation, according to PICO (Population/Problem, Intervention, Comparison, and Outcome) elements. We show some preliminary results of the automatic classification of sentences on a dataset of abstracts related to COVID-19. helpful with categorization of and identifying patterns across studies in simpler systematic reviews. We found that the clustering was sensitive enough to group studies according to linguistic differences that often corresponded to the manual categories. patient arms. Fifteen structures were found for the reporting of measurement context, which were broadly grouped into: 1×1 contexts, where two pieces of context are reported in total (eg, arms in columns, data elements in rows); 2×1 contexts, where two pieces of context are given on row headers (eg, time points in columns, arms nested in data elements on rows); and 1×2 contexts, where two pieces of context are given on column headers. The 1×1 contexts were present in 57% of tables (99/174), compared to 20% (34/174) for 2×1 contexts and 15% (26/174) for 1×2 contexts; the remaining 8% (15/174) used unique/other stratification methods. Statistic formats were reported in the headers or descriptions of 84% (65/74) of studies.In this cross-sectional pilot review, we found a high density of information in tables, but with major heterogeneity in presentation of measurement context. The highest-density studies reported both baseline and outcome measures in tables, with arm-level breakout, intervention labels, and arm sizes present, and reported both the statistic formats and units. The measurement context formats presented here, broadly classified into three classes that cover 92% (71/78) of studies, form a basis for understanding the frequency of different reporting styles, supporting automated detection of the data format for extraction of metrics. meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2022
DA  - 2022-02-28
JO  - {'id': 'https://openalex.org/S4210219776', 'issn_l': '2078-2489', 'issn': ['2078-2489'], 'display_name': 'Information', 'publisher': 'MDPI', 'type': 'journal', 'url': 'https://www.mdpi.com/2078-2489/13/3/117/pdf?version=1646045645', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Davide Golinelli
AU  - Andrea Giovanni Nuzzolese
AU  - Francesco Sanmarchi
AU  - Luana Bulla
AU  - Misael Mongiovì
AU  - Aldo Gangemi
AU  - Paola Rucci
ER  - 

319.
TY  - journal-article
ID  - https://openalex.org/W4281788268
DO  - https://doi.org/10.1016/j.iswa.2022.200091
TI  - Search strategy formulation for systematic reviews: Issues, challenges and opportunities
AB  - • Boolean logic is dominant in the formulation of search strategies for evidence synthesis in professional search, notably healthcare, but in other domains such as law, patents and recruitment. • Boolean methods are complex, time consuming, resource intensive and error prone, and a new approach is required. • Alternative approaches either suffer from the same problems as Boolean methods or introduce further problems such as lack of trust and transparency. • We propose a set of design principles to address the shortcomings of Boolean logic when formulating search strategies for evidence synthesis. Systematic literature reviews play a vital role in identifying the best available evidence for health and social care research, policy, and practice. The resources required to produce systematic reviews can be significant, and a key to the success of any review is the search strategy used to identify relevant literature. However, the methods used to construct search strategies can be complex, time consuming, resource intensive and error prone. In this review, we examine the state of the art in resolving complex structured information needs, focusing primarily on the healthcare context. We analyse the literature to identify key challenges and issues and explore appropriate solutions and workarounds. From this analysis we propose a way forward to facilitate trust and to aid explainability and transparency, reproducibility and replicability through a set of key design principles for tools to support the development of search strategies in systematic literature reviews. differences that often corresponded to the manual categories. patient arms. Fifteen structures were found for the reporting of measurement context, which were broadly grouped into: 1×1 contexts, where two pieces of context are reported in total (eg, arms in columns, data elements in rows); 2×1 contexts, where two pieces of context are given on row headers (eg, time points in columns, arms nested in data elements on rows); and 1×2 contexts, where two pieces of context are given on column headers. The 1×1 contexts were present in 57% of tables (99/174), compared to 20% (34/174) for 2×1 contexts and 15% (26/174) for 1×2 contexts; the remaining 8% (15/174) used unique/other stratification methods. Statistic formats were reported in the headers or descriptions of 84% (65/74) of studies.In this cross-sectional pilot review, we found a high density of information in tables, but with major heterogeneity in presentation of measurement context. The highest-density studies reported both baseline and outcome measures in tables, with arm-level breakout, intervention labels, and arm sizes present, and reported both the statistic formats and units. The measurement context formats presented here, broadly classified into three classes that cover 92% (71/78) of studies, form a basis for understanding the frequency of different reporting styles, supporting automated detection of the data format for extraction of metrics. meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2022
DA  - 2022-06-01
JO  - {'id': 'https://openalex.org/V4210234522', 'issn_l': '2667-3053', 'issn': ['2667-3053'], 'display_name': 'Intelligent systems with applications', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'https://doi.org/10.1016/j.iswa.2022.200091', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc-nd'}
DP  - OpenAlex
AU  - Andrew MacFarlane
AU  - Tony Russell-Rose
AU  - Farhad Shokraneh
ER  - 

320.
TY  - journal-article
ID  - https://openalex.org/W2996447026
DO  - https://doi.org/10.1111/1747-0080.12598
TI  - Exploring perceptions, barriers and use of systematic reviews amongst nutrition professionals and nutrition students
AB  - AIM: Systematic reviews (SRs) are a core component of evidence‐based practice and are widely used in developing nutrition policy. This study aimed to examine nutrition professionals and students' perceptions, barriers and use of SRs. A secondary aim was to examine confidence using and conducting SRs. METHODS: A self‐administered online survey was developed, pilot‐tested and implemented via SurveyMonkey. The survey consisted of 29 items separated into demographics, perceptions, use, and knowledge of SRs, confidence in using and conducting SRs, and barriers to use and conduct of SRs. The survey was disseminated via professional newsletters and social media. RESULTS: Ninety‐four nutrition professionals/students completed the survey. Survey results indicated respondents valued SRs, with SRs used most commonly to update knowledge. While most respondents (67%) were confident in using SRs, many (59%) expressed a lack of confidence in conducting a SR. In particular, few respondents (12%) reported confidence in conducting meta‐analyses. The majority of respondents were aware that SRs underpinned guidelines and nutrition resources, however, few (21%) respondents identified that self‐substantiation of health claims were based on SRs. Time, access to scientific database, lack of workplace support and confidence were the main barriers to SRs use. CONCLUSIONS: SRs were reported as being valued by nutrition professionals and students, though time constraints, a lack of confidence and organisations which did not prioritise research were barriers to conducting SRs. The findings of this survey highlight a need for training and education as potential strategies to promote SR engagement in nutrition professionals and students. arms. Fifteen structures were found for the reporting of measurement context, which were broadly grouped into: 1×1 contexts, where two pieces of context are reported in total (eg, arms in columns, data elements in rows); 2×1 contexts, where two pieces of context are given on row headers (eg, time points in columns, arms nested in data elements on rows); and 1×2 contexts, where two pieces of context are given on column headers. The 1×1 contexts were present in 57% of tables (99/174), compared to 20% (34/174) for 2×1 contexts and 15% (26/174) for 1×2 contexts; the remaining 8% (15/174) used unique/other stratification methods. Statistic formats were reported in the headers or descriptions of 84% (65/74) of studies.In this cross-sectional pilot review, we found a high density of information in tables, but with major heterogeneity in presentation of measurement context. The highest-density studies reported both baseline and outcome measures in tables, with arm-level breakout, intervention labels, and arm sizes present, and reported both the statistic formats and units. The measurement context formats presented here, broadly classified into three classes that cover 92% (71/78) of studies, form a basis for understanding the frequency of different reporting styles, supporting automated detection of the data format for extraction of metrics. meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2020
DA  - 2020-02-01
JO  - {'id': 'https://openalex.org/V76668921', 'issn_l': '1446-6368', 'issn': ['1747-0080', '1446-6368', '1839-3322'], 'display_name': 'Nutrition & Dietetics', 'publisher': 'Wiley-Blackwell', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Bethany Gooding
AU  - Yasmine Probst
AU  - Lauren Houston
AU  - Elizabeth P. Neale
ER  - 

321.
TY  - posted-content
ID  - https://openalex.org/W3037541136
DO  - nan
TI  - ASReview: Open Source Software for Efficient and Transparent Active Learning for Systematic Reviews.
AB  - For many tasks -- including guideline development for medical doctors and systematic reviews for research fields -- the scientific literature needs to be checked systematically. The current practice is that scholars and practitioners screen thousands of studies by hand to find which studies to include in their review. This is error prone and inefficient. We therefore developed an open source machine learning (ML)-aided pipeline: Active learning for Systematic Reviews (ASReview). We show that by using active learning, ASReview can lead to far more efficient reviewing than manual reviewing, while exhibiting adequate quality. Furthermore, the presented software is fully transparent and open source. survey. Survey results indicated respondents valued SRs, with SRs used most commonly to update knowledge. While most respondents (67%) were confident in using SRs, many (59%) expressed a lack of confidence in conducting a SR. In particular, few respondents (12%) reported confidence in conducting meta‐analyses. The majority of respondents were aware that SRs underpinned guidelines and nutrition resources, however, few (21%) respondents identified that self‐substantiation of health claims were based on SRs. Time, access to scientific database, lack of workplace support and confidence were the main barriers to SRs use. CONCLUSIONS: SRs were reported as being valued by nutrition professionals and students, though time constraints, a lack of confidence and organisations which did not prioritise research were barriers to conducting SRs. The findings of this survey highlight a need for training and education as potential strategies to promote SR engagement in nutrition professionals and students. arms. Fifteen structures were found for the reporting of measurement context, which were broadly grouped into: 1×1 contexts, where two pieces of context are reported in total (eg, arms in columns, data elements in rows); 2×1 contexts, where two pieces of context are given on row headers (eg, time points in columns, arms nested in data elements on rows); and 1×2 contexts, where two pieces of context are given on column headers. The 1×1 contexts were present in 57% of tables (99/174), compared to 20% (34/174) for 2×1 contexts and 15% (26/174) for 1×2 contexts; the remaining 8% (15/174) used unique/other stratification methods. Statistic formats were reported in the headers or descriptions of 84% (65/74) of studies.In this cross-sectional pilot review, we found a high density of information in tables, but with major heterogeneity in presentation of measurement context. The highest-density studies reported both baseline and outcome measures in tables, with arm-level breakout, intervention labels, and arm sizes present, and reported both the statistic formats and units. The measurement context formats presented here, broadly classified into three classes that cover 92% (71/78) of studies, form a basis for understanding the frequency of different reporting styles, supporting automated detection of the data format for extraction of metrics. meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2020
DA  - 2020-06-22
JO  - {'id': 'https://openalex.org/S2597136632', 'issn_l': None, 'issn': None, 'display_name': 'arXiv: Information Retrieval', 'publisher': None, 'type': 'journal', 'url': 'https://arxiv.org/pdf/2006.12166', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Rens van de Schoot
AU  - Jonathan de Bruin
AU  - Raoul D. Schram
AU  - Parisa Zahedi
AU  - Jan de Boer
AU  - Felix Weijdema
AU  - Bianca Kramer
AU  - Martijn Huijts
AU  - Maarten Hoogerwerf
AU  - Gerbrich Ferdinands
AU  - Albert Harkema
AU  - Joukje Willemsen
AU  - Yongchao Ma
AU  - Qixiang Fang
AU  - Lars Tummers
AU  - Daniel L. Oberski
ER  - 

322.
TY  - journal-article
ID  - https://openalex.org/W3135901362
DO  - https://doi.org/10.1371/journal.pcbi.1008757
TI  - Using neural networks to mine text and predict metabolic traits for thousands of microbes
AB  - Microbes can metabolize more chemical compounds than any other group of organisms. As a result, their metabolism is of interest to investigators across biology. Despite the interest, information on metabolism of specific microbes is hard to access. Information is buried in text of books and journals, and investigators have no easy way to extract it out. Here we investigate if neural networks can extract out this information and predict metabolic traits. For proof of concept, we predicted two traits: whether microbes carry one type of metabolism (fermentation) or produce one metabolite (acetate). We collected written descriptions of 7,021 species of bacteria and archaea from Bergey’s Manual . We read the descriptions and manually identified (labeled) which species were fermentative or produced acetate. We then trained neural networks to predict these labels. In total, we identified 2,364 species as fermentative, and 1,009 species as also producing acetate. Neural networks could predict which species were fermentative with 97.3% accuracy. Accuracy was even higher (98.6%) when predicting species also producing acetate. Phylogenetic trees of species and their traits confirmed that predictions were accurate. Our approach with neural networks can extract information efficiently and accurately. It paves the way for putting more metabolic traits into databases, providing easy access of information to investigators. of confidence and organisations which did not prioritise research were barriers to conducting SRs. The findings of this survey highlight a need for training and education as potential strategies to promote SR engagement in nutrition professionals and students. arms. Fifteen structures were found for the reporting of measurement context, which were broadly grouped into: 1×1 contexts, where two pieces of context are reported in total (eg, arms in columns, data elements in rows); 2×1 contexts, where two pieces of context are given on row headers (eg, time points in columns, arms nested in data elements on rows); and 1×2 contexts, where two pieces of context are given on column headers. The 1×1 contexts were present in 57% of tables (99/174), compared to 20% (34/174) for 2×1 contexts and 15% (26/174) for 1×2 contexts; the remaining 8% (15/174) used unique/other stratification methods. Statistic formats were reported in the headers or descriptions of 84% (65/74) of studies.In this cross-sectional pilot review, we found a high density of information in tables, but with major heterogeneity in presentation of measurement context. The highest-density studies reported both baseline and outcome measures in tables, with arm-level breakout, intervention labels, and arm sizes present, and reported both the statistic formats and units. The measurement context formats presented here, broadly classified into three classes that cover 92% (71/78) of studies, form a basis for understanding the frequency of different reporting styles, supporting automated detection of the data format for extraction of metrics. meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2021
DA  - 2021-03-02
JO  - {'id': 'https://openalex.org/S86033158', 'issn_l': '1553-734X', 'issn': ['1553-734X', '1553-7358'], 'display_name': 'PLOS Computational Biology', 'publisher': 'International Society for Computational Biology', 'type': 'journal', 'url': 'https://journals.plos.org/ploscompbiol/article/file?id=10.1371/journal.pcbi.1008757&type=printable', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Timothy J. Hackmann
AU  - Bo Zhang
ER  - 

323.
TY  - journal-article
ID  - https://openalex.org/W3164471952
DO  - https://doi.org/10.1002/jat.4204
TI  - Toxic effects of nanomaterials for health applications: How automation can support a systematic review of the literature?
AB  - Systematic reviews of the scientific literature can be an important source of information supporting the daily work of the regulators in their decision making, particularly in areas of innovative technologies where the regulatory experience is still limited. Significant research activities in the field of nanotechnology resulted in a huge number of publications in the last decades. However, even if the published data can provide relevant information, scientific articles are often of diverse quality, and it is nearly impossible to manually process and evaluate such amount of data in a systematic manner. In this feasibility study, we investigated to what extent open-access automation tools can support a systematic review of toxic effects of nanomaterials for health applications reported in the scientific literature. In this study, we used a battery of available tools to perform the initial steps of a systematic review such as targeted searches, data curation and abstract screening. This work was complemented with an in-house developed tool that allowed us to extract specific sections of the articles such as the materials and methods part or the results section where we could perform subsequent text analysis. We ranked the articles according to quality criteria based on the reported nanomaterial characterisation and extracted most frequently described toxic effects induced by different types of nanomaterials. Even if further demonstration of the reliability and applicability of automation tools is necessary, this study demonstrated the potential to leverage information from the scientific literature by using automation systems in a tiered strategy. arms. Fifteen structures were found for the reporting of measurement context, which were broadly grouped into: 1×1 contexts, where two pieces of context are reported in total (eg, arms in columns, data elements in rows); 2×1 contexts, where two pieces of context are given on row headers (eg, time points in columns, arms nested in data elements on rows); and 1×2 contexts, where two pieces of context are given on column headers. The 1×1 contexts were present in 57% of tables (99/174), compared to 20% (34/174) for 2×1 contexts and 15% (26/174) for 1×2 contexts; the remaining 8% (15/174) used unique/other stratification methods. Statistic formats were reported in the headers or descriptions of 84% (65/74) of studies.In this cross-sectional pilot review, we found a high density of information in tables, but with major heterogeneity in presentation of measurement context. The highest-density studies reported both baseline and outcome measures in tables, with arm-level breakout, intervention labels, and arm sizes present, and reported both the statistic formats and units. The measurement context formats presented here, broadly classified into three classes that cover 92% (71/78) of studies, form a basis for understanding the frequency of different reporting styles, supporting automated detection of the data format for extraction of metrics. meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2022
DA  - 2022-01-01
JO  - {'id': 'https://openalex.org/S81851855', 'issn_l': '0260-437X', 'issn': ['1099-1263', '0260-437X'], 'display_name': 'Journal of Applied Toxicology', 'publisher': 'Wiley', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Blanka Halamoda-Kenzaoui
AU  - Etienne Rolland
AU  - Jacopo Piovesan
AU  - Antonio Gallardo
AU  - Susanne Bremer-Hoffmann
ER  - 

324.
TY  - journal-article
ID  - https://openalex.org/W3201006746
DO  - https://doi.org/10.4097/kja.21374
TI  - Use, application, and interpretation of systematic reviews and meta-analyses
AB  - No Abstract Found
PY  - 2021
DA  - 2021-09-23
JO  - {'id': 'https://openalex.org/V7962169', 'issn_l': '2005-6419', 'issn': ['2005-7563', '2005-6419'], 'display_name': 'Korean Journal of Anesthesiology', 'publisher': 'Korean Society of Anesthesiologists', 'type': 'journal', 'url': 'https://ekja.org/upload/pdf/kja-21374.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc'}
DP  - OpenAlex
AU  - Hyun Kang
ER  - 

325.
TY  - journal-article
ID  - https://openalex.org/W3201898920
DO  - https://doi.org/10.2196/30582
TI  - Pediatric Chronic Critical Illness: Protocol for a Scoping Review
AB  - Background Improvements in the delivery of intensive care have increased survival among even the most critically ill children, thereby leading to a growing number of children with chronic complex medical conditions in the pediatric intensive care unit (PICU). Some of these children are at a significant risk of recurrent and prolonged critical illness, with higher morbidity and mortality, making them a unique population described as having chronic critical illness (CCI). To date, pediatric CCI has been understudied and lacks an accepted consensus case definition. Objective This study aims to describe the protocol and methodology used to perform a scoping review that will describe how pediatric CCI has been defined in the literature, including the concept of prolonged PICU admission and the methodologies used to develop any existing definitions. It also aims to describe patient characteristics and outcomes evaluated in the included studies. Methods We will search four electronic databases for studies that evaluated children admitted to any PICU identified with CCI. We will also search for studies describing prolonged PICU admission, as this concept is related to pediatric CCI. Furthermore, we will develop a hybrid crowdsourcing and machine learning (ML) methodology to complete citation screening. Screening and data abstraction will be performed by 2 reviewers independently and in duplicate. Data abstraction will include the details of population definitions, demographic and clinical characteristics of children with CCI, and evaluated outcomes. Results The database search, crowd reviewer recruitment, and ML algorithm development began in March 2021. Citation screening and data abstraction were completed in April 2021. Final data verification is ongoing, with analysis and results anticipated to be completed by fall 2021. Conclusions This scoping review will describe the existing or suggested definitions of pediatric CCI and important demographic and clinical characteristics of patients to whom these definitions have been applied. This review’s results will help inform the development of a consensus case definition for pediatric CCI and set a priority agenda for future research. We will use and demonstrate the validity of crowdsourcing and ML methodologies for improving the efficiency of large scoping reviews. International Registered Report Identifier (IRRID) DERR1-10.2196/30582 methods. Statistic formats were reported in the headers or descriptions of 84% (65/74) of studies.In this cross-sectional pilot review, we found a high density of information in tables, but with major heterogeneity in presentation of measurement context. The highest-density studies reported both baseline and outcome measures in tables, with arm-level breakout, intervention labels, and arm sizes present, and reported both the statistic formats and units. The measurement context formats presented here, broadly classified into three classes that cover 92% (71/78) of studies, form a basis for understanding the frequency of different reporting styles, supporting automated detection of the data format for extraction of metrics. meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2021
DA  - 2021-10-01
JO  - {'id': 'https://openalex.org/S2739058702', 'issn_l': '1929-0748', 'issn': ['1929-0748'], 'display_name': 'JMIR Research Protocols', 'publisher': 'JMIR Publications', 'type': 'journal', 'url': 'https://www.researchprotocols.org/2021/10/e30582/PDF', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - David J. Zorko
AU  - James G. McNally
AU  - Deborah J. Cook
AU  - Neethi Pinto
AU  - Rachel Couban
AU  - Katie O’Hearn
AU  - Karen Choong
ER  - 

326.
TY  - journal-article
ID  - https://openalex.org/W3217761402
DO  - https://doi.org/10.1111/bju.15662
TI  - Application of artificial intelligence to overcome clinical information overload in urological cancer
AB  - Objective To describe the use of artificial intelligence (AI) in medical literature and trial data extraction, and its applications in uro-oncology. This bridging review, which consolidates information from the diverse applications of AI, highlights how AI users can investigate more sophisticated queries than with traditional methods, leading to synthesis of raw data and complex outputs into more actionable and personalised results, particularly in the field of uro-oncology. Methods Literature and clinical trial searches were performed in PubMed, Dimensions, Embase and Google (1999–2020). The searches focussed on the use of AI and its various forms to facilitate literature searches, clinical guidelines development, and clinical trial data extraction in uro-oncology. To illustrate how AI can be applied to address questions about optimising therapeutic decision making and individualising treatment regimens, the Dimensions-linked information platform was searched for ‘prostate cancer’ keywords (76 publications were identified; 48 were included). Results AI offers the promise of transforming raw data and complex outputs into actionable insights. Literature and clinical trial searches can be automated, enabling clinicians to develop and analyse publications expeditiously on complex issues such as therapeutic sequencing and to obtain updates on documents that evolve at the pace and scope of the landscape. An AI-based platform inclusive of 12 trial databases and >100 scientific literature sources enabled the creation of an interactive visualisation. Conclusion As the literature and clinical trial landscape continues to grow in complexity and with increasing speed, the ability to pull the right information at the right time from different search engines and resources, while excluding social media bias, becomes more challenging. This review demonstrates that by applying natural language processing and machine learning algorithms, validated and optimised AI leads to a speedier, more personalised, efficient, and focussed search compared with traditional methods. patients to whom these definitions have been applied. This review’s results will help inform the development of a consensus case definition for pediatric CCI and set a priority agenda for future research. We will use and demonstrate the validity of crowdsourcing and ML methodologies for improving the efficiency of large scoping reviews. International Registered Report Identifier (IRRID) DERR1-10.2196/30582 methods. Statistic formats were reported in the headers or descriptions of 84% (65/74) of studies.In this cross-sectional pilot review, we found a high density of information in tables, but with major heterogeneity in presentation of measurement context. The highest-density studies reported both baseline and outcome measures in tables, with arm-level breakout, intervention labels, and arm sizes present, and reported both the statistic formats and units. The measurement context formats presented here, broadly classified into three classes that cover 92% (71/78) of studies, form a basis for understanding the frequency of different reporting styles, supporting automated detection of the data format for extraction of metrics. meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2021
DA  - 2021-11-30
JO  - {'id': 'https://openalex.org/V191188855', 'issn_l': '1464-4096', 'issn': ['1464-410X', '1464-4096'], 'display_name': 'BJUI', 'publisher': 'Wiley-Blackwell', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Arnulf Stenzl
AU  - Cora N. Sternberg
AU  - Jenny Ghith
AU  - Lucile Serfass
AU  - Bob J. A. Schijvenaars
AU  - Andrea Sboner
ER  - 

327.
TY  - journal-article
ID  - https://openalex.org/W4206010191
DO  - https://doi.org/10.15585/mmwr.su7101a1
TI  - Standards Required for the Development of CDC Evidence-Based Guidelines
AB  - CDC is the nation's premier health promotion, prevention, and preparedness agency. As such, CDC is an important source of public health and clinical guidelines. If CDC guidelines are to be trusted by partners and the public, they must be clear, valid, and reliable. Methods and processes used in CDC guideline development should follow universally accepted standards. This report describes the standards required by CDC for the development of evidence-based guidelines. These standards cover topics such as guideline scoping, soliciting external input, summarizing evidence, and crafting recommendations. Following these standards can help minimize bias and enhance the quality and consistency of CDC guidelines. clinical trial data extraction in uro-oncology. To illustrate how AI can be applied to address questions about optimising therapeutic decision making and individualising treatment regimens, the Dimensions-linked information platform was searched for ‘prostate cancer’ keywords (76 publications were identified; 48 were included). Results AI offers the promise of transforming raw data and complex outputs into actionable insights. Literature and clinical trial searches can be automated, enabling clinicians to develop and analyse publications expeditiously on complex issues such as therapeutic sequencing and to obtain updates on documents that evolve at the pace and scope of the landscape. An AI-based platform inclusive of 12 trial databases and >100 scientific literature sources enabled the creation of an interactive visualisation. Conclusion As the literature and clinical trial landscape continues to grow in complexity and with increasing speed, the ability to pull the right information at the right time from different search engines and resources, while excluding social media bias, becomes more challenging. This review demonstrates that by applying natural language processing and machine learning algorithms, validated and optimised AI leads to a speedier, more personalised, efficient, and focussed search compared with traditional methods. patients to whom these definitions have been applied. This review’s results will help inform the development of a consensus case definition for pediatric CCI and set a priority agenda for future research. We will use and demonstrate the validity of crowdsourcing and ML methodologies for improving the efficiency of large scoping reviews. International Registered Report Identifier (IRRID) DERR1-10.2196/30582 methods. Statistic formats were reported in the headers or descriptions of 84% (65/74) of studies.In this cross-sectional pilot review, we found a high density of information in tables, but with major heterogeneity in presentation of measurement context. The highest-density studies reported both baseline and outcome measures in tables, with arm-level breakout, intervention labels, and arm sizes present, and reported both the statistic formats and units. The measurement context formats presented here, broadly classified into three classes that cover 92% (71/78) of studies, form a basis for understanding the frequency of different reporting styles, supporting automated detection of the data format for extraction of metrics. meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2022
DA  - 2022-01-14
JO  - {'id': 'https://openalex.org/S2765065363', 'issn_l': '2380-8942', 'issn': ['2380-8942', '2380-8950'], 'display_name': 'MMWR supplements', 'publisher': 'Centers for Disease Control MMWR Office', 'type': 'journal', 'url': 'https://www.cdc.gov/mmwr/volumes/71/su/pdfs/su7101a1-H.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': None}
DP  - OpenAlex
AU  - Vilma G Carande-Kulis
AU  - Randy W. Elder
AU  - Dyann Matson Koffman
ER  - 

328.
TY  - journal-article
ID  - https://openalex.org/W4206736664
DO  - https://doi.org/10.1080/1750984x.2021.1966823
TI  - Systematic review methods
AB  - No Abstract Found
PY  - 2022
DA  - 2022-01-18
JO  - {'id': 'https://openalex.org/S115649667', 'issn_l': '1750-984X', 'issn': ['1750-984X', '1750-9858'], 'display_name': 'International Review of Sport and Exercise Psychology', 'publisher': 'Taylor & Francis', 'type': 'journal', 'url': 'https://www.tandfonline.com/doi/pdf/10.1080/1750984X.2021.1966823?needAccess=true', 'is_oa': True, 'version': 'publishedVersion', 'license': None}
DP  - OpenAlex
AU  - Marie-Pierre Sylvestre
AU  - Veronica J. Belcourt
AU  - Jennifer R Tomasone
AU  - Laura Weeks
ER  - 

329.
TY  - journal-article
ID  - https://openalex.org/W4210339418
DO  - https://doi.org/10.1080/17437199.2022.2034516
TI  - A machine-learning assisted review of the use of habit formation in medication adherence interventions for long-term conditions
AB  - Adherence to medication in long-term conditions is around 50%. The key components of successful interventions to improve medication adherence remain unclear, particularly when examined over prolonged follow-up periods. Behaviour change theories are increasingly interested in the utility of habit formation for the maintenance of health behaviour change, but there is no documentation on how habit has been conceptualised in the medication adherence intervention literature, or what effect the key technique identified in habit formation theory (context dependent repetition) has in these studies. To examine this, a machine-learning assisted review was conducted. Searches of MEDLINE, EMBASE and PSYCInfo and the reference list of a comprehensive systematic review of medication adherence interventions yielded 5973 articles. Machine learning-assisted title and abstract screening identified 15 independent RCTs published between 1976 and 2021, including 18 intervention comparisons of interest. Key findings indicate that conceptualisations of habit in the medication adherence literature are varied and behaviour change technique coding identified only six studies which explicitly described using habit formation. Future work should aim to develop this evidence base, drawing on contemporary habit theory and with explicit demonstration of what techniques have been used to promote habit formation. the pace and scope of the landscape. An AI-based platform inclusive of 12 trial databases and >100 scientific literature sources enabled the creation of an interactive visualisation. Conclusion As the literature and clinical trial landscape continues to grow in complexity and with increasing speed, the ability to pull the right information at the right time from different search engines and resources, while excluding social media bias, becomes more challenging. This review demonstrates that by applying natural language processing and machine learning algorithms, validated and optimised AI leads to a speedier, more personalised, efficient, and focussed search compared with traditional methods. patients to whom these definitions have been applied. This review’s results will help inform the development of a consensus case definition for pediatric CCI and set a priority agenda for future research. We will use and demonstrate the validity of crowdsourcing and ML methodologies for improving the efficiency of large scoping reviews. International Registered Report Identifier (IRRID) DERR1-10.2196/30582 methods. Statistic formats were reported in the headers or descriptions of 84% (65/74) of studies.In this cross-sectional pilot review, we found a high density of information in tables, but with major heterogeneity in presentation of measurement context. The highest-density studies reported both baseline and outcome measures in tables, with arm-level breakout, intervention labels, and arm sizes present, and reported both the statistic formats and units. The measurement context formats presented here, broadly classified into three classes that cover 92% (71/78) of studies, form a basis for understanding the frequency of different reporting styles, supporting automated detection of the data format for extraction of metrics. meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2022
DA  - 2022-01-28
JO  - {'id': 'https://openalex.org/S111502347', 'issn_l': '1743-7199', 'issn': ['1743-7199', '1743-7202'], 'display_name': 'Health Psychology Review', 'publisher': 'Taylor & Francis', 'type': 'journal', 'url': 'https://www.tandfonline.com/doi/pdf/10.1080/17437199.2022.2034516?needAccess=true', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc-nd'}
DP  - OpenAlex
AU  - L Robinson
AU  - Madelynne A Arden
AU  - Sarah-Jane Dawson
AU  - S J Walters
AU  - Martin J Wildman
AU  - M Stevenson
ER  - 

330.
TY  - journal-article
ID  - https://openalex.org/W4224243144
DO  - https://doi.org/10.1136/bmjgh-2021-007426
TI  - Examining vulnerability and resilience in maternal, newborn and child health through a gender lens in low-income and middle-income countries: a scoping review
AB  - Gender lens application is pertinent in addressing inequities that underlie morbidity and mortality in vulnerable populations, including mothers and children. While gender inequities may result in greater vulnerabilities for mothers and children, synthesising evidence on the constraints and opportunities is a step in accelerating reduction in poor outcomes and building resilience in individuals and across communities and health systems.We conducted a scoping review that examined vulnerability and resilience in maternal, newborn and child health (MNCH) through a gender lens to characterise gender roles, relationships and differences in maternal and child health. We conducted a comprehensive search of peer-reviewed and grey literature in popular scholarly databases, including PubMed, ScienceDirect, EBSCOhost and Google Scholar. We identified and analysed 17 published studies that met the inclusion criteria for key gendered themes in maternal and child health vulnerability and resilience in low-income and middle-income countries.Six key gendered dimensions of vulnerability and resilience emerged from our analysis: (1) restricted maternal access to financial and economic resources; (2) limited economic contribution of women as a result of motherhood; (3) social norms, ideologies, beliefs and perceptions inhibiting women's access to maternal healthcare services; (4) restricted maternal agency and contribution to reproductive decisions; (5) power dynamics and experience of intimate partner violence contributing to adverse health for women, children and their families; (6) partner emotional or affective support being crucial for maternal health and well-being prenatal and postnatal.This review highlights six domains that merit attention in addressing maternal and child health vulnerabilities. Recognising and understanding the gendered dynamics of vulnerability and resilience can help develop meaningful strategies that will guide the design and implementation of MNCH programmes in low-income and middle-income countries. and optimised AI leads to a speedier, more personalised, efficient, and focussed search compared with traditional methods. patients to whom these definitions have been applied. This review’s results will help inform the development of a consensus case definition for pediatric CCI and set a priority agenda for future research. We will use and demonstrate the validity of crowdsourcing and ML methodologies for improving the efficiency of large scoping reviews. International Registered Report Identifier (IRRID) DERR1-10.2196/30582 methods. Statistic formats were reported in the headers or descriptions of 84% (65/74) of studies.In this cross-sectional pilot review, we found a high density of information in tables, but with major heterogeneity in presentation of measurement context. The highest-density studies reported both baseline and outcome measures in tables, with arm-level breakout, intervention labels, and arm sizes present, and reported both the statistic formats and units. The measurement context formats presented here, broadly classified into three classes that cover 92% (71/78) of studies, form a basis for understanding the frequency of different reporting styles, supporting automated detection of the data format for extraction of metrics. meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2022
DA  - 2022-04-01
JO  - {'id': 'https://openalex.org/S2764928273', 'issn_l': '2059-7908', 'issn': ['2059-7908'], 'display_name': 'BMJ Global Health', 'publisher': 'BMJ', 'type': 'journal', 'url': 'https://gh.bmj.com/content/bmjgh/7/4/e007426.full.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Fatima Abdulaziz Sule
AU  - Olalekan A. Uthman
AU  - Emmanuel Olamijuwon
AU  - Nchelem Kokomma Ichegbo
AU  - I. Mgbachi
AU  - Babasola O. Okusanya
AU  - Olusesan Ayodeji Makinde
ER  - 

331.
TY  - journal-article
ID  - https://openalex.org/W4225303562
DO  - https://doi.org/10.1007/s00228-022-03329-8
TI  - Feasibility study and evaluation of expert opinion on the semi-automated meta-analysis and the conventional meta-analysis
AB  - No Abstract Found
PY  - 2022
DA  - 2022-05-03
JO  - {'id': 'https://openalex.org/S31780008', 'issn_l': '0031-6970', 'issn': ['0031-6970', '0369-9498', '1432-1041'], 'display_name': 'European Journal of Clinical Pharmacology', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Priscilla Ajiji
AU  - Judith Cottin
AU  - Cyndie Picot
AU  - Anil Uzunali
AU  - Emmanuelle Ripoche
AU  - Michel Cucherat
AU  - Patrick Maison
ER  - 

332.
TY  - journal-article
ID  - https://openalex.org/W4226027175
DO  - https://doi.org/10.2105/ajph.2021.306658
TI  - Value and Challenges of Using Observational Studies in Systematic Reviews of Public Health Interventions
AB  - No Abstract Found
PY  - 2022
DA  - 2022-04-01
JO  - {'id': 'https://openalex.org/S168049282', 'issn_l': '0090-0036', 'issn': ['1541-0048', '0090-0036'], 'display_name': 'American Journal of Public Health', 'publisher': 'American Public Health Association', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Michele Hilton Boon
AU  - Jacob Burns
AU  - Peter Craig
AU  - Ursula Griebler
AU  - Thomas L Heise
AU  - Srinivasa Vittal Katikireddi
AU  - Eva Rehfuess
AU  - Sasha Shepperd
AU  - Hilary Thomson
AU  - Lisa Bero
ER  - 

333.
TY  - journal-article
ID  - https://openalex.org/W4283011282
DO  - https://doi.org/10.1146/annurev-environ-112420-020640
TI  - How Stimulating Is a Green Stimulus? The Economic Attributes of Green Fiscal Spending
AB  - When deep recessions hit, some governments spend to rescue and recover their economies. Key economic objectives of such countercyclical spending include protecting and creating jobs while reinvigorating economic growth—but governments can also use this spending to achieve long-term social and environmental goals. During the coronavirus disease 2019 (COVID-19) pandemic, claims have been made that green recovery investments can meet both economic and environmental objectives. Here, we investigate the evidence behind these claims. We create a bespoke supervised machine learning algorithm to identify a comprehensive literature set. We analyze this literature using both structured qualitative assessment and machine learning models. We find evidence that green investments can indeed create more jobs and deliver higher fiscal multipliers than non-green investments. For policymakers, we suggest strong prioritization of green spending in recovery. For researchers, we highlight many research gaps and unalignment of research patterns with spending patterns. of vulnerability and resilience emerged from our analysis: (1) restricted maternal access to financial and economic resources; (2) limited economic contribution of women as a result of motherhood; (3) social norms, ideologies, beliefs and perceptions inhibiting women's access to maternal healthcare services; (4) restricted maternal agency and contribution to reproductive decisions; (5) power dynamics and experience of intimate partner violence contributing to adverse health for women, children and their families; (6) partner emotional or affective support being crucial for maternal health and well-being prenatal and postnatal.This review highlights six domains that merit attention in addressing maternal and child health vulnerabilities. Recognising and understanding the gendered dynamics of vulnerability and resilience can help develop meaningful strategies that will guide the design and implementation of MNCH programmes in low-income and middle-income countries. and optimised AI leads to a speedier, more personalised, efficient, and focussed search compared with traditional methods. patients to whom these definitions have been applied. This review’s results will help inform the development of a consensus case definition for pediatric CCI and set a priority agenda for future research. We will use and demonstrate the validity of crowdsourcing and ML methodologies for improving the efficiency of large scoping reviews. International Registered Report Identifier (IRRID) DERR1-10.2196/30582 methods. Statistic formats were reported in the headers or descriptions of 84% (65/74) of studies.In this cross-sectional pilot review, we found a high density of information in tables, but with major heterogeneity in presentation of measurement context. The highest-density studies reported both baseline and outcome measures in tables, with arm-level breakout, intervention labels, and arm sizes present, and reported both the statistic formats and units. The measurement context formats presented here, broadly classified into three classes that cover 92% (71/78) of studies, form a basis for understanding the frequency of different reporting styles, supporting automated detection of the data format for extraction of metrics. meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2022
DA  - 2022-06-16
JO  - {'id': 'https://openalex.org/S5491134', 'issn_l': '1543-5938', 'issn': ['1545-2050', '1543-5938'], 'display_name': 'Annual Review of Environment and Resources', 'publisher': 'Annual Reviews', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Brian O'Callaghan
AU  - Nigel Yau
AU  - Cameron Hepburn
ER  - 

334.
TY  - journal-article
ID  - https://openalex.org/W4283592999
DO  - https://doi.org/10.1016/j.xcrm.2022.100670
TI  - Clinical, phenotypic and genetic landscape of case reports with genetically proven inherited disorders of vitamin B12 metabolism: A meta-analysis
AB  - <h2>Summary</h2> Inherited disorders of B<sub>12</sub> metabolism produce a broad spectrum of manifestations, with limited knowledge of the influence of age and the function of related genes. We report a meta-analysis on 824 patients with a genetically proven diagnosis of an inherited disorder of vitamin B<sub>12</sub> metabolism. Gene clusters and age categories are associated with patients' manifestations. The "cytoplasmic transport" cluster is associated with neurological and ophthalmological manifestations, the "mitochondrion" cluster with hypotonia, acute metabolic decompensation, and death, and the "B<sub>12</sub> availability" and "remethylation" clusters with anemia and cytopenia. Hypotonia, EEG abnormalities, nystagmus, and strabismus are predominant in the younger patients, while neurological manifestations, such as walking difficulties, peripheral neuropathy, pyramidal syndrome, cerebral atrophy, psychiatric disorders, and thromboembolic manifestations, are predominant in the older patients. These results should prompt systematic checking of markers of vitamin B<sub>12</sub> status, including homocysteine and methylmalonic acid, when usual causes of these manifestations are discarded in adult patients. (1) restricted maternal access to financial and economic resources; (2) limited economic contribution of women as a result of motherhood; (3) social norms, ideologies, beliefs and perceptions inhibiting women's access to maternal healthcare services; (4) restricted maternal agency and contribution to reproductive decisions; (5) power dynamics and experience of intimate partner violence contributing to adverse health for women, children and their families; (6) partner emotional or affective support being crucial for maternal health and well-being prenatal and postnatal.This review highlights six domains that merit attention in addressing maternal and child health vulnerabilities. Recognising and understanding the gendered dynamics of vulnerability and resilience can help develop meaningful strategies that will guide the design and implementation of MNCH programmes in low-income and middle-income countries. and optimised AI leads to a speedier, more personalised, efficient, and focussed search compared with traditional methods. patients to whom these definitions have been applied. This review’s results will help inform the development of a consensus case definition for pediatric CCI and set a priority agenda for future research. We will use and demonstrate the validity of crowdsourcing and ML methodologies for improving the efficiency of large scoping reviews. International Registered Report Identifier (IRRID) DERR1-10.2196/30582 methods. Statistic formats were reported in the headers or descriptions of 84% (65/74) of studies.In this cross-sectional pilot review, we found a high density of information in tables, but with major heterogeneity in presentation of measurement context. The highest-density studies reported both baseline and outcome measures in tables, with arm-level breakout, intervention labels, and arm sizes present, and reported both the statistic formats and units. The measurement context formats presented here, broadly classified into three classes that cover 92% (71/78) of studies, form a basis for understanding the frequency of different reporting styles, supporting automated detection of the data format for extraction of metrics. meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2022
DA  - 2022-06-01
JO  - {'id': 'https://openalex.org/V4210207453', 'issn_l': '2666-3791', 'issn': ['2666-3791'], 'display_name': 'Cell reports medicine', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'http://www.cell.com/article/S2666379122002026/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc-nd'}
DP  - OpenAlex
AU  - Arnaud Wiedemann
AU  - Abderrahim Oussalah
AU  - Nathalie Lamireau
AU  - Maurane Théron
AU  - Melissa Julien
AU  - Jean-Philippe Mergnac
AU  - Baptiste Augay
AU  - Pauline Deniaud
AU  - T. Alix
AU  - Marine Frayssinoux
AU  - François Feillet
AU  - Jean-Louis Guéant
ER  - 

335.
TY  - journal-article
ID  - https://openalex.org/W4285024927
DO  - https://doi.org/10.1186/s12874-022-01673-y
TI  - Meta-analysis using Python: a hands-on tutorial
AB  - Abstract Background Meta-analysis is a central method for quality evidence generation. In particular, meta-analysis is gaining speedy momentum in the growing world of quantitative information. There are several software applications to process and output expected results. Open-source software applications generating such results are receiving more attention. This paper uses Python’s capabilities to provide applicable instruction to perform a meta-analysis. Methods We used the PythonMeta package with several modifications to perform the meta-analysis on an open-access dataset from Cochrane. The analyses were complemented by employing Python’s zEpid package capable of creating forest plots. Also, we developed Python scripts for contour-enhanced funnel plots to assess funnel plots asymmetry. Finally, we ran the analyses in R and STATA to check the cross-validity of the results. Results A stepwise instruction on installing the software and packages and performing meta-analysis was provided. We shared the Python codes for meta-analysts to follow and generate the standard outputs. Our results were similar to those yielded by R and STATA. Conclusion We successfully produced standard meta-analytic outputs using Python. This programming language has several flexibilities to improve the meta-analysis results even further. healthcare services; (4) restricted maternal agency and contribution to reproductive decisions; (5) power dynamics and experience of intimate partner violence contributing to adverse health for women, children and their families; (6) partner emotional or affective support being crucial for maternal health and well-being prenatal and postnatal.This review highlights six domains that merit attention in addressing maternal and child health vulnerabilities. Recognising and understanding the gendered dynamics of vulnerability and resilience can help develop meaningful strategies that will guide the design and implementation of MNCH programmes in low-income and middle-income countries. and optimised AI leads to a speedier, more personalised, efficient, and focussed search compared with traditional methods. patients to whom these definitions have been applied. This review’s results will help inform the development of a consensus case definition for pediatric CCI and set a priority agenda for future research. We will use and demonstrate the validity of crowdsourcing and ML methodologies for improving the efficiency of large scoping reviews. International Registered Report Identifier (IRRID) DERR1-10.2196/30582 methods. Statistic formats were reported in the headers or descriptions of 84% (65/74) of studies.In this cross-sectional pilot review, we found a high density of information in tables, but with major heterogeneity in presentation of measurement context. The highest-density studies reported both baseline and outcome measures in tables, with arm-level breakout, intervention labels, and arm sizes present, and reported both the statistic formats and units. The measurement context formats presented here, broadly classified into three classes that cover 92% (71/78) of studies, form a basis for understanding the frequency of different reporting styles, supporting automated detection of the data format for extraction of metrics. meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2022
DA  - 2022-07-12
JO  - {'id': 'https://openalex.org/S185874209', 'issn_l': '1471-2288', 'issn': ['1471-2288'], 'display_name': 'BMC Medical Research Methodology', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://bmcmedresmethodol.biomedcentral.com/counter/pdf/10.1186/s12874-022-01673-y', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Safoora Masoumi
AU  - Saeid Shahraz
ER  - 

336.
TY  - journal-article
ID  - https://openalex.org/W3044127670
DO  - https://doi.org/10.1186/s13643-020-01422-6
TI  - Professional identity formation within Longitudinal Integrated Clerkships: a scoping review protocol
AB  - Abstract Background Professional identity development is an area of contemporary interest within medical education. It can be defined as ‘the foundational process one experiences during the transformation from lay person to physician’. In order for this transformation to occur, medical values and principles are internalised. A robust professional identity is key to confident practice as a medical professional. As such, research regarding what works to encourage identity development is popular. New models of educational delivery, such as the increasingly popular Longitudinal Integrated Clerkship model (LICs), present an interesting opportunity to investigate impact on identity. As no previous literature reviews focus on identity development within LICs, it is unclear what is already known about their impact. Therefore, a scoping review synthesising current knowledge and mapping areas for future research is necessary. Methods Arksey and O’Malley’s scoping review steps will be used as a methodological framework. MEDLINE, EMBASE, PubMed, Web of Knowledge, ERIC, PsychINFO, Google Scholar, JSTOR, Scopus, and Web of science will be searched (from inception onwards). We will include single studies of any design (e.g. quantitative and qualitative) and reviews examining professional identity within Longitudinal Integrated Clerkships involving health profession students. Two reviewers will complete all screening and data abstraction independently. Deductive coding will be presented as a quantitative textual meta-analysis. Inductive coding will be presented in narrative format. Discussion This scoping review will explore professional identity formation within LICs, evaluating any known impact of the educational model and mapping the ways in which identity within LICs has been researched. Mapping of current knowledge should highlight whether LICs as an educational model can influence professional identity development and outline gaps in what is known about their impact to date. Theory used in LIC-based identity research will also be mapped, in order to summarise the main theoretical orientations of research to date. It is anticipated that through such evidence synthesis, directions for future research will become clear. Systematic review registration Open Science Framework: osf.io/hk83p We will use and demonstrate the validity of crowdsourcing and ML methodologies for improving the efficiency of large scoping reviews. International Registered Report Identifier (IRRID) DERR1-10.2196/30582 methods. Statistic formats were reported in the headers or descriptions of 84% (65/74) of studies.In this cross-sectional pilot review, we found a high density of information in tables, but with major heterogeneity in presentation of measurement context. The highest-density studies reported both baseline and outcome measures in tables, with arm-level breakout, intervention labels, and arm sizes present, and reported both the statistic formats and units. The measurement context formats presented here, broadly classified into three classes that cover 92% (71/78) of studies, form a basis for understanding the frequency of different reporting styles, supporting automated detection of the data format for extraction of metrics. meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2020
DA  - 2020-07-24
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://doi.org/10.1186/s13643-020-01422-6', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Megan E. L. Brown
AU  - Paul Whybrow
AU  - Gavin Kirwan
AU  - Gabrielle M. Finn
ER  - 

337.
TY  - proceedings-article
ID  - https://openalex.org/W3104619549
DO  - https://doi.org/10.18653/v1/2020.sdp-1.21
TI  - Scaling Systematic Literature Reviews with Machine Learning Pipelines
AB  - Systematic reviews, which entail the extraction of data from large numbers of scientific documents, are an ideal avenue for the application of machine learning. They are vital to many fields of science and philanthropy, but are very time-consuming and require experts. Yet the three main stages of a systematic review are easily done automatically: searching for documents can be done via APIs and scrapers, selection of relevant documents can be done via binary classification, and extraction of data can be done via sequence-labelling classification. Despite the promise of automation for this field, little research exists that examines the various ways to automate each of these tasks. We construct a pipeline that automates each of these aspects, and experiment with many human-time vs. system quality trade-offs. We test the ability of classifiers to work well on small amounts of data and to generalise to data from countries not represented in the training data. We test different types of data extraction with varying difficulty in annotation, and five different neural architectures to do the extraction. We find that we can get surprising accuracy and generalisability of the whole pipeline system with only 2 weeks of human-expert annotation, which is only 15% of the time it takes to do the whole review manually and can be repeated and extended to new data with no additional effort. will explore professional identity formation within LICs, evaluating any known impact of the educational model and mapping the ways in which identity within LICs has been researched. Mapping of current knowledge should highlight whether LICs as an educational model can influence professional identity development and outline gaps in what is known about their impact to date. Theory used in LIC-based identity research will also be mapped, in order to summarise the main theoretical orientations of research to date. It is anticipated that through such evidence synthesis, directions for future research will become clear. Systematic review registration Open Science Framework: osf.io/hk83p We will use and demonstrate the validity of crowdsourcing and ML methodologies for improving the efficiency of large scoping reviews. International Registered Report Identifier (IRRID) DERR1-10.2196/30582 methods. Statistic formats were reported in the headers or descriptions of 84% (65/74) of studies.In this cross-sectional pilot review, we found a high density of information in tables, but with major heterogeneity in presentation of measurement context. The highest-density studies reported both baseline and outcome measures in tables, with arm-level breakout, intervention labels, and arm sizes present, and reported both the statistic formats and units. The measurement context formats presented here, broadly classified into three classes that cover 92% (71/78) of studies, form a basis for understanding the frequency of different reporting styles, supporting automated detection of the data format for extraction of metrics. meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2020
DA  - 2020-11-01
JO  - {'id': 'https://openalex.org/V4306418267', 'issn_l': None, 'issn': None, 'display_name': 'Empirical Methods in Natural Language Processing', 'publisher': None, 'type': 'conference', 'url': 'https://www.aclweb.org/anthology/2020.sdp-1.21.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Seraphina Goldfarb-Tarrant
AU  - Alexander Robertson
AU  - Jasmina Lazic
AU  - Theodora K. Tsouloufi
AU  - Louise Donnison
AU  - Karen Smyth
ER  - 

338.
TY  - posted-content
ID  - https://openalex.org/W3125021981
DO  - https://doi.org/10.1101/2021.01.19.21250110
TI  - External Validations of Cardiovascular Clinical Prediction Models: A Large-scale Review of the Literature
AB  - Abstract Background There are many clinical prediction models (CPMs) available to inform treatment decisions for patients with cardiovascular disease. However, the extent to which they have been externally tested and how well they generally perform has not been broadly evaluated. Methods A SCOPUS citation search was run on March 22, 2017 to identify external validations of cardiovascular CPMs in the Tufts PACE CPM Registry. We assessed the extent of external validation, performance heterogeneity across databases, and explored factors associated with model performance, including a global assessment of the clinical relatedness between the derivation and validation data. Results 2030 external validations of 1382 CPMs were identified. 807 (58%) of the CPMs in the Registry have never been externally validated. On average there were 1.5 validations per CPM (range 0-94). The median external validation AUC was 0.73 (25 th −75 th percentile [IQR] 0.66, 0.79), representing a median percent decrease in discrimination of −11.1% (IQR −32.4%, +2.7%) compared to performance on derivation data. 81% (n = 1333) of validations reporting AUC showed discrimination below that reported in the derivation dataset. 53% (n = 983) of the validations report some measure of CPM calibration. For CPMs evaluated more than once, there was typically a large range of performance. Of 1702 validations classified by relatedness, the percent change in discrimination was −3.7% (IQR −13.2, 3.1) for ‘closely related’ validations (n=123), −9.0 (IQR −27.6, 3.9) for ‘related validations’ (n=862) and −17.2% (IQR −42.3, 0) for ‘distantly related’ validations (n=717) (p&lt;0.001). Conclusion Many published cardiovascular CPMs have never been externally validated and for those that have, apparent performance during development is often overly optimistic. A single external validation appears insufficient to broadly understand the performance heterogeneity across different settings. identity research will also be mapped, in order to summarise the main theoretical orientations of research to date. It is anticipated that through such evidence synthesis, directions for future research will become clear. Systematic review registration Open Science Framework: osf.io/hk83p We will use and demonstrate the validity of crowdsourcing and ML methodologies for improving the efficiency of large scoping reviews. International Registered Report Identifier (IRRID) DERR1-10.2196/30582 methods. Statistic formats were reported in the headers or descriptions of 84% (65/74) of studies.In this cross-sectional pilot review, we found a high density of information in tables, but with major heterogeneity in presentation of measurement context. The highest-density studies reported both baseline and outcome measures in tables, with arm-level breakout, intervention labels, and arm sizes present, and reported both the statistic formats and units. The measurement context formats presented here, broadly classified into three classes that cover 92% (71/78) of studies, form a basis for understanding the frequency of different reporting styles, supporting automated detection of the data format for extraction of metrics. meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2021
DA  - 2021-01-21
JO  - {'id': 'https://openalex.org/S4306400573', 'issn_l': None, 'issn': None, 'display_name': 'medRxiv (Cold Spring Harbor Laboratory)', 'publisher': 'Cold Spring Harbor Laboratory', 'type': 'repository', 'url': 'https://doi.org/10.1101/2021.01.19.21250110', 'is_oa': True, 'version': 'submittedVersion', 'license': None}
DP  - OpenAlex
AU  - Benjamin S. Wessler
AU  - Jason M. Nelson
AU  - Jinny Park
AU  - Hannah L. McGinnes
AU  - Gaurav Gulati
AU  - Riley Brazil
AU  - Ben Van Calster
AU  - D. van Klaveren
AU  - Esmee Venema
AU  - Ewout W. Steyerberg
AU  - Jessica K. Paulus
AU  - David M. Kent
ER  - 

339.
TY  - journal-article
ID  - https://openalex.org/W3136195042
DO  - https://doi.org/10.1086/713525
TI  - Technology for Research Synthesis: An Application of Sociotechnical Systems Theory
AB  - AbstractEvidence synthesis software has been developed to facilitate the conduct of systematic reviews. However, social work researchers may be unfamiliar with the range of software options availab... externally tested and how well they generally perform has not been broadly evaluated. Methods A SCOPUS citation search was run on March 22, 2017 to identify external validations of cardiovascular CPMs in the Tufts PACE CPM Registry. We assessed the extent of external validation, performance heterogeneity across databases, and explored factors associated with model performance, including a global assessment of the clinical relatedness between the derivation and validation data. Results 2030 external validations of 1382 CPMs were identified. 807 (58%) of the CPMs in the Registry have never been externally validated. On average there were 1.5 validations per CPM (range 0-94). The median external validation AUC was 0.73 (25 th −75 th percentile [IQR] 0.66, 0.79), representing a median percent decrease in discrimination of −11.1% (IQR −32.4%, +2.7%) compared to performance on derivation data. 81% (n = 1333) of validations reporting AUC showed discrimination below that reported in the derivation dataset. 53% (n = 983) of the validations report some measure of CPM calibration. For CPMs evaluated more than once, there was typically a large range of performance. Of 1702 validations classified by relatedness, the percent change in discrimination was −3.7% (IQR −13.2, 3.1) for ‘closely related’ validations (n=123), −9.0 (IQR −27.6, 3.9) for ‘related validations’ (n=862) and −17.2% (IQR −42.3, 0) for ‘distantly related’ validations (n=717) (p&lt;0.001). Conclusion Many published cardiovascular CPMs have never been externally validated and for those that have, apparent performance during development is often overly optimistic. A single external validation appears insufficient to broadly understand the performance heterogeneity across different settings. identity research will also be mapped, in order to summarise the main theoretical orientations of research to date. It is anticipated that through such evidence synthesis, directions for future research will become clear. Systematic review registration Open Science Framework: osf.io/hk83p We will use and demonstrate the validity of crowdsourcing and ML methodologies for improving the efficiency of large scoping reviews. International Registered Report Identifier (IRRID) DERR1-10.2196/30582 methods. Statistic formats were reported in the headers or descriptions of 84% (65/74) of studies.In this cross-sectional pilot review, we found a high density of information in tables, but with major heterogeneity in presentation of measurement context. The highest-density studies reported both baseline and outcome measures in tables, with arm-level breakout, intervention labels, and arm sizes present, and reported both the statistic formats and units. The measurement context formats presented here, broadly classified into three classes that cover 92% (71/78) of studies, form a basis for understanding the frequency of different reporting styles, supporting automated detection of the data format for extraction of metrics. meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2021
DA  - 2021-03-11
JO  - {'id': 'https://openalex.org/S5290899', 'issn_l': '1948-822X', 'issn': ['2334-2315', '1948-822X'], 'display_name': 'Journal of The Society for Social Work and Research', 'publisher': 'University of Chicago Press', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Nathaniel A. Dell
AU  - Brandy R. Maynard
AU  - Allison A. Murphy
AU  - Madeline Stewart
ER  - 

340.
TY  - journal-article
ID  - https://openalex.org/W3164676482
DO  - https://doi.org/10.1186/s12874-021-01354-2
TI  - Creating efficiencies in the extraction of data from randomized trials: a prospective evaluation of a machine learning and text mining tool
AB  - Abstract Background Machine learning tools that semi-automate data extraction may create efficiencies in systematic review production. We evaluated a machine learning and text mining tool’s ability to (a) automatically extract data elements from randomized trials, and (b) save time compared with manual extraction and verification. Methods For 75 randomized trials, we manually extracted and verified data for 21 data elements. We uploaded the randomized trials to an online machine learning and text mining tool, and quantified performance by evaluating its ability to identify the reporting of data elements (reported or not reported), and the relevance of the extracted sentences, fragments, and overall solutions. For each randomized trial, we measured the time to complete manual extraction and verification, and to review and amend the data extracted by the tool. We calculated the median (interquartile range [IQR]) time for manual and semi-automated data extraction, and overall time savings. Results The tool identified the reporting (reported or not reported) of data elements with median (IQR) 91% (75% to 99%) accuracy. Among the top five sentences for each data element at least one sentence was relevant in a median (IQR) 88% (83% to 99%) of cases. Among a median (IQR) 90% (86% to 97%) of relevant sentences, pertinent fragments had been highlighted by the tool; exact matches were unreliable (median (IQR) 52% [33% to 73%]). A median 48% of solutions were fully correct, but performance varied greatly across data elements (IQR 21% to 71%). Using ExaCT to assist the first reviewer resulted in a modest time savings compared with manual extraction by a single reviewer (17.9 vs. 21.6 h total extraction time across 75 randomized trials). Conclusions Using ExaCT to assist with data extraction resulted in modest gains in efficiency compared with manual extraction. The tool was reliable for identifying the reporting of most data elements. The tool’s ability to identify at least one relevant sentence and highlight pertinent fragments was generally good, but changes to sentence selection and/or highlighting were often required. Protocol https://doi.org/10.7939/DVN/RQPJKS crowdsourcing and ML methodologies for improving the efficiency of large scoping reviews. International Registered Report Identifier (IRRID) DERR1-10.2196/30582 methods. Statistic formats were reported in the headers or descriptions of 84% (65/74) of studies.In this cross-sectional pilot review, we found a high density of information in tables, but with major heterogeneity in presentation of measurement context. The highest-density studies reported both baseline and outcome measures in tables, with arm-level breakout, intervention labels, and arm sizes present, and reported both the statistic formats and units. The measurement context formats presented here, broadly classified into three classes that cover 92% (71/78) of studies, form a basis for understanding the frequency of different reporting styles, supporting automated detection of the data format for extraction of metrics. meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2021
DA  - 2021-08-16
JO  - {'id': 'https://openalex.org/S185874209', 'issn_l': '1471-2288', 'issn': ['1471-2288'], 'display_name': 'BMC Medical Research Methodology', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://bmcmedresmethodol.biomedcentral.com/track/pdf/10.1186/s12874-021-01354-2', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Allison Gates
AU  - Michelle Gates
AU  - Shannon Sim
AU  - Sarah A. Elliott
AU  - Jennifer Pillay
AU  - Lisa Hartling
ER  - 

341.
TY  - journal-article
ID  - https://openalex.org/W3167125828
DO  - https://doi.org/10.4037/aacnacc2021948
TI  - COVID-19 Technology-Enabled Living Systematic Reviews to Enhance Knowledge Translation
AB  - What happens when there is an urgent widespread need for knowledge in clinical practice? We saw the answer to this question during the early stages of the COVID-19 pandemic, when little was initially known about the novel virus, SARS-CoV-2, which causes the disease. The situation was compounded by the highly infectious nature of the virus. As clinicians and scientists scrambled for answers, information was quickly developing in relevance, accuracy, and abundance, and it kept changing. This column of Technology Today provides insights into technology that enabled the harnessing and updating of rapidly evolving evidence; this technology enhanced the translation of new knowledge into nursing practice, leading to improvements in patient outcomes.Relevant to this topic is a previous Technology Today column published in 2016 on cognitive technologies.1 Cognitive technologies were described as the differentiator in the digital age for mental work, enabling humans to extend and magnify their current knowledge and cognition.1 The article highlighted that the time from medical discoveries to dissemination in clinical practice had progressively decreased over the past 2500 years and was projected to reach convergence in 2025, at which point knowledge discovery would become instantaneous with widespread implementation in clinical practice.2 Enter COVID-19 a few years earlier than expected.As a pandemic outbreak of a novel disease, COVID-19 drove rapidly evolving information, pushing to the forefront a cognitive technology known as living systematic review (LSR), a method for continually curating evidence as new evidence becomes available.3 For comparison, a systematic review (SR) is an analysis of all existing literature or evidence on a specific topic at one point in time. It is like a snapshot, a static report, which over time “leads to a decay in review currency, accuracy, and utility.”4 An LSR, on the other hand, can be viewed as a 24/7 news outlet continually updating and disseminating new evidence as it becomes available.4 Living systematic reviews are enabled by technology to afford “dynamic, persistent, online-only evidence summaries, which are updated rapidly and frequently.”4Systematic reviews have been viewed by clinicians for many years as the best sources of evidence for practice decisions.5 Key resources such as Cochrane have served scientists and clinicians for more than 30 years by developing the science of evidence synthesis.5 Widespread use of SRs in health care resulted from the inability to identify, track, and use the increasing amounts of published research.6 Now, thousands of meta-analyses are published yearly.7 The challenges with SRs involve the amount of time required to develop them and how to keep them current.Manual development of SRs has proven costly in terms of time expenditure. In a recent study on length of time needed to conduct SRs of medical interventions, Borah et al8 reported that the mean estimated time to complete an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2021
DA  - 2021-06-15
JO  - {'id': 'https://openalex.org/S203251273', 'issn_l': '1559-7768', 'issn': ['1559-7768', '1559-7776', '2149-0481'], 'display_name': 'AACN Advanced Critical Care', 'publisher': 'Lippincott Williams & Wilkins', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Linda Harrington
ER  - 

342.
TY  - book-chapter
ID  - https://openalex.org/W3170008619
DO  - https://doi.org/10.1007/978-3-030-77417-2_17
TI  - A Roadmap for Composing Automatic Literature Reviews: A Text Mining Approach
AB  - Due to accelerated growth in the number of scientific papers, writing literature reviews has become an increasingly costly activity. Therefore, the search for computational tools to assist in this process has been gaining ground in recent years. This work presents an overview of the current scenario of development of artificial intelligence tools aimed to assist in the production of systematic literature reviews. The process of creating a literature review is both creative and technical. The technical part of this process is liable to automation. For the purpose of organization, we divide this technical part into four steps: searching, screening, extraction, and synthesis. For each of these steps, we present artificial intelligence techniques that can be useful to its realization. In addition, we also present the obstacles encountered for the application of each technique. Finally, we propose a pipeline for the automatic creation of systematic literature reviews, by combining and placing existing techniques in stages where they possess the greatest potential to be useful.KeywordsSystematic reviewText miningAutomation had progressively decreased over the past 2500 years and was projected to reach convergence in 2025, at which point knowledge discovery would become instantaneous with widespread implementation in clinical practice.2 Enter COVID-19 a few years earlier than expected.As a pandemic outbreak of a novel disease, COVID-19 drove rapidly evolving information, pushing to the forefront a cognitive technology known as living systematic review (LSR), a method for continually curating evidence as new evidence becomes available.3 For comparison, a systematic review (SR) is an analysis of all existing literature or evidence on a specific topic at one point in time. It is like a snapshot, a static report, which over time “leads to a decay in review currency, accuracy, and utility.”4 An LSR, on the other hand, can be viewed as a 24/7 news outlet continually updating and disseminating new evidence as it becomes available.4 Living systematic reviews are enabled by technology to afford “dynamic, persistent, online-only evidence summaries, which are updated rapidly and frequently.”4Systematic reviews have been viewed by clinicians for many years as the best sources of evidence for practice decisions.5 Key resources such as Cochrane have served scientists and clinicians for more than 30 years by developing the science of evidence synthesis.5 Widespread use of SRs in health care resulted from the inability to identify, track, and use the increasing amounts of published research.6 Now, thousands of meta-analyses are published yearly.7 The challenges with SRs involve the amount of time required to develop them and how to keep them current.Manual development of SRs has proven costly in terms of time expenditure. In a recent study on length of time needed to conduct SRs of medical interventions, Borah et al8 reported that the mean estimated time to complete an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2021
DA  - 2021-03-10
JO  - {'id': 'https://openalex.org/V4210216221', 'issn_l': '1867-8211', 'issn': ['1867-8211', '1867-822X'], 'display_name': 'Lecture notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Eugênio Monteiro da Silva Júnior
AU  - Moisés Lima Dutra
ER  - 

343.
TY  - posted-content
ID  - https://openalex.org/W3176001288
DO  - nan
TI  - Machine Reading of Hypotheses for Organizational Research Reviews and Pre-trained Models via R Shiny App for Non-Programmers.
AB  - The volume of scientific publications in organizational research becomes exceedingly overwhelming for human researchers who seek to timely extract and review knowledge. This paper introduces natural language processing (NLP) models to accelerate the discovery, extraction, and organization of theoretical developments (i.e., hypotheses) from social science publications. We illustrate and evaluate NLP models in the context of a systematic review of stakeholder value constructs and hypotheses. Specifically, we develop NLP models to automatically 1) detect sentences in scholarly documents as hypotheses or not (Hypothesis Detection), 2) deconstruct the hypotheses into nodes (constructs) and links (causal/associative relationships) (Relationship Deconstruction ), and 3) classify the features of links in terms causality (versus association) and direction (positive, negative, versus nonlinear) (Feature Classification). Our models have reported high performance metrics for all three tasks. While our models are built in Python, we have made the pre-trained models fully accessible for non-programmers. We have provided instructions on installing and using our pre-trained models via an R Shiny app graphic user interface (GUI). Finally, we suggest the next paths to extend our methodology for computer-assisted knowledge synthesis. 2025, at which point knowledge discovery would become instantaneous with widespread implementation in clinical practice.2 Enter COVID-19 a few years earlier than expected.As a pandemic outbreak of a novel disease, COVID-19 drove rapidly evolving information, pushing to the forefront a cognitive technology known as living systematic review (LSR), a method for continually curating evidence as new evidence becomes available.3 For comparison, a systematic review (SR) is an analysis of all existing literature or evidence on a specific topic at one point in time. It is like a snapshot, a static report, which over time “leads to a decay in review currency, accuracy, and utility.”4 An LSR, on the other hand, can be viewed as a 24/7 news outlet continually updating and disseminating new evidence as it becomes available.4 Living systematic reviews are enabled by technology to afford “dynamic, persistent, online-only evidence summaries, which are updated rapidly and frequently.”4Systematic reviews have been viewed by clinicians for many years as the best sources of evidence for practice decisions.5 Key resources such as Cochrane have served scientists and clinicians for more than 30 years by developing the science of evidence synthesis.5 Widespread use of SRs in health care resulted from the inability to identify, track, and use the increasing amounts of published research.6 Now, thousands of meta-analyses are published yearly.7 The challenges with SRs involve the amount of time required to develop them and how to keep them current.Manual development of SRs has proven costly in terms of time expenditure. In a recent study on length of time needed to conduct SRs of medical interventions, Borah et al8 reported that the mean estimated time to complete an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2021
DA  - 2021-06-30
JO  - {'id': 'https://openalex.org/S2597136632', 'issn_l': None, 'issn': None, 'display_name': 'arXiv: Information Retrieval', 'publisher': None, 'type': 'journal', 'url': 'https://arxiv.org/pdf/2106.16102', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Victor Zitian Chen
AU  - Felipe Montano-Campos
AU  - Wlodek Zadrozny
AU  - E. Canfield
ER  - 

344.
TY  - posted-content
ID  - https://openalex.org/W3181927451
DO  - https://doi.org/10.1101/2021.07.13.452159
TI  - PDF Data Extractor (PDE) - A Free Web Application and R Package Allowing the Extraction of Tables from Portable Document Format (PDF) Files and High-Throughput Keyword Searches of Full-Text Articles
AB  - Abstract The PDF Data Extractor ( PDE ) R package is designed to perform comprehensive literature reviews for scientists at any stage in a user-friendly way. The PDE_analyzer_i() function permits the user to filter and search thousands of scientific articles using a simple user interface, requiring no bioinformatics skills. In the additional PDE_reader_i() interface, the user can then quickly browse the sentences with detected keywords, open the full-text article, when required, and convert tables conveniently from PDF files to Excel sheets (pdf2table). Specific features of the literature analysis include the adaptability of analysis parameters and the detection of abbreviations of search words in articles. In this article, we demonstrate and exemplify how the PDE package allows the user-friendly, efficient, and automated extraction of meta-data from full-text articles, which can aid in summarizing the existing literature on any topic of interest. As such, we recommend the use of the PDE package as the first step in conducting an extensive review of the scientific literature. The PDE package is available from the Comprehensive R Archive Network at https://CRAN.R-project.org/package=PDE . computer-assisted knowledge synthesis. 2025, at which point knowledge discovery would become instantaneous with widespread implementation in clinical practice.2 Enter COVID-19 a few years earlier than expected.As a pandemic outbreak of a novel disease, COVID-19 drove rapidly evolving information, pushing to the forefront a cognitive technology known as living systematic review (LSR), a method for continually curating evidence as new evidence becomes available.3 For comparison, a systematic review (SR) is an analysis of all existing literature or evidence on a specific topic at one point in time. It is like a snapshot, a static report, which over time “leads to a decay in review currency, accuracy, and utility.”4 An LSR, on the other hand, can be viewed as a 24/7 news outlet continually updating and disseminating new evidence as it becomes available.4 Living systematic reviews are enabled by technology to afford “dynamic, persistent, online-only evidence summaries, which are updated rapidly and frequently.”4Systematic reviews have been viewed by clinicians for many years as the best sources of evidence for practice decisions.5 Key resources such as Cochrane have served scientists and clinicians for more than 30 years by developing the science of evidence synthesis.5 Widespread use of SRs in health care resulted from the inability to identify, track, and use the increasing amounts of published research.6 Now, thousands of meta-analyses are published yearly.7 The challenges with SRs involve the amount of time required to develop them and how to keep them current.Manual development of SRs has proven costly in terms of time expenditure. In a recent study on length of time needed to conduct SRs of medical interventions, Borah et al8 reported that the mean estimated time to complete an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2021
DA  - 2021-07-13
JO  - {'id': 'https://openalex.org/V2734324842', 'issn_l': None, 'issn': None, 'display_name': 'bioRxiv', 'publisher': None, 'type': 'repository', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Stricker E
AU  - Scheurer Me
ER  - 

345.
TY  - journal-article
ID  - https://openalex.org/W3184058630
DO  - https://doi.org/10.47909/ijsmc.52
TI  - A roadmap toward the automatic composition of systematic literature reviews
AB  - Objective. This paper presents an overview of existing artificial intelligence tools to produce systematic literature reviews. Furthermore, we propose a general framework resulting from combining these techniques to highlight the challenges and possibilities currently existing in this research area. Design/Methodology/Approach. We undertook a scoping review on the systematic literature review steps to automate them via computational techniques. Results/Discussion. The process of creating a literature review is both creative and technical. The technical part of this process is liable to automation. Based on the literature, we chose to divide this technical part into four steps: searching, screening, extraction, and synthesis. For each one of these steps, we presented practical artificial intelligence techniques to carry them out. In addition, we presented the obstacles encountered in the application of each technique. Conclusion. We proposed a framework for automatically creating systematic literature reviews by combining and placing existing techniques in stages where they possess the greatest potential to be useful. Despite still lacking practical assessment in different areas of knowledge, this proposal indicates ways with the potential to reduce the time-consuming and repetitive work embedded in the systematic literature review process. Originality/Value. The paper presents the current possibilities for automating systematic literature reviews and how they can work together to reduce researchers’ operational workload. COVID-19 drove rapidly evolving information, pushing to the forefront a cognitive technology known as living systematic review (LSR), a method for continually curating evidence as new evidence becomes available.3 For comparison, a systematic review (SR) is an analysis of all existing literature or evidence on a specific topic at one point in time. It is like a snapshot, a static report, which over time “leads to a decay in review currency, accuracy, and utility.”4 An LSR, on the other hand, can be viewed as a 24/7 news outlet continually updating and disseminating new evidence as it becomes available.4 Living systematic reviews are enabled by technology to afford “dynamic, persistent, online-only evidence summaries, which are updated rapidly and frequently.”4Systematic reviews have been viewed by clinicians for many years as the best sources of evidence for practice decisions.5 Key resources such as Cochrane have served scientists and clinicians for more than 30 years by developing the science of evidence synthesis.5 Widespread use of SRs in health care resulted from the inability to identify, track, and use the increasing amounts of published research.6 Now, thousands of meta-analyses are published yearly.7 The challenges with SRs involve the amount of time required to develop them and how to keep them current.Manual development of SRs has proven costly in terms of time expenditure. In a recent study on length of time needed to conduct SRs of medical interventions, Borah et al8 reported that the mean estimated time to complete an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2021
DA  - 2021-07-27
JO  - {'id': 'https://openalex.org/V4210199169', 'issn_l': '2709-3158', 'issn': ['2709-7595', '2709-3158'], 'display_name': 'Iberoamerican journal of science measurement and communication', 'publisher': 'ColNes', 'type': 'journal', 'url': 'https://pub.colnes.org/index.php/ijsmc/article/download/52/88', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc'}
DP  - OpenAlex
AU  - Eugênio Monteiro da Silva Júnior
AU  - Moisés Lima Dutra
ER  - 

346.
TY  - journal-article
ID  - https://openalex.org/W3184954410
DO  - https://doi.org/10.6087/kcse.244
TI  - Artificial intelligence-assisted tools for redefining the communication landscape of the scholarly world
AB  - The flood of research output and increasing demands for peer reviewers have necessitated the intervention of artificial intelligence (AI) in scholarly publishing. Although human input is seen as essential for writing publications, the contribution of AI slowly and steadily moves ahead. AI may redefine the role of science communication experts in the future and transform the scholarly publishing industry into a technology-driven one. It can prospectively improve the quality of publishable content and identify errors in published content. In this article, we review various AI and other associated tools currently in use or development for a range of publishing obligations and functions that have brought about or can soon leverage much-demanded advances in scholarly communications. Several AI-assisted tools, with diverse scope and scale, have emerged in the scholarly market. AI algorithms develop summaries of scientific publications and convert them into plain-language texts, press statements, and news stories. Retrieval of accurate and sufficient information is prominent in evidence-based science publications. Semantic tools may empower transparent and proficient data extraction tactics. From detecting simple plagiarism errors to predicting the projected citation impact of an unpublished article, AI’s role in scholarly publishing is expected to be multidimensional. AI, natural language processing, and machine learning in scholarly publishing have arrived for writers, editors, authors, and publishers. They should leverage these technologies to enable the fast and accurate dissemination of scientific information to contribute to the betterment of humankind. as new evidence becomes available.3 For comparison, a systematic review (SR) is an analysis of all existing literature or evidence on a specific topic at one point in time. It is like a snapshot, a static report, which over time “leads to a decay in review currency, accuracy, and utility.”4 An LSR, on the other hand, can be viewed as a 24/7 news outlet continually updating and disseminating new evidence as it becomes available.4 Living systematic reviews are enabled by technology to afford “dynamic, persistent, online-only evidence summaries, which are updated rapidly and frequently.”4Systematic reviews have been viewed by clinicians for many years as the best sources of evidence for practice decisions.5 Key resources such as Cochrane have served scientists and clinicians for more than 30 years by developing the science of evidence synthesis.5 Widespread use of SRs in health care resulted from the inability to identify, track, and use the increasing amounts of published research.6 Now, thousands of meta-analyses are published yearly.7 The challenges with SRs involve the amount of time required to develop them and how to keep them current.Manual development of SRs has proven costly in terms of time expenditure. In a recent study on length of time needed to conduct SRs of medical interventions, Borah et al8 reported that the mean estimated time to complete an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2021
DA  - 2021-07-27
JO  - {'id': 'https://openalex.org/S2739153651', 'issn_l': '2288-7474', 'issn': ['2288-7474', '2288-8063'], 'display_name': 'Science Editing', 'publisher': 'Korean Council of Science Editors', 'type': 'journal', 'url': 'https://www.escienceediting.org/upload/kcse-244.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc'}
DP  - OpenAlex
AU  - Habeeb Ibrahim Abdul Razack
AU  - Sam T Mathew
AU  - Fathinul Fikri Ahmad Saad
AU  - Saleh A. Alqahtani
ER  - 

347.
TY  - dissertation
ID  - https://openalex.org/W3185927732
DO  - https://doi.org/10.17863/cam.68583
TI  - Determining the biases and consistencies in the evidence for conservation
AB  - Alec Christie was supported by a Natural Environment Research Council studentship as part of the Cambridge Earth System Science NERC DTP [NE/L002507/1]. Although human input is seen as essential for writing publications, the contribution of AI slowly and steadily moves ahead. AI may redefine the role of science communication experts in the future and transform the scholarly publishing industry into a technology-driven one. It can prospectively improve the quality of publishable content and identify errors in published content. In this article, we review various AI and other associated tools currently in use or development for a range of publishing obligations and functions that have brought about or can soon leverage much-demanded advances in scholarly communications. Several AI-assisted tools, with diverse scope and scale, have emerged in the scholarly market. AI algorithms develop summaries of scientific publications and convert them into plain-language texts, press statements, and news stories. Retrieval of accurate and sufficient information is prominent in evidence-based science publications. Semantic tools may empower transparent and proficient data extraction tactics. From detecting simple plagiarism errors to predicting the projected citation impact of an unpublished article, AI’s role in scholarly publishing is expected to be multidimensional. AI, natural language processing, and machine learning in scholarly publishing have arrived for writers, editors, authors, and publishers. They should leverage these technologies to enable the fast and accurate dissemination of scientific information to contribute to the betterment of humankind. as new evidence becomes available.3 For comparison, a systematic review (SR) is an analysis of all existing literature or evidence on a specific topic at one point in time. It is like a snapshot, a static report, which over time “leads to a decay in review currency, accuracy, and utility.”4 An LSR, on the other hand, can be viewed as a 24/7 news outlet continually updating and disseminating new evidence as it becomes available.4 Living systematic reviews are enabled by technology to afford “dynamic, persistent, online-only evidence summaries, which are updated rapidly and frequently.”4Systematic reviews have been viewed by clinicians for many years as the best sources of evidence for practice decisions.5 Key resources such as Cochrane have served scientists and clinicians for more than 30 years by developing the science of evidence synthesis.5 Widespread use of SRs in health care resulted from the inability to identify, track, and use the increasing amounts of published research.6 Now, thousands of meta-analyses are published yearly.7 The challenges with SRs involve the amount of time required to develop them and how to keep them current.Manual development of SRs has proven costly in terms of time expenditure. In a recent study on length of time needed to conduct SRs of medical interventions, Borah et al8 reported that the mean estimated time to complete an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2021
DA  - 2021-04-22
JO  - {'id': None, 'issn_l': None, 'issn': None, 'display_name': None, 'publisher': None, 'type': None, 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Alec P. Christie
ER  - 

348.
TY  - journal-article
ID  - https://openalex.org/W3193696667
DO  - https://doi.org/10.12688/wellcomeopenres.17141.1
TI  - Cost-effectiveness of Microsoft Academic Graph with machine learning for automated study identification in a living map of coronavirus disease 2019 (COVID-19) research
AB  - <ns4:p><ns4:bold>Background:</ns4:bold> Conventionally, searching for eligible articles to include in systematic reviews and maps of research has relied primarily on information specialists conducting Boolean searches of multiple databases and manually processing the results, including deduplication between these multiple sources. Searching one, comprehensive source, rather than multiple databases, could save time and resources. Microsoft Academic Graph (MAG) is potentially such a source, containing a network graph structure which provides metadata that can be exploited in machine learning processes. Research is needed to establish the relative advantage of using MAG as a single source, compared with conventional searches of multiple databases. This study sought to establish whether: (a) MAG is sufficiently comprehensive to maintain our living map of coronavirus disease 2019 (COVID-19) research; and (b) eligible records can be identified with an acceptably high level of specificity.</ns4:p><ns4:p> <ns4:bold>Methods: </ns4:bold>We conducted a pragmatic, eight-arm cost-effectiveness analysis (simulation study) to assess the costs, recall and precision of our semi-automated MAG-enabled workflow versus conventional searches of MEDLINE and Embase (with and without machine learning classifiers, active learning and/or fixed screening targets) for maintaining a living map of COVID-19 research. Resource use data (time use) were collected from information specialists and other researchers involved in map production.</ns4:p><ns4:p> <ns4:bold>Results: </ns4:bold>MAG-enabled workflows dominated MEDLINE-Embase workflows in both the base case and sensitivity analyses. At one month (base case analysis) our MAG-enabled workflow with machine learning, active learning and fixed screening targets identified n=469 more new, eligible articles for inclusion in our living map – and cost £3,179 GBP ($5,691 AUD) less – than conventional MEDLINE-Embase searches without any automation or fixed screening targets.</ns4:p><ns4:p> <ns4:bold>Conclusions: </ns4:bold>MAG-enabled continuous surveillance workflows have potential to revolutionise study identification methods for living maps, specialised registers, databases of research studies and/or collections of systematic reviews, by increasing their recall and coverage, whilst reducing production costs.</ns4:p> and disseminating new evidence as it becomes available.4 Living systematic reviews are enabled by technology to afford “dynamic, persistent, online-only evidence summaries, which are updated rapidly and frequently.”4Systematic reviews have been viewed by clinicians for many years as the best sources of evidence for practice decisions.5 Key resources such as Cochrane have served scientists and clinicians for more than 30 years by developing the science of evidence synthesis.5 Widespread use of SRs in health care resulted from the inability to identify, track, and use the increasing amounts of published research.6 Now, thousands of meta-analyses are published yearly.7 The challenges with SRs involve the amount of time required to develop them and how to keep them current.Manual development of SRs has proven costly in terms of time expenditure. In a recent study on length of time needed to conduct SRs of medical interventions, Borah et al8 reported that the mean estimated time to complete an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2021
DA  - 2021-08-19
JO  - {'id': 'https://openalex.org/S4306534713', 'issn_l': '2398-502X', 'issn': ['2398-502X'], 'display_name': 'Wellcome Open Research', 'publisher': 'Wellcome', 'type': 'journal', 'url': 'https://doi.org/10.12688/wellcomeopenres.17141.1', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Ian Shemilt
AU  - Anneliese Arno
AU  - James D. Thomas
AU  - Theo Lorenc
AU  - Claire Louise Khouja
AU  - Gary Raine
AU  - Katy Sutcliffe
AU  - D'Souza Preethy
AU  - Irene Kwan
AU  - Kath Wright
AU  - Amanda Sowden
ER  - 

349.
TY  - book-chapter
ID  - https://openalex.org/W3199830233
DO  - https://doi.org/10.1007/978-1-0716-1566-9_2
TI  - Semi-automated Tools for Systematic Searches
AB  - Traditionally, literature identification for systematic reviews has relied on a two-step process: first, searching databases to identify potentially relevant citations, and then manually screening those citations. A number of tools have been developed to streamline and semi-automate this process, including tools to generate terms; to visualize and evaluate search queries; to trace citation linkages; to deduplicate, limit, or translate searches across databases; and to prioritize relevant abstracts for screening. Research is ongoing into tools that can unify searching and screening into a single step, and several protype tools have been developed. As this field grows, it is becoming increasingly important to develop and codify methods for evaluating the extent to which these tools fulfill their purpose. disease 2019 (COVID-19) research; and (b) eligible records can be identified with an acceptably high level of specificity.</ns4:p><ns4:p> <ns4:bold>Methods: </ns4:bold>We conducted a pragmatic, eight-arm cost-effectiveness analysis (simulation study) to assess the costs, recall and precision of our semi-automated MAG-enabled workflow versus conventional searches of MEDLINE and Embase (with and without machine learning classifiers, active learning and/or fixed screening targets) for maintaining a living map of COVID-19 research. Resource use data (time use) were collected from information specialists and other researchers involved in map production.</ns4:p><ns4:p> <ns4:bold>Results: </ns4:bold>MAG-enabled workflows dominated MEDLINE-Embase workflows in both the base case and sensitivity analyses. At one month (base case analysis) our MAG-enabled workflow with machine learning, active learning and fixed screening targets identified n=469 more new, eligible articles for inclusion in our living map – and cost £3,179 GBP ($5,691 AUD) less – than conventional MEDLINE-Embase searches without any automation or fixed screening targets.</ns4:p><ns4:p> <ns4:bold>Conclusions: </ns4:bold>MAG-enabled continuous surveillance workflows have potential to revolutionise study identification methods for living maps, specialised registers, databases of research studies and/or collections of systematic reviews, by increasing their recall and coverage, whilst reducing production costs.</ns4:p> and disseminating new evidence as it becomes available.4 Living systematic reviews are enabled by technology to afford “dynamic, persistent, online-only evidence summaries, which are updated rapidly and frequently.”4Systematic reviews have been viewed by clinicians for many years as the best sources of evidence for practice decisions.5 Key resources such as Cochrane have served scientists and clinicians for more than 30 years by developing the science of evidence synthesis.5 Widespread use of SRs in health care resulted from the inability to identify, track, and use the increasing amounts of published research.6 Now, thousands of meta-analyses are published yearly.7 The challenges with SRs involve the amount of time required to develop them and how to keep them current.Manual development of SRs has proven costly in terms of time expenditure. In a recent study on length of time needed to conduct SRs of medical interventions, Borah et al8 reported that the mean estimated time to complete an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2022
DA  - 2022-01-01
JO  - {'id': 'https://openalex.org/S4210172139', 'issn_l': '1064-3745', 'issn': ['1940-6029', '1064-3745'], 'display_name': 'Methods in molecular biology', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Gaelen P Adam
AU  - Byron C. Wallace
AU  - Thomas A Trikalinos
ER  - 

350.
TY  - posted-content
ID  - https://openalex.org/W4205931375
DO  - https://doi.org/10.1101/2021.07.13.21260468
TI  - Fifty Ways to Tag your Pubtypes: Multi-Tagger, a Set of Probabilistic Publication Type and Study Design Taggers to Support Biomedical Indexing and Evidence-Based Medicine
AB  - Abstract Objective Indexing articles according to publication types (PTs) and study designs can be a great aid to filtering literature for information retrieval, especially for evidence syntheses. In this study, 50 automated machine learning based probabilistic PT and study design taggers were built and applied to all articles in PubMed. Materials and Methods PubMed article metadata from 1987-2014 were used as training data, with 2015 used for recalibration. The set of articles indexed with a particular study design MeSH term or PT tag was used as positive training sets. For each PT, the rest of the literature from the same time period was used as its negative training set. Multiple features based on each article title, abstract and metadata were used in training the models. Taggers were evaluated on PubMed articles from 2016 and 2019. A manual analysis was also performed. Results Of the 50 predictive models that we created, 44 of these achieved an AUC of ∼0.90 or greater, with many having performance above 0.95. Of the clinically related study designs, the best performing was SYSTEMATIC_REVIEW with an AUC of 0.998; the lowest performing was RANDOM_ALLOCATION, with an AUC of 0.823. Discussion This work demonstrates that is feasible to build a large set of probabilistic publication type and study design taggers with high accuracy and ranking performance. Automated tagging permits users to identify qualifying articles as soon as they are published, and allows consistent criteria to be applied across different bibliographic databases. Probabilistic predictive scores are more flexible than binary yes/no predictions, since thresholds can be tailored for specific uses such as high recall literature search, user-adjustable retrieval size, and quality improvement of manually annotated databases. Conclusion The PT predictive probability scores for all PubMed articles are freely downloadable at http://arrowsmith.psych.uic.edu/evidence_based_medicine/mt_download.html for incorporation into user tools and workflows. Users can also perform PubMed queries at our Anne O’Tate value-added PubMed search engine http://arrowsmith.psych.uic.edu/cgi-bin/arrowsmith_uic/AnneOTate.cgi and filter retrieved articles according to both NLM-annotated and model-predicted publication types and study designs. have been viewed by clinicians for many years as the best sources of evidence for practice decisions.5 Key resources such as Cochrane have served scientists and clinicians for more than 30 years by developing the science of evidence synthesis.5 Widespread use of SRs in health care resulted from the inability to identify, track, and use the increasing amounts of published research.6 Now, thousands of meta-analyses are published yearly.7 The challenges with SRs involve the amount of time required to develop them and how to keep them current.Manual development of SRs has proven costly in terms of time expenditure. In a recent study on length of time needed to conduct SRs of medical interventions, Borah et al8 reported that the mean estimated time to complete an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2021
DA  - 2021-07-16
JO  - {'id': None, 'issn_l': None, 'issn': None, 'display_name': None, 'publisher': None, 'type': None, 'url': 'https://doi.org/10.1101/2021.07.13.21260468', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Aaron Cohen
AU  - Jodi Schneider
AU  - Yuanxi Fu
AU  - Marian McDonagh
AU  - Prerna Das
AU  - Arthur E. Holt
AU  - Neil R. Smalheiser
ER  - 

351.
TY  - book-chapter
ID  - https://openalex.org/W4210990158
DO  - https://doi.org/10.1007/978-3-030-66147-2_10
TI  - Systematic Reviews
AB  - Systematic reviews are a firmly established method of ensuring that proposed research is based upon the best available scientific evidence. In this chapter, we provide a brief history of systematic reviews and discuss their adaptation to preclinical studies. The steps in conducting a systematic review are explained, with examples of best practice. Readers will learn how to critically evaluate the quality of systematic reviews in their own fields. Basic guidance on the parts of a systematic review and meta-analysis are explained. Critically appraised topics (or knowledge summaries) are also described, and their relevance for preclinical research is explained, including a worked example. was used as its negative training set. Multiple features based on each article title, abstract and metadata were used in training the models. Taggers were evaluated on PubMed articles from 2016 and 2019. A manual analysis was also performed. Results Of the 50 predictive models that we created, 44 of these achieved an AUC of ∼0.90 or greater, with many having performance above 0.95. Of the clinically related study designs, the best performing was SYSTEMATIC_REVIEW with an AUC of 0.998; the lowest performing was RANDOM_ALLOCATION, with an AUC of 0.823. Discussion This work demonstrates that is feasible to build a large set of probabilistic publication type and study design taggers with high accuracy and ranking performance. Automated tagging permits users to identify qualifying articles as soon as they are published, and allows consistent criteria to be applied across different bibliographic databases. Probabilistic predictive scores are more flexible than binary yes/no predictions, since thresholds can be tailored for specific uses such as high recall literature search, user-adjustable retrieval size, and quality improvement of manually annotated databases. Conclusion The PT predictive probability scores for all PubMed articles are freely downloadable at http://arrowsmith.psych.uic.edu/evidence_based_medicine/mt_download.html for incorporation into user tools and workflows. Users can also perform PubMed queries at our Anne O’Tate value-added PubMed search engine http://arrowsmith.psych.uic.edu/cgi-bin/arrowsmith_uic/AnneOTate.cgi and filter retrieved articles according to both NLM-annotated and model-predicted publication types and study designs. have been viewed by clinicians for many years as the best sources of evidence for practice decisions.5 Key resources such as Cochrane have served scientists and clinicians for more than 30 years by developing the science of evidence synthesis.5 Widespread use of SRs in health care resulted from the inability to identify, track, and use the increasing amounts of published research.6 Now, thousands of meta-analyses are published yearly.7 The challenges with SRs involve the amount of time required to develop them and how to keep them current.Manual development of SRs has proven costly in terms of time expenditure. In a recent study on length of time needed to conduct SRs of medical interventions, Borah et al8 reported that the mean estimated time to complete an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2021
DA  - 2021-01-01
JO  - {'id': 'https://openalex.org/S4210204408', 'issn_l': '2730-7859', 'issn': ['2730-7859', '2730-7867'], 'display_name': 'Laboratory Animal Science and Medicine', 'publisher': 'Springer International Publishing', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Janet Rodgers
AU  - Merel Ritskes-Hoitinga
ER  - 

352.
TY  - journal-article
ID  - https://openalex.org/W4221026781
DO  - https://doi.org/10.1111/1365-2664.14154
TI  - Innovation and forward‐thinking are needed to improve traditional synthesis methods: A response to Pescott and Stewart
AB  - In Christie et al. (2019), we used simulations to quantitatively compare the bias of commonly used study designs in ecology and conservation. Based on these simulations, we proposed ‘accuracy weights’ as a potential way to account for study design validity in meta-analytic weighting methods. Pescott and Stewart (2022) raised concerns that these weights may not be generalisable and still lead to biased meta-estimates. Here we respond to their concerns and demonstrate why developing alternative weighting methods is key to the future of evidence synthesis. We acknowledge that our simple simulation unfairly penalised randomised controlled trial (RCT) relative to before-after control-impact (BACI) designs as we considered that the parallel trends assumption held for BACI designs. We point to an empirical follow-up study in which we more fairly quantify differences in biases between different study designs. However, we stand by our main findings that before-after (BA), control-impact (CI) and after designs are quantifiably more biased than BACI and RCT designs. We also emphasise that our ‘accuracy weighting’ method was preliminary and welcome future research to incorporate more dimensions of study quality. We further show that over a decade of advances in quality effect modelling, which Pescott and Stewart (2022) omit, highlights the importance of research such as ours in better understanding how to quantitatively integrate data on study quality directly into meta-analyses. We further argue that the traditional methods advocated for by Pescott and Stewart (2022; e.g. manual risk-of-bias assessments and inverse-variance weighting) are subjective, wasteful and potentially biased themselves. They also lack scalability for use in large syntheses that keep up-to-date with the rapidly growing scientific literature. Synthesis and applications. We suggest, contrary to Pescott and Stewart's narrative, that moving towards alternative weighting methods is key to future-proofing evidence synthesis through greater automation, flexibility and updating to respond to decision-makers' needs—particularly in crisis disciplines in conservation science where problematic biases and variability exist in study designs, contexts and metrics used. While we must be cautious to avoid misinforming decision-makers, this should not stop us investigating alternative weighting methods that integrate study quality data directly into meta-analyses. To reliably and pragmatically inform decision-makers with science, we need efficient, scalable, readily automated and feasible methods to appraise and weight studies to produce large-scale living syntheses of the future. resulted from the inability to identify, track, and use the increasing amounts of published research.6 Now, thousands of meta-analyses are published yearly.7 The challenges with SRs involve the amount of time required to develop them and how to keep them current.Manual development of SRs has proven costly in terms of time expenditure. In a recent study on length of time needed to conduct SRs of medical interventions, Borah et al8 reported that the mean estimated time to complete an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2022
DA  - 2022-03-22
JO  - {'id': 'https://openalex.org/S82098733', 'issn_l': '0021-8901', 'issn': ['0021-8901', '1365-2664'], 'display_name': 'Journal of Applied Ecology', 'publisher': 'Wiley-Blackwell', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Alec P. Christie
AU  - Tatsuya Amano
AU  - Philip L. Martin
AU  - Gorm E. Shackelford
AU  - Benno I. Simmons
AU  - William J. Sutherland
ER  - 

353.
TY  - journal-article
ID  - https://openalex.org/W4225297356
DO  - https://doi.org/10.2196/33219
TI  - Web-Based Software Tools for Systematic Literature Review in Medicine: Systematic Search and Feature Analysis
AB  - Background Systematic reviews (SRs) are central to evaluating therapies but have high costs in terms of both time and money. Many software tools exist to assist with SRs, but most tools do not support the full process, and transparency and replicability of SR depend on performing and presenting evidence according to established best practices. Objective This study aims to provide a basis for comparing and selecting between web-based software tools that support SR, by conducting a feature-by-feature comparison of SR tools. Methods We searched for SR tools by reviewing any such tool listed in the SR Toolbox, previous reviews of SR tools, and qualitative Google searching. We included all SR tools that were currently functional and required no coding, and excluded reference managers, desktop applications, and statistical software. The list of features to assess was populated by combining all features assessed in 4 previous reviews of SR tools; we also added 5 features (manual addition, screening automation, dual extraction, living review, and public outputs) that were independently noted as best practices or enhancements of transparency and replicability. Then, 2 reviewers assigned binary present or absent assessments to all SR tools with respect to all features, and a third reviewer adjudicated all disagreements. Results Of the 53 SR tools found, 55% (29/53) were excluded, leaving 45% (24/53) for assessment. In total, 30 features were assessed across 6 classes, and the interobserver agreement was 86.46%. Giotto Compliance (27/30, 90%), DistillerSR (26/30, 87%), and Nested Knowledge (26/30, 87%) support the most features, followed by EPPI-Reviewer Web (25/30, 83%), LitStream (23/30, 77%), JBI SUMARI (21/30, 70%), and SRDB.PRO (VTS Software) (21/30, 70%). Fewer than half of all the features assessed are supported by 7 tools: RobotAnalyst (National Centre for Text Mining), SRDR (Agency for Healthcare Research and Quality), SyRF (Systematic Review Facility), Data Abstraction Assistant (Center for Evidence Synthesis in Health), SR Accelerator (Institute for Evidence-Based Healthcare), RobotReviewer (RobotReviewer), and COVID-NMA (COVID-NMA). Notably, of the 24 tools, only 10 (42%) support direct search, only 7 (29%) offer dual extraction, and only 13 (54%) offer living/updatable reviews. Conclusions DistillerSR, Nested Knowledge, and EPPI-Reviewer Web each offer a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. of meta-analyses are published yearly.7 The challenges with SRs involve the amount of time required to develop them and how to keep them current.Manual development of SRs has proven costly in terms of time expenditure. In a recent study on length of time needed to conduct SRs of medical interventions, Borah et al8 reported that the mean estimated time to complete an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2022
DA  - 2022-05-02
JO  - {'id': 'https://openalex.org/S2764650051', 'issn_l': '2291-9694', 'issn': ['2291-9694'], 'display_name': 'JMIR medical informatics', 'publisher': 'JMIR Publications', 'type': 'journal', 'url': 'https://medinform.jmir.org/2022/5/e33219/PDF', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Kathryn Cowie
AU  - Asad Rahmatullah
AU  - Nicole Hardy
AU  - Kevin M. Kallmes
AU  - Kevin M. Kallmes
ER  - 

354.
TY  - journal-article
ID  - https://openalex.org/W4244190863
DO  - https://doi.org/10.12688/f1000research.22032.3
TI  - Toolkit of methodological resources to conduct systematic reviews
AB  - <ns4:p><ns4:bold>Background: </ns4:bold>Systematic reviews (SR) can be classified by type depending on the research question they are based on. This work identifies and describes the most relevant methodological resources to conduct high-quality reviews that answer health care questions regarding prevalence, prognosis, diagnostic accuracy and effects of interventions.</ns4:p><ns4:p> <ns4:bold>Methods: </ns4:bold>Methodological resources have been identified from literature searches and consulting guidelines from institutions that develop SRs. The selected resources are organized by type of SR, and stage of development of the review (formulation of the research question, development of the protocol, literature search, risk of bias assessment, synthesis of findings, assessment of the quality of evidence, and report of SR results and conclusions).</ns4:p><ns4:p> <ns4:bold>Results: </ns4:bold>Although the different types of SRs are developed following the same steps, each SR type requires specific methods, differing in characteristics and complexity. The extent of methodological development varies by type of SR, with more solid guidelines available for diagnostic accuracy and effects of interventions SRs.</ns4:p><ns4:p> This methodological toolkit describes the most up-to-date risk of bias instruments: Quality in Prognostic Studies (QUIPS) tool and Prediction model study Risk Of Bias Assessment Tool (PROBAST) for prognostic SRs, Quality assessment of diagnostic accuracy studies tool (QUADAS-2) for diagnostic accuracy SRs, Cochrane risk of bias tool (ROB-2) and Risk of bias in non-randomised studies of interventions studies tool (ROBINS-I) for effects of interventions SRs, as well as the latest developments on the Grading of Recommendations Assessment, Development and Evaluation (GRADE) system.</ns4:p><ns4:p> <ns4:bold>Conclusions</ns4:bold>: This structured compilation of the best methodological resources for each type of SR may prove to be a very useful tool for those researchers that wish to develop SRs or conduct methodological research works on SRs</ns4:p> are supported by 7 tools: RobotAnalyst (National Centre for Text Mining), SRDR (Agency for Healthcare Research and Quality), SyRF (Systematic Review Facility), Data Abstraction Assistant (Center for Evidence Synthesis in Health), SR Accelerator (Institute for Evidence-Based Healthcare), RobotReviewer (RobotReviewer), and COVID-NMA (COVID-NMA). Notably, of the 24 tools, only 10 (42%) support direct search, only 7 (29%) offer dual extraction, and only 13 (54%) offer living/updatable reviews. Conclusions DistillerSR, Nested Knowledge, and EPPI-Reviewer Web each offer a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. of meta-analyses are published yearly.7 The challenges with SRs involve the amount of time required to develop them and how to keep them current.Manual development of SRs has proven costly in terms of time expenditure. In a recent study on length of time needed to conduct SRs of medical interventions, Borah et al8 reported that the mean estimated time to complete an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2020
DA  - 2020-10-14
JO  - {'id': 'https://openalex.org/S4210239046', 'issn_l': '2046-1402', 'issn': ['2046-1402'], 'display_name': 'F1000Research', 'publisher': 'Faculty of 1000', 'type': 'journal', 'url': 'https://f1000research.com/articles/9-82/v3/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Marta Roqué i Figuls
AU  - Laura B. Martínez-García
AU  - Ivan Solà
AU  - Pablo Alonso-Coello
AU  - Xavier Bonfill
AU  - Javier Zamora
ER  - 

355.
TY  - journal-article
ID  - https://openalex.org/W4256113187
DO  - https://doi.org/10.12688/f1000research.22032.1
TI  - Toolkit of methodological resources to conduct systematic reviews
AB  - <ns4:p><ns4:bold>Background: </ns4:bold>Systematic reviews (SR) can be classified by type depending on the research question they are based on. This work identifies and describes the most relevant methodological resources to conduct high-quality reviews that answer clinical questions regarding prevalence, prognosis, diagnostic accuracy and efficacy of interventions.</ns4:p><ns4:p> <ns4:bold>Methods: </ns4:bold>Methodological resources have been identified from literature searches and consulting guidelines from institutions that develop SRs. The selected resources are organized by type of SR, and stage of development of the review (formulation of the research question, development of the protocol, literature search, risk of bias assessment, synthesis of findings, assessment of the quality of evidence, and report of SR results and conclusions).</ns4:p><ns4:p> <ns4:bold>Results: </ns4:bold>Although the different types of SRs are developed following the same steps, each SR type requires specific methods, differing in characteristics and complexity. The extent of methodological development varies by type of SR, with more solid guidelines available for diagnostic accuracy and efficacy of interventions SRs.</ns4:p><ns4:p> This methodological toolkit describes the most up-to-date risk of bias instruments: Quality in Prognostic Studies (QUIPS) tool and Prediction model study Risk Of Bias Assessment Tool (PROBAST) for prognostic SRs, Quality assessment of diagnostic accuracy studies tool (QUADAS-2) for diagnostic accuracy SRs, Cochrane risk of bias tool (ROB-2) and Risk of bias in non-randomised studies of interventions studies tool (ROBINS-I) for efficacy of interventions SRs, as well as the latest developments on the Grading of Recommendations Assessment, Development and Evaluation (GRADE) system.</ns4:p><ns4:p> <ns4:bold>Conclusions</ns4:bold>: This structured compilation of the best methodological resources for each type of SR may prove to be a very useful tool for those researchers that wish to develop SRs or conduct methodological research works on SRs.</ns4:p> SRs</ns4:p> are supported by 7 tools: RobotAnalyst (National Centre for Text Mining), SRDR (Agency for Healthcare Research and Quality), SyRF (Systematic Review Facility), Data Abstraction Assistant (Center for Evidence Synthesis in Health), SR Accelerator (Institute for Evidence-Based Healthcare), RobotReviewer (RobotReviewer), and COVID-NMA (COVID-NMA). Notably, of the 24 tools, only 10 (42%) support direct search, only 7 (29%) offer dual extraction, and only 13 (54%) offer living/updatable reviews. Conclusions DistillerSR, Nested Knowledge, and EPPI-Reviewer Web each offer a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. of meta-analyses are published yearly.7 The challenges with SRs involve the amount of time required to develop them and how to keep them current.Manual development of SRs has proven costly in terms of time expenditure. In a recent study on length of time needed to conduct SRs of medical interventions, Borah et al8 reported that the mean estimated time to complete an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2020
DA  - 2020-02-04
JO  - {'id': 'https://openalex.org/S4210239046', 'issn_l': '2046-1402', 'issn': ['2046-1402'], 'display_name': 'F1000Research', 'publisher': 'Faculty of 1000', 'type': 'journal', 'url': 'https://doi.org/10.12688/f1000research.22032.1', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Marta Roqué i Figuls
AU  - Laura B. Martínez-García
AU  - Ivan Solà
AU  - Pablo Alonso-Coello
AU  - Xavier Bonfill
AU  - Javier Zamora
ER  - 

356.
TY  - journal-article
ID  - https://openalex.org/W4280597817
DO  - https://doi.org/10.3389/fevo.2022.845608
TI  - Artificial Intelligence-Aided Meta-Analysis of Toxicological Assessment of Agrochemicals in Bees
AB  - The lack of consensus regarding pollinator decline in various parts of the planet has generated intense debates in different spheres. Consequently, much research has attempted to identify the leading causes of this decline, and a multifactorial synergism (i.e., different stressors acting together and mutually potentiating the harmful effects) seems to be the emerging consensus explaining this phenomenon. The emphasis on some stressor groups such as agrochemicals, and pollinators such as the honey bee Apis mellifera , can hide the real risk of anthropogenic stressors on pollinating insects. In the present study, we conducted a systematic review of the literature to identify general and temporal trends in publications, considering the different groups of pollinators and their exposure to agrochemicals over the last 76 years. Through an artificial intelligence (AI)-aided meta-analysis, we quantitatively assessed trends in publications on bee groups and agrochemicals. Using AI tools through machine learning enabled efficient evaluation of a large volume of published articles. Toxicological assessment of the impact of agrochemicals on insect pollinators is dominated by the order Hymenoptera, which includes honey bees. Although honey bees are well-explored, there is a lack of published articles exploring the toxicological assessment of agrochemicals for bumble bees, solitary bees, and stingless bees. The data gathered provide insights into the current scenario of the risk of pollinator decline imposed by agrochemicals and serve to guide further research in this area. Systematic Review Registration https://asreview.nl/ . and Evaluation (GRADE) system.</ns4:p><ns4:p> <ns4:bold>Conclusions</ns4:bold>: This structured compilation of the best methodological resources for each type of SR may prove to be a very useful tool for those researchers that wish to develop SRs or conduct methodological research works on SRs.</ns4:p> SRs</ns4:p> are supported by 7 tools: RobotAnalyst (National Centre for Text Mining), SRDR (Agency for Healthcare Research and Quality), SyRF (Systematic Review Facility), Data Abstraction Assistant (Center for Evidence Synthesis in Health), SR Accelerator (Institute for Evidence-Based Healthcare), RobotReviewer (RobotReviewer), and COVID-NMA (COVID-NMA). Notably, of the 24 tools, only 10 (42%) support direct search, only 7 (29%) offer dual extraction, and only 13 (54%) offer living/updatable reviews. Conclusions DistillerSR, Nested Knowledge, and EPPI-Reviewer Web each offer a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. of meta-analyses are published yearly.7 The challenges with SRs involve the amount of time required to develop them and how to keep them current.Manual development of SRs has proven costly in terms of time expenditure. In a recent study on length of time needed to conduct SRs of medical interventions, Borah et al8 reported that the mean estimated time to complete an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2022
DA  - 2022-05-19
JO  - {'id': 'https://openalex.org/S2597028195', 'issn_l': '2296-701X', 'issn': ['2296-701X'], 'display_name': 'Frontiers in Ecology and Evolution', 'publisher': 'Frontiers Media', 'type': 'journal', 'url': 'https://www.frontiersin.org/articles/10.3389/fevo.2022.845608/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Rodrigo Cupertino Bernardes
AU  - Lorena L. Botina
AU  - Renan dos Santos Araújo
AU  - Raul Narciso C. Guedes
AU  - Gustavo Ferreira Martins
AU  - Maria Luísa Lima
ER  - 

357.
TY  - journal-article
ID  - https://openalex.org/W4283079132
DO  - https://doi.org/10.1186/s12911-022-01897-4
TI  - Automatic data extraction to support meta-analysis statistical analysis: a case study on breast cancer
AB  - Meta-analyses aggregate results of different clinical studies to assess the effectiveness of a treatment. Despite their importance, meta-analyses are time-consuming and labor-intensive as they involve reading hundreds of research articles and extracting data. The number of research articles is increasing rapidly and most meta-analyses are outdated shortly after publication as new evidence has not been included. Automatic extraction of data from research articles can expedite the meta-analysis process and allow for automatic updates when new results become available. In this study, we propose a system for automatically extracting data from research abstracts and performing statistical analysis.Our corpus consists of 1011 PubMed abstracts of breast cancer randomized controlled trials annotated with the core elements of clinical trials: Participants, Intervention, Control, and Outcomes (PICO). We proposed a BERT-based named entity recognition (NER) model to identify PICO information from research abstracts. After extracting the PICO information, we parse numeric outcomes to identify the number of patients having certain outcomes for statistical analysis.The NER model extracted PICO elements with relatively high accuracy, achieving F1-scores greater than 0.80 in most entities. We assessed the performance of the proposed system by reproducing the results of an existing meta-analysis. The data extraction step achieved high accuracy, however the statistical analysis step achieved low performance because abstracts sometimes lack all the required information.We proposed a system for automatically extracting data from research abstracts and performing statistical analysis. We evaluated the performance of the system by reproducing an existing meta-analysis and the system achieved a relatively good performance, though more substantiation is required. to be a very useful tool for those researchers that wish to develop SRs or conduct methodological research works on SRs.</ns4:p> SRs</ns4:p> are supported by 7 tools: RobotAnalyst (National Centre for Text Mining), SRDR (Agency for Healthcare Research and Quality), SyRF (Systematic Review Facility), Data Abstraction Assistant (Center for Evidence Synthesis in Health), SR Accelerator (Institute for Evidence-Based Healthcare), RobotReviewer (RobotReviewer), and COVID-NMA (COVID-NMA). Notably, of the 24 tools, only 10 (42%) support direct search, only 7 (29%) offer dual extraction, and only 13 (54%) offer living/updatable reviews. Conclusions DistillerSR, Nested Knowledge, and EPPI-Reviewer Web each offer a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. of meta-analyses are published yearly.7 The challenges with SRs involve the amount of time required to develop them and how to keep them current.Manual development of SRs has proven costly in terms of time expenditure. In a recent study on length of time needed to conduct SRs of medical interventions, Borah et al8 reported that the mean estimated time to complete an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2022
DA  - 2022-06-18
JO  - {'id': 'https://openalex.org/S107516304', 'issn_l': '1472-6947', 'issn': ['1472-6947'], 'display_name': 'BMC Medical Informatics and Decision Making', 'publisher': 'BioMed Central', 'type': 'journal', 'url': 'https://bmcmedinformdecismak.biomedcentral.com/counter/pdf/10.1186/s12911-022-01897-4', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Faith W. Mutinda
AU  - Kongmeng Liew
AU  - Shuntaro Yada
AU  - Shoko Wakamiya
AU  - Eiji Aramaki
ER  - 

358.
TY  - journal-article
ID  - https://openalex.org/W4296930504
DO  - https://doi.org/10.3390/biomedinformatics2030032
TI  - Machine Learning Tools and Platforms in Clinical Trial Outputs to Support Evidence-Based Health Informatics: A Rapid Review of the Literature
AB  - Background: The application of machine learning (ML) tools (MLTs) to support clinical trials outputs in evidence-based health informatics can be an effective, useful, feasible, and acceptable way to advance medical research and provide precision medicine. Methods: In this study, the author used the rapid review approach and snowballing methods. The review was conducted in the following databases: PubMed, Scopus, COCHRANE LIBRARY, clinicaltrials.gov, Semantic Scholar, and the first six pages of Google Scholar from the 10 July–15 August 2022 period. Results: Here, 49 articles met the required criteria and were included in this review. Accordingly, 32 MLTs and platforms were identified in this study that applied the automatic extraction of knowledge from clinical trial outputs. Specifically, the initial use of automated tools resulted in modest to satisfactory time savings compared with the manual management. In addition, the evaluation of performance, functionality, usability, user interface, and system requirements also yielded positive results. Moreover, the evaluation of some tools in terms of acceptance, feasibility, precision, accuracy, efficiency, efficacy, and reliability was also positive. Conclusions: In summary, design based on the application of clinical trial results in ML is a promising approach to apply more reliable solutions. Future studies are needed to propose common standards for the assessment of MLTs and to clinically validate the performance in specific healthcare and technical domains. for automatically extracting data from research abstracts and performing statistical analysis. We evaluated the performance of the system by reproducing an existing meta-analysis and the system achieved a relatively good performance, though more substantiation is required. to be a very useful tool for those researchers that wish to develop SRs or conduct methodological research works on SRs.</ns4:p> SRs</ns4:p> are supported by 7 tools: RobotAnalyst (National Centre for Text Mining), SRDR (Agency for Healthcare Research and Quality), SyRF (Systematic Review Facility), Data Abstraction Assistant (Center for Evidence Synthesis in Health), SR Accelerator (Institute for Evidence-Based Healthcare), RobotReviewer (RobotReviewer), and COVID-NMA (COVID-NMA). Notably, of the 24 tools, only 10 (42%) support direct search, only 7 (29%) offer dual extraction, and only 13 (54%) offer living/updatable reviews. Conclusions DistillerSR, Nested Knowledge, and EPPI-Reviewer Web each offer a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. of meta-analyses are published yearly.7 The challenges with SRs involve the amount of time required to develop them and how to keep them current.Manual development of SRs has proven costly in terms of time expenditure. In a recent study on length of time needed to conduct SRs of medical interventions, Borah et al8 reported that the mean estimated time to complete an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2022
DA  - 2022-09-14
JO  - {'id': 'https://openalex.org/S4210213753', 'issn_l': '2673-7426', 'issn': ['2673-7426'], 'display_name': 'BioMedInformatics', 'publisher': 'MDPI AG', 'type': 'journal', 'url': 'https://www.mdpi.com/2673-7426/2/3/32/pdf?version=1663163045', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Stella C. Christopoulou
ER  - 

359.
TY  - journal-article
ID  - https://openalex.org/W4298110672
DO  - https://doi.org/10.1186/s13643-022-02074-4
TI  - PICO entity extraction for preclinical animal literature
AB  - Abstract Background Natural language processing could assist multiple tasks in systematic reviews to reduce workflow, including the extraction of PICO elements such as study populations, interventions, comparators and outcomes. The PICO framework provides a basis for the retrieval and selection for inclusion of evidence relevant to a specific systematic review question, and automatic approaches to PICO extraction have been developed particularly for reviews of clinical trial findings. Considering the difference between preclinical animal studies and clinical trials, developing separate approaches is necessary. Facilitating preclinical systematic reviews will inform the translation from preclinical to clinical research. Methods We randomly selected 400 abstracts from the PubMed Central Open Access database which described in vivo animal research and manually annotated these with PICO phrases for Species, Strain, methods of Induction of disease model, Intervention, Comparator and Outcome. We developed a two-stage workflow for preclinical PICO extraction. Firstly we fine-tuned BERT with different pre-trained modules for PICO sentence classification. Then, after removing the text irrelevant to PICO features, we explored LSTM-, CRF- and BERT-based models for PICO entity recognition. We also explored a self-training approach because of the small training corpus. Results For PICO sentence classification, BERT models using all pre-trained modules achieved an F1 score of over 80%, and models pre-trained on PubMed abstracts achieved the highest F1 of 85%. For PICO entity recognition, fine-tuning BERT pre-trained on PubMed abstracts achieved an overall F1 of 71% and satisfactory F1 for Species (98%), Strain (70%), Intervention (70%) and Outcome (67%). The score of Induction and Comparator is less satisfactory, but F1 of Comparator can be improved to 50% by applying self-training. Conclusions Our study indicates that of the approaches tested, BERT pre-trained on PubMed abstracts is the best for both PICO sentence classification and PICO entity recognition in the preclinical abstracts. Self-training yields better performance for identifying comparators and strains. Health), SR Accelerator (Institute for Evidence-Based Healthcare), RobotReviewer (RobotReviewer), and COVID-NMA (COVID-NMA). Notably, of the 24 tools, only 10 (42%) support direct search, only 7 (29%) offer dual extraction, and only 13 (54%) offer living/updatable reviews. Conclusions DistillerSR, Nested Knowledge, and EPPI-Reviewer Web each offer a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. of meta-analyses are published yearly.7 The challenges with SRs involve the amount of time required to develop them and how to keep them current.Manual development of SRs has proven costly in terms of time expenditure. In a recent study on length of time needed to conduct SRs of medical interventions, Borah et al8 reported that the mean estimated time to complete an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2022
DA  - 2022-09-30
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://systematicreviewsjournal.biomedcentral.com/counter/pdf/10.1186/s13643-022-02074-4', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Qianying Wang
AU  - Jing Liao
AU  - Mirella Lapata
AU  - Malcolm R. Macleod
ER  - 

360.
TY  - journal-article
ID  - https://openalex.org/W4307635344
DO  - https://doi.org/10.3390/f13111779
TI  - Street Tree Structure, Function, and Value: A Review of Scholarly Research (1997–2020)
AB  - Street trees are components of the urban forest that receive considerable attention across academic and professional disciplines. They are also one of the most common types of urban tree that people routinely encounter. A systematic review methodology was used to examine contemporary urban street tree research across natural and social science disciplines. The records collected (n = 429) were published between January 1997 and the mid-2020s and were coded for descriptive information (e.g., publishing journal and geography of study areas) as well as emergent focal research areas (e.g., ecosystem services, economic valuation, and inventory methods). From this sample, there has been considerable growth in street tree literature over time and across research themes, especially following major turning points in the field of urban forestry. Regulating ecosystem functions/services of street trees, especially cooling, has had the greatest attention in the literature, but other robust areas of research also exist, including the utility of pruning waste as construction materials, the benefits and disservices to human health and safety, and indicators of environmental (in)justice. Opportunities for future research and implications for research and practice are also discussed. small training corpus. Results For PICO sentence classification, BERT models using all pre-trained modules achieved an F1 score of over 80%, and models pre-trained on PubMed abstracts achieved the highest F1 of 85%. For PICO entity recognition, fine-tuning BERT pre-trained on PubMed abstracts achieved an overall F1 of 71% and satisfactory F1 for Species (98%), Strain (70%), Intervention (70%) and Outcome (67%). The score of Induction and Comparator is less satisfactory, but F1 of Comparator can be improved to 50% by applying self-training. Conclusions Our study indicates that of the approaches tested, BERT pre-trained on PubMed abstracts is the best for both PICO sentence classification and PICO entity recognition in the preclinical abstracts. Self-training yields better performance for identifying comparators and strains. Health), SR Accelerator (Institute for Evidence-Based Healthcare), RobotReviewer (RobotReviewer), and COVID-NMA (COVID-NMA). Notably, of the 24 tools, only 10 (42%) support direct search, only 7 (29%) offer dual extraction, and only 13 (54%) offer living/updatable reviews. Conclusions DistillerSR, Nested Knowledge, and EPPI-Reviewer Web each offer a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. of meta-analyses are published yearly.7 The challenges with SRs involve the amount of time required to develop them and how to keep them current.Manual development of SRs has proven costly in terms of time expenditure. In a recent study on length of time needed to conduct SRs of medical interventions, Borah et al8 reported that the mean estimated time to complete an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2022
DA  - 2022-10-27
JO  - {'id': 'https://openalex.org/S71324801', 'issn_l': '1999-4907', 'issn': ['1999-4907'], 'display_name': 'Forests', 'publisher': 'MDPI', 'type': 'journal', 'url': 'https://www.mdpi.com/1999-4907/13/11/1779/pdf?version=1666924530', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Alicia F. Coleman
AU  - Richard W. Harper
AU  - Galina Churkina
AU  - Suzanne H. Warner
AU  - Michael A. Wilkinson
ER  - 

361.
TY  - posted-content
ID  - https://openalex.org/W3023421484
DO  - nan
TI  - Evidence Inference 2.0: More Data, Better Models.
AB  - How do we most effectively treat a disease or condition? Ideally, we could consult a database of evidence gleaned from clinical trials to answer such questions. Unfortunately, no such database exists; clinical trial results are instead disseminated primarily via lengthy natural language articles. Perusing all such articles would be prohibitively time-consuming for healthcare practitioners; they instead tend to depend on manually compiled systematic reviews of medical literature to inform care. 
NLP may speed this process up, and eventually facilitate immediate consult of published evidence. The Evidence Inference dataset was recently released to facilitate research toward this end. This task entails inferring the comparative performance of two treatments, with respect to a given outcome, from a particular article (describing a clinical trial) and identifying supporting evidence. For instance: Does this article report that chemotherapy performed better than surgery for five-year survival rates of operable cancers? In this paper, we collect additional annotations to expand the Evidence Inference dataset by 25\%, provide stronger baseline models, systematically inspect the errors that these make, and probe dataset quality. We also release an abstract only (as opposed to full-texts) version of the task for rapid model prototyping. The updated corpus, documentation, and code for new baselines and evaluations are available at this http URL. PubMed abstracts achieved the highest F1 of 85%. For PICO entity recognition, fine-tuning BERT pre-trained on PubMed abstracts achieved an overall F1 of 71% and satisfactory F1 for Species (98%), Strain (70%), Intervention (70%) and Outcome (67%). The score of Induction and Comparator is less satisfactory, but F1 of Comparator can be improved to 50% by applying self-training. Conclusions Our study indicates that of the approaches tested, BERT pre-trained on PubMed abstracts is the best for both PICO sentence classification and PICO entity recognition in the preclinical abstracts. Self-training yields better performance for identifying comparators and strains. Health), SR Accelerator (Institute for Evidence-Based Healthcare), RobotReviewer (RobotReviewer), and COVID-NMA (COVID-NMA). Notably, of the 24 tools, only 10 (42%) support direct search, only 7 (29%) offer dual extraction, and only 13 (54%) offer living/updatable reviews. Conclusions DistillerSR, Nested Knowledge, and EPPI-Reviewer Web each offer a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. of meta-analyses are published yearly.7 The challenges with SRs involve the amount of time required to develop them and how to keep them current.Manual development of SRs has proven costly in terms of time expenditure. In a recent study on length of time needed to conduct SRs of medical interventions, Borah et al8 reported that the mean estimated time to complete an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2020
DA  - 2020-05-08
JO  - {'id': 'https://openalex.org/V2596401190', 'issn_l': None, 'issn': None, 'display_name': 'arXiv: Computation and Language', 'publisher': None, 'type': 'journal', 'url': 'http://export.arxiv.org/pdf/2005.04177', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Jay DeYoung
AU  - Eric Lehman
AU  - Benjamin E. Nye
AU  - Iain J. Marshall
AU  - Byron C. Wallace
ER  - 

362.
TY  - proceedings-article
ID  - https://openalex.org/W3081749182
DO  - https://doi.org/10.1109/icabcd49160.2020.9183816
TI  - Identifying Recent Telemedicine Research Trends Using a Natural Language Processing Approach
AB  - Conventional literature review processes undertaken by human experts require considerable effort. Automating them is elusive due to subtlety of concepts and complexity of interrelationships implicit in text semantics. However, when assessing topics relating to current trends, these factors are less important as there is inherent breadth and diversity in the text which countermands the need for expertise. This paper presents an approach for trend topic analysis using simple bibliometrics of Term Frequency and Keyword Selection, extracted with natural language processing tools NLTK and AntConc. This approach is applied to a case study of identifying trends in Telemedicine research in South Africa based on 2019 publications included in PubMed. Lists of topics generated by the analysis methods show consistency in identified trends and suggest their suitability to categorise small focussed corpora. report that chemotherapy performed better than surgery for five-year survival rates of operable cancers? In this paper, we collect additional annotations to expand the Evidence Inference dataset by 25\%, provide stronger baseline models, systematically inspect the errors that these make, and probe dataset quality. We also release an abstract only (as opposed to full-texts) version of the task for rapid model prototyping. The updated corpus, documentation, and code for new baselines and evaluations are available at this http URL. PubMed abstracts achieved the highest F1 of 85%. For PICO entity recognition, fine-tuning BERT pre-trained on PubMed abstracts achieved an overall F1 of 71% and satisfactory F1 for Species (98%), Strain (70%), Intervention (70%) and Outcome (67%). The score of Induction and Comparator is less satisfactory, but F1 of Comparator can be improved to 50% by applying self-training. Conclusions Our study indicates that of the approaches tested, BERT pre-trained on PubMed abstracts is the best for both PICO sentence classification and PICO entity recognition in the preclinical abstracts. Self-training yields better performance for identifying comparators and strains. Health), SR Accelerator (Institute for Evidence-Based Healthcare), RobotReviewer (RobotReviewer), and COVID-NMA (COVID-NMA). Notably, of the 24 tools, only 10 (42%) support direct search, only 7 (29%) offer dual extraction, and only 13 (54%) offer living/updatable reviews. Conclusions DistillerSR, Nested Knowledge, and EPPI-Reviewer Web each offer a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. of meta-analyses are published yearly.7 The challenges with SRs involve the amount of time required to develop them and how to keep them current.Manual development of SRs has proven costly in terms of time expenditure. In a recent study on length of time needed to conduct SRs of medical interventions, Borah et al8 reported that the mean estimated time to complete an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2020
DA  - 2020-08-01
JO  - {'id': 'https://openalex.org/S4306419142', 'issn_l': None, 'issn': None, 'display_name': 'International Conference on Artificial Intelligence', 'publisher': None, 'type': 'conference', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Anthony Maeder
AU  - Martyn George
AU  - Bertha Naveda
ER  - 

363.
TY  - posted-content
ID  - https://openalex.org/W3090726544
DO  - https://doi.org/10.1101/2020.09.29.319335
TI  - Using neural networks to mine text and predict metabolic traits for thousands of microbes
AB  - Abstract Microbes can metabolize more chemical compounds than any other group of organisms. As a result, their metabolism is of interest to investigators across biology. Despite the interest, information on metabolism of specific microbes is hard to access. Information is buried in text of books and journals, and investigators have no easy way to extract it out. Here we investigate if neural networks can extract out this information and predict metabolic traits. For proof of concept, we predicted two traits: whether microbes carry one type of metabolism (fermentation) or produce one metabolite (acetate). We collected written descriptions of 7,021 species of bacteria and archaea from Bergey’s Manual. We read the descriptions and manually identified (labeled) which species were fermentative or produced acetate. We then trained neural networks to predict these labels. In total, we identified 2,364 species as fermentative, and 1,009 species as also producing acetate. Neural networks could predict which species were fermentative with 97.3% accuracy. Accuracy was even higher (98.6%) when predicting species also producing acetate. We used these predictions to draw phylogenetic trees of species with these traits. The resulting trees were close to the actual trees (drawn using labels). Previous counts of fermentative species are 4-fold lower than our own. For acetate-producing species, they are 100-fold lower. This undercounting confirms past difficulty in extracting metabolic traits from text. Our approach with neural networks can extract information efficiently and accurately. It paves the way for putting more metabolic traits into databases, providing easy access of information by investigators. Comparator is less satisfactory, but F1 of Comparator can be improved to 50% by applying self-training. Conclusions Our study indicates that of the approaches tested, BERT pre-trained on PubMed abstracts is the best for both PICO sentence classification and PICO entity recognition in the preclinical abstracts. Self-training yields better performance for identifying comparators and strains. Health), SR Accelerator (Institute for Evidence-Based Healthcare), RobotReviewer (RobotReviewer), and COVID-NMA (COVID-NMA). Notably, of the 24 tools, only 10 (42%) support direct search, only 7 (29%) offer dual extraction, and only 13 (54%) offer living/updatable reviews. Conclusions DistillerSR, Nested Knowledge, and EPPI-Reviewer Web each offer a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. of meta-analyses are published yearly.7 The challenges with SRs involve the amount of time required to develop them and how to keep them current.Manual development of SRs has proven costly in terms of time expenditure. In a recent study on length of time needed to conduct SRs of medical interventions, Borah et al8 reported that the mean estimated time to complete an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2020
DA  - 2020-09-30
JO  - {'id': 'https://openalex.org/S2734324842', 'issn_l': None, 'issn': None, 'display_name': 'bioRxiv', 'publisher': None, 'type': 'repository', 'url': 'https://journals.plos.org/ploscompbiol/article/file?id=10.1371/journal.pcbi.1008757&type=printable', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Timothy J. Hackmann
ER  - 

364.
TY  - posted-content
ID  - https://openalex.org/W3092309472
DO  - nan
TI  - Scaling Systematic Literature Reviews with Machine Learning Pipelines.
AB  - Systematic reviews, which entail the extraction of data from large numbers of scientific documents, are an ideal avenue for the application of machine learning. They are vital to many fields of science and philanthropy, but are very time-consuming and require experts. Yet the three main stages of a systematic review are easily done automatically: searching for documents can be done via APIs and scrapers, selection of relevant documents can be done via binary classification, and extraction of data can be done via sequence-labelling classification. Despite the promise of automation for this field, little research exists that examines the various ways to automate each of these tasks. We construct a pipeline that automates each of these aspects, and experiment with many human-time vs. system quality trade-offs. We test the ability of classifiers to work well on small amounts of data and to generalise to data from countries not represented in the training data. We test different types of data extraction with varying difficulty in annotation, and five different neural architectures to do the extraction. We find that we can get surprising accuracy and generalisability of the whole pipeline system with only 2 weeks of human-expert annotation, which is only 15% of the time it takes to do the whole review manually and can be repeated and extended to new data with no additional effort. approach with neural networks can extract information efficiently and accurately. It paves the way for putting more metabolic traits into databases, providing easy access of information by investigators. Comparator is less satisfactory, but F1 of Comparator can be improved to 50% by applying self-training. Conclusions Our study indicates that of the approaches tested, BERT pre-trained on PubMed abstracts is the best for both PICO sentence classification and PICO entity recognition in the preclinical abstracts. Self-training yields better performance for identifying comparators and strains. Health), SR Accelerator (Institute for Evidence-Based Healthcare), RobotReviewer (RobotReviewer), and COVID-NMA (COVID-NMA). Notably, of the 24 tools, only 10 (42%) support direct search, only 7 (29%) offer dual extraction, and only 13 (54%) offer living/updatable reviews. Conclusions DistillerSR, Nested Knowledge, and EPPI-Reviewer Web each offer a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. of meta-analyses are published yearly.7 The challenges with SRs involve the amount of time required to develop them and how to keep them current.Manual development of SRs has proven costly in terms of time expenditure. In a recent study on length of time needed to conduct SRs of medical interventions, Borah et al8 reported that the mean estimated time to complete an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2020
DA  - 2020-10-09
JO  - {'id': 'https://openalex.org/S2596401190', 'issn_l': None, 'issn': None, 'display_name': 'arXiv: Computation and Language', 'publisher': None, 'type': 'journal', 'url': 'https://arxiv.org/pdf/2010.04665.pdf', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Seraphina Goldfarb-Tarrant
AU  - Alexander Robertson
AU  - Jasmina Lazic
AU  - Theodora K. Tsouloufi
AU  - Louise Donnison
AU  - Karen Smyth
ER  - 

365.
TY  - posted-content
ID  - https://openalex.org/W3123718743
DO  - nan
TI  - Unsupervised Key-phrase Extraction and Clustering for Classification Scheme in Scientific Publications
AB  - Several methods have been explored for automating parts of Systematic Mapping (SM) and Systematic Review (SR) methodologies. Challenges typically evolve around the gaps in semantic understanding of text, as well as lack of domain and background knowledge necessary to bridge that gap. In this paper we investigate possible ways of automating parts of the SM/SR process, i.e. that of extracting keywords and key-phrases from scientific documents using unsupervised methods, which are then used as a basis to construct the corresponding Classification Scheme using semantic key-phrase clustering techniques. Specifically, we explore the effect of ensemble scores measure in key-phrase extraction, we explore semantic network based word embedding in embedding representation of phrase semantics and finally we also explore how clustering can be used to group related key-phrases. The evaluation is conducted on a dataset of publications pertaining the domain of Explainable AI which we constructed using standard publicly available digital libraries and sets of indexing terms (keywords). Results shows that: ensemble ranking score does improve the key-phrase extraction performance. Semantic-network based word embedding based on the ConceptNet Semantic Network has similar performance with contextualized word embedding, however the former are computationally more efficient. Finally Semantic key-phrase clustering at term-level can group similar terms together that can be suitable for classification scheme. and can be repeated and extended to new data with no additional effort. approach with neural networks can extract information efficiently and accurately. It paves the way for putting more metabolic traits into databases, providing easy access of information by investigators. Comparator is less satisfactory, but F1 of Comparator can be improved to 50% by applying self-training. Conclusions Our study indicates that of the approaches tested, BERT pre-trained on PubMed abstracts is the best for both PICO sentence classification and PICO entity recognition in the preclinical abstracts. Self-training yields better performance for identifying comparators and strains. Health), SR Accelerator (Institute for Evidence-Based Healthcare), RobotReviewer (RobotReviewer), and COVID-NMA (COVID-NMA). Notably, of the 24 tools, only 10 (42%) support direct search, only 7 (29%) offer dual extraction, and only 13 (54%) offer living/updatable reviews. Conclusions DistillerSR, Nested Knowledge, and EPPI-Reviewer Web each offer a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. of meta-analyses are published yearly.7 The challenges with SRs involve the amount of time required to develop them and how to keep them current.Manual development of SRs has proven costly in terms of time expenditure. In a recent study on length of time needed to conduct SRs of medical interventions, Borah et al8 reported that the mean estimated time to complete an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2021
DA  - 2021-01-25
JO  - {'id': 'https://openalex.org/V2596401190', 'issn_l': None, 'issn': None, 'display_name': 'arXiv: Computation and Language', 'publisher': None, 'type': 'journal', 'url': 'http://export.arxiv.org/pdf/2101.09990', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Xiajing Li
AU  - Marios Daoutis
ER  - 

366.
TY  - journal-article
ID  - https://openalex.org/W3158862932
DO  - https://doi.org/10.1093/jamia/ocab077
TI  - A neuro-symbolic method for understanding free-text medical evidence
AB  - Abstract Objective We introduce Medical evidence Dependency (MD)–informed attention, a novel neuro-symbolic model for understanding free-text clinical trial publications with generalizability and interpretability. Materials and Methods We trained one head in the multi-head self-attention model to attend to the Medical evidence Ddependency (MD) and to pass linguistic and domain knowledge on to later layers (MD informed). This MD-informed attention model was integrated into BioBERT and tested on 2 public machine reading comprehension benchmarks for clinical trial publications: Evidence Inference 2.0 and PubMedQA. We also curated a small set of recently published articles reporting randomized controlled trials on COVID-19 (coronavirus disease 2019) following the Evidence Inference 2.0 guidelines to evaluate the model’s robustness to unseen data. Results The integration of MD-informed attention head improves BioBERT substantially in both benchmark tasks—as large as an increase of +30% in the F1 score—and achieves the new state-of-the-art performance on the Evidence Inference 2.0. It achieves 84% and 82% in overall accuracy and F1 score, respectively, on the unseen COVID-19 data. Conclusions MD-informed attention empowers neural reading comprehension models with interpretability and generalizability via reusable domain knowledge. Its compositionality can benefit any transformer-based architecture for machine reading comprehension of free-text medical evidence. term-level can group similar terms together that can be suitable for classification scheme. and can be repeated and extended to new data with no additional effort. approach with neural networks can extract information efficiently and accurately. It paves the way for putting more metabolic traits into databases, providing easy access of information by investigators. Comparator is less satisfactory, but F1 of Comparator can be improved to 50% by applying self-training. Conclusions Our study indicates that of the approaches tested, BERT pre-trained on PubMed abstracts is the best for both PICO sentence classification and PICO entity recognition in the preclinical abstracts. Self-training yields better performance for identifying comparators and strains. Health), SR Accelerator (Institute for Evidence-Based Healthcare), RobotReviewer (RobotReviewer), and COVID-NMA (COVID-NMA). Notably, of the 24 tools, only 10 (42%) support direct search, only 7 (29%) offer dual extraction, and only 13 (54%) offer living/updatable reviews. Conclusions DistillerSR, Nested Knowledge, and EPPI-Reviewer Web each offer a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. of meta-analyses are published yearly.7 The challenges with SRs involve the amount of time required to develop them and how to keep them current.Manual development of SRs has proven costly in terms of time expenditure. In a recent study on length of time needed to conduct SRs of medical interventions, Borah et al8 reported that the mean estimated time to complete an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2021
DA  - 2021-07-30
JO  - {'id': 'https://openalex.org/S129839026', 'issn_l': '1067-5027', 'issn': ['1067-5027', '1527-974X'], 'display_name': 'Journal of the American Medical Informatics Association', 'publisher': 'Oxford University Press', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Tian Kang
AU  - Ali Turfah
AU  - Jae-Hyun Kim
AU  - Adler J. Perotte
AU  - Chunhua Weng
ER  - 

367.
TY  - journal-article
ID  - https://openalex.org/W3159037398
DO  - nan
TI  - Knowledge Extraction and Prediction from Behavior Science Randomized Controlled Trials: A Case Study in Smoking Cessation.
AB  - Due to the fast pace at which randomized controlled trials are published in the health domain, researchers, consultants and policymakers would benefit from more automatic ways to process them by both extracting relevant information and automating the meta-analysis processes. In this paper, we present a novel methodology based on natural language processing and reasoning models to 1) extract relevant information from RCTs and 2) predict potential outcome values on novel scenarios, given the extracted knowledge, in the domain of behavior change for smoking cessation. curated a small set of recently published articles reporting randomized controlled trials on COVID-19 (coronavirus disease 2019) following the Evidence Inference 2.0 guidelines to evaluate the model’s robustness to unseen data. Results The integration of MD-informed attention head improves BioBERT substantially in both benchmark tasks—as large as an increase of +30% in the F1 score—and achieves the new state-of-the-art performance on the Evidence Inference 2.0. It achieves 84% and 82% in overall accuracy and F1 score, respectively, on the unseen COVID-19 data. Conclusions MD-informed attention empowers neural reading comprehension models with interpretability and generalizability via reusable domain knowledge. Its compositionality can benefit any transformer-based architecture for machine reading comprehension of free-text medical evidence. term-level can group similar terms together that can be suitable for classification scheme. and can be repeated and extended to new data with no additional effort. approach with neural networks can extract information efficiently and accurately. It paves the way for putting more metabolic traits into databases, providing easy access of information by investigators. Comparator is less satisfactory, but F1 of Comparator can be improved to 50% by applying self-training. Conclusions Our study indicates that of the approaches tested, BERT pre-trained on PubMed abstracts is the best for both PICO sentence classification and PICO entity recognition in the preclinical abstracts. Self-training yields better performance for identifying comparators and strains. Health), SR Accelerator (Institute for Evidence-Based Healthcare), RobotReviewer (RobotReviewer), and COVID-NMA (COVID-NMA). Notably, of the 24 tools, only 10 (42%) support direct search, only 7 (29%) offer dual extraction, and only 13 (54%) offer living/updatable reviews. Conclusions DistillerSR, Nested Knowledge, and EPPI-Reviewer Web each offer a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. of meta-analyses are published yearly.7 The challenges with SRs involve the amount of time required to develop them and how to keep them current.Manual development of SRs has proven costly in terms of time expenditure. In a recent study on length of time needed to conduct SRs of medical interventions, Borah et al8 reported that the mean estimated time to complete an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2020
DA  - 2020-01-01
JO  - {'id': 'https://openalex.org/V4306417663', 'issn_l': None, 'issn': None, 'display_name': 'American Medical Informatics Association Annual Symposium', 'publisher': None, 'type': 'conference', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Francesca Bonin
AU  - Martin Gleize
AU  - Yufang Hou
AU  - Debasis Ganguly
AU  - Ailbhe Finnerty
AU  - Charles Jochim
AU  - Alessandra Pascale
AU  - Pierpaolo Tommasi
AU  - Pol Mac Aonghusa
AU  - Susan Michie
ER  - 

368.
TY  - posted-content
ID  - https://openalex.org/W3159696841
DO  - https://doi.org/10.1101/2021.04.29.440076
TI  - Life-histories as determinants of infection prevalence for trypanosomatids: A meta-analysis
AB  - Abstract Trypanosomatids are a diverse family of protozoan parasites, some of which cause devastating human and livestock diseases. There are two distinct infection life-cycles in trypanosomatids; some species complete their entire life-cycle in a single host (monoxenous) while others infect two hosts (dixenous). Dixenous trypanosomatids are mostly vectored by insects, and the human trypanosomatid diseases are transmitted mainly by vectored parasites. While infection prevalence has been described for subsets of hosts and trypanosomatids, little is known about whether monoxenous and dixenous trypanosomatids differ in infection prevalence. Here, we use meta-analyses to synthesise all published evidence of trypanosomatid infection prevalence for the last two decades. We employed a semi-automated screening protocol, using machine learning algorithms and natural language processing, resulting in the qualitative inclusion of 569 citations and quantitative inclusion of 261 citations. We find striking difference in infection prevalence with monoxenous species having twice the infection prevalence (19.8%) than dixenous species (8.68%) in both insect and non-insect hosts and are more than three-fold more prevalent in insects (20.9%) compared to their dixenous kins (6.61%). We also find that dixenous trypanosomatids have lower infection prevalence among insects compared to their definitive hosts, which is consistent across dixenous genera. Within the monoxenous trypanosomatids, genera infecting bees are characterised with the highest prevalence, which does not vary between wild and managed bees. To our knowledge, these results reveal for the first time, a fundamental difference in infection prevalence according to host specificity where vectored species suffer from lower infection prevalence as a result of a ‘jack of all trades, master of none’ style trade-off between the vector and definitive host. Conclusions Our study indicates that of the approaches tested, BERT pre-trained on PubMed abstracts is the best for both PICO sentence classification and PICO entity recognition in the preclinical abstracts. Self-training yields better performance for identifying comparators and strains. Health), SR Accelerator (Institute for Evidence-Based Healthcare), RobotReviewer (RobotReviewer), and COVID-NMA (COVID-NMA). Notably, of the 24 tools, only 10 (42%) support direct search, only 7 (29%) offer dual extraction, and only 13 (54%) offer living/updatable reviews. Conclusions DistillerSR, Nested Knowledge, and EPPI-Reviewer Web each offer a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. of meta-analyses are published yearly.7 The challenges with SRs involve the amount of time required to develop them and how to keep them current.Manual development of SRs has proven costly in terms of time expenditure. In a recent study on length of time needed to conduct SRs of medical interventions, Borah et al8 reported that the mean estimated time to complete an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2021
DA  - 2021-04-30
JO  - {'id': 'https://openalex.org/S2734324842', 'issn_l': None, 'issn': None, 'display_name': 'bioRxiv', 'publisher': None, 'type': 'repository', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Al-Ghafli H
AU  - Seth M. Barribeau
ER  - 

369.
TY  - nan
ID  - https://openalex.org/W3169332062
DO  - nan
TI  - Conducting a Systematic Review: Trends in Machine Learning and Text Mining
AB  - No Abstract Found
PY  - 2020
DA  - 2020-01-01
JO  - {'id': None, 'issn_l': None, 'issn': None, 'display_name': 'XXVI Congreso Argentino de Ciencias de la Computación (CACIC) (Modalidad virtual, 5 al 9 de octubre de 2020)', 'publisher': None, 'type': None, 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Mariana Falco
AU  - Ignacio Berdiñas
ER  - 

370.
TY  - posted-content
ID  - https://openalex.org/W3184381949
DO  - https://doi.org/10.13012/b2idb-4635945_v1
TI  - Dataset for Fifty Ways to Tag your Pubtypes: Multi-Tagger, a Set of Probabilistic Publication Type and Study Design Taggers to Support Biomedical Indexing and Evidence-Based Medicine
AB  - Objective: Indexing articles according to publication types (PTs) and study designs can be a great aid to filtering literature for information retrieval, especially for evidence syntheses. In this study, 50 automated machine learning based probabilistic PT and study design taggers were built and applied to all articles in PubMed. 
Materials and Methods: PubMed article metadata from 1987-2014 were used as training data, with 2015 used for recalibration. The set of articles indexed with a particular study design MeSH term or PT tag was used as positive training sets. For each PT, the rest of the literature from the same time period was used as its negative training set. Multiple features based on each article title, abstract and metadata were used in training the models. Taggers were evaluated on PubMed articles from 2016 and 2019. A manual analysis was also performed. 
Results: Of the 50 predictive models that we created, 44 of these achieved an AUC of ~0.90 or greater, with many having performance above 0.95. Of the clinically related study designs, the best performing was SYSTEMATIC_REVIEW with an AUC of 0.998; the lowest performing was RANDOM_ALLOCATION, with an AUC of 0.823. which 
Discussion: This work demonstrates that is feasible to build a large set of probabilistic publication type and study design taggers with high accuracy and ranking performance. Automated tagging permits users to identify qualifying articles as soon as they are published, and allows consistent criteria to be applied across different bibliographic databases. Probabilistic predictive scores are more flexible than binary yes/no predictions, since thresholds can be tailored for specific uses such as high recall literature search, user-adjustable retrieval size, and quality improvement of manually annotated databases. pre-trained 
Conclusion: The PT predictive probability scores for all PubMed articles are freely downloadable at http://arrowsmith.psych.uic.edu/evidence_based_medicine/mt_download.html for incorporation into user tools and workflows. Users can also perform PubMed queries at our Anne O9Tate value-added PubMed search engine http://arrowsmith.psych.uic.edu/cgi-bin/arrowsmith_uic/AnneOTate.cgi and filter retrieved articles according to both NLM-annotated and model-predicted publication types and study designs. 7 (29%) offer dual extraction, and only 13 (54%) offer living/updatable reviews. Conclusions DistillerSR, Nested Knowledge, and EPPI-Reviewer Web each offer a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. of meta-analyses are published yearly.7 The challenges with SRs involve the amount of time required to develop them and how to keep them current.Manual development of SRs has proven costly in terms of time expenditure. In a recent study on length of time needed to conduct SRs of medical interventions, Borah et al8 reported that the mean estimated time to complete an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2021
DA  - 2021-07-16
JO  - {'id': 'https://openalex.org/V3005729997', 'issn_l': None, 'issn': None, 'display_name': 'medRxiv', 'publisher': None, 'type': 'journal', 'url': 'https://medrxiv.org/content/10.1101/2021.07.13.21260468v1.full.pdf', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Yuanxi Fu
AU  - Jodi Schneider
ER  - 

371.
TY  - book-chapter
ID  - https://openalex.org/W3185932187
DO  - https://doi.org/10.1007/978-3-030-71881-7_12
TI  - Machine Learning in Evidence Synthesis Research
AB  - No Abstract Found
PY  - 2021
DA  - 2021-01-01
JO  - {'id': 'https://openalex.org/V4306463941', 'issn_l': None, 'issn': None, 'display_name': 'Springer International Publishing eBooks', 'publisher': 'Springer Nature', 'type': 'ebook platform', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Alonso Carrasco-Labra
AU  - Olivia Urquhart
AU  - Heiko Spallek
ER  - 

372.
TY  - book-chapter
ID  - https://openalex.org/W3190720226
DO  - https://doi.org/10.1007/978-3-030-58080-3_43-1
TI  - Artificial Intelligence in Evidence-Based Medicine
AB  - No Abstract Found
PY  - 2021
DA  - 2021-01-01
JO  - {'id': 'https://openalex.org/S4306463941', 'issn_l': None, 'issn': None, 'display_name': 'Springer International Publishing eBooks', 'publisher': 'Springer Nature', 'type': 'ebook platform', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Artur Nowak
ER  - 

373.
TY  - posted-content
ID  - https://openalex.org/W3196741167
DO  - nan
TI  - TAR on Social Media: A Framework for Online Content Moderation.
AB  - Content moderation (removing or limiting the distribution of posts based on their contents) is one tool social networks use to fight problems such as harassment and disinformation. Manually screening all content is usually impractical given the scale of social media data, and the need for nuanced human interpretations makes fully automated approaches infeasible. We consider content moderation from the perspective of technology-assisted review (TAR): a human-in-the-loop active learning approach developed for high recall retrieval problems in civil litigation and other fields. We show how TAR workflows, and a TAR cost model, can be adapted to the content moderation problem. We then demonstrate on two publicly available content moderation data sets that a TAR workflow can reduce moderation costs by 20% to 55% across a variety of conditions. on PubMed articles from 2016 and 2019. A manual analysis was also performed. 
Results: Of the 50 predictive models that we created, 44 of these achieved an AUC of ~0.90 or greater, with many having performance above 0.95. Of the clinically related study designs, the best performing was SYSTEMATIC_REVIEW with an AUC of 0.998; the lowest performing was RANDOM_ALLOCATION, with an AUC of 0.823. which 
Discussion: This work demonstrates that is feasible to build a large set of probabilistic publication type and study design taggers with high accuracy and ranking performance. Automated tagging permits users to identify qualifying articles as soon as they are published, and allows consistent criteria to be applied across different bibliographic databases. Probabilistic predictive scores are more flexible than binary yes/no predictions, since thresholds can be tailored for specific uses such as high recall literature search, user-adjustable retrieval size, and quality improvement of manually annotated databases. pre-trained 
Conclusion: The PT predictive probability scores for all PubMed articles are freely downloadable at http://arrowsmith.psych.uic.edu/evidence_based_medicine/mt_download.html for incorporation into user tools and workflows. Users can also perform PubMed queries at our Anne O9Tate value-added PubMed search engine http://arrowsmith.psych.uic.edu/cgi-bin/arrowsmith_uic/AnneOTate.cgi and filter retrieved articles according to both NLM-annotated and model-predicted publication types and study designs. 7 (29%) offer dual extraction, and only 13 (54%) offer living/updatable reviews. Conclusions DistillerSR, Nested Knowledge, and EPPI-Reviewer Web each offer a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. of meta-analyses are published yearly.7 The challenges with SRs involve the amount of time required to develop them and how to keep them current.Manual development of SRs has proven costly in terms of time expenditure. In a recent study on length of time needed to conduct SRs of medical interventions, Borah et al8 reported that the mean estimated time to complete an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2021
DA  - 2021-08-29
JO  - {'id': 'https://openalex.org/V2597136632', 'issn_l': None, 'issn': None, 'display_name': 'arXiv: Information Retrieval', 'publisher': None, 'type': 'journal', 'url': 'https://arxiv.org/pdf/2108.12752.pdf', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Eugene Yang
AU  - David A. Lewis
AU  - Ophir Frieder
ER  - 

374.
TY  - proceedings-article
ID  - https://openalex.org/W3198005027
DO  - https://doi.org/10.18653/v1/2021.findings-emnlp.147
TI  - Sent2Span: Span Detection for PICO Extraction in the Biomedical Text without Span Annotations
AB  - The rapid growth in published clinical trials makes it difficult to maintain up-to-date systematic reviews, which requires finding all relevant trials. This leads to policy and practice decisions based on out-of-date, incomplete, and biased subsets of available clinical evidence. Extracting and then normalising Population, Intervention, Comparator, and Outcome (PICO) information from clinical trial articles may be an effective way to automatically assign trials to systematic reviews and avoid searching and screening - the two most time-consuming systematic review processes. We propose and test a novel approach to PICO span detection. The major difference between our proposed method and previous approaches comes from detecting spans without needing annotated span data and using only crowdsourced sentence-level annotations. Experiments on two datasets show that PICO span detection results achieve much higher results for recall when compared to fully supervised methods with PICO sentence detection at least as good as human annotations. By removing the reliance on expert annotations for span detection, this work could be used in human-machine pipeline for turning low-quality crowdsourced, and sentence-level PICO annotations into structured information that can be used to quickly assign trials to relevant systematic reviews. of 0.823. which 
Discussion: This work demonstrates that is feasible to build a large set of probabilistic publication type and study design taggers with high accuracy and ranking performance. Automated tagging permits users to identify qualifying articles as soon as they are published, and allows consistent criteria to be applied across different bibliographic databases. Probabilistic predictive scores are more flexible than binary yes/no predictions, since thresholds can be tailored for specific uses such as high recall literature search, user-adjustable retrieval size, and quality improvement of manually annotated databases. pre-trained 
Conclusion: The PT predictive probability scores for all PubMed articles are freely downloadable at http://arrowsmith.psych.uic.edu/evidence_based_medicine/mt_download.html for incorporation into user tools and workflows. Users can also perform PubMed queries at our Anne O9Tate value-added PubMed search engine http://arrowsmith.psych.uic.edu/cgi-bin/arrowsmith_uic/AnneOTate.cgi and filter retrieved articles according to both NLM-annotated and model-predicted publication types and study designs. 7 (29%) offer dual extraction, and only 13 (54%) offer living/updatable reviews. Conclusions DistillerSR, Nested Knowledge, and EPPI-Reviewer Web each offer a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. of meta-analyses are published yearly.7 The challenges with SRs involve the amount of time required to develop them and how to keep them current.Manual development of SRs has proven costly in terms of time expenditure. In a recent study on length of time needed to conduct SRs of medical interventions, Borah et al8 reported that the mean estimated time to complete an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2021
DA  - 2021-01-01
JO  - {'id': 'https://openalex.org/S2596401190', 'issn_l': None, 'issn': None, 'display_name': 'arXiv: Computation and Language', 'publisher': None, 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Shifeng Liu
AU  - Yifang Sun
AU  - Bing Li
AU  - Wei Wang
AU  - Florence T. Bourgeois
AU  - Adam G. Dunn
ER  - 

375.
TY  - journal-article
ID  - https://openalex.org/W3200271358
DO  - https://doi.org/10.3389/fpubh.2021.763828
TI  - Evidence Integration in the Era of Information Flooding—The Advent of the Comprehensive Review
AB  - No Abstract Found
PY  - 2021
DA  - 2021-09-09
JO  - {'id': 'https://openalex.org/V2595931848', 'issn_l': '2296-2565', 'issn': ['2296-2565'], 'display_name': 'Frontiers in Public Health', 'publisher': 'Frontiers Media', 'type': 'journal', 'url': 'https://www.frontiersin.org/articles/10.3389/fpubh.2021.763828/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Thomas Hartung
ER  - 

376.
TY  - proceedings-article
ID  - https://openalex.org/W3212062532
DO  - nan
TI  - MS\^2: Multi-Document Summarization of Medical Studies.
AB  - To assess the effectiveness of any medical intervention, researchers must conduct a time-intensive and manual literature review. NLP systems can help to automate or assist in parts of this expensive process. In support of this goal, we release MSˆ2 (Multi-Document Summarization of Medical Studies), a dataset of over 470k documents and 20K summaries derived from the scientific literature. This dataset facilitates the development of systems that can assess and aggregate contradictory evidence across multiple studies, and is the first large-scale, publicly available multi-document summarization dataset in the biomedical domain. We experiment with a summarization system based on BART, with promising early results, though significant work remains to achieve higher summarization quality. We formulate our summarization inputs and targets in both free text and structured forms and modify a recently proposed metric to assess the quality of our system’s generated summaries. Data and models are available at https://github.com/allenai/ms2. annotations. By removing the reliance on expert annotations for span detection, this work could be used in human-machine pipeline for turning low-quality crowdsourced, and sentence-level PICO annotations into structured information that can be used to quickly assign trials to relevant systematic reviews. of 0.823. which 
Discussion: This work demonstrates that is feasible to build a large set of probabilistic publication type and study design taggers with high accuracy and ranking performance. Automated tagging permits users to identify qualifying articles as soon as they are published, and allows consistent criteria to be applied across different bibliographic databases. Probabilistic predictive scores are more flexible than binary yes/no predictions, since thresholds can be tailored for specific uses such as high recall literature search, user-adjustable retrieval size, and quality improvement of manually annotated databases. pre-trained 
Conclusion: The PT predictive probability scores for all PubMed articles are freely downloadable at http://arrowsmith.psych.uic.edu/evidence_based_medicine/mt_download.html for incorporation into user tools and workflows. Users can also perform PubMed queries at our Anne O9Tate value-added PubMed search engine http://arrowsmith.psych.uic.edu/cgi-bin/arrowsmith_uic/AnneOTate.cgi and filter retrieved articles according to both NLM-annotated and model-predicted publication types and study designs. 7 (29%) offer dual extraction, and only 13 (54%) offer living/updatable reviews. Conclusions DistillerSR, Nested Knowledge, and EPPI-Reviewer Web each offer a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. of meta-analyses are published yearly.7 The challenges with SRs involve the amount of time required to develop them and how to keep them current.Manual development of SRs has proven costly in terms of time expenditure. In a recent study on length of time needed to conduct SRs of medical interventions, Borah et al8 reported that the mean estimated time to complete an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2021
DA  - 2021-11-01
JO  - {'id': 'https://openalex.org/S4306418267', 'issn_l': None, 'issn': None, 'display_name': 'Empirical Methods in Natural Language Processing', 'publisher': None, 'type': 'conference', 'url': 'https://arxiv.org/pdf/2104.06486', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Jay DeYoung
AU  - Iz Beltagy
AU  - Madeleine van Zuylen
AU  - Bailey Kuehl
AU  - Lucy Lu Wang
ER  - 

377.
TY  - posted-content
ID  - https://openalex.org/W3212218981
DO  - https://doi.org/10.48550/arxiv.2109.02254
TI  - Sent2Span: Span Detection for PICO Extraction in the Biomedical Text
  without Span Annotations
AB  - The rapid growth in published clinical trials makes it difficult to maintain up-to-date systematic reviews, which requires finding all relevant trials. This leads to policy and practice decisions based on out-of-date, incomplete, and biased subsets of available clinical evidence. Extracting and then normalising Population, Intervention, Comparator, and Outcome (PICO) information from clinical trial articles may be an effective way to automatically assign trials to systematic reviews and avoid searching and screening - the two most time-consuming systematic review processes. We propose and test a novel approach to PICO span detection. The major difference between our proposed method and previous approaches comes from detecting spans without needing annotated span data and using only crowdsourced sentence-level annotations. Experiments on two datasets show that PICO span detection results achieve much higher results for recall when compared to fully supervised methods with PICO sentence detection at least as good as human annotations. By removing the reliance on expert annotations for span detection, this work could be used in human-machine pipeline for turning low-quality crowdsourced, and sentence-level PICO annotations into structured information that can be used to quickly assign trials to relevant systematic reviews. of 0.823. which 
Discussion: This work demonstrates that is feasible to build a large set of probabilistic publication type and study design taggers with high accuracy and ranking performance. Automated tagging permits users to identify qualifying articles as soon as they are published, and allows consistent criteria to be applied across different bibliographic databases. Probabilistic predictive scores are more flexible than binary yes/no predictions, since thresholds can be tailored for specific uses such as high recall literature search, user-adjustable retrieval size, and quality improvement of manually annotated databases. pre-trained 
Conclusion: The PT predictive probability scores for all PubMed articles are freely downloadable at http://arrowsmith.psych.uic.edu/evidence_based_medicine/mt_download.html for incorporation into user tools and workflows. Users can also perform PubMed queries at our Anne O9Tate value-added PubMed search engine http://arrowsmith.psych.uic.edu/cgi-bin/arrowsmith_uic/AnneOTate.cgi and filter retrieved articles according to both NLM-annotated and model-predicted publication types and study designs. 7 (29%) offer dual extraction, and only 13 (54%) offer living/updatable reviews. Conclusions DistillerSR, Nested Knowledge, and EPPI-Reviewer Web each offer a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. of meta-analyses are published yearly.7 The challenges with SRs involve the amount of time required to develop them and how to keep them current.Manual development of SRs has proven costly in terms of time expenditure. In a recent study on length of time needed to conduct SRs of medical interventions, Borah et al8 reported that the mean estimated time to complete an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2021
DA  - 2021-11-01
JO  - {'id': 'https://openalex.org/S4306400194', 'issn_l': None, 'issn': None, 'display_name': 'arXiv (Cornell University)', 'publisher': 'Cornell University', 'type': 'repository', 'url': 'http://arxiv.org/pdf/2109.02254', 'is_oa': True, 'version': 'submittedVersion', 'license': None}
DP  - OpenAlex
AU  - Shifeng Liu
AU  - Yifang Sun
AU  - Bing Li
AU  - Wei Wang
AU  - Florence T. Bourgeois
AU  - Adam G. Dunn
ER  - 

378.
TY  - book-chapter
ID  - https://openalex.org/W3215531002
DO  - https://doi.org/10.1007/978-3-030-90966-6_9
TI  - Automation in Healthcare Systematic Review
AB  - Systematic reviews are an essential tool to help healthcare providers and medical practitioners stay up to date on the latest evidence and practices within their field. In recent years, developments have arisen in automating these systematic reviews. While automated systematic reviews are not currently in widespread use in the medical field, they present a way to increase the output of systematic reviews. This study is a literature review of how the automating of systematic reviews is currently being integrated into the healthcare system. This literature review will be relying on tools such as Web of Science, Harzing’s Publish or Perish, VOSviewer, CiteSpace, and MAXQDA to collect and analyze article data sets based on keywords “automating systematic reviews” and “healthcare systematic reviews”. Co-citation and content analyses were performed on data sets to determine which articles were most relevant. These analyses showed that automating systematic reviews is developing more within fields outside of the medical field. However, researchers are beginning to take an interest in the applications of an automated systematic review to use in the medical field. The healthcare sector has been more hesitant to adopt automation and often continues to rely on traditional methods. Automation technology is quickly advancing but currently lacks the ability to apply critical thinking of how literature is relevant to current practice, more easily understood by clinician experience, attitudes, and values. articles as soon as they are published, and allows consistent criteria to be applied across different bibliographic databases. Probabilistic predictive scores are more flexible than binary yes/no predictions, since thresholds can be tailored for specific uses such as high recall literature search, user-adjustable retrieval size, and quality improvement of manually annotated databases. pre-trained 
Conclusion: The PT predictive probability scores for all PubMed articles are freely downloadable at http://arrowsmith.psych.uic.edu/evidence_based_medicine/mt_download.html for incorporation into user tools and workflows. Users can also perform PubMed queries at our Anne O9Tate value-added PubMed search engine http://arrowsmith.psych.uic.edu/cgi-bin/arrowsmith_uic/AnneOTate.cgi and filter retrieved articles according to both NLM-annotated and model-predicted publication types and study designs. 7 (29%) offer dual extraction, and only 13 (54%) offer living/updatable reviews. Conclusions DistillerSR, Nested Knowledge, and EPPI-Reviewer Web each offer a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. of meta-analyses are published yearly.7 The challenges with SRs involve the amount of time required to develop them and how to keep them current.Manual development of SRs has proven costly in terms of time expenditure. In a recent study on length of time needed to conduct SRs of medical interventions, Borah et al8 reported that the mean estimated time to complete an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2021
DA  - 2021-07-24
JO  - {'id': 'https://openalex.org/S106296714', 'issn_l': '0302-9743', 'issn': ['1611-3349', '0302-9743'], 'display_name': 'Lecture Notes in Computer Science', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Raquel Sánchez Ruiz
AU  - Vincent G. Duffy
ER  - 

379.
TY  - journal-article
ID  - https://openalex.org/W4200056480
DO  - https://doi.org/10.1016/j.jbi.2021.103970
TI  - Extracting experimental parameter entities from scientific articles
AB  - Systematic reviews are labor-intensive processes to combine all knowledge about a given topic into a coherent summary. Despite the high labor investment, they are necessary to create an exhaustive overview of current evidence relevant to a research question. In this work, we evaluate three state-of-the-art supervised multi-label sequence classification systems to automatically identify 24 different experimental design factors for the categories of Animal, Dose, Exposure, and Endpoint from journal articles describing the experiments related to toxicity and health effects of environmental agents. We then present an in depth analysis of the results evaluating the lexical diversity of the design parameters with respect to model performance, evaluating the impact of tokenization and non-contiguous mentions, and finally evaluating the dependencies between entities within the category entities. We demonstrate that in general, algorithms that use embedded representations of the sequences out-perform statistical algorithms, but that even these algorithms struggle with lexically diverse entities. of the medical field. However, researchers are beginning to take an interest in the applications of an automated systematic review to use in the medical field. The healthcare sector has been more hesitant to adopt automation and often continues to rely on traditional methods. Automation technology is quickly advancing but currently lacks the ability to apply critical thinking of how literature is relevant to current practice, more easily understood by clinician experience, attitudes, and values. articles as soon as they are published, and allows consistent criteria to be applied across different bibliographic databases. Probabilistic predictive scores are more flexible than binary yes/no predictions, since thresholds can be tailored for specific uses such as high recall literature search, user-adjustable retrieval size, and quality improvement of manually annotated databases. pre-trained 
Conclusion: The PT predictive probability scores for all PubMed articles are freely downloadable at http://arrowsmith.psych.uic.edu/evidence_based_medicine/mt_download.html for incorporation into user tools and workflows. Users can also perform PubMed queries at our Anne O9Tate value-added PubMed search engine http://arrowsmith.psych.uic.edu/cgi-bin/arrowsmith_uic/AnneOTate.cgi and filter retrieved articles according to both NLM-annotated and model-predicted publication types and study designs. 7 (29%) offer dual extraction, and only 13 (54%) offer living/updatable reviews. Conclusions DistillerSR, Nested Knowledge, and EPPI-Reviewer Web each offer a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. of meta-analyses are published yearly.7 The challenges with SRs involve the amount of time required to develop them and how to keep them current.Manual development of SRs has proven costly in terms of time expenditure. In a recent study on length of time needed to conduct SRs of medical interventions, Borah et al8 reported that the mean estimated time to complete an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2021
DA  - 2021-12-01
JO  - {'id': 'https://openalex.org/S11622463', 'issn_l': '1532-0464', 'issn': ['1532-0480', '1532-0464'], 'display_name': 'Journal of Biomedical Informatics', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Steele Farnsworth
AU  - Gabrielle Gurdin
AU  - Jorge A Vargas
AU  - Andriy Mulyar
AU  - Nastassja Lewinski
AU  - Bridget T. McInnes
ER  - 

380.
TY  - journal-article
ID  - https://openalex.org/W4210317074
DO  - https://doi.org/10.1080/08827508.2021.2023520
TI  - International Trends in Mining Tailings Research through Machine Learning Method: Retrospective or Prospective Oriented Research?
AB  - No Abstract Found
PY  - 2022
DA  - 2022-01-18
JO  - {'id': 'https://openalex.org/S146233897', 'issn_l': '0882-7508', 'issn': ['0882-7508', '1547-7401'], 'display_name': 'Mineral Processing and Extractive Metallurgy Review', 'publisher': 'Taylor & Francis', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Fernando Campos-Medina
AU  - Iván Ojeda-Pereira
AU  - Joaquín Quiroz
AU  - Joao Guzmán
ER  - 

381.
TY  - book-chapter
ID  - https://openalex.org/W4210345665
DO  - https://doi.org/10.1007/978-3-030-93715-7_22
TI  - Designing Workflow for Improving Literature Review Process Based on Co-citation Networks
AB  - AbstractLiterature reviews are essential parts of every academic paper, and there are many tools, which are trying to suggest relevant articles and make the process of working with citations easier. Many of them offer to focus on just specific recommended papers or provide a general picture of the area without explanations or hints on how particular papers can help. Co-citation networks serve as a foundation of multiple useful methods for citation recommendations, enabling the analysis of the structure of the scientific field. However, existing instruments using them have a steep learning curve. In this paper, we present the workflow prototype to elicit and evaluate a set of heuristics employing co-citation network analysis in the literature review process. We performed a step-by-step analysis, including analysis of bibliographic data visualization service VOSviewer patterns of use, which allowed us to synthesize Job Stories for the specification of possible user needs for citation recommendation. We produced a set of heuristics for the analysis of co-citation networks based on Job Stories. The heuristics are then evaluated on the set of papers from two Human-Computer Interaction conferences to reflect on their applicability and usability. Our results can be used to inform more straightforward navigation through co-citation networks, possible design improvements of services for literature management and bibliographic data visualization, as well as a foundation for learning designs for enhancing academic writing skills.KeywordsCo-citation networksBibliometricsLiterature searchHuman-computer interaction they are published, and allows consistent criteria to be applied across different bibliographic databases. Probabilistic predictive scores are more flexible than binary yes/no predictions, since thresholds can be tailored for specific uses such as high recall literature search, user-adjustable retrieval size, and quality improvement of manually annotated databases. pre-trained 
Conclusion: The PT predictive probability scores for all PubMed articles are freely downloadable at http://arrowsmith.psych.uic.edu/evidence_based_medicine/mt_download.html for incorporation into user tools and workflows. Users can also perform PubMed queries at our Anne O9Tate value-added PubMed search engine http://arrowsmith.psych.uic.edu/cgi-bin/arrowsmith_uic/AnneOTate.cgi and filter retrieved articles according to both NLM-annotated and model-predicted publication types and study designs. 7 (29%) offer dual extraction, and only 13 (54%) offer living/updatable reviews. Conclusions DistillerSR, Nested Knowledge, and EPPI-Reviewer Web each offer a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. of meta-analyses are published yearly.7 The challenges with SRs involve the amount of time required to develop them and how to keep them current.Manual development of SRs has proven costly in terms of time expenditure. In a recent study on length of time needed to conduct SRs of medical interventions, Borah et al8 reported that the mean estimated time to complete an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2022
DA  - 2022-01-01
JO  - {'id': 'https://openalex.org/V2764900261', 'issn_l': '1865-0929', 'issn': ['1865-0937', '1865-0929'], 'display_name': 'Communications in computer and information science', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Anastasiya Kuznetsova
ER  - 

382.
TY  - journal-article
ID  - https://openalex.org/W4211093622
DO  - https://doi.org/10.5195/jmla.2022.1236
TI  - Artificial intelligence behind the scenes: PubMed’s Best Match algorithm
AB  - This article focuses on PubMed's Best Match sorting algorithm, presenting a simplified explanation of how it operates and highlighting how artificial intelligence affects search results in ways that are not seen by users. We further discuss user search behaviors and the ethical implications of algorithms, specifically for health care practitioners. PubMed recently began using artificial intelligence to improve the sorting of search results using a Best Match option. In 2020, PubMed deployed this algorithm as the default search method, necessitating serious discussion around the ethics of this and similar algorithms, as users do not always know when an algorithm uses artificial intelligence, what artificial intelligence is, and how it may impact their everyday tasks. These implications resonate strongly in health care, in which the speed and relevancy of search results is crucial but does not negate the importance of a lack of bias in how those search results are selected or presented to the user. As a health care provider will not often venture past the first few results in search of a clinical decision, will Best Match help them find the answers they need more quickly? Or will the algorithm bias their results, leading to the potential suppression of more recent or relevant results? services for literature management and bibliographic data visualization, as well as a foundation for learning designs for enhancing academic writing skills.KeywordsCo-citation networksBibliometricsLiterature searchHuman-computer interaction they are published, and allows consistent criteria to be applied across different bibliographic databases. Probabilistic predictive scores are more flexible than binary yes/no predictions, since thresholds can be tailored for specific uses such as high recall literature search, user-adjustable retrieval size, and quality improvement of manually annotated databases. pre-trained 
Conclusion: The PT predictive probability scores for all PubMed articles are freely downloadable at http://arrowsmith.psych.uic.edu/evidence_based_medicine/mt_download.html for incorporation into user tools and workflows. Users can also perform PubMed queries at our Anne O9Tate value-added PubMed search engine http://arrowsmith.psych.uic.edu/cgi-bin/arrowsmith_uic/AnneOTate.cgi and filter retrieved articles according to both NLM-annotated and model-predicted publication types and study designs. 7 (29%) offer dual extraction, and only 13 (54%) offer living/updatable reviews. Conclusions DistillerSR, Nested Knowledge, and EPPI-Reviewer Web each offer a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. of meta-analyses are published yearly.7 The challenges with SRs involve the amount of time required to develop them and how to keep them current.Manual development of SRs has proven costly in terms of time expenditure. In a recent study on length of time needed to conduct SRs of medical interventions, Borah et al8 reported that the mean estimated time to complete an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2022
DA  - 2022-02-11
JO  - {'id': 'https://openalex.org/S146304353', 'issn_l': '1536-5050', 'issn': ['1536-5050', '1558-9439'], 'display_name': 'Journal of The Medical Library Association', 'publisher': 'University Library System, University of Pittsburgh', 'type': 'journal', 'url': 'https://jmla.pitt.edu/ojs/jmla/article/download/1236/1991', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Lucy Kiester
AU  - Clara Turp
ER  - 

383.
TY  - posted-content
ID  - https://openalex.org/W4213285645
DO  - https://doi.org/10.2196/preprints.33124
TI  - Toward Automated Data Extraction: A Pilot Survey of the Structure of Tabular Data in Clinical Comparative Literature (Preprint)
AB  - <sec> <title>BACKGROUND</title> Systematic reviews depend on time-consuming extraction of data from PDFs of underlying studies. To date, automation efforts have focused on extracting from the text, and no approach has yet succeeded in fully automating ingestion of quantitative evidence. However, the majority of relevant data is generally presented in tables, and tabular structure is more amenable to automated extraction than free-text. </sec> <sec> <title>OBJECTIVE</title> The purpose of this survey is to classify the structure and format of descriptive statistics reported in tables in the comparative medical literature. </sec> <sec> <title>METHODS</title> We sampled 100 published randomized controlled trials (RCTs) from the year 2019 from PubMed; these results were imported to the AutoLit platform. Studies were excluded if they were non-clinical, non-comparative, not in English, protocol-only, or not available in full text. In AutoLit, tables reporting baseline or outcome data in all studies were characterized based on reporting practices. Measurement context, meaning the structure in which the interventions of interest, patient arm breakdown, measurement timepoints, and data element descriptions were presented, was classified based on the number of contextual pieces and metadata reported. Then, the statistic formats for reported metrics (specific instances of reporting of data elements) were classified by location and broken down into reporting strategies for continuous, dichotomous, and categorical metrics. </sec> <sec> <title>RESULTS</title> We included 78 of 100 studies, one of which (1.3%) did not report data elements in tables. The remaining 77 studies reported baseline and outcome data in 174 tables, and 97% of these tables broke down reporting by patient arms. Fifteen structures were found for the reporting of measurement context, which were broadly grouped into: 1x1 Contexts, where two pieces of context are reported total (e.g. “arms in columns, data elements in rows); 2x1 Contexts, where two pieces of context are given on row headers (e.g. timepoints in columns, arms nested in data elements on rows); 1x2 Contexts, where two pieces of context are given on column headers. 1x1 contexts were present in 57% of tables, compared to 20% for 2x1 and 15% for 1x2 (8% used unique/other stratification). Statistic formats were reported in the headers or descriptions of 84% of studies. </sec> <sec> <title>CONCLUSIONS</title> In this pilot survey, we found a high density of information in tables, but with major heterogeneity in presentation of measurement context. The highest-density studies reported both baseline and outcome measures in tables, with arm-level breakout, intervention labels and arm sizes present, and reported both the statistic formats and units. The measurement context formats presented here, broadly classified into three classes that cover 92% of studies, form a basis for understanding the frequency of different reporting styles, supporting automated detection of data format for extraction of metrics. </sec> the mean estimated time to complete an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2021
DA  - 2021-08-24
JO  - {'id': None, 'issn_l': None, 'issn': None, 'display_name': None, 'publisher': None, 'type': None, 'url': 'https://doi.org/10.2196/preprints.33124', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Kevin M. Kallmes
AU  - Nicole Hardy
AU  - Kevin M. Kallmes
ER  - 

384.
TY  - journal-article
ID  - https://openalex.org/W4213373191
DO  - https://doi.org/10.1111/ecog.06068
TI  - Automated synthesis of biodiversity knowledge requires better tools and standardised research output
AB  - As the impact of anthropogenic activity on the environment has grown, research into biodiversity change and associated threats has also accelerated. Synthesising this vast literature is important for understanding the drivers of biodiversity change and identifying those actions that will mitigate further ecological losses. However, keeping pace with an ever-increasing publication rate presents a substantial challenge to efficient syntheses, an issue which could be partly addressed by increasing levels of automation in the synthesis pipeline. Here, we evaluate the potential for automated tools to extract ecologically important information from the abstracts of articles compiled in the Living Planet Database. Specifically, we focused on extracting key information on taxonomy (studied species names), geographic location and estimated population trend, assessing the accuracy of automated versus manual information extraction, the potential for automated tools to introduce biases into syntheses, and evaluating if synthesising abstracts was enough to capture the key information from the full article. Taxonomic and geographic extraction tools performed reasonably well, although information on studied species was sometimes limited in the abstract (compared to the main text) preventing fast extraction. In contrast, extraction of trends was less successful, highlighting the challenges involved in automating information extraction from abstracts, such as deficiencies in the algorithms, linguistic complexity associated with ecological findings, and limited information when compared to the main text. In light of these results, we cautiously advocate for a wider use of automated taxonomic and geographic parsing tools for ecological synthesis. Additionally, to further the use of automated synthesis within ecology, we recommend a dual approach: development of improved computational tools to reduce biases; and enhanced protocols for abstracts (and associated metadata) to ensure key information is included in a format that facilitates machine-readability. data elements in rows); 2x1 Contexts, where two pieces of context are given on row headers (e.g. timepoints in columns, arms nested in data elements on rows); 1x2 Contexts, where two pieces of context are given on column headers. 1x1 contexts were present in 57% of tables, compared to 20% for 2x1 and 15% for 1x2 (8% used unique/other stratification). Statistic formats were reported in the headers or descriptions of 84% of studies. </sec> <sec> <title>CONCLUSIONS</title> In this pilot survey, we found a high density of information in tables, but with major heterogeneity in presentation of measurement context. The highest-density studies reported both baseline and outcome measures in tables, with arm-level breakout, intervention labels and arm sizes present, and reported both the statistic formats and units. The measurement context formats presented here, broadly classified into three classes that cover 92% of studies, form a basis for understanding the frequency of different reporting styles, supporting automated detection of data format for extraction of metrics. </sec> the mean estimated time to complete an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2022
DA  - 2022-02-18
JO  - {'id': 'https://openalex.org/S25093289', 'issn_l': '0906-7590', 'issn': ['0906-7590', '1600-0587'], 'display_name': 'Ecography', 'publisher': 'Wiley-Blackwell', 'type': 'journal', 'url': 'https://doi.org/10.1111/ecog.06068', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Richard Cornford
AU  - Joseph W. Millard
AU  - Manuela González-Suárez
AU  - Robin Freeman
AU  - Thomas E. Johnson
ER  - 

385.
TY  - book-chapter
ID  - https://openalex.org/W4213379757
DO  - https://doi.org/10.1007/978-3-030-64573-1_43
TI  - Artificial Intelligence in Evidence-Based Medicine
AB  - No Abstract Found
PY  - 2022
DA  - 2022-01-01
JO  - {'id': 'https://openalex.org/S4306463941', 'issn_l': None, 'issn': None, 'display_name': 'Springer International Publishing eBooks', 'publisher': 'Springer Nature', 'type': 'ebook platform', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Artur Nowak
ER  - 

386.
TY  - posted-content
ID  - https://openalex.org/W4214599167
DO  - https://doi.org/10.2196/preprints.34575
TI  - Digital learning tools for postgraduate family medicine training: Protocol for a scoping review using natural language processing (Preprint)
AB  - <sec> <title>BACKGROUND</title> Introduction The COVID-19 pandemic has highlighted the growing need for digital learning tools in postgraduate family medicine training. Family medicine departments must understand and recognize the use and effectiveness of digital tools in order to integrate them into curricula and develop effective learning tools that fill gaps and meet the learning needs of trainees. </sec> <sec> <title>OBJECTIVE</title> This scoping review will aim to explore and organize the breadth of knowledge regarding digital learning tools in family medicine training. </sec> <sec> <title>METHODS</title> This scoping review will follow the methodological framework outlined by Arksey and O’Malley, including a search of published academic literature in six databases (MEDLINE, ERIC, Education Source, Embase, Scopus, and Web of Science) and grey literature. Following title/abstract, and full text screening, characteristics and main findings of the included studies and resources will be tabulated and summarized. Thematic analysis and natural language processing will be conducted to identify common themes and synthesize the literature. Additionally, natural language processing (NLP) will be employed for bibliometric and scientometric analysis of the identified literature. </sec> <sec> <title>RESULTS</title> The search strategy has been developed and launched. Data extraction is currently underway. </sec> <sec> <title>CONCLUSIONS</title> In this scoping review, we will identify and consolidate information and evidence related to the use and effectiveness of existing digital learning tools in postgraduate family medicine training. Our findings will improve the understanding of the current landscape of digital learning tools, which will be of great value to educators and trainees interested in using existing tools, to innovators looking to design digital learning tools that meet current needs, and to researchers involved in the study of digital tools. </sec> key information is included in a format that facilitates machine-readability. data elements in rows); 2x1 Contexts, where two pieces of context are given on row headers (e.g. timepoints in columns, arms nested in data elements on rows); 1x2 Contexts, where two pieces of context are given on column headers. 1x1 contexts were present in 57% of tables, compared to 20% for 2x1 and 15% for 1x2 (8% used unique/other stratification). Statistic formats were reported in the headers or descriptions of 84% of studies. </sec> <sec> <title>CONCLUSIONS</title> In this pilot survey, we found a high density of information in tables, but with major heterogeneity in presentation of measurement context. The highest-density studies reported both baseline and outcome measures in tables, with arm-level breakout, intervention labels and arm sizes present, and reported both the statistic formats and units. The measurement context formats presented here, broadly classified into three classes that cover 92% of studies, form a basis for understanding the frequency of different reporting styles, supporting automated detection of data format for extraction of metrics. </sec> the mean estimated time to complete an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2021
DA  - 2021-10-29
JO  - {'id': None, 'issn_l': None, 'issn': None, 'display_name': None, 'publisher': None, 'type': None, 'url': 'https://doi.org/10.2196/preprints.34575', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Hui Yan
AU  - Arya Rahgozar
AU  - Claire Sethuram
AU  - Sathya Karunananathan
AU  - Douglas Archibald
AU  - Lindsay Bradley
AU  - Ramtin Hakimjavadi
AU  - Mary Helmer-Smith
AU  - Kheira Jolin-Dahel
AU  - Tess McCutcheon
AU  - Jeffrey Puncher
AU  - Parisa Rezaiefar
AU  - Lina Shoppoff
AU  - Clare Liddy
ER  - 

387.
TY  - journal-article
ID  - https://openalex.org/W4214835971
DO  - https://doi.org/10.4103/idoj.idoj_264_21
TI  - Comparison of artificial intelligence with a conventional search in dermatology: A case study of systematic review of apremilast in hidradenitis suppurativa performed by both methods
AB  - No Abstract Found
PY  - 2022
DA  - 2022-01-01
JO  - {'id': 'https://openalex.org/S2754097677', 'issn_l': '2229-5178', 'issn': ['2229-5178', '2249-5673'], 'display_name': 'Indian Dermatology Online Journal', 'publisher': 'Medknow', 'type': 'journal', 'url': 'https://doi.org/10.4103/idoj.idoj_264_21', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc-sa'}
DP  - OpenAlex
AU  - Deepak Jakhar
AU  - Subuhi Kaul
AU  - Subhav Sinha
ER  - 

388.
TY  - journal-article
ID  - https://openalex.org/W4220860813
DO  - https://doi.org/10.1016/j.heliyon.2022.e09095
TI  - Assessing author willingness to enter study information into structured data templates as part of the manuscript submission process: A pilot study
AB  - Environmental health and other researchers can benefit from automated or semi-automated summaries of data within published studies as summarizing study methods and results is time and resource intensive. Automated summaries can be designed to identify and extract details of interest pertaining to the study design, population, testing agent/intervention, or outcome (etc.). Much of the data reported across existing publications lack unified structure, standardization and machine-readable formats or may be presented in complex tables which serve as barriers that impede the development of automated data extraction methodologies.As full automation of data extraction seems unlikely soon, encouraging investigators to submit structured summaries of methods and results in standardized formats with meta-data tagging of content may be of value during the publication process. This would produce machine-readable content to facilitate automated data extraction, establish sharable data repositories, help make research data FAIR, and could improve reporting quality.A pilot study was conducted to assess the feasibility of asking participants to summarize study methods and results using a structured, web-based data extraction model as a potential workflow that could be implemented during the manuscript submission process.Eight participants entered study details and data into the Health Assessment Workplace Collaborative (HAWC). Participants were surveyed after the extraction exercise to ascertain 1) whether this extraction exercise will impact their conducting and reporting of future research, 2) the ease of data extraction, including which fields were easiest and relatively more problematic to extract and 3) the amount of time taken to perform data extractions and other related tasks. Investigators then presented participants the potential benefits of providing structured data in the format they were extracting. After this, participants were surveyed about 1) their willingness to provide structured data during the publication process and 2) whether they felt the potential application of structured data entry approaches and their implementation during the journal submission process should continue to be further explored.Routine provision of structured data that summarizes key information from research studies could reduce the amount of effort required for reusing that data in the future, such as in systematic reviews or agency scientific assessments. Our pilot study suggests that directly asking authors to provide that data, via structured templates, may be a viable approach to achieving this: participants were willing to do so, and the overall process was not prohibitively arduous. We also found some support for the hypothesis that use of study templates may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken. an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2022
DA  - 2022-03-01
JO  - {'id': 'https://openalex.org/S2898612692', 'issn_l': '2405-8440', 'issn': ['2405-8440'], 'display_name': 'Heliyon', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'http://www.cell.com/article/S2405844022003838/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc-nd'}
DP  - OpenAlex
AU  - A. Amina Wilkins
AU  - Amanda S. Persad
AU  - Ingrid L. Druwe
AU  - Janice C. Lee
AU  - Paul Whaley
AU  - M. Taylor
AU  - Andrew A. Shapiro
AU  - Natalie Blanton
AU  - Courtney Lemeris
AU  - Kristina A. Thayer
ER  - 

389.
TY  - journal-article
ID  - https://openalex.org/W4221116448
DO  - https://doi.org/10.1016/j.jclinepi.2022.03.019
TI  - Crowdsourcing trainees in a living systematic review provided valuable experiential learning opportunities: a mixed-methods study
AB  - <h2>Abstract</h2><h3>Objectives</h3> To understand trainee experiences of participating in a living systematic review (LSR) for rheumatoid arthritis and the potential benefits in terms of experiential evidence-based medicine (EBM) education. <h3>Study Design and Setting</h3> We conducted a mixed-methods study with trainees who participated in the LSR and who were recruited broadly from training programs in two countries. Trainees received task-specific training and completed one or more tasks in the review: assessing article eligibility, data extraction, and quality assessment. Trainees completed a survey followed by a one-on-one interview. Data were triangulated to produce broad themes. <h3>Results</h3> Twenty one trainees, most of whom had a little prior experience with systematic reviews, reported a positive overall experience. Key benefits included learning opportunities, task segmentation (ability to focus on a single task, as opposed to an entire review), working in a supportive environment, international collaboration, and incentives such as authorship or acknowledgment. Trainees reported improvement in their competency as a Scholar, Collaborator, Leader, and Medical Expert. Challenges included communication and technical difficulties and appropriate matching of tasks to trainee skillsets. <h3>Conclusion</h3> Participating in an LSR provided benefits to a wide range of trainees and may provide an opportunity for experiential EBM training, while helping LSR sustainability. exercise to ascertain 1) whether this extraction exercise will impact their conducting and reporting of future research, 2) the ease of data extraction, including which fields were easiest and relatively more problematic to extract and 3) the amount of time taken to perform data extractions and other related tasks. Investigators then presented participants the potential benefits of providing structured data in the format they were extracting. After this, participants were surveyed about 1) their willingness to provide structured data during the publication process and 2) whether they felt the potential application of structured data entry approaches and their implementation during the journal submission process should continue to be further explored.Routine provision of structured data that summarizes key information from research studies could reduce the amount of effort required for reusing that data in the future, such as in systematic reviews or agency scientific assessments. Our pilot study suggests that directly asking authors to provide that data, via structured templates, may be a viable approach to achieving this: participants were willing to do so, and the overall process was not prohibitively arduous. We also found some support for the hypothesis that use of study templates may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken. an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2022
DA  - 2022-03-01
JO  - {'id': 'https://openalex.org/S64418186', 'issn_l': '0895-4356', 'issn': ['1878-5921', '0895-4356'], 'display_name': 'Journal of Clinical Epidemiology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Chloe H. Lee
AU  - Megan C. Thomas
AU  - None Ejaredar
AU  - Aliya Kassam
AU  - Samuel L Whittle
AU  - Rachelle Buchbinder
AU  - Peter Tugwell
AU  - George A. Wells
AU  - Jordi Pardo Pardo
AU  - Glen Hazlewood
ER  - 

390.
TY  - journal-article
ID  - https://openalex.org/W4225326828
DO  - https://doi.org/10.2196/34575
TI  - Natural Language Processing to Identify Digital Learning Tools in Postgraduate Family Medicine: Protocol for a Scoping Review
AB  - Background The COVID-19 pandemic has highlighted the growing need for digital learning tools in postgraduate family medicine training. Family medicine departments must understand and recognize the use and effectiveness of digital tools in order to integrate them into curricula and develop effective learning tools that fill gaps and meet the learning needs of trainees. Objective This scoping review will aim to explore and organize the breadth of knowledge regarding digital learning tools in family medicine training. Methods This scoping review follows the 6 stages of the methodological framework outlined first by Arksey and O’Malley, then refined by Levac et al, including a search of published academic literature in 6 databases (MEDLINE, ERIC, Education Source, Embase, Scopus, and Web of Science) and gray literature. Following title and abstract and full text screening, characteristics and main findings of the included studies and resources will be tabulated and summarized. Thematic analysis and natural language processing (NLP) will be conducted in parallel using a 9-step approach to identify common themes and synthesize the literature. Additionally, NLP will be employed for bibliometric and scientometric analysis of the identified literature. Results The search strategy has been developed and launched. As of October 2021, we have completed stages 1, 2, and 3 of the scoping review. We identified 132 studies for inclusion through the academic literature search and 127 relevant studies in the gray literature search. Further refinement of the eligibility criteria and data extraction has been ongoing since September 2021. Conclusions In this scoping review, we will identify and consolidate information and evidence related to the use and effectiveness of existing digital learning tools in postgraduate family medicine training. Our findings will improve the understanding of the current landscape of digital learning tools, which will be of great value to educators and trainees interested in using existing tools, innovators looking to design digital learning tools that meet current needs, and researchers involved in the study of digital tools. Trial Registration OSF Registries osf.io/wju4k; https://osf.io/wju4k International Registered Report Identifier (IRRID) DERR1-10.2196/34575 future, such as in systematic reviews or agency scientific assessments. Our pilot study suggests that directly asking authors to provide that data, via structured templates, may be a viable approach to achieving this: participants were willing to do so, and the overall process was not prohibitively arduous. We also found some support for the hypothesis that use of study templates may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken. an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2022
DA  - 2022-05-02
JO  - {'id': 'https://openalex.org/S2739058702', 'issn_l': '1929-0748', 'issn': ['1929-0748'], 'display_name': 'JMIR Research Protocols', 'publisher': 'JMIR Publications', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Hui Yan
AU  - Arya Rahgozar
AU  - Claire Sethuram
AU  - Sathya Karunananthan
AU  - Douglas Archibald
AU  - Lindsay Bradley
AU  - Ramtin Hakimjavadi
AU  - Mary Helmer-Smith
AU  - Kheira Jolin-Dahel
AU  - Tess McCutcheon
AU  - Jeffrey Puncher
AU  - Parisa Rezaiefar
AU  - Lina Shoppoff
AU  - Clare Liddy
ER  - 

391.
TY  - posted-content
ID  - https://openalex.org/W4240818803
DO  - https://doi.org/10.2196/preprints.33219
TI  - Software Tools for Systematic Literature Review in Medicine: A Review and Feature Analysis (Preprint)
AB  - <sec> <title>BACKGROUND</title> Systematic reviews (SRs) are central to evaluating therapies but have high costs in terms of both time and money. Many software tools exist to assist with SRs, but most tools do not support the full process, and transparency and replicability of SR depends on performing and presenting evidence according to established best practices. </sec> <sec> <title>OBJECTIVE</title> In order to provide a basis for comparing and selecting between software tools that support SR, we performed a feature-by-feature comparison of SR tools. </sec> <sec> <title>METHODS</title> We searched for SR tools by reviewing any such tool listed the Systematic Review Toolbox, previous reviews of SR tools, and qualitative Google searching. We included all SR tools that were currently functional, and require no coding and excluded reference managers, desktop applications, and statistical software. The list of features to assess was populated by combining all features assessed in four previous reviews of SR tools; we also added five features (Manual Addition, Screening Automation, Dual Extraction, Living review, Public outputs) that were independently noted as best practices or enhancements of transparency/replicability. Then, two reviewers assigned binary “present/absent” assessments to all SR tools with respect to all features, and a third reviewer adjudicated all disagreements. </sec> <sec> <title>RESULTS</title> Of 49 SR tools found, 27 were excluded, leaving 22 for assessment. Twenty-eight features were assessed across 6 classes, and the inter-observer agreement was 86.46%. DistillerSR, EPPI-Reviewer Web, and Nested Knowledge support the most features (24/28, 86%), followed by Covidence, SRDB.PRO, SysRev (20/28, 71%). Six tools support fewer than half of all features assessed: SyRF, Data Abstraction Assistant, SWIFT-review, SR-Accelerator, RobotReviewer, and COVID-NMA. Notably, only 9 of 22 tools (41%) support direct search, only four (18%) offer dual extraction, and only 9 (41%) offer living/updatable reviews. </sec> <sec> <title>CONCLUSIONS</title> DistillerSR, EPPI-Reviewer Web, and Nested Knowledge each offer a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. </sec> scientific assessments. Our pilot study suggests that directly asking authors to provide that data, via structured templates, may be a viable approach to achieving this: participants were willing to do so, and the overall process was not prohibitively arduous. We also found some support for the hypothesis that use of study templates may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken. an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2021
DA  - 2021-08-28
JO  - {'id': None, 'issn_l': None, 'issn': None, 'display_name': None, 'publisher': None, 'type': None, 'url': 'https://doi.org/10.2196/preprints.33219', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Kathryn Cowie
AU  - Asad Rahmatullah
AU  - Nicole Hardy
AU  - Kevin M. Kallmes
AU  - Kevin M. Kallmes
ER  - 

392.
TY  - posted-content
ID  - https://openalex.org/W4240826740
DO  - https://doi.org/10.2196/preprints.30582
TI  - Pediatric Chronic Critical Illness: Protocol for a Scoping Review (Preprint)
AB  - <sec> <title>BACKGROUND</title> Improvements in the delivery of intensive care have increased survival among even the most critically ill children, thereby leading to a growing number of children with chronic complex medical conditions in the pediatric intensive care unit (PICU). Some of these children are at a significant risk of recurrent and prolonged critical illness, with higher morbidity and mortality, making them a unique population described as having chronic critical illness (CCI). To date, pediatric CCI has been understudied and lacks an accepted consensus case definition. </sec> <sec> <title>OBJECTIVE</title> This study aims to describe the protocol and methodology used to perform a scoping review that will describe how pediatric CCI has been defined in the literature, including the concept of prolonged PICU admission and the methodologies used to develop any existing definitions. It also aims to describe patient characteristics and outcomes evaluated in the included studies. </sec> <sec> <title>METHODS</title> We will search four electronic databases for studies that evaluated children admitted to any PICU identified with CCI. We will also search for studies describing prolonged PICU admission, as this concept is related to pediatric CCI. Furthermore, we will develop a hybrid crowdsourcing and machine learning (ML) methodology to complete citation screening. Screening and data abstraction will be performed by 2 reviewers independently and in duplicate. Data abstraction will include the details of population definitions, demographic and clinical characteristics of children with CCI, and evaluated outcomes. </sec> <sec> <title>RESULTS</title> The database search, crowd reviewer recruitment, and ML algorithm development began in March 2021. Citation screening and data abstraction were completed in April 2021. Final data verification is ongoing, with analysis and results anticipated to be completed by fall 2021. </sec> <sec> <title>CONCLUSIONS</title> This scoping review will describe the existing or suggested definitions of pediatric CCI and important demographic and clinical characteristics of patients to whom these definitions have been applied. This review’s results will help inform the development of a consensus case definition for pediatric CCI and set a priority agenda for future research. We will use and demonstrate the validity of crowdsourcing and ML methodologies for improving the efficiency of large scoping reviews. </sec> <sec> <title>CLINICALTRIAL</title> <p /> </sec> <sec> <title>INTERNATIONAL REGISTERED REPORT</title> DERR1-10.2196/30582 </sec> to achieving this: participants were willing to do so, and the overall process was not prohibitively arduous. We also found some support for the hypothesis that use of study templates may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken. an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2021
DA  - 2021-05-27
JO  - {'id': None, 'issn_l': None, 'issn': None, 'display_name': None, 'publisher': None, 'type': None, 'url': 'https://doi.org/10.2196/preprints.30582', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - David J. Zorko
AU  - James G. McNally
AU  - Deborah J. Cook
AU  - Neethi Pinto
AU  - Rachel Couban
AU  - Katie O’Hearn
AU  - Karen Choong
ER  - 

393.
TY  - journal-article
ID  - https://openalex.org/W4281612100
DO  - https://doi.org/10.3389/fpsyg.2022.899430
TI  - To Have the Best Interest at Heart: Analyzing the Match Between Laypersons’ Interests and Publication Activity in Psychology
AB  - There is a growing public interest in science and, by extension, in psychology, and human behavior. Yet, detailed investigations on whether academic psychological research activity matches lay interests are still scarce. In addition, while lay-friendly communication of research findings becomes continually more important, it is unclear which subfields of psychological research are particularly interesting to laypeople. To address these research gaps, we carried out an explorative study of psychological literature included in two large reference databases, one with a German ( PSYNDEX ) and one with an international ( PsycInfo ) scope. The years of 2018–2020 were scanned for articles belonging to one of 20 topic areas assessed as most interesting by lay participants in a previous study. We determined and compared the share of empirical research and research syntheses for each topic area and database and computed rank correlations between lay interest and academic publication volume. Results suggest a positive relationship between lay interest and academic publication activity specifically for research syntheses. Additionally, topic areas associated with clinical psychology offered a large share of research syntheses, while other topic areas such as “Psychodynamics” or “Industrial &amp;amp; Organizational Psychology” encompassed a smaller share of syntheses. Finally, we outline perspectives for long-term monitoring of psychology-related lay interests. Thus, the present study connects academic activity with the public interest in psychology by identifying and quantifying research syntheses for topics garnering the most lay interest. evaluated outcomes. </sec> <sec> <title>RESULTS</title> The database search, crowd reviewer recruitment, and ML algorithm development began in March 2021. Citation screening and data abstraction were completed in April 2021. Final data verification is ongoing, with analysis and results anticipated to be completed by fall 2021. </sec> <sec> <title>CONCLUSIONS</title> This scoping review will describe the existing or suggested definitions of pediatric CCI and important demographic and clinical characteristics of patients to whom these definitions have been applied. This review’s results will help inform the development of a consensus case definition for pediatric CCI and set a priority agenda for future research. We will use and demonstrate the validity of crowdsourcing and ML methodologies for improving the efficiency of large scoping reviews. </sec> <sec> <title>CLINICALTRIAL</title> <p /> </sec> <sec> <title>INTERNATIONAL REGISTERED REPORT</title> DERR1-10.2196/30582 </sec> to achieving this: participants were willing to do so, and the overall process was not prohibitively arduous. We also found some support for the hypothesis that use of study templates may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken. an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2022
DA  - 2022-06-02
JO  - {'id': 'https://openalex.org/S9692511', 'issn_l': '1664-1078', 'issn': ['1664-1078'], 'display_name': 'Frontiers in Psychology', 'publisher': 'Frontiers Media', 'type': 'journal', 'url': 'https://www.frontiersin.org/articles/10.3389/fpsyg.2022.899430/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Mark E. Jonas
AU  - André Bittermann
AU  - Anita Chasiotis
AU  - Tom Rosman
ER  - 

394.
TY  - journal-article
ID  - https://openalex.org/W4281625986
DO  - https://doi.org/10.1200/cci.21.00129
TI  - Machine Learning Approach to Facilitate Knowledge Synthesis at the Intersection of Liver Cancer, Epidemiology, and Health Disparities Research
AB  - PURPOSE Liver cancer is a global challenge, and disparities exist across multiple domains and throughout the disease continuum. However, liver cancer's global epidemiology and etiology are shifting, and the literature is rapidly evolving, presenting a challenge to the synthesis of knowledge needed to identify areas of research needs and to develop research agendas focusing on disparities. Machine learning (ML) techniques can be used to semiautomate the literature review process and improve efficiency. In this study, we detail our approach and provide practical benchmarks for the development of a ML approach to classify literature and extract data at the intersection of three fields: liver cancer, health disparities, and epidemiology. METHODS We performed a six-phase process including: training (I), validating (II), confirming (III), and performing error analysis (IV) for a ML classifier. We then developed an extraction model (V) and applied it (VI) to the liver cancer literature identified through PubMed. We present precision, recall, F1, and accuracy metrics for the classifier and extraction models as appropriate for each phase of the process. We also provide the results for the application of our extraction model. RESULTS With limited training data, we achieved a high degree of accuracy for both our classifier and for the extraction model for liver cancer disparities research literature performed using epidemiologic methods. The disparities concept was the most challenging to accurately classify, and concepts that appeared infrequently in our data set were the most difficult to extract. CONCLUSION We provide a roadmap for using ML to classify and extract comprehensive information on multidisciplinary literature. Our technique can be adapted and modified for other cancers or diseases where disparities persist. to be completed by fall 2021. </sec> <sec> <title>CONCLUSIONS</title> This scoping review will describe the existing or suggested definitions of pediatric CCI and important demographic and clinical characteristics of patients to whom these definitions have been applied. This review’s results will help inform the development of a consensus case definition for pediatric CCI and set a priority agenda for future research. We will use and demonstrate the validity of crowdsourcing and ML methodologies for improving the efficiency of large scoping reviews. </sec> <sec> <title>CLINICALTRIAL</title> <p /> </sec> <sec> <title>INTERNATIONAL REGISTERED REPORT</title> DERR1-10.2196/30582 </sec> to achieving this: participants were willing to do so, and the overall process was not prohibitively arduous. We also found some support for the hypothesis that use of study templates may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken. an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2022
DA  - 2022-05-01
JO  - {'id': 'https://openalex.org/S4210181501', 'issn_l': '2473-4276', 'issn': ['2473-4276'], 'display_name': 'JCO clinical cancer informatics', 'publisher': 'American Society of Clinical Oncology', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Travis Hyams
AU  - Ling Luo
AU  - Brionna Hair
AU  - Sanghyuk Lee
AU  - Zhiyong Lu
AU  - Daniela Seminara
ER  - 

395.
TY  - proceedings-article
ID  - https://openalex.org/W4283367682
DO  - https://doi.org/10.1109/icapai55158.2022.9801564
TI  - The application of artificial intelligence on different types of literature reviews - A comparative study
AB  - The growing number of published academic literature poses challenges to the research community which struggles to keep up with the vast amount of publications through traditional research methods that are highly manual in nature. Researchers are struggling to determine the most relevant research gaps, yielding insignificant publications that constitute a waste of resources. As a consequence, AI applications are being applied increasingly to automate and facilitate the review process of these vast amounts of papers. However, scholars have so far only addressed a limited number of scientific fields and focused their efforts on one end of the spectrum in automating systematic literature reviews (SLRs). Yet, these are not sufficient to cover the full range of research questions and available data sources. This paper offers a comparative study of systematic and semi-systematic literature reviews to determine the potential of AI applications in both types of literature review processes. The analysis addresses the status quo and discusses apparent limitations of AI to automate reviews. Results are synthesized in proposing a new tool integrating various AI applications along the research process that improve the speed, quality, and cost-efficiency of the overall research process. a high degree of accuracy for both our classifier and for the extraction model for liver cancer disparities research literature performed using epidemiologic methods. The disparities concept was the most challenging to accurately classify, and concepts that appeared infrequently in our data set were the most difficult to extract. CONCLUSION We provide a roadmap for using ML to classify and extract comprehensive information on multidisciplinary literature. Our technique can be adapted and modified for other cancers or diseases where disparities persist. to be completed by fall 2021. </sec> <sec> <title>CONCLUSIONS</title> This scoping review will describe the existing or suggested definitions of pediatric CCI and important demographic and clinical characteristics of patients to whom these definitions have been applied. This review’s results will help inform the development of a consensus case definition for pediatric CCI and set a priority agenda for future research. We will use and demonstrate the validity of crowdsourcing and ML methodologies for improving the efficiency of large scoping reviews. </sec> <sec> <title>CLINICALTRIAL</title> <p /> </sec> <sec> <title>INTERNATIONAL REGISTERED REPORT</title> DERR1-10.2196/30582 </sec> to achieving this: participants were willing to do so, and the overall process was not prohibitively arduous. We also found some support for the hypothesis that use of study templates may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken. an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2022
DA  - 2022-05-05
JO  - {'id': None, 'issn_l': None, 'issn': None, 'display_name': '2022 International Conference on Applied Artificial Intelligence (ICAPAI)', 'publisher': None, 'type': None, 'url': 'https://doi.org/10.1109/icapai55158.2022.9801564', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Henry R. Muller
AU  - Simran Pachnanda
AU  - Felix Hendrik Pahl
AU  - Christopher Rosenqvist
ER  - 

396.
TY  - journal-article
ID  - https://openalex.org/W4285098583
DO  - https://doi.org/10.1136/bmjopen-2021-058405
TI  - Mapping the evidence on identity processes and identity-related interventions in the smoking and physical activity domains: a scoping review protocol
AB  - Smoking and insufficient physical activity (PA), independently but especially in conjunction, often lead to disease and (premature) death. For this reason, there is need for effective smoking cessation and PA-increasing interventions. Identity-related interventions which aim to influence how people view themselves offer promising prospects, but an overview of the existing evidence is needed first. This is the protocol for a scoping review aiming to aggregate the evidence on identity processes and identity-related interventions in the smoking and physical activity domains.The scoping review will be guided by an adaption by Levac et al of the 2005 Arksey and O'Malley methodological framework, the 2020 Preferred Reporting Items for Systematic Reviews and Meta-Analyses: Extension for Scoping Review (PRISMA-ScR) and the 2017 Joanna Briggs Institute guidelines. It will include scientific publications discussing identity (processes) and/or identity-related interventions in the context of smoking (cessation) and/or physical (in)activity, in individuals aged 12 and over. A systematic search will be carried out in multiple databases (eg, PubMed, Web of Science). Records will be independently screened against prepiloted inclusion/exclusion criteria by two reviewers, using the Active Learning for Systematic Reviews machine learning artificial intelligence and Rayyan QCRI, a screening assistant. A prepiloted charting table will be used to extract data from included full-text articles. Findings will be reported according to the PRISMA-ScR guidelines and include study quality assessment.Ethical approval is not required for scoping reviews. Findings will aid the development of future identity-related interventions targeting smoking and physical inactivity. provide a roadmap for using ML to classify and extract comprehensive information on multidisciplinary literature. Our technique can be adapted and modified for other cancers or diseases where disparities persist. to be completed by fall 2021. </sec> <sec> <title>CONCLUSIONS</title> This scoping review will describe the existing or suggested definitions of pediatric CCI and important demographic and clinical characteristics of patients to whom these definitions have been applied. This review’s results will help inform the development of a consensus case definition for pediatric CCI and set a priority agenda for future research. We will use and demonstrate the validity of crowdsourcing and ML methodologies for improving the efficiency of large scoping reviews. </sec> <sec> <title>CLINICALTRIAL</title> <p /> </sec> <sec> <title>INTERNATIONAL REGISTERED REPORT</title> DERR1-10.2196/30582 </sec> to achieving this: participants were willing to do so, and the overall process was not prohibitively arduous. We also found some support for the hypothesis that use of study templates may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken. an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2022
DA  - 2022-07-01
JO  - {'id': 'https://openalex.org/S79054089', 'issn_l': '2044-6055', 'issn': ['2044-6055'], 'display_name': 'BMJ Open', 'publisher': 'BMJ', 'type': 'journal', 'url': 'https://bmjopen.bmj.com/content/bmjopen/12/7/e058405.full.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc'}
DP  - OpenAlex
AU  - Kristell M Penfornis
AU  - Milon H M Van Vliet
AU  - Eline Meijer
AU  - Winifred A. Gebhardt
ER  - 

397.
TY  - journal-article
ID  - https://openalex.org/W4287412700
DO  - nan
TI  - Outcome Prediction from Behaviour Change Intervention Evaluations using a Combination of Node and Word Embedding.
AB  - Findings from randomized controlled trials (RCTs) of behaviour change interventions encode much of our knowledge on intervention efficacy under defined conditions. Predicting outcomes of novel interventions in novel conditions can be challenging, as can predicting differences in outcomes between different interventions or different conditions. To predict outcomes from RCTs, we propose a generic framework of combining the information from two sources - i) the instances (comprised of surrounding text and their numeric values) of relevant attributes, namely the intervention, setting and population characteristics of a study, and ii) abstract representation of the categories of these attributes themselves. We demonstrate that this way of encoding both the information about an attribute and its value when used as an embedding layer within a standard deep sequence modeling setup improves the outcome prediction effectiveness. identity-related interventions in the context of smoking (cessation) and/or physical (in)activity, in individuals aged 12 and over. A systematic search will be carried out in multiple databases (eg, PubMed, Web of Science). Records will be independently screened against prepiloted inclusion/exclusion criteria by two reviewers, using the Active Learning for Systematic Reviews machine learning artificial intelligence and Rayyan QCRI, a screening assistant. A prepiloted charting table will be used to extract data from included full-text articles. Findings will be reported according to the PRISMA-ScR guidelines and include study quality assessment.Ethical approval is not required for scoping reviews. Findings will aid the development of future identity-related interventions targeting smoking and physical inactivity. provide a roadmap for using ML to classify and extract comprehensive information on multidisciplinary literature. Our technique can be adapted and modified for other cancers or diseases where disparities persist. to be completed by fall 2021. </sec> <sec> <title>CONCLUSIONS</title> This scoping review will describe the existing or suggested definitions of pediatric CCI and important demographic and clinical characteristics of patients to whom these definitions have been applied. This review’s results will help inform the development of a consensus case definition for pediatric CCI and set a priority agenda for future research. We will use and demonstrate the validity of crowdsourcing and ML methodologies for improving the efficiency of large scoping reviews. </sec> <sec> <title>CLINICALTRIAL</title> <p /> </sec> <sec> <title>INTERNATIONAL REGISTERED REPORT</title> DERR1-10.2196/30582 </sec> to achieving this: participants were willing to do so, and the overall process was not prohibitively arduous. We also found some support for the hypothesis that use of study templates may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken. an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2021
DA  - 2021-01-01
JO  - {'id': None, 'issn_l': None, 'issn': None, 'display_name': 'AMIA ... Annual Symposium proceedings. AMIA Symposium', 'publisher': None, 'type': None, 'url': 'https://pubmed.ncbi.nlm.nih.gov/35308987/', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Debasis Ganguly
AU  - Martin Gleize
AU  - Yufang Hou
AU  - Charles Jochim
AU  - Francesca Bonin
AU  - Alessandra Pascale
AU  - Pierpaolo Tommasi
AU  - Pol Mac Aonghusa
AU  - Robert West
AU  - Marie Johnston
AU  - Michael Kelly
AU  - Susan Michie
ER  - 

398.
TY  - journal-article
ID  - https://openalex.org/W4293216978
DO  - https://doi.org/10.1016/j.jbi.2022.104185
TI  - Improvement of intervention information detection for automated clinical literature screening during systematic review
AB  - Systematic literature review (SLR) is a crucial method for clinicians and policymakers to make their decisions in a flood of new clinical studies. Because manual literature screening in SLR is a highly laborious task, its automation by natural language processing (NLP) has been welcomed. Although intervention is a key information for literature screening, NLP models for its detection in previous works have not shown adequate performance. In this work, we first design an algorithm for automated construction of high-quality intervention labels by utilizing information retrieved from a clinical trial database. We then design another algorithm for improving model's recall and F1 score by imposing adaptive weights on training instances in the loss function. The intervention detection model trained on the weighted datasets is tested with the Evidence-Based Medicine NLP (EBM-NLP) corpus, and shows 9.7% and 4.0% improvements respectively in recall and F1 score compared to the previous state-of-the-art model on the corpus. The proposed algorithms can boost automation of literature screening during SLR in the clinical domain. screened against prepiloted inclusion/exclusion criteria by two reviewers, using the Active Learning for Systematic Reviews machine learning artificial intelligence and Rayyan QCRI, a screening assistant. A prepiloted charting table will be used to extract data from included full-text articles. Findings will be reported according to the PRISMA-ScR guidelines and include study quality assessment.Ethical approval is not required for scoping reviews. Findings will aid the development of future identity-related interventions targeting smoking and physical inactivity. provide a roadmap for using ML to classify and extract comprehensive information on multidisciplinary literature. Our technique can be adapted and modified for other cancers or diseases where disparities persist. to be completed by fall 2021. </sec> <sec> <title>CONCLUSIONS</title> This scoping review will describe the existing or suggested definitions of pediatric CCI and important demographic and clinical characteristics of patients to whom these definitions have been applied. This review’s results will help inform the development of a consensus case definition for pediatric CCI and set a priority agenda for future research. We will use and demonstrate the validity of crowdsourcing and ML methodologies for improving the efficiency of large scoping reviews. </sec> <sec> <title>CLINICALTRIAL</title> <p /> </sec> <sec> <title>INTERNATIONAL REGISTERED REPORT</title> DERR1-10.2196/30582 </sec> to achieving this: participants were willing to do so, and the overall process was not prohibitively arduous. We also found some support for the hypothesis that use of study templates may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken. an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2022
DA  - 2022-08-01
JO  - {'id': 'https://openalex.org/S11622463', 'issn_l': '1532-0464', 'issn': ['1532-0480', '1532-0464'], 'display_name': 'Journal of Biomedical Informatics', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'https://doi.org/10.1016/j.jbi.2022.104185', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc-nd'}
DP  - OpenAlex
AU  - Tadashi Tsubota
AU  - Danushka Bollegala
AU  - Yang Zhao
AU  - Yingzi Jin
AU  - Tomotake Kozu
ER  - 

399.
TY  - journal-article
ID  - https://openalex.org/W4296546700
DO  - https://doi.org/10.12688/f1000research.125198.1
TI  - (Semi)automated approaches to data extraction for systematic reviews and meta-analyses in social sciences: A living review protocol
AB  - <ns3:p><ns3:bold>Background</ns3:bold>: An abundance of rapidly accumulating scientific evidence presents novel opportunities for researchers and practitioners alike, yet such advantages are often overshadowed by resource demands associated with finding and aggregating a continually expanding body of scientific information. Across social science disciplines, the use of automation technologies for timely and accurate knowledge synthesis can enhance research translation value, better inform key policy development, and expand the current understanding of human interactions, organizations, and systems. Ongoing developments surrounding automation are highly concentrated in research for evidence-based medicine with limited evidence surrounding tools and techniques applied outside of the clinical research community. Our objective is to conduct a living systematic review of automated data extraction techniques supporting systematic reviews and meta-analyses in the social sciences. The aim of this study is to extend the automation knowledge base by synthesizing current trends in the application of extraction technologies of key data elements of interest for social scientists.</ns3:p><ns3:p> <ns3:bold>Methods</ns3:bold>: The proposed study is a living systematic review employing a partial replication framework based on extant literature surrounding automation of data extraction for systematic reviews and meta-analyses. Protocol development, base review, and updates follow PRISMA standards for reporting systematic reviews. This protocol is preregistered in OSF: <ns3:ext-link xmlns:ns4="http://www.w3.org/1999/xlink" ext-link-type="uri" ns4:href="https://doi.org/10.17605/OSF.IO/YWTF9">(Semi)Automated Approaches to Data Extraction for Systematic Reviews and Meta-Analyses in Social Sciences: A Living Review Protocol</ns3:ext-link> on August 14, 2022.</ns3:p><ns3:p> <ns3:bold>Conclusions</ns3:bold>: Anticipated outcomes of this study include: (a) generate insights supporting advancement in transferring existing reliable methods to social science research; (b) provide a foundation for protocol development leading to enhancement of comparability and benchmarking standards across disciplines; and (c) uncover exigencies that spur continued value-adding innovation and interdisciplinary collaboration for the benefit of the collective systematic review community.</ns3:p> will describe the existing or suggested definitions of pediatric CCI and important demographic and clinical characteristics of patients to whom these definitions have been applied. This review’s results will help inform the development of a consensus case definition for pediatric CCI and set a priority agenda for future research. We will use and demonstrate the validity of crowdsourcing and ML methodologies for improving the efficiency of large scoping reviews. </sec> <sec> <title>CLINICALTRIAL</title> <p /> </sec> <sec> <title>INTERNATIONAL REGISTERED REPORT</title> DERR1-10.2196/30582 </sec> to achieving this: participants were willing to do so, and the overall process was not prohibitively arduous. We also found some support for the hypothesis that use of study templates may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken. an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2022
DA  - 2022-09-12
JO  - {'id': 'https://openalex.org/S4210239046', 'issn_l': '2046-1402', 'issn': ['2046-1402'], 'display_name': 'F1000Research', 'publisher': 'Faculty of 1000', 'type': 'journal', 'url': 'https://f1000research.com/articles/11-1036/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Amanda Legate
AU  - Kim Nimon
ER  - 

400.
TY  - journal-article
ID  - https://openalex.org/W4297860676
DO  - https://doi.org/10.1016/j.jclinepi.2022.08.013
TI  - In a pilot study, automated real-time systematic review updates were feasible, accurate, and work-saving
AB  - <h2>Abstract</h2><h3>Objectives</h3> The aim of this study is to describe and pilot a novel method for continuously identifying newly published trials relevant to a systematic review, enabled by combining artificial intelligence (AI) with human expertise. <h3>Study Design and Setting</h3> We used RobotReviewer LIVE to keep a review of COVID-19 vaccination trials updated from February to August 2021. We compared the papers identified by the system with those found by the conventional manual process by the review team. <h3>Results</h3> The manual update searches (last search date July 2021) retrieved 135 abstracts, of which 31 were included after screening (23% precision, 100% recall). By the same date, the automated system retrieved 56 abstracts, of which 31 were included after manual screening (55% precision, 100% recall). Key limitations of the system include that it is limited to searches of PubMed/MEDLINE, and considers only randomized controlled trial reports. We aim to address these limitations in future. The system is available as open-source software for further piloting and evaluation. <h3>Conclusion</h3> Our system identified all relevant studies, reduced manual screening work, and enabled rolling updates on publication of new primary research. review, and updates follow PRISMA standards for reporting systematic reviews. This protocol is preregistered in OSF: <ns3:ext-link xmlns:ns4="http://www.w3.org/1999/xlink" ext-link-type="uri" ns4:href="https://doi.org/10.17605/OSF.IO/YWTF9">(Semi)Automated Approaches to Data Extraction for Systematic Reviews and Meta-Analyses in Social Sciences: A Living Review Protocol</ns3:ext-link> on August 14, 2022.</ns3:p><ns3:p> <ns3:bold>Conclusions</ns3:bold>: Anticipated outcomes of this study include: (a) generate insights supporting advancement in transferring existing reliable methods to social science research; (b) provide a foundation for protocol development leading to enhancement of comparability and benchmarking standards across disciplines; and (c) uncover exigencies that spur continued value-adding innovation and interdisciplinary collaboration for the benefit of the collective systematic review community.</ns3:p> will describe the existing or suggested definitions of pediatric CCI and important demographic and clinical characteristics of patients to whom these definitions have been applied. This review’s results will help inform the development of a consensus case definition for pediatric CCI and set a priority agenda for future research. We will use and demonstrate the validity of crowdsourcing and ML methodologies for improving the efficiency of large scoping reviews. </sec> <sec> <title>CLINICALTRIAL</title> <p /> </sec> <sec> <title>INTERNATIONAL REGISTERED REPORT</title> DERR1-10.2196/30582 </sec> to achieving this: participants were willing to do so, and the overall process was not prohibitively arduous. We also found some support for the hypothesis that use of study templates may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken. an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2022
DA  - 2022-09-01
JO  - {'id': 'https://openalex.org/S64418186', 'issn_l': '0895-4356', 'issn': ['1878-5921', '0895-4356'], 'display_name': 'Journal of Clinical Epidemiology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'http://www.jclinepi.com/article/S089543562200213X/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Iain J Marshall
AU  - Thomas A Trikalinos
AU  - Frank Soboczenski
AU  - Hye Sun Yun
AU  - Gregory Kell
AU  - Rachel Marshall
AU  - Byron C Wallace
ER  - 

401.
TY  - posted-content
ID  - https://openalex.org/W4307468686
DO  - https://doi.org/10.21203/rs.3.rs-1887873/v1
TI  - Natural Language Processing (NLP) to Facilitate Abstract Review in Medical Research: The Application of BioBERT to exploring the 20-years use of NLP in medical research
AB  - Abstract Background Abstract review is a time and labor-consuming step in the systematic and scoping literature review in medicine. Automation methods, typically natural language processing (NLP), may efficiently replace manual abstract screening. This study applies NLP to a deliberately selected literature review problem, the trend of using NLP in medical research, to demonstrate the performance of this automated abstract review model. Methods Scanning PubMed, Embase, PsycINFO, and CINAHL databases, we identified 22,294 with a final selection of 12,817 English abstracts published between 2000 to 2021. We invented a manual classification of medical fields, three variables, i.e., the context of use (COU), text source (TS), and primary research field (PRF). A training dataset was developed after reviewing 485 abstracts. We used a language model called Bidirectional Encoder Representations from Transformers to classify the abstracts. To evaluate the performance of the trained models, we report a micro f1-score and accuracy. Results The trained models' micro f1-score in classifying abstracts the three variables were 77.35 % for COU, 76.24% for TS, and 85.64 % for PRF. The average annual growth rate (AAGR) of the publications was 20.99% between 2000 and 2020 (72.01 articles (95%CI: 56.80-78.30) yearly increase), with 81.76% of the abstracts published between 2010 and 2020. Studies on neoplasms constituted 27.66% of the entire corpus with an AAGR of 42.41%, followed by studies on mental conditions (AAGR=39.28%). While electronic health or medical records comprised the highest proportion of text sources (57.12%), omics databases had the highest growth among all text sources with an AAGR of 65.08%. The most common NLP application was clinical decision support (25.45%). Conclusions BioBERT showed an acceptable performance in the abstract review. If future research shows the high performance of this language model, it can reliably replace manual abstract reviews. CCI and important demographic and clinical characteristics of patients to whom these definitions have been applied. This review’s results will help inform the development of a consensus case definition for pediatric CCI and set a priority agenda for future research. We will use and demonstrate the validity of crowdsourcing and ML methodologies for improving the efficiency of large scoping reviews. </sec> <sec> <title>CLINICALTRIAL</title> <p /> </sec> <sec> <title>INTERNATIONAL REGISTERED REPORT</title> DERR1-10.2196/30582 </sec> to achieving this: participants were willing to do so, and the overall process was not prohibitively arduous. We also found some support for the hypothesis that use of study templates may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken. an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2022
DA  - 2022-10-28
JO  - {'id': 'https://openalex.org/S4306402450', 'issn_l': None, 'issn': None, 'display_name': 'Research Square (Research Square)', 'publisher': 'Research Square', 'type': 'repository', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Safoora Masoumi
AU  - Hossein Amirkhani
AU  - Najmeh Sadeghian
AU  - Saeid Shahraz
ER  - 

402.
TY  - journal-article
ID  - https://openalex.org/W4307482990
DO  - https://doi.org/10.1016/j.asr.2022.10.051
TI  - The LIKED resource - a LIbrary KnowledgE and discovery online resource for discovering and implementing knowledge, data, and infrastructure resources
AB  - Access points to Heliophysics information are often poorly inter-linked to one another, making it challenging for researchers to integrate information, mature their understanding, and incorporate more complex ideas and relationships into their analyses. The authors reason this behavior to be a direct conseaquence of the lack of infrastructure for knowledge and data discovery in Heliophysics. Building an online library resource for Heliophysics addresses this gap in resources, and can also address other troublesome gaps related to community-building, such as access to help from other scientists, example analysis tutorials, and collaboration opportunities. This paper envisions a resource that better connects existing Heliophysics information and knowledge sources, the LIbrary for KnowledgE and Discovery (LIKED), which will be an online resource that interlinks information across databases (e.g., observational and publication), researcher interactions (e.g., conferences and discussion boards), and educational materials. The result is a rich and searchable environment to provide users a more productive experience for research and collaboration. In this paper, we provide the conceptual model for LIKED. We expand to detail how LIKED will serve to connect the various knowledge and research components available internationally together in an uniformly searchable manner. Finally, this work outlines various contributions the community can make towards this goal. 2020. Studies on neoplasms constituted 27.66% of the entire corpus with an AAGR of 42.41%, followed by studies on mental conditions (AAGR=39.28%). While electronic health or medical records comprised the highest proportion of text sources (57.12%), omics databases had the highest growth among all text sources with an AAGR of 65.08%. The most common NLP application was clinical decision support (25.45%). Conclusions BioBERT showed an acceptable performance in the abstract review. If future research shows the high performance of this language model, it can reliably replace manual abstract reviews. CCI and important demographic and clinical characteristics of patients to whom these definitions have been applied. This review’s results will help inform the development of a consensus case definition for pediatric CCI and set a priority agenda for future research. We will use and demonstrate the validity of crowdsourcing and ML methodologies for improving the efficiency of large scoping reviews. </sec> <sec> <title>CLINICALTRIAL</title> <p /> </sec> <sec> <title>INTERNATIONAL REGISTERED REPORT</title> DERR1-10.2196/30582 </sec> to achieving this: participants were willing to do so, and the overall process was not prohibitively arduous. We also found some support for the hypothesis that use of study templates may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken. an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2022
DA  - 2022-10-01
JO  - {'id': 'https://openalex.org/V113313948', 'issn_l': '0273-1177', 'issn': ['0273-1177', '1879-1948'], 'display_name': 'Advances in Space Research', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'https://doi.org/10.1016/j.asr.2022.10.051', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Rebecca Ringuette
AU  - Ryan M. McGranaghan
AU  - B.J. Thompson
ER  - 

403.
TY  - journal-article
ID  - https://openalex.org/W4308791552
DO  - https://doi.org/10.1371/journal.pone.0276747
TI  - Vulnerability in maternal, new-born, and child health in low- and middle-income countries: Findings from a scoping review
AB  - Objectives To identify and synthesise prevailing definitions and indices of vulnerability in maternal, new-born and child health (MNCH) research and health programs in low- and middle-income countries. Design and setting Scoping review using Arksey and O’Malley’s framework and a Delphi survey for consensus building. Participants Mothers, new-borns, and children living in low- and middle-income countries were selected as participants. Outcomes Vulnerability as defined by the authors was deduced from the studies. Results A total of 61 studies were included in this scoping review. Of this, 22 were publications on vulnerability in the context of maternal health and 40 were on new-born and child health. Definitions used in included studies can be broadly categorised into three domains: biological, socioeconomic, and environmental. Eleven studies defined vulnerability in the context of maternal health, five reported on the scales used to measure vulnerability in maternal health and only one study used a validated scale. Of the 40 included studies on vulnerability in child health, 19 defined vulnerability in the context of new-born and/or child health, 15 reported on the scales used to measure vulnerability in child health and nine reported on childhood vulnerability indices. As it was difficult to synthesise the definitions, their keywords were extracted to generate new candidate definitions for vulnerability in MNCH. Conclusion Included studies paid greater attention to new-born/ child vulnerability than maternal vulnerability, with authors defining the terms differently. A definition which helps in improving the description of vulnerability in MNCH across various programs and researchers was arrived at. This will further help in streamlining research and interventions which can influence the design of high impact MNCH programs. Scoping review registration The protocol for this review was registered in the open science framework at the registered address ( https://osf.io/jt6nr ). reviews. CCI and important demographic and clinical characteristics of patients to whom these definitions have been applied. This review’s results will help inform the development of a consensus case definition for pediatric CCI and set a priority agenda for future research. We will use and demonstrate the validity of crowdsourcing and ML methodologies for improving the efficiency of large scoping reviews. </sec> <sec> <title>CLINICALTRIAL</title> <p /> </sec> <sec> <title>INTERNATIONAL REGISTERED REPORT</title> DERR1-10.2196/30582 </sec> to achieving this: participants were willing to do so, and the overall process was not prohibitively arduous. We also found some support for the hypothesis that use of study templates may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken. an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2022
DA  - 2022-11-11
JO  - {'id': 'https://openalex.org/S202381698', 'issn_l': '1932-6203', 'issn': ['1932-6203'], 'display_name': 'PLOS ONE', 'publisher': 'Public Library of Science', 'type': 'journal', 'url': 'https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0276747&type=printable', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Olusesan Ayodeji Makinde
AU  - Olalekan A. Uthman
AU  - Ifeanyi C Mgbachi
AU  - Nchelem Kokomma Ichegbo
AU  - Fatima Abdulaziz Sule
AU  - Emmanuel Olamijuwon
AU  - Babasola O. Okusanya
ER  - 

404.
TY  - journal-article
ID  - https://openalex.org/W4309154626
DO  - https://doi.org/10.1088/1742-5468/ac9463
TI  - Network meta-analysis: a statistical physics perspective
AB  - Network meta-analysis (NMA) is a technique used in medical statistics to combine evidence from multiple medical trials. NMA defines an inference and information processing problem on a network of treatment options and trials connecting the treatments. We believe that statistical physics can offer useful ideas and tools for this area, including from the theory of complex networks, stochastic modelling and simulation techniques. The lack of a unique source that would allow physicists to learn about NMA effectively is a barrier to this. In this article we aim to present the `NMA problem' and existing approaches to it coherently and in a language accessible to statistical physicists. We also summarise existing points of contact between statistical physics and NMA, and describe our ideas of how physics might make a difference for NMA in the future. The overall goal of the article is to attract physicists to this interesting, timely and worthwhile field of research. included studies on vulnerability in child health, 19 defined vulnerability in the context of new-born and/or child health, 15 reported on the scales used to measure vulnerability in child health and nine reported on childhood vulnerability indices. As it was difficult to synthesise the definitions, their keywords were extracted to generate new candidate definitions for vulnerability in MNCH. Conclusion Included studies paid greater attention to new-born/ child vulnerability than maternal vulnerability, with authors defining the terms differently. A definition which helps in improving the description of vulnerability in MNCH across various programs and researchers was arrived at. This will further help in streamlining research and interventions which can influence the design of high impact MNCH programs. Scoping review registration The protocol for this review was registered in the open science framework at the registered address ( https://osf.io/jt6nr ). reviews. CCI and important demographic and clinical characteristics of patients to whom these definitions have been applied. This review’s results will help inform the development of a consensus case definition for pediatric CCI and set a priority agenda for future research. We will use and demonstrate the validity of crowdsourcing and ML methodologies for improving the efficiency of large scoping reviews. </sec> <sec> <title>CLINICALTRIAL</title> <p /> </sec> <sec> <title>INTERNATIONAL REGISTERED REPORT</title> DERR1-10.2196/30582 </sec> to achieving this: participants were willing to do so, and the overall process was not prohibitively arduous. We also found some support for the hypothesis that use of study templates may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken. an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2022
DA  - 2022-11-01
JO  - {'id': 'https://openalex.org/S167943036', 'issn_l': '1742-5468', 'issn': ['1742-5468'], 'display_name': 'Journal of Statistical Mechanics: Theory and Experiment', 'publisher': 'International School for Advanced Studies', 'type': 'journal', 'url': 'https://doi.org/10.1088/1742-5468/ac9463', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Annabel L Davies
AU  - Tobias Galla
ER  - 

405.
TY  - book-chapter
ID  - https://openalex.org/W4309301221
DO  - https://doi.org/10.1016/b978-0-12-818630-5.10092-2
TI  - Meta-analysis
AB  - Meta-analysis is the quantitative synthesis of the results of studies on a common topic or question. Its key goals are to assess the magnitudes of effects from the studies, and to quantify and explore variation in those effects. This chapter describes the set of practical and statistical procedures required to conduct a high-quality meta-analysis. The process begins with the formulation of a problem. This is followed by the data-collection step, during which the meta-analyst conducts a reproducible, exhaustive, and unbiased search for relevant studies that meet specific inclusion criteria. In the data-evaluation stage the meta-analyst extracts effect indices to represent study results, along with features of the participants, treatments (if any), methods, and measures used, and indicators of study quality. During data analysis, study features serve as potential explanations of between-studies differences. Finally, the review process and meta-analytic results are fully described and interpreted in the meta-analysis report. We illustrate these steps using two recent meta-analyses of studies of game-based instruction for second-language learning. Analyses based on data from Thompson and von Gillern (2020) illustrate fixed- and random-effects models for estimating overall effect magnitudes and their variance across studies, and for exploring predictors of between-studies differences. We also demonstrate the use of Bayesian meta-analysis to obtain information on the potential distributions of population parameters. paid greater attention to new-born/ child vulnerability than maternal vulnerability, with authors defining the terms differently. A definition which helps in improving the description of vulnerability in MNCH across various programs and researchers was arrived at. This will further help in streamlining research and interventions which can influence the design of high impact MNCH programs. Scoping review registration The protocol for this review was registered in the open science framework at the registered address ( https://osf.io/jt6nr ). reviews. CCI and important demographic and clinical characteristics of patients to whom these definitions have been applied. This review’s results will help inform the development of a consensus case definition for pediatric CCI and set a priority agenda for future research. We will use and demonstrate the validity of crowdsourcing and ML methodologies for improving the efficiency of large scoping reviews. </sec> <sec> <title>CLINICALTRIAL</title> <p /> </sec> <sec> <title>INTERNATIONAL REGISTERED REPORT</title> DERR1-10.2196/30582 </sec> to achieving this: participants were willing to do so, and the overall process was not prohibitively arduous. We also found some support for the hypothesis that use of study templates may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken. an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2023
DA  - 2023-01-01
JO  - {'id': 'https://openalex.org/S4306463230', 'issn_l': None, 'issn': None, 'display_name': 'Elsevier eBooks', 'publisher': 'Elsevier BV', 'type': 'ebook platform', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Betsy Jane Becker
AU  - Christopher G. Thompson
ER  - 

406.
TY  - posted-content
ID  - https://openalex.org/W4309542200
DO  - https://doi.org/10.1101/2022.11.17.22282374
TI  - Validation of semi-automatic citation screening software for creating clinical practice guidelines: A protocol for a prospective observational study
AB  - Abstract Background This study aims to investigate the quality of the literature search and workload saving using the semi-automatic software for citation screening in the development of the Japanese Clinical Practice Guidelines for Management of Sepsis and Septic Shock (J-SSCG). Methods We will conduct a prospective study to compare the efficiency of citation screening between the conventional method using Rayyan and semi-automatic citation screening using ASReview. The two independent reviewers will conduct literature searches for clinical questions. During the session, we objectively measure the time to accomplish the citation screening. After the citation screening, we will calculate the sensitivity and specificity from the results of the conventional and semi-automatic procedures. Also, we will compare the accumulated time between the two methods. Trial registration This research is submitted with the University hospital medical information network clinical trial registry (UMIN-CTR) [UMIN000049366]. Conflicts of interest All authors declare no conflicts of interest to have. Funding None two recent meta-analyses of studies of game-based instruction for second-language learning. Analyses based on data from Thompson and von Gillern (2020) illustrate fixed- and random-effects models for estimating overall effect magnitudes and their variance across studies, and for exploring predictors of between-studies differences. We also demonstrate the use of Bayesian meta-analysis to obtain information on the potential distributions of population parameters. paid greater attention to new-born/ child vulnerability than maternal vulnerability, with authors defining the terms differently. A definition which helps in improving the description of vulnerability in MNCH across various programs and researchers was arrived at. This will further help in streamlining research and interventions which can influence the design of high impact MNCH programs. Scoping review registration The protocol for this review was registered in the open science framework at the registered address ( https://osf.io/jt6nr ). reviews. CCI and important demographic and clinical characteristics of patients to whom these definitions have been applied. This review’s results will help inform the development of a consensus case definition for pediatric CCI and set a priority agenda for future research. We will use and demonstrate the validity of crowdsourcing and ML methodologies for improving the efficiency of large scoping reviews. </sec> <sec> <title>CLINICALTRIAL</title> <p /> </sec> <sec> <title>INTERNATIONAL REGISTERED REPORT</title> DERR1-10.2196/30582 </sec> to achieving this: participants were willing to do so, and the overall process was not prohibitively arduous. We also found some support for the hypothesis that use of study templates may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken. an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2022
DA  - 2022-11-18
JO  - {'id': 'https://openalex.org/V4306400573', 'issn_l': None, 'issn': None, 'display_name': 'Cold Spring Harbor Laboratory - medRxiv', 'publisher': 'Cold Spring Harbor Laboratory', 'type': 'repository', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Takehiko Oami
AU  - Yohei Okada
AU  - Tatsuma Fukuda
AU  - Masaaki Sakuraya
AU  - Taka-aki Nakada
AU  - Nobuaki Shime
ER  - 

407.
TY  - journal-article
ID  - https://openalex.org/W4309811661
DO  - https://doi.org/10.1016/j.mex.2022.101935
TI  - An automated method for developing search strategies for systematic review using Natural Language Processing (NLP)
AB  - The design and implementation of systematic reviews and meta-analyses are often hampered by high financial costs, significant time commitment, and biases due to researchers' familiarity with studies. We proposed and implemented a fast and standardized method for search term selection using Natural Language Processing (NLP) and co-occurrence networks to identify relevant search terms to reduce biases in conducting systematic reviews and meta-analyses.•The method was implemented using Python packaged dubbed Ananse, which is benchmarked on the search terms strategy for naïve search proposed by Grames et al. (2019) written in "R". Ananse was applied to a case example towards finding search terms to implement a systematic literature review on cumulative effect studies on forest ecosystems.•The software automatically corrected and classified 100% of the duplicate articles identified by manual deduplication. Ananse was applied to the cumulative effects assessment case study, but it can serve as a general-purpose, open-source software system that can support extensive systematic reviews within a relatively short period with reduced biases.•Besides generating keywords, Ananse can act as middleware or a data converter for integrating multiple datasets into a database. estimating overall effect magnitudes and their variance across studies, and for exploring predictors of between-studies differences. We also demonstrate the use of Bayesian meta-analysis to obtain information on the potential distributions of population parameters. paid greater attention to new-born/ child vulnerability than maternal vulnerability, with authors defining the terms differently. A definition which helps in improving the description of vulnerability in MNCH across various programs and researchers was arrived at. This will further help in streamlining research and interventions which can influence the design of high impact MNCH programs. Scoping review registration The protocol for this review was registered in the open science framework at the registered address ( https://osf.io/jt6nr ). reviews. CCI and important demographic and clinical characteristics of patients to whom these definitions have been applied. This review’s results will help inform the development of a consensus case definition for pediatric CCI and set a priority agenda for future research. We will use and demonstrate the validity of crowdsourcing and ML methodologies for improving the efficiency of large scoping reviews. </sec> <sec> <title>CLINICALTRIAL</title> <p /> </sec> <sec> <title>INTERNATIONAL REGISTERED REPORT</title> DERR1-10.2196/30582 </sec> to achieving this: participants were willing to do so, and the overall process was not prohibitively arduous. We also found some support for the hypothesis that use of study templates may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken. an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2022
DA  - 2022-11-01
JO  - {'id': 'https://openalex.org/S2898269294', 'issn_l': '2215-0161', 'issn': ['2215-0161'], 'display_name': 'MethodsX', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'http://methods-x.com/article/S2215016122003120/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Antwi Effah Kwabena
AU  - Owusu-Banahene Wiafe
AU  - Boakye-Danquah John
AU  - Asare Bernard
AU  - Frimpong A.F Boateng
ER  - 

408.
TY  - journal-article
ID  - https://openalex.org/W4311625871
DO  - https://doi.org/10.12688/f1000research.127179.1
TI  - The role of open research in improving the standards of evidence synthesis: current challenges and potential solutions in systematic reviews
AB  - <ns3:p>Systematic reviews (SRs) and meta-analyses (MAs) are the cornerstone of evidence-based medicine and are placed at the top of the level-of-evidence pyramid. To date, there are several methodological resources available from international organizations such as the Cochrane Collaboration that aim to aid researchers in conducting high-quality secondary research and promoting reproducibility, transparency and scientific rigour. Nevertheless, researchers still face challenges in most stages of evidence synthesis. Open research and the FAIR (findability, accessibility, interoperability, and reusability) principles are rising initiatives being increasingly implemented in primary research. However, their beneficial role in secondary research is less emphasized. This article addresses how the challenges commonly faced during evidence synthesis research could be overcome using open research practices and currently available open research tools. Despite the phenomenally simple SR workflow, researchers still find tasks such as framing the SR research question, search strategy development, data extraction, and assessing for bias, challenging. The implementation of FAIR practices, including prospective registration at the PROSPERO database, abiding with the PRISMA guidelines, and making all SR data openly available could have significant benefits in avoiding duplication of effort and reducing research waste while improving the reporting standards of SRs. Additionally, this article highlights the need for further education in open research culture to overcome ethical and motivational barriers in implementing open research practices in evidence synthesis. Finally, in the era of technological breakthroughs, artificial intelligence may eventually be incorporated into the process of SRs and should abide by the FAIR standards for open research.</ns3:p> was arrived at. This will further help in streamlining research and interventions which can influence the design of high impact MNCH programs. Scoping review registration The protocol for this review was registered in the open science framework at the registered address ( https://osf.io/jt6nr ). reviews. CCI and important demographic and clinical characteristics of patients to whom these definitions have been applied. This review’s results will help inform the development of a consensus case definition for pediatric CCI and set a priority agenda for future research. We will use and demonstrate the validity of crowdsourcing and ML methodologies for improving the efficiency of large scoping reviews. </sec> <sec> <title>CLINICALTRIAL</title> <p /> </sec> <sec> <title>INTERNATIONAL REGISTERED REPORT</title> DERR1-10.2196/30582 </sec> to achieving this: participants were willing to do so, and the overall process was not prohibitively arduous. We also found some support for the hypothesis that use of study templates may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken. an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2022
DA  - 2022-12-05
JO  - {'id': 'https://openalex.org/S4210239046', 'issn_l': '2046-1402', 'issn': ['2046-1402'], 'display_name': 'F1000Research', 'publisher': 'Faculty of 1000', 'type': 'journal', 'url': 'https://f1000research.com/articles/11-1435/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Eirini Martinou
AU  - Angeliki Angelidi
ER  - 

409.
TY  - journal-article
ID  - https://openalex.org/W4312018506
DO  - https://doi.org/10.1186/s12874-022-01805-4
TI  - Machine learning computational tools to assist the performance of systematic reviews: A mapping review
AB  - Abstract Background Within evidence-based practice (EBP), systematic reviews (SR) are considered the highest level of evidence in that they summarize the best available research and describe the progress in a determined field. Due its methodology, SR require significant time and resources to be performed; they also require repetitive steps that may introduce biases and human errors. Machine learning (ML) algorithms therefore present a promising alternative and a potential game changer to speed up and automate the SR process. This review aims to map the current availability of computational tools that use ML techniques to assist in the performance of SR, and to support authors in the selection of the right software for the performance of evidence synthesis. Methods The mapping review was based on comprehensive searches in electronic databases and software repositories to obtain relevant literature and records, followed by screening for eligibility based on titles, abstracts, and full text by two reviewers. The data extraction consisted of listing and extracting the name and basic characteristics of the included tools, for example a tool’s applicability to the various SR stages, pricing options, open-source availability, and type of software. These tools were classified and graphically represented to facilitate the description of our findings. Results A total of 9653 studies and 585 records were obtained from the structured searches performed on selected bibliometric databases and software repositories respectively. After screening, a total of 119 descriptions from publications and records allowed us to identify 63 tools that assist the SR process using ML techniques. Conclusions This review provides a high-quality map of currently available ML software to assist the performance of SR. ML algorithms are arguably one of the best techniques at present for the automation of SR. The most promising tools were easily accessible and included a high number of user-friendly features permitting the automation of SR and other kinds of evidence synthesis reviews. help inform the development of a consensus case definition for pediatric CCI and set a priority agenda for future research. We will use and demonstrate the validity of crowdsourcing and ML methodologies for improving the efficiency of large scoping reviews. </sec> <sec> <title>CLINICALTRIAL</title> <p /> </sec> <sec> <title>INTERNATIONAL REGISTERED REPORT</title> DERR1-10.2196/30582 </sec> to achieving this: participants were willing to do so, and the overall process was not prohibitively arduous. We also found some support for the hypothesis that use of study templates may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken. an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2022
DA  - 2022-12-16
JO  - {'id': 'https://openalex.org/S185874209', 'issn_l': '1471-2288', 'issn': ['1471-2288'], 'display_name': 'BMC Medical Research Methodology', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://bmcmedresmethodol.biomedcentral.com/counter/pdf/10.1186/s12874-022-01805-4', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Ramon Cierco Jimenez
AU  - Teresa Lee
AU  - Nicolás Rosillo
AU  - Reynalda Cordova
AU  - Ian A Cree
AU  - Angel Gonzalez
AU  - Blanca Iciar Indave Ruiz
ER  - 

410.
TY  - book-chapter
ID  - https://openalex.org/W4312580430
DO  - https://doi.org/10.1007/978-3-031-09108-7_13
TI  - Public Health Applications
AB  - No Abstract Found
PY  - 2022
DA  - 2022-01-01
JO  - {'id': 'https://openalex.org/S4306463941', 'issn_l': None, 'issn': None, 'display_name': 'Springer International Publishing eBooks', 'publisher': 'Springer Nature', 'type': 'ebook platform', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - David L. Buckeridge
ER  - 

411.
TY  - journal-article
ID  - https://openalex.org/W4313329309
DO  - https://doi.org/10.26633/rpsp.2022.112
TI  - A declaração PRISMA 2020: diretriz atualizada para relatar revisões sistemáticas
AB  - The Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) statement, published in 2009, was designed to help systematic reviewers transparently report why the review was done, what the authors did, and what they found. Over the past decade, advances in systematic review methodology and terminology have necessitated an update to the guideline. The PRISMA 2020 statement replaces the 2009 statement and includes new reporting guidance that reflects advances in methods to identify, select, appraise, and synthesise studies. The structure and presentation of the items have been modified to facilitate implementation. In this article, we present the PRISMA 2020 27-item checklist, an expanded checklist that details reporting recommendations for each item, the PRISMA 2020 abstract checklist, and the revised flow diagrams for original and updated reviews.La declaración PRISMA (Preferred Reporting Items for Systematic reviews and Meta-Analyses), publicada en 2009, se diseñó para ayudar a los autores de revisiones sistemáticas a documentar de manera transparente el porqué de la revisión, qué hicieron los autores y qué encontraron. Durante la última década, ha habido muchos avances en la metodología y terminología de las revisiones sistemáticas, lo que ha requerido una actualización de esta guía. La declaración PRISMA 2020 sustituye a la declaración de 2009 e incluye una nueva guía de presentación de las publicaciones que refleja los avances en los métodos para identificar, seleccionar, evaluar y sintetizar estudios. La estructura y la presentación de los ítems ha sido modificada para facilitar su implementación. En este artículo, presentamos la lista de verificación PRISMA 2020 con 27 ítems, y una lista de verificación ampliada que detalla las recomendaciones en la publicación de cada ítem, la lista de verificación del resumen estructurado PRISMA 2020 y el diagrama de flujo revisado para revisiones sistemáticas. tools were easily accessible and included a high number of user-friendly features permitting the automation of SR and other kinds of evidence synthesis reviews. help inform the development of a consensus case definition for pediatric CCI and set a priority agenda for future research. We will use and demonstrate the validity of crowdsourcing and ML methodologies for improving the efficiency of large scoping reviews. </sec> <sec> <title>CLINICALTRIAL</title> <p /> </sec> <sec> <title>INTERNATIONAL REGISTERED REPORT</title> DERR1-10.2196/30582 </sec> to achieving this: participants were willing to do so, and the overall process was not prohibitively arduous. We also found some support for the hypothesis that use of study templates may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken. an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2022
DA  - 2022-12-30
JO  - {'id': 'https://openalex.org/S4210196923', 'issn_l': '1020-4989', 'issn': ['1020-4989', '1680-5348'], 'display_name': 'Revista panamericana de salud pública (Impresa)', 'publisher': 'Pan American Health Organization', 'type': 'journal', 'url': 'https://iris.paho.org/bitstream/10665.2/56882/5/v46e1122022.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc-nd'}
DP  - OpenAlex
AU  - Matthew J Page
AU  - Joanne E McKenzie
AU  - Patrick M Bossuyt
AU  - Isabelle Boutron
AU  - Tammy C Hoffmann
AU  - Cynthia D Mulrow
AU  - Larissa Shamseer
AU  - Jennifer Tetzlaff
AU  - Elie A Akl
AU  - Sue E Brennan
AU  - Roger Chou
AU  - Julie Glanville
AU  - Jeremy M Grimshaw
AU  - Asbjørn Hróbjartsson
AU  - Manoj M Lalu
AU  - Tianjing Li
AU  - Elizabeth W Loder
AU  - Evan Mayo-Wilson
AU  - Steve McDonald
AU  - Luke A McGuinness
AU  - Lesley A Stewart
AU  - James Thomas
AU  - Andrea C Tricco
AU  - Vivian A Welch
AU  - Penny Whiting
AU  - David Moher
ER  - 

412.
TY  - journal-article
ID  - https://openalex.org/W4313406414
DO  - https://doi.org/10.3390/min12121621
TI  - Automated Hyperparameter Optimization of Gradient Boosting Decision Tree Approach for Gold Mineral Prospectivity Mapping in the Xiong’ershan Area
AB  - The weak classifier ensemble algorithms based on the decision tree model, mainly include bagging (e.g., fandom forest-RF) and boosting (e.g., gradient boosting decision tree, eXtreme gradient boosting), the former reduces the variance for the overall generalization error reduction while the latter focuses on reducing the overall bias to that end. Because of its straightforward idea, it is prevalent in MPM (mineral prospectivity mapping). However, an inevitable problem in the application of such methods is the hyperparameters tuning which is a laborious and time-consuming task. The selection of hyperparameters suitable for a specific task is worth investigating. In this paper, a tree Parzen estimator-based GBDT (gradient boosting decision tree) model (TPE-GBDT) was introduced for hyperparameters tuning (e.g., loss criterion, n_estimators, learning_rate, max_features, subsample, max_depth, min_impurity_decrease). Then, the geological data of the gold deposit in the Xiong ‘ershan area was used to create training data for MPM and to compare the TPE-GBDT and random search-GBDT training results. Results showed that the TPE-GBDT model can obtain higher accuracy than random search-GBDT in a shorter time for the same parameter space, which proves that this algorithm is superior to random search in principle and more suitable for complex hyperparametric tuning. Subsequently, the validation measures, five-fold cross-validation, confusion matrix and success rate curves were employed to evaluate the overall performance of the hyperparameter optimization models. The results showed good scores for the predictive models. Finally, according to the maximum Youden index as the threshold to divide metallogenic potential areas and non-prospective areas, the high metallogenic prospect area (accounts for 10.22% of the total study area) derived by the TPE-GBDT model contained &gt; 90% of the known deposits and provided a preferred range for future exploration work. diagrama de flujo revisado para revisiones sistemáticas. tools were easily accessible and included a high number of user-friendly features permitting the automation of SR and other kinds of evidence synthesis reviews. help inform the development of a consensus case definition for pediatric CCI and set a priority agenda for future research. We will use and demonstrate the validity of crowdsourcing and ML methodologies for improving the efficiency of large scoping reviews. </sec> <sec> <title>CLINICALTRIAL</title> <p /> </sec> <sec> <title>INTERNATIONAL REGISTERED REPORT</title> DERR1-10.2196/30582 </sec> to achieving this: participants were willing to do so, and the overall process was not prohibitively arduous. We also found some support for the hypothesis that use of study templates may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken. an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2022
DA  - 2022-12-16
JO  - {'id': 'https://openalex.org/S2737336974', 'issn_l': '2075-163X', 'issn': ['2075-163X'], 'display_name': 'Minerals', 'publisher': 'MDPI', 'type': 'journal', 'url': 'https://www.mdpi.com/2075-163X/12/12/1621/pdf?version=1671195392', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Mingjing Fan
AU  - Keyan Xiao
AU  - Sheng-Rong Li
AU  - Shuai Zhang
AU  - Yang Xu
ER  - 

413.
TY  - journal-article
ID  - https://openalex.org/W4313419185
DO  - https://doi.org/10.1016/j.techfore.2022.122222
TI  - The digital and sustainable transition of the agri-food sector
AB  - No Abstract Found
PY  - 2023
DA  - 2023-02-01
JO  - {'id': 'https://openalex.org/S39307421', 'issn_l': '0040-1625', 'issn': ['0040-1625', '1873-5509'], 'display_name': 'Technological Forecasting and Social Change', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Stefano Abbate
AU  - Piera Centobelli
AU  - Roberto Cerchione
ER  - 

414.
TY  - journal-article
ID  - https://openalex.org/W4313446661
DO  - https://doi.org/10.1186/s13643-022-02163-4
TI  - Unsupervised title and abstract screening for systematic review: a retrospective case-study using topic modelling methodology
AB  - Abstract Background The importance of systematic reviews in collating and summarising available research output on a particular topic cannot be over-emphasized. However, initial screening of retrieved literature is significantly time and labour intensive. Attempts at automating parts of the systematic review process have been made with varying degree of success partly due to being domain-specific, requiring vendor-specific software or manually labelled training data. Our primary objective was to develop statistical methodology for performing automated title and abstract screening for systematic reviews. Secondary objectives included (1) to retrospectively apply the automated screening methodology to previously manually screened systematic reviews and (2) to characterize the performance of the automated screening methodology scoring algorithm in a simulation study. Methods We implemented a Latent Dirichlet Allocation-based topic model to derive representative topics from the retrieved documents’ title and abstract. The second step involves defining a score threshold for classifying the documents as relevant for full-text review or not. The score is derived based on a set of search keywords (often the database retrieval search terms). Two systematic review studies were retrospectively used to illustrate the methodology. Results In one case study (helminth dataset), $$69.83\%$$ <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"> <mml:mrow> <mml:mn>69.83</mml:mn> <mml:mo>%</mml:mo> </mml:mrow> </mml:math> sensitivity compared to manual title and abstract screening was achieved. This is against a false positive rate of $$22.63\%$$ <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"> <mml:mrow> <mml:mn>22.63</mml:mn> <mml:mo>%</mml:mo> </mml:mrow> </mml:math> . For the second case study (Wilson disease dataset), a sensitivity of $$54.02\%$$ <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"> <mml:mrow> <mml:mn>54.02</mml:mn> <mml:mo>%</mml:mo> </mml:mrow> </mml:math> and specificity of $$67.03\%$$ <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"> <mml:mrow> <mml:mn>67.03</mml:mn> <mml:mo>%</mml:mo> </mml:mrow> </mml:math> were achieved. Conclusions Unsupervised title and abstract screening has the potential to reduce the workload involved in conducting systematic review. While sensitivity of the methodology on the tested data is low, approximately $$70\%$$ <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"> <mml:mrow> <mml:mn>70</mml:mn> <mml:mo>%</mml:mo> </mml:mrow> </mml:math> specificity was achieved. Users ought to keep in mind that potentially low sensitivity might occur. One approach to mitigate this might be to incorporate additional targeted search keywords such as the indexing databases terms into the search term copora. Moreover, automated screening can be used as an additional screener to the manual screeners. efficiency of large scoping reviews. </sec> <sec> <title>CLINICALTRIAL</title> <p /> </sec> <sec> <title>INTERNATIONAL REGISTERED REPORT</title> DERR1-10.2196/30582 </sec> to achieving this: participants were willing to do so, and the overall process was not prohibitively arduous. We also found some support for the hypothesis that use of study templates may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken. an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2023
DA  - 2023-01-03
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://systematicreviewsjournal.biomedcentral.com/counter/pdf/10.1186/s13643-022-02163-4', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Leacky Muchene
AU  - Leacky K Muchene
ER  - 

415.
TY  - journal-article
ID  - https://openalex.org/W4315631519
DO  - https://doi.org/10.1042/cs20220594
TI  - Screening for <i>in vitro</i> systematic reviews: a comparison of screening methods and training of a machine learning classifier
AB  - Abstract Objective: Existing strategies to identify relevant studies for systematic review may not perform equally well across research domains. We compare four approaches based on either human or automated screening of either title and abstract or full text, and report the training of a machine learning algorithm to identify in vitro studies from bibliographic records. Methods: We used a systematic review of oxygen–glucose deprivation (OGD) in PC-12 cells to compare approaches. For human screening, two reviewers independently screened studies based on title and abstract or full text, with disagreements reconciled by a third. For automated screening, we applied text mining to either title and abstract or full text. We trained a machine learning algorithm with decisions from 2000 randomly selected PubMed Central records enriched with a dataset of known in vitro studies. Results: Full-text approaches performed best, with human (sensitivity: 0.990, specificity: 1.000 and precision: 0.994) outperforming text mining (sensitivity: 0.972, specificity: 0.980 and precision: 0.764). For title and abstract, text mining (sensitivity: 0.890, specificity: 0.995 and precision: 0.922) outperformed human screening (sensitivity: 0.862, specificity: 0.998 and precision: 0.975). At our target sensitivity of 95% the algorithm performed with specificity of 0.850 and precision of 0.700. Conclusion: In this in vitro systematic review, human screening based on title and abstract erroneously excluded 14% of relevant studies, perhaps because title and abstract provide an incomplete description of methods used. Our algorithm might be used as a first selection phase in in vitro systematic reviews to limit the extent of full text screening required. </mml:mrow> </mml:math> were achieved. Conclusions Unsupervised title and abstract screening has the potential to reduce the workload involved in conducting systematic review. While sensitivity of the methodology on the tested data is low, approximately $$70\%$$ <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"> <mml:mrow> <mml:mn>70</mml:mn> <mml:mo>%</mml:mo> </mml:mrow> </mml:math> specificity was achieved. Users ought to keep in mind that potentially low sensitivity might occur. One approach to mitigate this might be to incorporate additional targeted search keywords such as the indexing databases terms into the search term copora. Moreover, automated screening can be used as an additional screener to the manual screeners. efficiency of large scoping reviews. </sec> <sec> <title>CLINICALTRIAL</title> <p /> </sec> <sec> <title>INTERNATIONAL REGISTERED REPORT</title> DERR1-10.2196/30582 </sec> to achieving this: participants were willing to do so, and the overall process was not prohibitively arduous. We also found some support for the hypothesis that use of study templates may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken. an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2023
DA  - 2023-01-11
JO  - {'id': 'https://openalex.org/S206649051', 'issn_l': '0143-5221', 'issn': ['1470-8736', '0143-5221'], 'display_name': 'Clinical Science', 'publisher': 'Portland Press', 'type': 'journal', 'url': 'https://portlandpress.com/clinsci/article-pdf/doi/10.1042/CS20220594/941887/cs-2022-0594.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Emma Wilson
AU  - Florenz Cruz
AU  - Duncan Maclean
AU  - Joly Ghanawi
AU  - Sarah K McCann
AU  - Paul M Brennan
AU  - Jing Liao
AU  - Emily S Sena
AU  - Malcolm R Macleod
ER  - 

416.
TY  - journal-article
ID  - https://openalex.org/W4318225126
DO  - https://doi.org/10.12688/f1000research.125198.2
TI  - (Semi)automated approaches to data extraction for systematic reviews and meta-analyses in social sciences: A living review protocol
AB  - <ns3:p><ns3:bold>Background</ns3:bold>: An abundance of rapidly accumulating scientific evidence presents novel opportunities for researchers and practitioners alike, yet such advantages are often overshadowed by resource demands associated with finding and aggregating a continually expanding body of scientific information. Across social science disciplines, the use of automation technologies for timely and accurate knowledge synthesis can enhance research translation value, better inform key policy development, and expand the current understanding of human interactions, organizations, and systems. Ongoing developments surrounding automation are highly concentrated in research for evidence-based medicine with limited evidence surrounding tools and techniques applied outside of the clinical research community. Our objective is to conduct a living systematic review of automated data extraction techniques supporting systematic reviews and meta-analyses in the social sciences. The aim of this study is to extend the automation knowledge base by synthesizing current trends in the application of extraction technologies of key data elements of interest for social scientists.</ns3:p><ns3:p> <ns3:bold>Methods</ns3:bold>: The proposed study is a living systematic review employing a partial replication framework based on extant literature surrounding automation of data extraction for systematic reviews and meta-analyses. Protocol development, base review, and updates follow PRISMA standards for reporting systematic reviews. This protocol is preregistered in OSF: <ns3:ext-link xmlns:ns4="http://www.w3.org/1999/xlink" ext-link-type="uri" ns4:href="https://doi.org/10.17605/OSF.IO/YWTF9">(Semi)Automated Approaches to Data Extraction for Systematic Reviews and Meta-Analyses in Social Sciences: A Living Review Protocol</ns3:ext-link> on August 14, 2022.</ns3:p><ns3:p> <ns3:bold>Conclusions</ns3:bold>: Anticipated outcomes of this study include: (a) generate insights supporting advancement in transferring existing reliable methods to social science research; (b) provide a foundation for protocol development leading to enhancement of comparability and benchmarking standards across disciplines; and (c) uncover exigencies that spur continued value-adding innovation and interdisciplinary collaboration for the benefit of the collective systematic review community.</ns3:p> is low, approximately $$70\%$$ <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"> <mml:mrow> <mml:mn>70</mml:mn> <mml:mo>%</mml:mo> </mml:mrow> </mml:math> specificity was achieved. Users ought to keep in mind that potentially low sensitivity might occur. One approach to mitigate this might be to incorporate additional targeted search keywords such as the indexing databases terms into the search term copora. Moreover, automated screening can be used as an additional screener to the manual screeners. efficiency of large scoping reviews. </sec> <sec> <title>CLINICALTRIAL</title> <p /> </sec> <sec> <title>INTERNATIONAL REGISTERED REPORT</title> DERR1-10.2196/30582 </sec> to achieving this: participants were willing to do so, and the overall process was not prohibitively arduous. We also found some support for the hypothesis that use of study templates may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken. an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2023
DA  - 2023-01-27
JO  - {'id': 'https://openalex.org/S4210239046', 'issn_l': '2046-1402', 'issn': ['2046-1402'], 'display_name': 'F1000Research', 'publisher': 'Faculty of 1000', 'type': 'journal', 'url': 'https://f1000research.com/articles/11-1036/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Amanda Legate
AU  - Kim Nimon
ER  - 

417.
TY  - book-chapter
ID  - https://openalex.org/W4318620127
DO  - https://doi.org/10.1007/978-3-031-14339-7_3
TI  - Clinical Neuroinnovation: Ethical Frameworks and Emerging Issues
AB  - No Abstract Found
PY  - 2023
DA  - 2023-01-01
JO  - {'id': 'https://openalex.org/S4306463941', 'issn_l': None, 'issn': None, 'display_name': 'Springer International Publishing eBooks', 'publisher': 'Springer Nature', 'type': 'ebook platform', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Max Kasun
AU  - Laura B. Dunn
AU  - Barton W. Palmer
AU  - Jane Paik Kim
AU  - Laura Weiss Roberts
ER  - 

418.
TY  - journal-article
ID  - https://openalex.org/W4318664208
DO  - https://doi.org/10.2196/35568
TI  - Automating Quality Assessment of Medical Evidence in Systematic Reviews (Preprint)
AB  - Assessment of the quality of medical evidence available online is a critical step in the systematic review of clinical evidence. Existing tools that automate parts of this task validate the quality of individual studies but not of entire bodies of evidence, and focus on a restricted set of quality criteria.We propose a quality assessment task that consists of providing an overall quality rating for each outcome, as well as finer-grained justification for different quality criteria according to the GRADE formalisation framework. For this, we construct a new dataset and develop a machine-learning baseline system (EvidenceGRADEr). Our goal is to work towards evaluating the quality of a body of evidence (BoE) for a specific clinical question, rather than assessing the quality of individual primary studies.We algorithmically extracted quality-related data from all summaries of findings found in the Cochrane Database of Systematic Reviews (CDSR). Each BoE is defined by a set of PICO criteria (population-intervention-comparison-outcome) and assigned a quality grade (high/moderate/low/very low) together with quality criteria (justification) that influenced that decision. Different statistical data, metadata about the review, and parts of review text are extracted as support for grading each BoE. After pruning the resulting dataset with various quality checks, we used it to train several variants of a feature-rich neural model. The predictions were compared against the labels originally assigned by the authors of the systematic reviews.Our quality assessment dataset, CDSR-QoE, contains 13,440 instances, or BoEs labelled for quality, originating from 2,252 systematic reviews published on the Internet in the years 2002--2020. Based on 10-fold cross-validation, the best neural binary classifiers for quality criteria detect risk of bias at .78 F1 (P: .68, R: .92) and imprecision at .75 F1 (P: .66, R: .86), while the performance on inconsistency, indirectness and publication bias criteria is lower (F1 in the range of .3-.4). The prediction of the overall quality grade into one of the four levels results in 0.5 F1. When casting the task as a binary problem by merging the GRADE classes (high+moderate vs. low+very low quality evidence), we attain .74 F1. We also find that the results vary depending on what supporting information is provided as input to the models.There are different factors affecting the quality of evidence in the context of systematic reviews of medical evidence. Some of them (risk of bias and imprecision) can be automated with reasonable accuracy. Other quality dimensions such as indirectness, inconsistency, and publication bias prove more challenging for machine learning, largely because they are much rarer. This technology could substantially reduce reviewer workload in the future and expedite quality assessment as part of evidence synthesis. such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken. an SR project and publish the review was 67.3 weeks (SD, 31.0; range, 6-186 weeks). Funded SRs reported significantly greater time to complete and publish (mean, 42 vs 26 weeks) and involved more authors and team members (mean, 6.8 vs 4.8 people) than those SRs not reporting funding (P&lt;.001 for both).8 Time needed to develop SRs can be expected to increase as the number of journals and publications are continually increasing.8Perhaps the most important challenge for SRs that is remedied by LSRs is keeping information updated with important changes in evidence as they become available.5 Findings from a seminal study in 2007 highlighted the relatively short lifespan of SRs and thus the issues with currency and accuracy.5 Using a survival analysis of 100 quantitative SRs relevant to clinical practice, researchers found a median survival of 5.5 years (CI, 4.6 to 7.6 years) with signals for updating occurring within 2 years (23%), 1 year (15%), and before publication (7%).5 These results called into question the currency of clinicians’ knowledge.Advances in technology support LSRs as a method for continually updating SRs to maintain currency, accuracy, and usefulness of information.4 These technologies allow LSRs to benefit from predefined methods for search frequency, as well as to describe when and how new evidence is incorporated into the LSR.4 Most important, these technologies provide LSRs the ability to actively monitor evidence and immediately flag and communicate updates to users when data, information, new research, or evidence becomes available.6The most important enabling technology for LSRs is machine learning (ML).6 Machine learning is an application of artificial intelligence (AI) technology that allows it to automatically learn and improve from experience without being explicitly programmed.9 Machine learning tools play an important role in improving efficiency by automating human tasks associated with SRs such as searching, screening, and data extraction.10Machine learning is useful in the search task for identifying relevant research to create a new LSR or update an existing LSR. Two key areas are filtering articles by study design and finding relevant articles by topic to include.10 Machine learning classifiers can screen large volumes of research to predict the class of given data points.11 As an example, ML text classifiers are used to predict how well a new citation describes randomized controlled trials.3,10Another use of ML is in the screening task of SRs.10 In this case, an ML classifier can be trained to screen titles and abstracts and prioritize them for manual review.10 Machine learning data or information extraction tools are used to select studies for inclusion in creating or updating LSRs.3 These tools can highlight relevant text or make suggestions to users.10It is important to note that not every SR requires an LSR. An LSR is considered appropriate when (1) the review question is of sufficient priority to justify resource allocation needed for the LSR, (2) there is inadequate evidence to answer the review question to the level of certainty, and (3) research on the review question is moving relatively quickly, making it likely there is emerging evidence impacting conclusions.6 As a cognitive technology, an LSR is a good solution for providing clinicians with needed information while preventing cognitive overload, especially during a pandemic when more than 10 000 articles per month were produced on COVID-19 during the first year.12Living systematic reviews substantially enhance the translation of knowledge into nursing practice; they do this primarily through currency, keeping evidence as up-to-date as possible.13 The addition of currency, in turn, substantially improves accuracy and usefulness of evidence being used in nursing practice, driving better outcomes.13 The need for improved translation of knowledge about COVID-19 will continue for many years to come.Patients’ needs resulting from the current pandemic will become relevant to every health care setting as survivors deal with short-term and long-term effects. There are disabilities stemming from damage to lungs, the brain, kidneys, and the heart and liver, including those requiring associated transplants. There is also evolving knowledge on chronic COVID syndrome, sometimes referred to as “long-COVID,” experienced by “COVID long-haulers.”14 People who had mild symptoms of COVID-19 and were not hospitalized may present to health care professionals with persistent or late symptoms.15 Myriad psychosocial and economic issues resulting from the pandemic will require health care resources to address. And there are likely health-related issues we have yet to uncover.Meanwhile, technology continues to advance, creating better support for nurses’ information needs. It is important for nurses to appreciate, as previously mentioned, that the gap between medical discovery and dissemination in clinical practice is closing, creating numerous opportunities for nurses in leadership, informatics, clinical education, academic education, research, quality, and safety.2 Nurses must lead information technology solutions to ensure that, in this new technology ecosystem, the needs of nurses are accurately understood and the best mechanisms to receive information are created, implemented, and continually evaluated and updated as needed.Nurses should consider connecting to newer and more reliable curated resources, ideally LSRs. Clinicians discovered quickly during the pandemic that information rapidly evolves as researchers continue to examine safer and more effective evaluation methods and treatments.12 One resource worth exploring is the COVID-19 LSR COVID-NMA, an international research initiative sponsored by the World Health Organization and Cochrane (https://covid-nma.com). Another resource is the COVID-19 Evidence Reviews by the US Veterans’ Affairs Evidence Synthesis Program, which includes both traditional SRs as well as LSRs (https://www.covid19reviews.org). There are also good resources that are not LSRs, but it is worth noting the difference; these other resources include a compilation of research studies, including more recent ones, but do not provide the synthesis and currency of the body of evidence as compared with an LSR. Other resources of these types include the site by the Society of Critical Care Medicine, which offers research on COVID-19 specific to critical care (https://www.sccm.org/Disaster/COVID19/COVID-19-Literature) and the COVID-19 Global Clinical Knowledge Base by University of California San Francisco Health Hospital Epidemiology and Infection Prevention, a curated directory of publicly available practice guidelines, clinical protocols, and other COVID-19 resources (https://infectioncontrol.ucsfmedicalcenter.org/covid-kb).The first case of COVID-19 was reported on November 17, 2019.16 At that time, neither the virus nor the disease had a name, creating challenges in reporting on the virus in the research literature.16 Reporting was further complicated by the requirement of journal submission systems for a prescribed number of keywords. As a result, authors created terms such as “Whahan Pneumonia,” “Coronavirus 2019,” or “Wuhan Seafood Market Pneumonia Virus.”16 Technologies associated with LSRs can enable more rapid linkages between disparate terms. Editorial boards of journals should review their policies that may hinder sudden, urgent, and widespread information needs such as occurs in a pandemic. Use of current and reliable information is inextricably tied to nursing practice and patient outcomes.An LSR is a curation method that keeps SRs current as new evidence becomes available and is essential in advancing nursing practice and improving patient outcomes. The need for current and relevant information becomes more critical in a novel pandemic, when development and turnover of information accelerates. With the COVID-19 pandemic, this resulted in a health care environment where clinicians initially struggled to find reliable information to effectively treat a rapidly growing number of extremely sick and dying patients. Living systematic reviews provided a method for rethinking conventional research review processes, automating some of the human tasks to improve the efficiency and effectiveness of information delivery. Curations for COVID-19 will be needed for years to come, and technology will continue to advance to better support nurses’ information needs. Nurses must be involved to ensure ongoing success.
PY  - 2021
DA  - 2021-12-12
JO  - {'id': 'https://openalex.org/V17147534', 'issn_l': '1438-8871', 'issn': ['1439-4456', '1438-8871'], 'display_name': 'Journal of Medical Internet Research', 'publisher': 'JMIR Publications', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Simon Šuster
AU  - Timothy Baldwin
AU  - Jey Han Lau
AU  - Antonio Jimeno Yepes
AU  - David Martinez Iraola
AU  - Yulia Otmakhova
AU  - Karin Verspoor
ER  - 

419.
TY  - journal-article
ID  - https://openalex.org/W4320491552
DO  - https://doi.org/10.1002/leap.1514
TI  - The future of scientific journals: The rise of <scp>UniAI</scp>
AB  - No Abstract Found
PY  - 2023
DA  - 2023-02-13
JO  - {'id': 'https://openalex.org/S29676049', 'issn_l': '0953-1513', 'issn': ['0953-1513', '1741-4857'], 'display_name': 'Learned Publishing', 'publisher': 'Wiley', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Farrokh Habibzadeh
ER  - 

420.
TY  - journal-article
ID  - https://openalex.org/W3118615836
DO  - https://doi.org/10.1136/bmj.n71
TI  - The PRISMA 2020 statement: an updated guideline for reporting systematic reviews
AB  - The Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) statement, published in 2009, was designed to help systematic reviewers transparently report why the review was done, what the authors did, and what they found. Over the past decade, advances in systematic review methodology and terminology have necessitated an update to the guideline. The PRISMA 2020 statement replaces the 2009 statement and includes new reporting guidance that reflects advances in methods to identify, select, appraise, and synthesise studies. The structure and presentation of the items have been modified to facilitate implementation. In this article, we present the PRISMA 2020 27-item checklist, an expanded checklist that details reporting recommendations for each item, the PRISMA 2020 abstract checklist, and the revised flow diagrams for original and updated reviews.
PY  - 2021
DA  - 2021-03-29
JO  - {'id': 'https://openalex.org/S4210185579', 'issn_l': '1756-1833', 'issn': ['1756-1833'], 'display_name': 'BMJ', 'publisher': 'BMJ', 'type': 'journal', 'url': 'https://www.bmj.com/content/bmj/372/bmj.n71.full.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Matthew J. Page
AU  - Joanne E. McKenzie
AU  - Patrick M.M. Bossuyt
AU  - Isabelle Boutron
AU  - Tammy Hoffmann
AU  - Cynthia D. Mulrow
AU  - Larissa Shamseer
AU  - Jennifer Tetzlaff
AU  - Elie A. Akl
AU  - Sue E. Brennan
AU  - Roger Chou
AU  - Julie Glanville
AU  - Jeremy M. Grimshaw
AU  - Asbjørn Hróbjartsson
AU  - Manoj M. Lalu
AU  - Tianjing Li
AU  - Elizabeth Loder
AU  - Evan Mayo-Wilson
AU  - Steve McDonald
AU  - Adrian M. Price-Whelan
AU  - Lesley A. Stewart
AU  - James D. Thomas
AU  - Andrea C. Tricco
AU  - Vivian Welch
AU  - Penny Whiting
AU  - David Moher
ER  - 

421.
TY  - journal-article
ID  - https://openalex.org/W2560438049
DO  - https://doi.org/10.1186/s13643-016-0384-4
TI  - Rayyan—a web and mobile app for systematic reviews
AB  - Synthesis of multiple randomized controlled trials (RCTs) in a systematic review can summarize the effects of individual outcomes and provide numerical answers about the effectiveness of interventions. Filtering of searches is time consuming, and no single method fulfills the principal requirements of speed with accuracy. Automation of systematic reviews is driven by a necessity to expedite the availability of current best evidence for policy and clinical decision-making. We developed Rayyan ( http://rayyan.qcri.org ), a free web and mobile app, that helps expedite the initial screening of abstracts and titles using a process of semi-automation while incorporating a high level of usability. For the beta testing phase, we used two published Cochrane reviews in which included studies had been selected manually. Their searches, with 1030 records and 273 records, were uploaded to Rayyan. Different features of Rayyan were tested using these two reviews. We also conducted a survey of Rayyan's users and collected feedback through a built-in feature.Pilot testing of Rayyan focused on usability, accuracy against manual methods, and the added value of the prediction feature. The "taster" review (273 records) allowed a quick overview of Rayyan for early comments on usability. The second review (1030 records) required several iterations to identify the previously identified 11 trials. The "suggestions" and "hints," based on the "prediction model," appeared as testing progressed beyond five included studies. Post rollout user experiences and a reflexive response by the developers enabled real-time modifications and improvements. The survey respondents reported 40% average time savings when using Rayyan compared to others tools, with 34% of the respondents reporting more than 50% time savings. In addition, around 75% of the respondents mentioned that screening and labeling studies as well as collaborating on reviews to be the two most important features of Rayyan. As of November 2016, Rayyan users exceed 2000 from over 60 countries conducting hundreds of reviews totaling more than 1.6M citations. Feedback from users, obtained mostly through the app web site and a recent survey, has highlighted the ease in exploration of searches, the time saved, and simplicity in sharing and comparing include-exclude decisions. The strongest features of the app, identified and reported in user feedback, were its ability to help in screening and collaboration as well as the time savings it affords to users.Rayyan is responsive and intuitive in use with significant potential to lighten the load of reviewers.
PY  - 2016
DA  - 2016-12-05
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://systematicreviewsjournal.biomedcentral.com/track/pdf/10.1186/s13643-016-0384-4', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Mourad Ouzzani
AU  - Hossam M. Hammady
AU  - Zbys Fedorowicz
AU  - Ahmed K. Elmagarmid
ER  - 

422.
TY  - journal-article
ID  - https://openalex.org/W3144543375
DO  - https://doi.org/10.1186/s13643-021-01626-4
TI  - The PRISMA 2020 statement: an updated guideline for reporting systematic reviews
AB  - The Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) statement, published in 2009, was designed to help systematic reviewers transparently report why the review was done, what the authors did, and what they found. Over the past decade, advances in systematic review methodology and terminology have necessitated an update to the guideline. The PRISMA 2020 statement replaces the 2009 statement and includes new reporting guidance that reflects advances in methods to identify, select, appraise, and synthesise studies. The structure and presentation of the items have been modified to facilitate implementation. In this article, we present the PRISMA 2020 27-item checklist, an expanded checklist that details reporting recommendations for each item, the PRISMA 2020 abstract checklist, and the revised flow diagrams for original and updated reviews. 273 records, were uploaded to Rayyan. Different features of Rayyan were tested using these two reviews. We also conducted a survey of Rayyan's users and collected feedback through a built-in feature.Pilot testing of Rayyan focused on usability, accuracy against manual methods, and the added value of the prediction feature. The "taster" review (273 records) allowed a quick overview of Rayyan for early comments on usability. The second review (1030 records) required several iterations to identify the previously identified 11 trials. The "suggestions" and "hints," based on the "prediction model," appeared as testing progressed beyond five included studies. Post rollout user experiences and a reflexive response by the developers enabled real-time modifications and improvements. The survey respondents reported 40% average time savings when using Rayyan compared to others tools, with 34% of the respondents reporting more than 50% time savings. In addition, around 75% of the respondents mentioned that screening and labeling studies as well as collaborating on reviews to be the two most important features of Rayyan. As of November 2016, Rayyan users exceed 2000 from over 60 countries conducting hundreds of reviews totaling more than 1.6M citations. Feedback from users, obtained mostly through the app web site and a recent survey, has highlighted the ease in exploration of searches, the time saved, and simplicity in sharing and comparing include-exclude decisions. The strongest features of the app, identified and reported in user feedback, were its ability to help in screening and collaboration as well as the time savings it affords to users.Rayyan is responsive and intuitive in use with significant potential to lighten the load of reviewers.
PY  - 2021
DA  - 2021-03-29
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://systematicreviewsjournal.biomedcentral.com/track/pdf/10.1186/s13643-021-01626-4', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Matthew J. Page
AU  - Joanne E. McKenzie
AU  - Patrick M.M. Bossuyt
AU  - Isabelle Boutron
AU  - Tammy Hoffmann
AU  - Cynthia D. Mulrow
AU  - Larissa Shamseer
AU  - Jennifer Tetzlaff
AU  - Elie A. Akl
AU  - Sue E. Brennan
AU  - Roger Chou
AU  - Julie Glanville
AU  - Jeremy M. Grimshaw
AU  - Asbjørn Hróbjartsson
AU  - Manoj M. Lalu
AU  - Tianjing Li
AU  - Elizabeth Loder
AU  - Evan Mayo-Wilson
AU  - Steve McDonald
AU  - Adrian M. Price-Whelan
AU  - Lesley A. Stewart
AU  - James D. Thomas
AU  - Andrea C. Tricco
AU  - Vivian Welch
AU  - Penny Whiting
AU  - David Moher
ER  - 

423.
TY  - journal-article
ID  - https://openalex.org/W3146142859
DO  - https://doi.org/10.1016/j.ijsu.2021.105906
TI  - The PRISMA 2020 statement: An updated guideline for reporting systematic reviews
AB  - The Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) statement, published in 2009, was designed to help systematic reviewers transparently report why the review was done, what the authors did, and what they found. Over the past decade, advances in systematic review methodology and terminology have necessitated an update to the guideline. The PRISMA 2020 statement replaces the 2009 statement and includes new reporting guidance that reflects advances in methods to identify, select, appraise, and synthesise studies. The structure and presentation of the items have been modified to facilitate implementation. In this article, we present the PRISMA 2020 27-item checklist, an expanded checklist that details reporting recommendations for each item, the PRISMA 2020 abstract checklist, and the revised flow diagrams for original and updated reviews. 273 records, were uploaded to Rayyan. Different features of Rayyan were tested using these two reviews. We also conducted a survey of Rayyan's users and collected feedback through a built-in feature.Pilot testing of Rayyan focused on usability, accuracy against manual methods, and the added value of the prediction feature. The "taster" review (273 records) allowed a quick overview of Rayyan for early comments on usability. The second review (1030 records) required several iterations to identify the previously identified 11 trials. The "suggestions" and "hints," based on the "prediction model," appeared as testing progressed beyond five included studies. Post rollout user experiences and a reflexive response by the developers enabled real-time modifications and improvements. The survey respondents reported 40% average time savings when using Rayyan compared to others tools, with 34% of the respondents reporting more than 50% time savings. In addition, around 75% of the respondents mentioned that screening and labeling studies as well as collaborating on reviews to be the two most important features of Rayyan. As of November 2016, Rayyan users exceed 2000 from over 60 countries conducting hundreds of reviews totaling more than 1.6M citations. Feedback from users, obtained mostly through the app web site and a recent survey, has highlighted the ease in exploration of searches, the time saved, and simplicity in sharing and comparing include-exclude decisions. The strongest features of the app, identified and reported in user feedback, were its ability to help in screening and collaboration as well as the time savings it affords to users.Rayyan is responsive and intuitive in use with significant potential to lighten the load of reviewers.
PY  - 2021
DA  - 2021-03-29
JO  - {'id': 'https://openalex.org/S67965910', 'issn_l': '1743-9159', 'issn': ['1743-9191', '1743-9159'], 'display_name': 'International Journal of Surgery', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Matthew J. Page
AU  - Joanne E. McKenzie
AU  - Patrick M.M. Bossuyt
AU  - Isabelle Boutron
AU  - Tammy Hoffmann
AU  - Cynthia D. Mulrow
AU  - Larissa Shamseer
AU  - Jennifer Tetzlaff
AU  - Elie A. Akl
AU  - Sue E. Brennan
AU  - Roger Chou
AU  - Julie Glanville
AU  - Jeremy M. Grimshaw
AU  - Asbjørn Hróbjartsson
AU  - Manoj M. Lalu
AU  - Tianjing Li
AU  - Elizabeth Loder
AU  - Evan Mayo-Wilson
AU  - Steve McDonald
AU  - Adrian M. Price-Whelan
AU  - Lesley A. Stewart
AU  - James D. Thomas
AU  - Andrea C. Tricco
AU  - Vivian Welch
AU  - Penny Whiting
AU  - David Moher
ER  - 

424.
TY  - journal-article
ID  - https://openalex.org/W3148962211
DO  - https://doi.org/10.1371/journal.pmed.1003583
TI  - The PRISMA 2020 statement: An updated guideline for reporting systematic reviews
AB  - Matthew Page and co-authors describe PRISMA 2020, an updated reporting guideline for systematic reviews and meta-analyses. to help systematic reviewers transparently report why the review was done, what the authors did, and what they found. Over the past decade, advances in systematic review methodology and terminology have necessitated an update to the guideline. The PRISMA 2020 statement replaces the 2009 statement and includes new reporting guidance that reflects advances in methods to identify, select, appraise, and synthesise studies. The structure and presentation of the items have been modified to facilitate implementation. In this article, we present the PRISMA 2020 27-item checklist, an expanded checklist that details reporting recommendations for each item, the PRISMA 2020 abstract checklist, and the revised flow diagrams for original and updated reviews. 273 records, were uploaded to Rayyan. Different features of Rayyan were tested using these two reviews. We also conducted a survey of Rayyan's users and collected feedback through a built-in feature.Pilot testing of Rayyan focused on usability, accuracy against manual methods, and the added value of the prediction feature. The "taster" review (273 records) allowed a quick overview of Rayyan for early comments on usability. The second review (1030 records) required several iterations to identify the previously identified 11 trials. The "suggestions" and "hints," based on the "prediction model," appeared as testing progressed beyond five included studies. Post rollout user experiences and a reflexive response by the developers enabled real-time modifications and improvements. The survey respondents reported 40% average time savings when using Rayyan compared to others tools, with 34% of the respondents reporting more than 50% time savings. In addition, around 75% of the respondents mentioned that screening and labeling studies as well as collaborating on reviews to be the two most important features of Rayyan. As of November 2016, Rayyan users exceed 2000 from over 60 countries conducting hundreds of reviews totaling more than 1.6M citations. Feedback from users, obtained mostly through the app web site and a recent survey, has highlighted the ease in exploration of searches, the time saved, and simplicity in sharing and comparing include-exclude decisions. The strongest features of the app, identified and reported in user feedback, were its ability to help in screening and collaboration as well as the time savings it affords to users.Rayyan is responsive and intuitive in use with significant potential to lighten the load of reviewers.
PY  - 2021
DA  - 2021-03-29
JO  - {'id': 'https://openalex.org/S197939330', 'issn_l': '1549-1277', 'issn': ['1549-1676', '1549-1277'], 'display_name': 'PLOS Medicine', 'publisher': 'Public Library of Science', 'type': 'journal', 'url': 'https://journals.plos.org/plosmedicine/article/file?id=10.1371/journal.pmed.1003583&type=printable', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Matthew J. Page
AU  - Joanne E. McKenzie
AU  - Patrick M.M. Bossuyt
AU  - Isabelle Boutron
AU  - Tammy Hoffmann
AU  - Cynthia D. Mulrow
AU  - Larissa Shamseer
AU  - Jennifer Tetzlaff
AU  - Elie A. Akl
AU  - Sue E. Brennan
AU  - Roger Chou
AU  - Julie Glanville
AU  - Jeremy M. Grimshaw
AU  - Asbjørn Hróbjartsson
AU  - Manoj M. Lalu
AU  - Tianjing Li
AU  - Elizabeth Loder
AU  - Evan Mayo-Wilson
AU  - Steve McDonald
AU  - Adrian M. Price-Whelan
AU  - Lesley A. Stewart
AU  - James D. Thomas
AU  - Andrea C. Tricco
AU  - Vivian Welch
AU  - Penny Whiting
AU  - David Moher
ER  - 

425.
TY  - journal-article
ID  - https://openalex.org/W2755149525
DO  - https://doi.org/10.1016/j.jclinepi.2017.08.011
TI  - Living systematic reviews: 2. Combining human and machine effort
AB  - New approaches to evidence synthesis, which use human effort and machine automation in mutually reinforcing ways, can enhance the feasibility and sustainability of living systematic reviews. Human effort is a scarce and valuable resource, required when automation is impossible or undesirable, and includes contributions from online communities ("crowds") as well as more conventional contributions from review authors and information specialists. Automation can assist with some systematic review tasks, including searching, eligibility assessment, identification and retrieval of full-text reports, extraction of data, and risk of bias assessment. Workflows can be developed in which human effort and machine automation can each enable the other to operate in more effective and efficient ways, offering substantial enhancement to the productivity of systematic reviews. This paper describes and discusses the potential-and limitations-of new ways of undertaking specific tasks in living systematic reviews, identifying areas where these human/machine "technologies" are already in use, and where further research and development is needed. While the context is living systematic reviews, many of these enabling technologies apply equally to standard approaches to systematic reviewing. The "taster" review (273 records) allowed a quick overview of Rayyan for early comments on usability. The second review (1030 records) required several iterations to identify the previously identified 11 trials. The "suggestions" and "hints," based on the "prediction model," appeared as testing progressed beyond five included studies. Post rollout user experiences and a reflexive response by the developers enabled real-time modifications and improvements. The survey respondents reported 40% average time savings when using Rayyan compared to others tools, with 34% of the respondents reporting more than 50% time savings. In addition, around 75% of the respondents mentioned that screening and labeling studies as well as collaborating on reviews to be the two most important features of Rayyan. As of November 2016, Rayyan users exceed 2000 from over 60 countries conducting hundreds of reviews totaling more than 1.6M citations. Feedback from users, obtained mostly through the app web site and a recent survey, has highlighted the ease in exploration of searches, the time saved, and simplicity in sharing and comparing include-exclude decisions. The strongest features of the app, identified and reported in user feedback, were its ability to help in screening and collaboration as well as the time savings it affords to users.Rayyan is responsive and intuitive in use with significant potential to lighten the load of reviewers.
PY  - 2017
DA  - 2017-11-01
JO  - {'id': 'https://openalex.org/S64418186', 'issn_l': '0895-4356', 'issn': ['1878-5921', '0895-4356'], 'display_name': 'Journal of Clinical Epidemiology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'http://www.jclinepi.com/article/S0895435617306042/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc-nd'}
DP  - OpenAlex
AU  - James D. Thomas
AU  - Anna H Noel-Storr
AU  - Iain J. Marshall
AU  - Byron C. Wallace
AU  - Steve McDonald
AU  - Chris Mavergames
AU  - Paul Glasziou
AU  - Ian Shemilt
AU  - Anneliese Synnot
AU  - Tari Turner
AU  - Julian Elliott
ER  - 

426.
TY  - journal-article
ID  - https://openalex.org/W2961191798
DO  - https://doi.org/10.1186/s13643-019-1074-9
TI  - Toward systematic review automation: a practical guide to using machine learning tools in research synthesis
AB  - Technologies and methods to speed up the production of systematic reviews by reducing the manual labour involved have recently emerged. Automation has been proposed or used to expedite most steps of the systematic review process, including search, screening, and data extraction. However, how these technologies work in practice and when (and when not) to use them is often not clear to practitioners. In this practical guide, we provide an overview of current machine learning methods that have been proposed to expedite evidence synthesis. We also offer guidance on which of these are ready for use, their strengths and weaknesses, and how a systematic review team might go about using them in practice. enhancement to the productivity of systematic reviews. This paper describes and discusses the potential-and limitations-of new ways of undertaking specific tasks in living systematic reviews, identifying areas where these human/machine "technologies" are already in use, and where further research and development is needed. While the context is living systematic reviews, many of these enabling technologies apply equally to standard approaches to systematic reviewing. The "taster" review (273 records) allowed a quick overview of Rayyan for early comments on usability. The second review (1030 records) required several iterations to identify the previously identified 11 trials. The "suggestions" and "hints," based on the "prediction model," appeared as testing progressed beyond five included studies. Post rollout user experiences and a reflexive response by the developers enabled real-time modifications and improvements. The survey respondents reported 40% average time savings when using Rayyan compared to others tools, with 34% of the respondents reporting more than 50% time savings. In addition, around 75% of the respondents mentioned that screening and labeling studies as well as collaborating on reviews to be the two most important features of Rayyan. As of November 2016, Rayyan users exceed 2000 from over 60 countries conducting hundreds of reviews totaling more than 1.6M citations. Feedback from users, obtained mostly through the app web site and a recent survey, has highlighted the ease in exploration of searches, the time saved, and simplicity in sharing and comparing include-exclude decisions. The strongest features of the app, identified and reported in user feedback, were its ability to help in screening and collaboration as well as the time savings it affords to users.Rayyan is responsive and intuitive in use with significant potential to lighten the load of reviewers.
PY  - 2019
DA  - 2019-07-11
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://systematicreviewsjournal.biomedcentral.com/track/pdf/10.1186/s13643-019-1074-9', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Iain J. Marshall
AU  - Byron C. Wallace
ER  - 

427.
TY  - journal-article
ID  - https://openalex.org/W2774736760
DO  - https://doi.org/10.1007/s00423-017-1646-x
TI  - Optimal literature search for systematic reviews in surgery
AB  - No Abstract Found
PY  - 2018
DA  - 2018-02-01
JO  - {'id': 'https://openalex.org/S133324295', 'issn_l': '1435-2443', 'issn': ['1435-2443', '1435-2451'], 'display_name': "Langenbeck's Archives of Surgery", 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Käthe Goossen
AU  - Solveig Tenckhoff
AU  - Pascal Probst
AU  - Kathrin Grummich
AU  - André L. Mihaljevic
AU  - Markus W. Büchler
AU  - Markus K. Diener
ER  - 

428.
TY  - journal-article
ID  - https://openalex.org/W2955273711
DO  - https://doi.org/10.1186/s12874-019-0782-0
TI  - Single screening versus conventional double screening for study selection in systematic reviews: a methodological systematic review
AB  - Stringent requirements exist regarding the transparency of the study selection process and the reliability of results. A 2-step selection process is generally recommended; this is conducted by 2 reviewers independently of each other (conventional double-screening). However, the approach is resource intensive, which can be a problem, as systematic reviews generally need to be completed within a defined period with a limited budget. The aim of the following methodological systematic review was to analyse the evidence available on whether single screening is equivalent to double screening in the screening process conducted in systematic reviews.We searched Medline, PubMed and the Cochrane Methodology Register (last search 10/2018). We also used supplementary search techniques and sources ("similar articles" function in PubMed, conference abstracts and reference lists). We included all evaluations comparing single with double screening. Data were summarized in a structured, narrative way.The 4 evaluations included investigated a total of 23 single screenings (12 sets for screening involving 9 reviewers). The median proportion of missed studies was 5% (range 0 to 58%). The median proportion of missed studies was 3% for the 6 experienced reviewers (range: 0 to 21%) and 13% for the 3 reviewers with less experience (range: 0 to 58%). The impact of missing studies on the findings of meta-analyses had been reported in 2 evaluations for 7 single screenings including a total of 18,148 references. In 3 of these 7 single screenings - all conducted by the same reviewer (with less experience) - the findings would have changed substantially. The remaining 4 of these 7 screenings were conducted by experienced reviewers and the missing studies had no impact or a negligible on the findings of the meta-analyses.Single screening of the titles and abstracts of studies retrieved in bibliographic searches is not equivalent to double screening, as substantially more studies are missed. However, in our opinion such an approach could still represent an appropriate methodological shortcut in rapid reviews, as long as it is conducted by an experienced reviewer. Further research on single screening is required, for instance, regarding factors influencing the number of studies missed. comparing include-exclude decisions. The strongest features of the app, identified and reported in user feedback, were its ability to help in screening and collaboration as well as the time savings it affords to users.Rayyan is responsive and intuitive in use with significant potential to lighten the load of reviewers.
PY  - 2019
DA  - 2019-06-28
JO  - {'id': 'https://openalex.org/S185874209', 'issn_l': '1471-2288', 'issn': ['1471-2288'], 'display_name': 'BMC Medical Research Methodology', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://bmcmedresmethodol.biomedcentral.com/track/pdf/10.1186/s12874-019-0782-0.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Siw Waffenschmidt
AU  - Marco Knelangen
AU  - Wiebke Sieben
AU  - Stefanie Bühn
AU  - Dawid Pieper
ER  - 

429.
TY  - journal-article
ID  - https://openalex.org/W2973631095
DO  - https://doi.org/10.1111/hir.12276
TI  - Meeting the review family: exploring review types and associated information retrieval requirements
AB  - The last decade has witnessed increased recognition of the value of literature reviews for advancing understanding and decision making. This has been accompanied by an expansion in the range of methodological approaches and types of review. However, there remains uncertainty over definitions and search requirements beyond those for the 'traditional' systematic review. This study aims to characterise health related reviews by type and to provide recommendations on appropriate methods of information retrieval based on the available guidance.A list of review types was generated from published typologies and categorised into 'families' based on their common features. Guidance on information retrieval for each review type was identified by searching pubmed, medline and Google Scholar, supplemented by scrutinising websites of review producing organisations.Forty-eight review types were identified and categorised into seven families. Published guidance reveals increasing specification of methods for information retrieval; however, much of it remains generic with many review types lacking explicit requirements for the identification of evidence.Defining review types and utilising appropriate search methods remain challenging. By familiarising themselves with a range of review methodologies and associated search methods, information specialists will be better equipped to select suitable approaches for future projects. less experience (range: 0 to 58%). The impact of missing studies on the findings of meta-analyses had been reported in 2 evaluations for 7 single screenings including a total of 18,148 references. In 3 of these 7 single screenings - all conducted by the same reviewer (with less experience) - the findings would have changed substantially. The remaining 4 of these 7 screenings were conducted by experienced reviewers and the missing studies had no impact or a negligible on the findings of the meta-analyses.Single screening of the titles and abstracts of studies retrieved in bibliographic searches is not equivalent to double screening, as substantially more studies are missed. However, in our opinion such an approach could still represent an appropriate methodological shortcut in rapid reviews, as long as it is conducted by an experienced reviewer. Further research on single screening is required, for instance, regarding factors influencing the number of studies missed. comparing include-exclude decisions. The strongest features of the app, identified and reported in user feedback, were its ability to help in screening and collaboration as well as the time savings it affords to users.Rayyan is responsive and intuitive in use with significant potential to lighten the load of reviewers.
PY  - 2019
DA  - 2019-09-01
JO  - {'id': 'https://openalex.org/S66051165', 'issn_l': '1471-1834', 'issn': ['1365-2532', '1471-1842', '0265-6647', '1471-1834'], 'display_name': 'Health Information and Libraries Journal', 'publisher': 'Wiley-Blackwell', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Anthea Sutton
AU  - Mark Clowes
AU  - Louise Preston
AU  - Andrew Booth
ER  - 

430.
TY  - journal-article
ID  - https://openalex.org/W3191480438
DO  - https://doi.org/10.1016/j.recesp.2021.06.016
TI  - Declaración PRISMA 2020: una guía actualizada para la publicación de revisiones sistemáticas
AB  - La declaración PRISMA ( Preferred Reporting Items for Systematic reviews and Meta-Analyses ), publicada en 2009, se diseñó para ayudar a los autores de revisiones sistemáticas a documentar de manera transparente el porqué de la revisión, qué hicieron los autores y qué encontraron. Durante la última década, ha habido muchos avances en la metodología y terminología de las revisiones sistemáticas, lo que ha requerido una actualización de esta guía. La declaración prisma 2020 sustituye a la declaración de 2009 e incluye una nueva guía de presentación de las publicaciones que refleja los avances en los métodos para identificar, seleccionar, evaluar y sintetizar estudios. La estructura y la presentación de los ítems ha sido modificada para facilitar su implementación. En este artículo, presentamos la lista de verificación PRISMA 2020 con 27 ítems, y una lista de verificación ampliada que detalla las recomendaciones en la publicación de cada ítem, la lista de verificación del resumen estructurado PRISMA 2020 y el diagrama de flujo revisado para revisiones sistemáticas. The Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) statement, published in 2009, was designed to help systematic reviewers transparently report why the review was done, what the authors did, and what they found. Over the past decade, advances in systematic review methodology and terminology have necessitated an update to the guideline. The PRISMA 2020 statement replaces the 2009 statement and includes new reporting guidance that reflects advances in methods to identify, select, appraise, and synthesise studies. The structure and presentation of the items have been modified to facilitate implementation. In this article, we present the PRISMA 2020 27-item checklist, an expanded checklist that details reporting recommendations for each item, the PRISMA 2020 abstract checklist, and the revised flow diagrams for original and updated reviews. Full English text available from : www.revespcardiol.org/en are missed. However, in our opinion such an approach could still represent an appropriate methodological shortcut in rapid reviews, as long as it is conducted by an experienced reviewer. Further research on single screening is required, for instance, regarding factors influencing the number of studies missed. comparing include-exclude decisions. The strongest features of the app, identified and reported in user feedback, were its ability to help in screening and collaboration as well as the time savings it affords to users.Rayyan is responsive and intuitive in use with significant potential to lighten the load of reviewers.
PY  - 2021
DA  - 2021-09-01
JO  - {'id': 'https://openalex.org/S69770752', 'issn_l': '0300-8932', 'issn': ['1579-2242', '0300-8932', '1577-3698'], 'display_name': 'Revista Espanola De Cardiologia', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'https://doi.org/10.1016/j.recesp.2021.06.016', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc-nd'}
DP  - OpenAlex
AU  - Juan José Yepes-Nuñez
AU  - Gerard Urrútia
AU  - Marta Romero-García
AU  - Sergio Alonso-Fernández
ER  - 

431.
TY  - journal-article
ID  - https://openalex.org/W3193329895
DO  - https://doi.org/10.1016/j.rec.2021.07.010
TI  - Declaración PRISMA 2020: una guía actualizada para la publicación de revisiones sistemáticas
AB  - The Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) statement, published in 2009, was designed to help systematic reviewers transparently report why the review was done, what the authors did, and what they found. Over the past decade, advances in systematic review methodology and terminology have necessitated an update to the guideline. The PRISMA 2020 statement replaces the 2009 statement and includes new reporting guidance that reflects advances in methods to identify, select, appraise, and synthesise studies. The structure and presentation of the items have been modified to facilitate implementation. In this article, we present the PRISMA 2020 27-item checklist, an expanded checklist that details reporting recommendations for each item, the PRISMA 2020 abstract checklist, and the revised flow diagrams for original and updated reviews. Full English text available from:www.revespcardiol.org/en. y una lista de verificación ampliada que detalla las recomendaciones en la publicación de cada ítem, la lista de verificación del resumen estructurado PRISMA 2020 y el diagrama de flujo revisado para revisiones sistemáticas. The Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) statement, published in 2009, was designed to help systematic reviewers transparently report why the review was done, what the authors did, and what they found. Over the past decade, advances in systematic review methodology and terminology have necessitated an update to the guideline. The PRISMA 2020 statement replaces the 2009 statement and includes new reporting guidance that reflects advances in methods to identify, select, appraise, and synthesise studies. The structure and presentation of the items have been modified to facilitate implementation. In this article, we present the PRISMA 2020 27-item checklist, an expanded checklist that details reporting recommendations for each item, the PRISMA 2020 abstract checklist, and the revised flow diagrams for original and updated reviews. Full English text available from : www.revespcardiol.org/en are missed. However, in our opinion such an approach could still represent an appropriate methodological shortcut in rapid reviews, as long as it is conducted by an experienced reviewer. Further research on single screening is required, for instance, regarding factors influencing the number of studies missed. comparing include-exclude decisions. The strongest features of the app, identified and reported in user feedback, were its ability to help in screening and collaboration as well as the time savings it affords to users.Rayyan is responsive and intuitive in use with significant potential to lighten the load of reviewers.
PY  - 2021
DA  - 2021-09-01
JO  - {'id': 'https://openalex.org/S4210221393', 'issn_l': '1885-5857', 'issn': ['1885-5857'], 'display_name': 'Revista española de cardiología', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'https://doi.org/10.1016/j.rec.2021.07.010', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc-nd'}
DP  - OpenAlex
AU  - Juan José Yepes-Nuñez
AU  - Gerard Urrútia
AU  - Marta Romero-García
AU  - Sergio Alonso-Fernández
ER  - 

432.
TY  - journal-article
ID  - https://openalex.org/W2794350945
DO  - https://doi.org/10.1186/s13750-018-0115-5
TI  - Online tools supporting the conduct and reporting of systematic reviews and systematic maps: a case study on CADIMA and review of existing tools
AB  - Systematic reviews and systematic maps represent powerful tools to identify, collect, evaluate and summarise primary research pertinent to a specific research question or topic in a highly standardised and reproducible manner. Even though they are seen as the “gold standard” when synthesising primary research, systematic reviews and maps are typically resource-intensive and complex activities. Thus, managing the conduct and reporting of such reviews can become a time consuming and challenging task. This paper introduces the open access online tool CADIMA, which was developed through a collaboration between the Julius Kuhn-Institut and the Collaboration for Environmental Evidence, in order to increase the efficiency of the evidence synthesis process and facilitate reporting of all activities to maximise methodological rigour. Furthermore, we analyse how CADIMA compares with other available tools by providing a comprehensive summary of existing software designed for the purposes of systematic review management. We show that CADIMA is the only available open access tool that is designed to: (1) assist throughout the systematic review/map process; (2) be suited to reviews broader than medical sciences; (3) allow for offline data extraction; and, (4) support working as a review team. the review was done, what the authors did, and what they found. Over the past decade, advances in systematic review methodology and terminology have necessitated an update to the guideline. The PRISMA 2020 statement replaces the 2009 statement and includes new reporting guidance that reflects advances in methods to identify, select, appraise, and synthesise studies. The structure and presentation of the items have been modified to facilitate implementation. In this article, we present the PRISMA 2020 27-item checklist, an expanded checklist that details reporting recommendations for each item, the PRISMA 2020 abstract checklist, and the revised flow diagrams for original and updated reviews. Full English text available from : www.revespcardiol.org/en are missed. However, in our opinion such an approach could still represent an appropriate methodological shortcut in rapid reviews, as long as it is conducted by an experienced reviewer. Further research on single screening is required, for instance, regarding factors influencing the number of studies missed. comparing include-exclude decisions. The strongest features of the app, identified and reported in user feedback, were its ability to help in screening and collaboration as well as the time savings it affords to users.Rayyan is responsive and intuitive in use with significant potential to lighten the load of reviewers.
PY  - 2018
DA  - 2018-02-01
JO  - {'id': 'https://openalex.org/S2737036037', 'issn_l': '2047-2382', 'issn': ['2047-2382'], 'display_name': 'Environmental Evidence', 'publisher': 'BioMed Central', 'type': 'journal', 'url': 'https://doi.org/10.1186/s13750-018-0115-5', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Christian Kohl
AU  - Emma McIntosh
AU  - Stefan Unger
AU  - Neal R. Haddaway
AU  - Steffen Kecke
AU  - Joachim Schiemann
AU  - Ralf Wilhelm
ER  - 

433.
TY  - journal-article
ID  - https://openalex.org/W122374328
DO  - https://doi.org/10.4073/cmg.2016.1
TI  - Searching for studies: a guide to information retrieval for Campbell systematic reviews
AB  - No Abstract Found
PY  - 2017
DA  - 2017-01-01
JO  - {'id': 'https://openalex.org/S2739193000', 'issn_l': '1891-1803', 'issn': ['1891-1803'], 'display_name': 'Campbell Systematic Reviews', 'publisher': 'The Campbell Collaboration', 'type': 'journal', 'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.4073/cmg.2016.1', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Shannon Kugley
AU  - Anne Wade
AU  - James D. Thomas
AU  - Quenby Mahood
AU  - Anne-Marie Klint Jørgensen
AU  - Karianne Thune Hammerstrøm
AU  - Nila A Sathe
ER  - 

434.
TY  - journal-article
ID  - https://openalex.org/W2397182203
DO  - https://doi.org/10.1186/s13643-016-0263-z
TI  - SWIFT-Review: a text-mining workbench for systematic review
AB  - There is growing interest in using machine learning approaches to priority rank studies and reduce human burden in screening literature when conducting systematic reviews. In addition, identifying addressable questions during the problem formulation phase of systematic review can be challenging, especially for topics having a large literature base. Here, we assess the performance of the SWIFT-Review priority ranking algorithm for identifying studies relevant to a given research question. We also explore the use of SWIFT-Review during problem formulation to identify, categorize, and visualize research areas that are data rich/data poor within a large literature corpus.Twenty case studies, including 15 public data sets, representing a range of complexity and size, were used to assess the priority ranking performance of SWIFT-Review. For each study, seed sets of manually annotated included and excluded titles and abstracts were used for machine training. The remaining references were then ranked for relevance using an algorithm that considers term frequency and latent Dirichlet allocation (LDA) topic modeling. This ranking was evaluated with respect to (1) the number of studies screened in order to identify 95 % of known relevant studies and (2) the "Work Saved over Sampling" (WSS) performance metric. To assess SWIFT-Review for use in problem formulation, PubMed literature search results for 171 chemicals implicated as EDCs were uploaded into SWIFT-Review (264,588 studies) and categorized based on evidence stream and health outcome. Patterns of search results were surveyed and visualized using a variety of interactive graphics.Compared with the reported performance of other tools using the same datasets, the SWIFT-Review ranking procedure obtained the highest scores on 11 out of 15 of the public datasets. Overall, these results suggest that using machine learning to triage documents for screening has the potential to save, on average, more than 50 % of the screening effort ordinarily required when using un-ordered document lists. In addition, the tagging and annotation capabilities of SWIFT-Review can be useful during the activities of scoping and problem formulation.Text-mining and machine learning software such as SWIFT-Review can be valuable tools to reduce the human screening burden and assist in problem formulation. include-exclude decisions. The strongest features of the app, identified and reported in user feedback, were its ability to help in screening and collaboration as well as the time savings it affords to users.Rayyan is responsive and intuitive in use with significant potential to lighten the load of reviewers.
PY  - 2016
DA  - 2016-05-23
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://doi.org/10.1186/s13643-016-0263-z', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Brian M. Howard
AU  - Jason J. Phillips
AU  - Kyle M. Miller
AU  - Arpit Tandon
AU  - Deepak Mav
AU  - Mihir M. Shah
AU  - Stephanie Holmgren
AU  - Katherine E. Pelch
AU  - Vickie R. Walker
AU  - Andrew A. Rooney
AU  - Malcolm R. Macleod
AU  - Ruchir R. Shah
AU  - Kristina A. Thayer
ER  - 

435.
TY  - journal-article
ID  - https://openalex.org/W2285413972
DO  - https://doi.org/10.1186/s12916-016-0555-0
TI  - Wasted research when systematic reviews fail to provide a complete and up-to-date evidence synthesis: the example of lung cancer
AB  - Multiple treatments are frequently available for a given condition, and clinicians and patients need a comprehensive, up-to-date synthesis of evidence for all competing treatments. We aimed to quantify the waste of research related to the failure of systematic reviews to provide a complete and up-to-date evidence synthesis over time.We performed a series of systematic overviews and networks of randomized trials assessing the gap between evidence covered by systematic reviews and available trials of second-line treatments for advanced non-small cell lung cancer. We searched the Cochrane Database of Systematic Reviews, Database of Abstracts of Reviews of Effects, MEDLINE, EMBASE, and other resources sequentially by year from 2009 to March 2, 2015. We sequentially compared the amount of evidence missing from systematic reviews to the randomized evidence available for inclusion each year. We constructed cumulative networks of randomized evidence over time and evaluated the proportion of trials, patients, treatments, and treatment comparisons not covered by systematic reviews on December 31 each year from 2009 to 2015.We identified 77 trials (28,636 patients) assessing 47 treatments with 54 comparisons and 29 systematic reviews (13 published after 2013). From 2009 to 2015, the evidence covered by existing systematic reviews was consistently incomplete: 45 % to 70 % of trials; 30 % to 58 % of patients; 40 % to 66 % of treatments; and 38 % to 71 % of comparisons were missing. In the cumulative networks of randomized evidence, 10 % to 17 % of treatment comparisons were partially covered by systematic reviews and 55 % to 85 % were partially or not covered.We illustrate how systematic reviews of a given condition provide a fragmented, out-of-date panorama of the evidence for all treatments. This waste of research might be reduced by the development of live cumulative network meta-analyses. screening effort ordinarily required when using un-ordered document lists. In addition, the tagging and annotation capabilities of SWIFT-Review can be useful during the activities of scoping and problem formulation.Text-mining and machine learning software such as SWIFT-Review can be valuable tools to reduce the human screening burden and assist in problem formulation. include-exclude decisions. The strongest features of the app, identified and reported in user feedback, were its ability to help in screening and collaboration as well as the time savings it affords to users.Rayyan is responsive and intuitive in use with significant potential to lighten the load of reviewers.
PY  - 2016
DA  - 2016-01-20
JO  - {'id': 'https://openalex.org/S135560524', 'issn_l': '1741-7015', 'issn': ['1741-7015'], 'display_name': 'BMC Medicine', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://bmcmedicine.biomedcentral.com/track/pdf/10.1186/s12916-016-0555-0', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Perrine Créquit
AU  - Ludovic Trinquart
AU  - Amélie Yavchitz
AU  - Philippe Ravaud
ER  - 

436.
TY  - journal-article
ID  - https://openalex.org/W3128349626
DO  - https://doi.org/10.1038/s42256-020-00287-7
TI  - An open source machine learning framework for efficient and transparent systematic reviews
AB  - To help researchers conduct a systematic review or meta-analysis as efficiently and transparently as possible, we designed a tool (ASReview) to accelerate the step of screening titles and abstracts. For many tasks - including but not limited to systematic reviews and meta-analyses - the scientific literature needs to be checked systematically. Currently, scholars and practitioners screen thousands of studies by hand to determine which studies to include in their review or meta-analysis. This is error prone and inefficient because of extremely imbalanced data: only a fraction of the screened studies is relevant. The future of systematic reviewing will be an interaction with machine learning algorithms to deal with the enormous increase of available text. We therefore developed an open source machine learning-aided pipeline applying active learning: ASReview. We demonstrate by means of simulation studies that ASReview can yield far more efficient reviewing than manual reviewing, while providing high quality. Furthermore, we describe the options of the free and open source research software and present the results from user experience tests. We invite the community to contribute to open source projects such as our own that provide measurable and reproducible improvements over current practice. reviews was consistently incomplete: 45 % to 70 % of trials; 30 % to 58 % of patients; 40 % to 66 % of treatments; and 38 % to 71 % of comparisons were missing. In the cumulative networks of randomized evidence, 10 % to 17 % of treatment comparisons were partially covered by systematic reviews and 55 % to 85 % were partially or not covered.We illustrate how systematic reviews of a given condition provide a fragmented, out-of-date panorama of the evidence for all treatments. This waste of research might be reduced by the development of live cumulative network meta-analyses. screening effort ordinarily required when using un-ordered document lists. In addition, the tagging and annotation capabilities of SWIFT-Review can be useful during the activities of scoping and problem formulation.Text-mining and machine learning software such as SWIFT-Review can be valuable tools to reduce the human screening burden and assist in problem formulation. include-exclude decisions. The strongest features of the app, identified and reported in user feedback, were its ability to help in screening and collaboration as well as the time savings it affords to users.Rayyan is responsive and intuitive in use with significant potential to lighten the load of reviewers.
PY  - 2021
DA  - 2021-02-01
JO  - {'id': 'https://openalex.org/S2912241403', 'issn_l': '2522-5839', 'issn': ['2522-5839'], 'display_name': 'Nature Machine Intelligence', 'publisher': 'Nature Portfolio', 'type': 'journal', 'url': 'https://www.nature.com/articles/s42256-020-00287-7.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Rens van de Schoot
AU  - Jonathan de Bruin
AU  - Raoul D. Schram
AU  - Parisa Zahedi
AU  - Jan de Boer
AU  - Felix Weijdema
AU  - Bianca Kramer
AU  - Martijn Huijts
AU  - Maarten Hoogerwerf
AU  - Gerbrich Ferdinands
AU  - Albert Harkema
AU  - Joukje Willemsen
AU  - Yongchao Ma
AU  - Qixiang Fang
AU  - Sybren Hindriks
AU  - Lars Tummers
AU  - Daniel L. Oberski
ER  - 

437.
TY  - journal-article
ID  - https://openalex.org/W2512040454
DO  - https://doi.org/10.1186/s13643-016-0315-4
TI  - Use of cost-effectiveness analysis to compare the efficiency of study identification methods in systematic reviews
AB  - Meta-research studies investigating methods, systems, and processes designed to improve the efficiency of systematic review workflows can contribute to building an evidence base that can help to increase value and reduce waste in research. This study demonstrates the use of an economic evaluation framework to compare the costs and effects of four variant approaches to identifying eligible studies for consideration in systematic reviews.A cost-effectiveness analysis was conducted using a basic decision-analytic model, to compare the relative efficiency of 'safety first', 'double screening', 'single screening' and 'single screening with text mining' approaches in the title-abstract screening stage of a 'case study' systematic review about undergraduate medical education in UK general practice settings. Incremental cost-effectiveness ratios (ICERs) were calculated as the 'incremental cost per citation 'saved' from inappropriate exclusion' from the review. Resource use and effect parameters were estimated based on retrospective analysis of 'review process' meta-data curated alongside the 'case study' review, in conjunction with retrospective simulation studies to model the integrated use of text mining. Unit cost parameters were estimated based on the 'case study' review's project budget. A base case analysis was conducted, with deterministic sensitivity analyses to investigate the impact of variations in values of key parameters.Use of 'single screening with text mining' would have resulted in title-abstract screening workload reductions (base case analysis) of >60 % compared with other approaches. Across modelled scenarios, the 'safety first' approach was, consistently, equally effective and less costly than conventional 'double screening'. Compared with 'single screening with text mining', estimated ICERs for the two non-dominated approaches (base case analyses) ranged from £1975 ('single screening' without a 'provisionally included' code) to £4427 ('safety first' with a 'provisionally included' code) per citation 'saved'. Patterns of results were consistent between base case and sensitivity analyses.Alternatives to the conventional 'double screening' approach, integrating text mining, warrant further consideration as potentially more efficient approaches to identifying eligible studies for systematic reviews. Comparable economic evaluations conducted using other systematic review datasets are needed to determine the generalisability of these findings and to build an evidence base to inform guidance for review authors. include-exclude decisions. The strongest features of the app, identified and reported in user feedback, were its ability to help in screening and collaboration as well as the time savings it affords to users.Rayyan is responsive and intuitive in use with significant potential to lighten the load of reviewers.
PY  - 2016
DA  - 2016-08-17
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://doi.org/10.1186/s13643-016-0315-4', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Ian Shemilt
AU  - Nada F. Khan
AU  - Sophie Park
AU  - James D. Thomas
ER  - 

438.
TY  - journal-article
ID  - https://openalex.org/W2413669350
DO  - https://doi.org/10.1016/j.jbi.2016.06.001
TI  - Topic detection using paragraph vectors to support active learning in systematic reviews
AB  - Systematic reviews require expert reviewers to manually screen thousands of citations in order to identify all relevant articles to the review. Active learning text classification is a supervised machine learning approach that has been shown to significantly reduce the manual annotation workload by semi-automating the citation screening process of systematic reviews. In this paper, we present a new topic detection method that induces an informative representation of studies, to improve the performance of the underlying active learner. Our proposed topic detection method uses a neural network-based vector space model to capture semantic similarities between documents. We firstly represent documents within the vector space, and cluster the documents into a predefined number of clusters. The centroids of the clusters are treated as latent topics. We then represent each document as a mixture of latent topics. For evaluation purposes, we employ the active learning strategy using both our novel topic detection method and a baseline topic model (i.e., Latent Dirichlet Allocation). Results obtained demonstrate that our method is able to achieve a high sensitivity of eligible studies and a significantly reduced manual annotation cost when compared to the baseline method. This observation is consistent across two clinical and three public health reviews. The tool introduced in this work is available from https://nactem.ac.uk/pvtopic/. screening workload reductions (base case analysis) of >60 % compared with other approaches. Across modelled scenarios, the 'safety first' approach was, consistently, equally effective and less costly than conventional 'double screening'. Compared with 'single screening with text mining', estimated ICERs for the two non-dominated approaches (base case analyses) ranged from £1975 ('single screening' without a 'provisionally included' code) to £4427 ('safety first' with a 'provisionally included' code) per citation 'saved'. Patterns of results were consistent between base case and sensitivity analyses.Alternatives to the conventional 'double screening' approach, integrating text mining, warrant further consideration as potentially more efficient approaches to identifying eligible studies for systematic reviews. Comparable economic evaluations conducted using other systematic review datasets are needed to determine the generalisability of these findings and to build an evidence base to inform guidance for review authors. include-exclude decisions. The strongest features of the app, identified and reported in user feedback, were its ability to help in screening and collaboration as well as the time savings it affords to users.Rayyan is responsive and intuitive in use with significant potential to lighten the load of reviewers.
PY  - 2016
DA  - 2016-08-01
JO  - {'id': 'https://openalex.org/S11622463', 'issn_l': '1532-0464', 'issn': ['1532-0480', '1532-0464'], 'display_name': 'Journal of Biomedical Informatics', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'https://doi.org/10.1016/j.jbi.2016.06.001', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Kazuma Hashimoto
AU  - Georgios Kontonatsios
AU  - Makoto Miwa
AU  - Sophia Ananiadou
ER  - 

439.
TY  - journal-article
ID  - https://openalex.org/W2953730938
DO  - https://doi.org/10.1002/jrsm.1369
TI  - The value of a second reviewer for study selection in systematic reviews
AB  - Although dual independent review of search results by two reviewers is generally recommended for systematic reviews, there are not consistent recommendations regarding the timing of the use of the second reviewer. This study compared the use of a complete dual review approach, with two reviewers in both the title/abstract screening stage and the full-text screening stage, as compared with a limited dual review approach, with two reviewers only in the full-text stage.This study was performed within the context of a large systematic review. Two reviewers performed a complete dual review of 15 000 search results and a limited dual review of 15 000 search results. The number of relevant studies mistakenly excluded by highly experienced reviewers in the complete dual review was compared with the number mistakenly excluded during the full-text stage of the limited dual review.In the complete dual review approach, an additional 6.6% to 9.1% of eligible studies were identified during the title/abstract stage by using two reviewers, and an additional 6.6% to 11.9% of eligible studies were identified during the full-text stage by using two reviewers. In the limited dual review approach, an additional 4.4% to 5.3% of eligible studies were identified with the use of two reviewers.Using a second reviewer throughout the entire study screening process can increase the number of relevant studies identified for use in a systematic review. Systematic review performers should consider using a complete dual review process to ensure all relevant studies are included in their review. with text mining', estimated ICERs for the two non-dominated approaches (base case analyses) ranged from £1975 ('single screening' without a 'provisionally included' code) to £4427 ('safety first' with a 'provisionally included' code) per citation 'saved'. Patterns of results were consistent between base case and sensitivity analyses.Alternatives to the conventional 'double screening' approach, integrating text mining, warrant further consideration as potentially more efficient approaches to identifying eligible studies for systematic reviews. Comparable economic evaluations conducted using other systematic review datasets are needed to determine the generalisability of these findings and to build an evidence base to inform guidance for review authors. include-exclude decisions. The strongest features of the app, identified and reported in user feedback, were its ability to help in screening and collaboration as well as the time savings it affords to users.Rayyan is responsive and intuitive in use with significant potential to lighten the load of reviewers.
PY  - 2019
DA  - 2019-12-01
JO  - {'id': 'https://openalex.org/S205768342', 'issn_l': '1759-2879', 'issn': ['1759-2879', '1759-2887'], 'display_name': 'Research Synthesis Methods', 'publisher': 'Wiley-Blackwell', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Carolyn R. T. Stoll
AU  - Sonya Izadi
AU  - Susan A. Fowler
AU  - Paige A. Green
AU  - Jerry Suls
AU  - Graham A. Colditz
ER  - 

440.
TY  - journal-article
ID  - https://openalex.org/W2301801058
DO  - https://doi.org/10.1186/s12889-016-2932-1
TI  - Text mining for identifying topics in the literatures about adolescent substance use and depression
AB  - Both adolescent substance use and adolescent depression are major public health problems, and have the tendency to co-occur. Thousands of articles on adolescent substance use or depression have been published. It is labor intensive and time consuming to extract huge amounts of information from the cumulated collections. Topic modeling offers a computational tool to find relevant topics by capturing meaningful structure among collections of documents.In this study, a total of 17,723 abstracts from PubMed published from 2000 to 2014 on adolescent substance use and depression were downloaded as objects, and Latent Dirichlet allocation (LDA) was applied to perform text mining on the dataset. Word clouds were used to visually display the content of topics and demonstrate the distribution of vocabularies over each topic.The LDA topics recaptured the search keywords in PubMed, and further discovered relevant issues, such as intervention program, association links between adolescent substance use and adolescent depression, such as sexual experience and violence, and risk factors of adolescent substance use, such as family factors and peer networks. Using trend analysis to explore the dynamics of proportion of topics, we found that brain research was assessed as a hot issue by the coefficient of the trend test.Topic modeling has the ability to segregate a large collection of articles into distinct themes, and it could be used as a tool to understand the literature, not only by recapturing known facts but also by discovering other relevant topics. all relevant studies are included in their review. with text mining', estimated ICERs for the two non-dominated approaches (base case analyses) ranged from £1975 ('single screening' without a 'provisionally included' code) to £4427 ('safety first' with a 'provisionally included' code) per citation 'saved'. Patterns of results were consistent between base case and sensitivity analyses.Alternatives to the conventional 'double screening' approach, integrating text mining, warrant further consideration as potentially more efficient approaches to identifying eligible studies for systematic reviews. Comparable economic evaluations conducted using other systematic review datasets are needed to determine the generalisability of these findings and to build an evidence base to inform guidance for review authors. include-exclude decisions. The strongest features of the app, identified and reported in user feedback, were its ability to help in screening and collaboration as well as the time savings it affords to users.Rayyan is responsive and intuitive in use with significant potential to lighten the load of reviewers.
PY  - 2016
DA  - 2016-03-19
JO  - {'id': 'https://openalex.org/S200437886', 'issn_l': '1471-2458', 'issn': ['1471-2458'], 'display_name': 'BMC Public Health', 'publisher': 'BioMed Central', 'type': 'journal', 'url': 'https://doi.org/10.1186/s12889-016-2932-1', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Shiheng Wang
AU  - Yijun Ding
AU  - Weizhong Zhao
AU  - Yung-Hsiang Huang
AU  - Roger Perkins
AU  - Wen Zou
AU  - James Ming Chen
ER  - 

441.
TY  - journal-article
ID  - https://openalex.org/W2999748455
DO  - https://doi.org/10.1146/annurev-publhealth-040119-094220
TI  - Partnerships, Processes, and Outcomes: A Health Equity–Focused Scoping Meta-Review of Community-Engaged Scholarship
AB  - In recent decades, there has been remarkable growth in scholarship examining the usefulness of community-engaged research (CEnR) and community-based participatory research (CBPR) for eliminating health inequities.This article seeks to synthesize the extant literature of systematic reviews, scoping reviews, and other related reviews regarding the context, processes, and research designs and interventions underlying CEnR that optimize its effectiveness. Through a scoping review, we have utilized an empirically derived framework of CBPR to map this literature and identify key findings and priorities for future research. Our study found 100 reviews of CEnR that largely support the CBPR conceptual framework. perform text mining on the dataset. Word clouds were used to visually display the content of topics and demonstrate the distribution of vocabularies over each topic.The LDA topics recaptured the search keywords in PubMed, and further discovered relevant issues, such as intervention program, association links between adolescent substance use and adolescent depression, such as sexual experience and violence, and risk factors of adolescent substance use, such as family factors and peer networks. Using trend analysis to explore the dynamics of proportion of topics, we found that brain research was assessed as a hot issue by the coefficient of the trend test.Topic modeling has the ability to segregate a large collection of articles into distinct themes, and it could be used as a tool to understand the literature, not only by recapturing known facts but also by discovering other relevant topics. all relevant studies are included in their review. with text mining', estimated ICERs for the two non-dominated approaches (base case analyses) ranged from £1975 ('single screening' without a 'provisionally included' code) to £4427 ('safety first' with a 'provisionally included' code) per citation 'saved'. Patterns of results were consistent between base case and sensitivity analyses.Alternatives to the conventional 'double screening' approach, integrating text mining, warrant further consideration as potentially more efficient approaches to identifying eligible studies for systematic reviews. Comparable economic evaluations conducted using other systematic review datasets are needed to determine the generalisability of these findings and to build an evidence base to inform guidance for review authors. include-exclude decisions. The strongest features of the app, identified and reported in user feedback, were its ability to help in screening and collaboration as well as the time savings it affords to users.Rayyan is responsive and intuitive in use with significant potential to lighten the load of reviewers.
PY  - 2020
DA  - 2020-04-02
JO  - {'id': 'https://openalex.org/S113591250', 'issn_l': '0163-7525', 'issn': ['1545-2093', '0163-7525'], 'display_name': 'Annual Review of Public Health', 'publisher': 'Annual Reviews', 'type': 'journal', 'url': 'https://doi.org/10.1146/annurev-publhealth-040119-094220', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Kasim Ortiz
AU  - Jacob L Nash
AU  - Logan Shea
AU  - John G. Oetzel
AU  - Justin Garoutte
AU  - Shannon Sanchez-Youngman
AU  - Nina Wallerstein
ER  - 

442.
TY  - journal-article
ID  - https://openalex.org/W2342152064
DO  - https://doi.org/10.1002/rev3.3065
TI  - Origins, methods and advances in qualitative meta-synthesis
AB  - Qualitative research is a broad term encompassing many methods. Critiques of the field of qualitative research argue that while individual studies provide rich descriptions and insights, the absence of connections drawn between studies limits their usefulness. In response, qualitative meta-synthesis serves as a design to interpret and synthesise qualitative findings across individual studies. More than a broad summary, meta-syntheses do not aim merely to summarise all available data; rather, qualitative meta-syntheses present new perspectives on topics through interpreting findings from different qualitative studies to create ‘third-level’ findings for the advancement of both knowledge and theory. The diversity of opinion on qualitative meta-synthesis is mirrored in its practice. Several different approaches to qualitative meta-synthesis have emerged, with most connected to the meta-ethnographic procedures originally outlined in 1988. This paper: (1) discusses the key philosophical and methodological issues in the literature on qualitative meta-synthesis, (2) highlights key methods that are used in qualitative meta-synthesis, and (3) offers an overview of where the field is going. Examples from the last four years of qualitative meta-syntheses highlight some of this design's current contributions and future usefulness for research in the field of education. hot issue by the coefficient of the trend test.Topic modeling has the ability to segregate a large collection of articles into distinct themes, and it could be used as a tool to understand the literature, not only by recapturing known facts but also by discovering other relevant topics. all relevant studies are included in their review. with text mining', estimated ICERs for the two non-dominated approaches (base case analyses) ranged from £1975 ('single screening' without a 'provisionally included' code) to £4427 ('safety first' with a 'provisionally included' code) per citation 'saved'. Patterns of results were consistent between base case and sensitivity analyses.Alternatives to the conventional 'double screening' approach, integrating text mining, warrant further consideration as potentially more efficient approaches to identifying eligible studies for systematic reviews. Comparable economic evaluations conducted using other systematic review datasets are needed to determine the generalisability of these findings and to build an evidence base to inform guidance for review authors. include-exclude decisions. The strongest features of the app, identified and reported in user feedback, were its ability to help in screening and collaboration as well as the time savings it affords to users.Rayyan is responsive and intuitive in use with significant potential to lighten the load of reviewers.
PY  - 2016
DA  - 2016-02-01
JO  - {'id': 'https://openalex.org/S4210183019', 'issn_l': '2049-6613', 'issn': ['2049-6613'], 'display_name': 'Review of education', 'publisher': 'Wiley', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Elizabeth Nye
AU  - G. J. Melendez-Torres
AU  - Chris Bonell
ER  - 

443.
TY  - journal-article
ID  - https://openalex.org/W2807522649
DO  - https://doi.org/10.1186/s13643-018-0707-8
TI  - Technology-assisted title and abstract screening for systematic reviews: a retrospective evaluation of the Abstrackr machine learning tool
AB  - Machine learning tools can expedite systematic review (SR) processes by semi-automating citation screening. Abstrackr semi-automates citation screening by predicting relevant records. We evaluated its performance for four screening projects.We used a convenience sample of screening projects completed at the Alberta Research Centre for Health Evidence, Edmonton, Canada: three SRs and one descriptive analysis for which we had used SR screening methods. The projects were heterogeneous with respect to search yield (median 9328; range 5243 to 47,385 records; interquartile range (IQR) 15,688 records), topic (Antipsychotics, Bronchiolitis, Diabetes, Child Health SRs), and screening complexity. We uploaded the records to Abstrackr and screened until it made predictions about the relevance of the remaining records. Across three trials for each project, we compared the predictions to human reviewer decisions and calculated the sensitivity, specificity, precision, false negative rate, proportion missed, and workload savings.Abstrackr's sensitivity was > 0.75 for all projects and the mean specificity ranged from 0.69 to 0.90 with the exception of Child Health SRs, for which it was 0.19. The precision (proportion of records correctly predicted as relevant) varied by screening task (median 26.6%; range 14.8 to 64.7%; IQR 29.7%). The median false negative rate (proportion of records incorrectly predicted as irrelevant) was 12.6% (range 3.5 to 21.2%; IQR 12.3%). The workload savings were often large (median 67.2%, range 9.5 to 88.4%; IQR 23.9%). The proportion missed (proportion of records predicted as irrelevant that were included in the final report, out of the total number predicted as irrelevant) was 0.1% for all SRs and 6.4% for the descriptive analysis. This equated to 4.2% (range 0 to 12.2%; IQR 7.8%) of the records in the final reports.Abstrackr's reliability and the workload savings varied by screening task. Workload savings came at the expense of potentially missing relevant records. How this might affect the results and conclusions of SRs needs to be evaluated. Studies evaluating Abstrackr as the second reviewer in a pair would be of interest to determine if concerns for reliability would diminish. Further evaluations of Abstrackr's performance and usability will inform its refinement and practical utility. authors. include-exclude decisions. The strongest features of the app, identified and reported in user feedback, were its ability to help in screening and collaboration as well as the time savings it affords to users.Rayyan is responsive and intuitive in use with significant potential to lighten the load of reviewers.
PY  - 2018
DA  - 2018-03-12
JO  - {'id': 'https://openalex.org/V82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://systematicreviewsjournal.biomedcentral.com/track/pdf/10.1186/s13643-018-0707-8.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Allison Gates
AU  - Cydney N. Johnson
AU  - Lisa Hartling
ER  - 

444.
TY  - journal-article
ID  - https://openalex.org/W2805385227
DO  - https://doi.org/10.1108/jkm-11-2017-0517
TI  - Knowledge discovery out of text data: a systematic review via text mining
AB  - Purpose The aim of this work is to increase awareness of the potential of the technique of text mining to discover knowledge and further promote research collaboration between knowledge management and the information technology communities. Since its emergence, text mining has involved multidisciplinary studies, focused primarily on database technology, Web-based collaborative writing, text analysis, machine learning and knowledge discovery. However, owing to the large amount of research in this field, it is becoming increasingly difficult to identify existing studies and therefore suggest new topics. Design/methodology/approach This article offers a systematic review of 85 academic outputs (articles and books) focused on knowledge discovery derived from the text mining technique. The systematic review is conducted by applying “text mining at the term level, in which knowledge discovery takes place on a more focused collection of words and phrases that are extracted from and label each document” (Feldman et al., 1998, p. 1). Findings The results revealed that the keywords extracted to be associated with the main labels, id est , knowledge discovery and text mining, can be categorized in two periods: from 1998 to 2009, the term knowledge and text were always used. From 2010 to 2017 in addition to these terms, sentiment analysis, review manipulation, microblogging data and knowledgeable users were the other terms frequently used. Besides this, it is possible to notice the technical, engineering nature of each term present in the first decade. Whereas, a diverse range of fields such as business, marketing and finance emerged from 2010 to 2017 owing to a greater interest in the online environment. Originality/value This is a first comprehensive systematic review on knowledge discovery and text mining through the use of a text mining technique at term level, which offers to reduce redundant research and to avoid the possibility of missing relevant publications. and conclusions of SRs needs to be evaluated. Studies evaluating Abstrackr as the second reviewer in a pair would be of interest to determine if concerns for reliability would diminish. Further evaluations of Abstrackr's performance and usability will inform its refinement and practical utility. authors. include-exclude decisions. The strongest features of the app, identified and reported in user feedback, were its ability to help in screening and collaboration as well as the time savings it affords to users.Rayyan is responsive and intuitive in use with significant potential to lighten the load of reviewers.
PY  - 2018
DA  - 2018-05-31
JO  - {'id': 'https://openalex.org/S50631486', 'issn_l': '1367-3270', 'issn': ['1758-7484', '1367-3270'], 'display_name': 'Journal of Knowledge Management', 'publisher': 'Emerald Publishing Limited', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Antonio Usai
AU  - Marco Pironti
AU  - Monika Mital
AU  - Chiraz Aouina Mejri
ER  - 

445.
TY  - journal-article
ID  - https://openalex.org/W2180291732
DO  - https://doi.org/10.1186/s13643-015-0147-7
TI  - How to conduct systematic reviews more expeditiously?
AB  - Healthcare consumers, researchers, patients and policy makers increasingly use systematic reviews (SRs) to aid their decision-making process. However, the conduct of SRs can be a time-consuming and resource-intensive task. Often, clinical practice guideline developers or other decision-makers need to make informed decisions in a timely fashion (e.g. outbreaks of infection, hospital-based health technology assessments). Possible approaches to address the issue of timeliness in the production of SRs are to (a) implement process parallelisation, (b) adapt and apply innovative technologies, and/or (c) modify SR processes (e.g. study eligibility criteria, search sources, data extraction or quality assessment). Highly parallelised systematic reviewing requires substantial resources to support a team of experienced information specialists, reviewers and methodologists working alongside with clinical content experts to minimise the time for completing individual review steps while maximising the parallel progression of multiple steps. Effective coordination and management within the team and across external stakeholders are essential elements of this process. Emerging innovative technologies have a great potential for reducing workload and improving efficiency of SR production. The most promising areas of application would be to allow automation of specific SR tasks, in particular if these tasks are time consuming and resource intensive (e.g. language translation, study selection, data extraction). Modification of SR processes involves restricting, truncating and/or bypassing one or more SR steps, which may risk introducing bias to the review findings. Although the growing experiences in producing various types of rapid reviews (RR) and the accumulation of empirical studies exploring potential bias associated with specific SR tasks have contributed to the methodological development for expediting SR production, there is still a dearth of research examining the actual impact of methodological modifications and comparing the findings between RRs and SRs. This evidence would help to inform as to which SR tasks can be accelerated or truncated and to what degree, while maintaining the validity of review findings. Timely delivered SRs can be of value in informing healthcare decisions and recommendations, especially when there is practical urgency and there is no other relevant synthesised evidence. will inform its refinement and practical utility. authors. include-exclude decisions. The strongest features of the app, identified and reported in user feedback, were its ability to help in screening and collaboration as well as the time savings it affords to users.Rayyan is responsive and intuitive in use with significant potential to lighten the load of reviewers.
PY  - 2015
DA  - 2015-11-12
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://doi.org/10.1186/s13643-015-0147-7', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Alexander Tsertsvadze
AU  - Yen-Fu Chen
AU  - David Moher
AU  - Paul Sutcliffe
AU  - Noel D. McCarthy
ER  - 

446.
TY  - journal-article
ID  - https://openalex.org/W2728712790
DO  - https://doi.org/10.1002/jrsm.1252
TI  - An exploration of crowdsourcing citation screening for systematic reviews
AB  - Systematic reviews are increasingly used to inform health care decisions, but are expensive to produce. We explore the use of crowdsourcing (distributing tasks to untrained workers via the web) to reduce the cost of screening citations. We used Amazon Mechanical Turk as our platform and 4 previously conducted systematic reviews as examples. For each citation, workers answered 4 or 5 questions that were equivalent to the eligibility criteria. We aggregated responses from multiple workers into an overall decision to include or exclude the citation using 1 of 9 algorithms and compared the performance of these algorithms to the corresponding decisions of trained experts. The most inclusive algorithm (designating a citation as relevant if any worker did) identified 95% to 99% of the citations that were ultimately included in the reviews while excluding 68% to 82% of irrelevant citations. Other algorithms increased the fraction of irrelevant articles excluded at some cost to the inclusion of relevant studies. Crowdworkers completed screening in 4 to 17 days, costing $460 to $2220, a cost reduction of up to 88% compared to trained experts. Crowdsourcing may represent a useful approach to reducing the cost of identifying literature for systematic reviews. intensive (e.g. language translation, study selection, data extraction). Modification of SR processes involves restricting, truncating and/or bypassing one or more SR steps, which may risk introducing bias to the review findings. Although the growing experiences in producing various types of rapid reviews (RR) and the accumulation of empirical studies exploring potential bias associated with specific SR tasks have contributed to the methodological development for expediting SR production, there is still a dearth of research examining the actual impact of methodological modifications and comparing the findings between RRs and SRs. This evidence would help to inform as to which SR tasks can be accelerated or truncated and to what degree, while maintaining the validity of review findings. Timely delivered SRs can be of value in informing healthcare decisions and recommendations, especially when there is practical urgency and there is no other relevant synthesised evidence. will inform its refinement and practical utility. authors. include-exclude decisions. The strongest features of the app, identified and reported in user feedback, were its ability to help in screening and collaboration as well as the time savings it affords to users.Rayyan is responsive and intuitive in use with significant potential to lighten the load of reviewers.
PY  - 2017
DA  - 2017-07-04
JO  - {'id': 'https://openalex.org/S205768342', 'issn_l': '1759-2879', 'issn': ['1759-2879', '1759-2887'], 'display_name': 'Research Synthesis Methods', 'publisher': 'Wiley-Blackwell', 'type': 'journal', 'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/jrsm.1252', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Michael Bau Mortensen
AU  - Gaelen P Adam
AU  - Thomas A Trikalinos
AU  - Tim Kraska
AU  - Byron C. Wallace
ER  - 

447.
TY  - journal-article
ID  - https://openalex.org/W2996500226
DO  - https://doi.org/10.1093/bib/bbz130
TI  - An extensive review of tools for manual annotation of documents
AB  - Abstract Motivation Annotation tools are applied to build training and test corpora, which are essential for the development and evaluation of new natural language processing algorithms. Further, annotation tools are also used to extract new information for a particular use case. However, owing to the high number of existing annotation tools, finding the one that best fits particular needs is a demanding task that requires searching the scientific literature followed by installing and trying various tools. Methods We searched for annotation tools and selected a subset of them according to five requirements with which they should comply, such as being Web-based or supporting the definition of a schema. We installed the selected tools (when necessary), carried out hands-on experiments and evaluated them using 26 criteria that covered functional and technical aspects. We defined each criterion on three levels of matches and a score for the final evaluation of the tools. Results We evaluated 78 tools and selected the following 15 for a detailed evaluation: BioQRator, brat, Catma, Djangology, ezTag, FLAT, LightTag, MAT, MyMiner, PDFAnno, prodigy, tagtog, TextAE, WAT-SL and WebAnno. Full compliance with our 26 criteria ranged from only 9 up to 20 criteria, which demonstrated that some tools are comprehensive and mature enough to be used on most annotation projects. The highest score of 0.81 was obtained by WebAnno (of a maximum value of 1.0). the growing experiences in producing various types of rapid reviews (RR) and the accumulation of empirical studies exploring potential bias associated with specific SR tasks have contributed to the methodological development for expediting SR production, there is still a dearth of research examining the actual impact of methodological modifications and comparing the findings between RRs and SRs. This evidence would help to inform as to which SR tasks can be accelerated or truncated and to what degree, while maintaining the validity of review findings. Timely delivered SRs can be of value in informing healthcare decisions and recommendations, especially when there is practical urgency and there is no other relevant synthesised evidence. will inform its refinement and practical utility. authors. include-exclude decisions. The strongest features of the app, identified and reported in user feedback, were its ability to help in screening and collaboration as well as the time savings it affords to users.Rayyan is responsive and intuitive in use with significant potential to lighten the load of reviewers.
PY  - 2021
DA  - 2021-01-18
JO  - {'id': 'https://openalex.org/S91767247', 'issn_l': '1467-5463', 'issn': ['1467-5463', '1477-4054'], 'display_name': 'Briefings in Bioinformatics', 'publisher': 'Oxford University Press', 'type': 'journal', 'url': 'https://academic.oup.com/bib/article-pdf/22/1/146/35934686/bbz130.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Mariana Neves
AU  - Jurica Ševa
ER  - 

448.
TY  - journal-article
ID  - https://openalex.org/W2411035889
DO  - https://doi.org/10.1515/jdis-2017-0019
TI  - Rediscovering Don Swanson:The Past, Present and Future of Literature-based Discovery
AB  - Abstract Purpose The late Don R. Swanson was well appreciated during his lifetime as Dean of the Graduate Library School at University of Chicago, as winner of the American Society for Information Science Award of Merit for 2000, and as author of many seminal articles. In this informal essay, I will give my personal perspective on Don’s contributions to science, and outline some current and future directions in literature-based discovery that are rooted in concepts that he developed. Design/methodology/approach Personal recollections and literature review. Findings The Swanson A-B-C model of literature-based discovery has been successfully used by laboratory investigators analyzing their findings and hypotheses. It continues to be a fertile area of research in a wide range of application areas including text mining, drug repurposing, studies of scientific innovation, knowledge discovery in databases, and bioinformatics. Recently, additional modes of discovery that do not follow the A-B-C model have also been proposed and explored (e.g. so-called storytelling, gaps, analogies, link prediction, negative consensus, outliers, and revival of neglected or discarded research questions). Research limitations This paper reflects the opinions of the author and is not a comprehensive nor technically based review of literature-based discovery. Practical implications The general scientific public is still not aware of the availability of tools for literature-based discovery. Our Arrowsmith project site maintains a suite of discovery tools that are free and open to the public ( http://arrowsmith.psych.uic.edu) , as does BITOLA which is maintained by Dmitar Hristovski ( http://http://ibmi.mf.uni-lj.si/bitola) , and Epiphanet which is maintained by Trevor Cohen ( http://epiphanet.uth.tmc.edu/) . Bringing user-friendly tools to the public should be a high priority, since even more than advancing basic research in informatics, it is vital that we ensure that scientists actually use discovery tools and that these are actually able to help them make experimental discoveries in the lab and in the clinic. Originality/value This paper discusses problems and issues which were inherent in Don’s thoughts during his life, including those which have not yet been fully taken up and studied systematically. synthesised evidence. will inform its refinement and practical utility. authors. include-exclude decisions. The strongest features of the app, identified and reported in user feedback, were its ability to help in screening and collaboration as well as the time savings it affords to users.Rayyan is responsive and intuitive in use with significant potential to lighten the load of reviewers.
PY  - 2017
DA  - 2017-12-29
JO  - {'id': 'https://openalex.org/S2764801193', 'issn_l': '2096-157X', 'issn': ['2096-157X', '2543-683X'], 'display_name': 'Journal of Data and Information Science', 'publisher': 'Chinese Academy of Sciences', 'type': 'journal', 'url': 'https://content.sciendo.com/downloadpdf/journals/jdis/2/4/article-p43.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc-nd'}
DP  - OpenAlex
AU  - Neil R. Smalheiser
ER  - 

449.
TY  - journal-article
ID  - https://openalex.org/W2890472403
DO  - https://doi.org/10.1186/s13750-018-0134-2
TI  - Absence of evidence for the conservation outcomes of systematic conservation planning around the globe: a systematic map
AB  - Abstract Background Systematic conservation planning is a discipline concerned with the prioritisation of resources for biodiversity conservation and is often used in the design or assessment of terrestrial and marine protected area networks. Despite being an evidence-based discipline, to date there has been no comprehensive review of the outcomes of systematic conservation plans and assessments of the relative effectiveness of applications in different contexts. To address this fundamental gap in knowledge, our primary research question was: what is the extent, distribution and robustness of evidence on conservation outcomes of systematic conservation planning around the globe? Methods A systematic mapping exercise was undertaken using standardised search terms across 29 sources, including publication databases, online repositories and a wide range of grey literature sources. The review team screened articles recursively, first by title only, then abstract and finally by full-text, using inclusion criteria related to systematic conservation plans conducted at sub-global scales and reported on since 1983. We sought studies that reported outcomes relating to natural, human, social, financial or institutional outcomes and which employed robust evaluation study designs. The following information was extracted from included studies: bibliographic details, background information including location of study and broad objectives of the plan, study design, reported outcomes and context. Results Of the approximately 10,000 unique articles returned through our searches, 1209 were included for full-text screening and 43 studies reported outcomes of conservation planning interventions. However, only three studies involved the use of evaluation study designs which are suitably rigorous for inclusion, according to best-practice guidelines. The three included studies were undertaken in the Gulf of California (Mexico), Réunion Island, and The Nature Conservancy’s landholdings across the USA. The studies varied widely in context, purpose and outcomes. Study designs were non-experimental or qualitative, and involved use of spatial landholdings over time, stakeholder surveys and modelling of alternative planning scenarios. Conclusion Rigorous evaluations of systematic conservation plans are currently not published in academic journals or made publicly available elsewhere. Despite frequent claims relating to positive implications and outcomes of these planning activities, we show that evaluations are probably rarely conducted. This finding does not imply systematic conservation planning is not effective but highlights a significant gap in our understanding of how, when and why it may or may not be effective. Our results also corroborate claims that the literature on systematic conservation planning is dominated by methodological studies, rather than those that focus on implementation and outcomes, and support the case that this is a problematic imbalance in the literature. We emphasise the need for academics and practitioners to publish the outcomes of systematic conservation planning exercises and to consider employing robust evaluation methodologies when reporting project outcomes. Adequate reporting of outcomes will in turn enable transparency and accountability between institutions and funding bodies as well as improving the science and practice of conservation planning.
PY  - 2018
DA  - 2018-09-22
JO  - {'id': 'https://openalex.org/S2737036037', 'issn_l': '2047-2382', 'issn': ['2047-2382'], 'display_name': 'Environmental Evidence', 'publisher': 'BioMed Central', 'type': 'journal', 'url': 'https://environmentalevidencejournal.biomedcentral.com/track/pdf/10.1186/s13750-018-0134-2', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Emma McIntosh
AU  - Sarah Chapman
AU  - Stephen G. Kearney
AU  - Brooke Williams
AU  - Glenn Althor
AU  - Jessica P. R. Thorn
AU  - Robert L. Pressey
AU  - Madeleine C. McKinnon
AU  - Richard Grenyer
ER  - 

450.
TY  - journal-article
ID  - https://openalex.org/W3047814069
DO  - https://doi.org/10.1057/s41267-020-00353-7
TI  - Methodological practices in international business research: An after-action review of challenges and solutions
AB  - Abstract We combine after-action review and needs-assessment frameworks to describe the four most pervasive contemporary methodological challenges faced by international business (IB) researchers, as identified by authors of Journal of International Business Studies articles: Psychometrically deficient measures (mentioned in 73% of articles), idiosyncratic samples or contexts (mentioned in 62.2% of articles), less-than-ideal research designs (mentioned in 62.2% of articles), and insufficient evidence about causal relations (mentioned in 8.1% of articles). Then, we offer solutions to address these challenges: demonstrating why and how the conceptualization of a construct is accurate given a particular context, specifying whether constructs are reflective or formative, taking advantage of the existence of multiple indicators to measure multi-dimensional constructs, using particular samples and contexts as vehicles for theorizing and further theory development, seeking out particular samples or contexts where hypotheses are more or less likely to be supported empirically, using Big Data techniques to take advantage of untapped sources of information and to re-analyze currently available data, implementing quasi-experiments, and conducting necessary-condition analysis. Our article aims to advance IB theory by tackling the most typical methodological challenges and is intended for researchers, reviewers and editors, research consumers, and instructors who are training the next generation of scholars. design, reported outcomes and context. Results Of the approximately 10,000 unique articles returned through our searches, 1209 were included for full-text screening and 43 studies reported outcomes of conservation planning interventions. However, only three studies involved the use of evaluation study designs which are suitably rigorous for inclusion, according to best-practice guidelines. The three included studies were undertaken in the Gulf of California (Mexico), Réunion Island, and The Nature Conservancy’s landholdings across the USA. The studies varied widely in context, purpose and outcomes. Study designs were non-experimental or qualitative, and involved use of spatial landholdings over time, stakeholder surveys and modelling of alternative planning scenarios. Conclusion Rigorous evaluations of systematic conservation plans are currently not published in academic journals or made publicly available elsewhere. Despite frequent claims relating to positive implications and outcomes of these planning activities, we show that evaluations are probably rarely conducted. This finding does not imply systematic conservation planning is not effective but highlights a significant gap in our understanding of how, when and why it may or may not be effective. Our results also corroborate claims that the literature on systematic conservation planning is dominated by methodological studies, rather than those that focus on implementation and outcomes, and support the case that this is a problematic imbalance in the literature. We emphasise the need for academics and practitioners to publish the outcomes of systematic conservation planning exercises and to consider employing robust evaluation methodologies when reporting project outcomes. Adequate reporting of outcomes will in turn enable transparency and accountability between institutions and funding bodies as well as improving the science and practice of conservation planning.
PY  - 2020
DA  - 2020-08-09
JO  - {'id': 'https://openalex.org/S38024979', 'issn_l': '0047-2506', 'issn': ['0047-2506', '1478-6990'], 'display_name': 'Journal of International Business Studies', 'publisher': 'Palgrave Macmillan', 'type': 'journal', 'url': 'https://link.springer.com/content/pdf/10.1057/s41267-020-00353-7.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Herman Aguinis
AU  - Ravi Ramani
AU  - Wayne F. Cascio
ER  - 

451.
TY  - journal-article
ID  - https://openalex.org/W2593464417
DO  - https://doi.org/10.1002/14651858.cd012573
TI  - Altering the availability or proximity of food, alcohol and tobacco products to change their selection and consumption
AB  - BACKGROUND: Overconsumption of food, alcohol, and tobacco products increases the risk of non-communicable diseases. Interventions to change characteristics of physical micro-environments where people may select or consume these products - including shops, restaurants, workplaces, and schools - are of considerable public health policy and research interest. This review addresses two types of intervention within such environments: altering the availability (the range and/or amount of options) of these products, or their proximity (the distance at which they are positioned) to potential consumers. OBJECTIVES: 1. To assess the impact on selection and consumption of altering the availability or proximity of (a) food (including non-alcoholic beverages), (b) alcohol, and (c) tobacco products.2. To assess the extent to which the impact of these interventions is modified by characteristics of: i. studies, ii. interventions, and iii. PARTICIPANTS: SEARCH METHODS: We searched CENTRAL, MEDLINE, Embase, PsycINFO, and seven other published or grey literature databases, as well as trial registries and key websites, up to 23 July 2018, followed by citation searches. SELECTION CRITERIA: We included randomised controlled trials with between-participants (parallel group) or within-participants (cross-over) designs. Eligible studies compared effects of exposure to at least two different levels of availability of a product or its proximity, and included a measure of selection or consumption of the manipulated product. DATA COLLECTION AND ANALYSIS: We used a novel semi-automated screening workflow and applied standard Cochrane methods to select eligible studies, collect data, and assess risk of bias. In separate analyses for availability interventions and proximity interventions, we combined results using random-effects meta-analysis and meta-regression models to estimate summary effect sizes (as standardised mean differences (SMDs)) and to investigate associations between summary effect sizes and selected study, intervention, or participant characteristics. We rated the certainty of evidence for each outcome using GRADE. MAIN RESULTS: We included 24 studies, with the majority (20/24) giving concerns about risk of bias. All of the included studies investigated food products; none investigated alcohol or tobacco. The majority were conducted in laboratory settings (14/24), with adult participants (17/24), and used between-participants designs (19/24). All studies were conducted in high-income countries, predominantly in the USA (14/24).Six studies investigated availability interventions, of which two changed the absolute number of different options available, and four altered the relative proportion of less-healthy (to healthier) options. Most studies (4/6) manipulated snack foods or drinks. For selection outcomes, meta-analysis of three comparisons from three studies (n = 154) found that exposure to fewer options resulted in a large reduction in selection of the targeted food(s): SMD -1.13 (95% confidence interval (CI) -1.90 to -0.37) (low certainty evidence). For consumption outcomes, meta-analysis of three comparisons from two studies (n = 150) found that exposure to fewer options resulted in a moderate reduction in consumption of those foods, but with considerable uncertainty: SMD -0.55 (95% CI -1.27 to 0.18) (low certainty evidence).Eighteen studies investigated proximity interventions. Most (14/18) changed the distance at which a snack food or drink was placed from the participants, whilst four studies changed the order of meal components encountered along a line. For selection outcomes, only one study with one comparison (n = 41) was identified, which found that food placed farther away resulted in a moderate reduction in its selection: SMD -0.65 (95% CI -1.29 to -0.01) (very low certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias. AUTHORS' CONCLUSIONS: The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2017
DA  - 2017-03-01
JO  - {'id': 'https://openalex.org/V4210172715', 'issn_l': '1464-780X', 'issn': ['1464-780X', '1465-184X', '1465-1858'], 'display_name': 'The Cochrane library', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Gareth J Hollands
AU  - Patrice Carter
AU  - Ian Shemilt
AU  - Theresa M. Marteau
AU  - Susan A. Jebb
AU  - Julian P T Higgins
AU  - David Ogilvie
ER  - 

452.
TY  - journal-article
ID  - https://openalex.org/W2981181409
DO  - https://doi.org/10.1177/1042258719879635
TI  - Opportunities and Threats in Reviewing Entrepreneurship Theory and Practice
AB  - Reviews have a critical role in knowledge accumulation in entrepreneurship. Good reviews do not just summarize the literature but provide unique contributions on theory testing, theory development, the identification of research gaps, and suggestions for future research. This editorial discusses different forms for reviews, their strengths and weaknesses, and how they best contribute to the field. altering the availability (the range and/or amount of options) of these products, or their proximity (the distance at which they are positioned) to potential consumers. OBJECTIVES: 1. To assess the impact on selection and consumption of altering the availability or proximity of (a) food (including non-alcoholic beverages), (b) alcohol, and (c) tobacco products.2. To assess the extent to which the impact of these interventions is modified by characteristics of: i. studies, ii. interventions, and iii. PARTICIPANTS: SEARCH METHODS: We searched CENTRAL, MEDLINE, Embase, PsycINFO, and seven other published or grey literature databases, as well as trial registries and key websites, up to 23 July 2018, followed by citation searches. SELECTION CRITERIA: We included randomised controlled trials with between-participants (parallel group) or within-participants (cross-over) designs. Eligible studies compared effects of exposure to at least two different levels of availability of a product or its proximity, and included a measure of selection or consumption of the manipulated product. DATA COLLECTION AND ANALYSIS: We used a novel semi-automated screening workflow and applied standard Cochrane methods to select eligible studies, collect data, and assess risk of bias. In separate analyses for availability interventions and proximity interventions, we combined results using random-effects meta-analysis and meta-regression models to estimate summary effect sizes (as standardised mean differences (SMDs)) and to investigate associations between summary effect sizes and selected study, intervention, or participant characteristics. We rated the certainty of evidence for each outcome using GRADE. MAIN RESULTS: We included 24 studies, with the majority (20/24) giving concerns about risk of bias. All of the included studies investigated food products; none investigated alcohol or tobacco. The majority were conducted in laboratory settings (14/24), with adult participants (17/24), and used between-participants designs (19/24). All studies were conducted in high-income countries, predominantly in the USA (14/24).Six studies investigated availability interventions, of which two changed the absolute number of different options available, and four altered the relative proportion of less-healthy (to healthier) options. Most studies (4/6) manipulated snack foods or drinks. For selection outcomes, meta-analysis of three comparisons from three studies (n = 154) found that exposure to fewer options resulted in a large reduction in selection of the targeted food(s): SMD -1.13 (95% confidence interval (CI) -1.90 to -0.37) (low certainty evidence). For consumption outcomes, meta-analysis of three comparisons from two studies (n = 150) found that exposure to fewer options resulted in a moderate reduction in consumption of those foods, but with considerable uncertainty: SMD -0.55 (95% CI -1.27 to 0.18) (low certainty evidence).Eighteen studies investigated proximity interventions. Most (14/18) changed the distance at which a snack food or drink was placed from the participants, whilst four studies changed the order of meal components encountered along a line. For selection outcomes, only one study with one comparison (n = 41) was identified, which found that food placed farther away resulted in a moderate reduction in its selection: SMD -0.65 (95% CI -1.29 to -0.01) (very low certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias. AUTHORS' CONCLUSIONS: The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2020
DA  - 2020-09-01
JO  - {'id': 'https://openalex.org/S187626162', 'issn_l': '1042-2587', 'issn': ['1540-6520', '1042-2587'], 'display_name': 'Entrepreneurship Theory and Practice', 'publisher': 'Wiley-Blackwell', 'type': 'journal', 'url': 'https://journals.sagepub.com/doi/pdf/10.1177/1042258719879635', 'is_oa': True, 'version': 'publishedVersion', 'license': None}
DP  - OpenAlex
AU  - Andreas Rauch
ER  - 

453.
TY  - journal-article
ID  - https://openalex.org/W2765760594
DO  - https://doi.org/10.1111/cobi.13044
TI  - Using machine learning to disentangle homonyms in large text corpora
AB  - Systematic reviews are an increasingly popular decision-making tool that provides an unbiased summary of evidence to support conservation action. These reviews bridge the gap between researchers and managers by presenting a comprehensive overview of all studies relating to a particular topic and identify specifically where and under which conditions an effect is present. However, several technical challenges can severely hinder the feasibility and applicability of systematic reviews, for example, homonyms (terms that share spelling but differ in meaning). Homonyms add noise to search results and cannot be easily identified or removed. We developed a semiautomated approach that can aid in the classification of homonyms among narratives. We used a combination of automated content analysis and artificial neural networks to quickly and accurately sift through large corpora of academic texts and classify them to distinct topics. As an example, we explored the use of the word reintroduction in academic texts. Reintroduction is used within the conservation context to indicate the release of organisms to their former native habitat; however, a Web of Science search for this word returned thousands of publications in which the term has other meanings and contexts. Using our method, we automatically classified a sample of 3000 of these publications with over 99% accuracy, relative to a manual classification. Our approach can be used easily with other homonyms and can greatly facilitate systematic reviews or similar work in which homonyms hinder the harnessing of large text corpora. Beyond homonyms we see great promise in combining automated content analysis and machine-learning methods to handle and screen big data for relevant information in conservation science. differences (SMDs)) and to investigate associations between summary effect sizes and selected study, intervention, or participant characteristics. We rated the certainty of evidence for each outcome using GRADE. MAIN RESULTS: We included 24 studies, with the majority (20/24) giving concerns about risk of bias. All of the included studies investigated food products; none investigated alcohol or tobacco. The majority were conducted in laboratory settings (14/24), with adult participants (17/24), and used between-participants designs (19/24). All studies were conducted in high-income countries, predominantly in the USA (14/24).Six studies investigated availability interventions, of which two changed the absolute number of different options available, and four altered the relative proportion of less-healthy (to healthier) options. Most studies (4/6) manipulated snack foods or drinks. For selection outcomes, meta-analysis of three comparisons from three studies (n = 154) found that exposure to fewer options resulted in a large reduction in selection of the targeted food(s): SMD -1.13 (95% confidence interval (CI) -1.90 to -0.37) (low certainty evidence). For consumption outcomes, meta-analysis of three comparisons from two studies (n = 150) found that exposure to fewer options resulted in a moderate reduction in consumption of those foods, but with considerable uncertainty: SMD -0.55 (95% CI -1.27 to 0.18) (low certainty evidence).Eighteen studies investigated proximity interventions. Most (14/18) changed the distance at which a snack food or drink was placed from the participants, whilst four studies changed the order of meal components encountered along a line. For selection outcomes, only one study with one comparison (n = 41) was identified, which found that food placed farther away resulted in a moderate reduction in its selection: SMD -0.65 (95% CI -1.29 to -0.01) (very low certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias. AUTHORS' CONCLUSIONS: The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2018
DA  - 2018-06-01
JO  - {'id': 'https://openalex.org/S98137347', 'issn_l': '0888-8892', 'issn': ['0888-8892', '1523-1739'], 'display_name': 'Conservation Biology', 'publisher': 'Wiley-Blackwell', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Uri Roll
AU  - Ricardo A. Correia
AU  - Oded Berger-Tal
ER  - 

454.
TY  - journal-article
ID  - https://openalex.org/W2180673283
DO  - https://doi.org/10.1186/s13643-015-0117-0
TI  - Supporting systematic reviews using LDA-based document representations
AB  - Identifying relevant studies for inclusion in a systematic review (i.e. screening) is a complex, laborious and expensive task. Recently, a number of studies has shown that the use of machine learning and text mining methods to automatically identify relevant studies has the potential to drastically decrease the workload involved in the screening phase. The vast majority of these machine learning methods exploit the same underlying principle, i.e. a study is modelled as a bag-of-words (BOW).We explore the use of topic modelling methods to derive a more informative representation of studies. We apply Latent Dirichlet allocation (LDA), an unsupervised topic modelling approach, to automatically identify topics in a collection of studies. We then represent each study as a distribution of LDA topics. Additionally, we enrich topics derived using LDA with multi-word terms identified by using an automatic term recognition (ATR) tool. For evaluation purposes, we carry out automatic identification of relevant studies using support vector machine (SVM)-based classifiers that employ both our novel topic-based representation and the BOW representation.Our results show that the SVM classifier is able to identify a greater number of relevant studies when using the LDA representation than the BOW representation. These observations hold for two systematic reviews of the clinical domain and three reviews of the social science domain.A topic-based feature representation of documents outperforms the BOW representation when applied to the task of automatic citation screening. The proposed term-enriched topics are more informative and less ambiguous to systematic reviewers. great promise in combining automated content analysis and machine-learning methods to handle and screen big data for relevant information in conservation science. differences (SMDs)) and to investigate associations between summary effect sizes and selected study, intervention, or participant characteristics. We rated the certainty of evidence for each outcome using GRADE. MAIN RESULTS: We included 24 studies, with the majority (20/24) giving concerns about risk of bias. All of the included studies investigated food products; none investigated alcohol or tobacco. The majority were conducted in laboratory settings (14/24), with adult participants (17/24), and used between-participants designs (19/24). All studies were conducted in high-income countries, predominantly in the USA (14/24).Six studies investigated availability interventions, of which two changed the absolute number of different options available, and four altered the relative proportion of less-healthy (to healthier) options. Most studies (4/6) manipulated snack foods or drinks. For selection outcomes, meta-analysis of three comparisons from three studies (n = 154) found that exposure to fewer options resulted in a large reduction in selection of the targeted food(s): SMD -1.13 (95% confidence interval (CI) -1.90 to -0.37) (low certainty evidence). For consumption outcomes, meta-analysis of three comparisons from two studies (n = 150) found that exposure to fewer options resulted in a moderate reduction in consumption of those foods, but with considerable uncertainty: SMD -0.55 (95% CI -1.27 to 0.18) (low certainty evidence).Eighteen studies investigated proximity interventions. Most (14/18) changed the distance at which a snack food or drink was placed from the participants, whilst four studies changed the order of meal components encountered along a line. For selection outcomes, only one study with one comparison (n = 41) was identified, which found that food placed farther away resulted in a moderate reduction in its selection: SMD -0.65 (95% CI -1.29 to -0.01) (very low certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias. AUTHORS' CONCLUSIONS: The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2015
DA  - 2015-11-26
JO  - {'id': 'https://openalex.org/V82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://doi.org/10.1186/s13643-015-0117-0', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Yuanhan Mo
AU  - Georgios Kontonatsios
AU  - Sophia Ananiadou
ER  - 

455.
TY  - journal-article
ID  - https://openalex.org/W2418744968
DO  - https://doi.org/10.1016/j.jclinepi.2016.05.002
TI  - Prospective comparison of search strategies for systematic reviews: an objective approach yielded higher sensitivity than a conceptual one
AB  - In the development of search strategies for systematic reviews, "conceptual approaches" are generally recommended to identify appropriate search terms for those parts of the strategies for which no validated search filters exist. However, "objective approaches" based on search terms identified by text analysis are increasingly being applied.To prospectively compare an objective with a conceptual approach for the development of search strategies.Two different MEDLINE search strategies were developed in parallel for five systematic reviews covering a range of topics and study designs. The Institute for Quality and Efficiency in Health Care (IQWiG) applied an objective approach, and external experts applied a conceptual approach for the same research questions. For each systematic review, the citations retrieved were combined and the overall pool of citations screened to determine sensitivity and precision.The objective approach yielded a weighted mean sensitivity and precision of 97% and 5%. The corresponding values for the conceptual approach were 75% and 4%.Our findings indicate that the objective approach applied by IQWiG for search strategy development yields higher sensitivity than and similar precision to a conceptual approach. The main advantage of the objective approach is that it produces consistent results across searches. BOW representation. These observations hold for two systematic reviews of the clinical domain and three reviews of the social science domain.A topic-based feature representation of documents outperforms the BOW representation when applied to the task of automatic citation screening. The proposed term-enriched topics are more informative and less ambiguous to systematic reviewers. great promise in combining automated content analysis and machine-learning methods to handle and screen big data for relevant information in conservation science. differences (SMDs)) and to investigate associations between summary effect sizes and selected study, intervention, or participant characteristics. We rated the certainty of evidence for each outcome using GRADE. MAIN RESULTS: We included 24 studies, with the majority (20/24) giving concerns about risk of bias. All of the included studies investigated food products; none investigated alcohol or tobacco. The majority were conducted in laboratory settings (14/24), with adult participants (17/24), and used between-participants designs (19/24). All studies were conducted in high-income countries, predominantly in the USA (14/24).Six studies investigated availability interventions, of which two changed the absolute number of different options available, and four altered the relative proportion of less-healthy (to healthier) options. Most studies (4/6) manipulated snack foods or drinks. For selection outcomes, meta-analysis of three comparisons from three studies (n = 154) found that exposure to fewer options resulted in a large reduction in selection of the targeted food(s): SMD -1.13 (95% confidence interval (CI) -1.90 to -0.37) (low certainty evidence). For consumption outcomes, meta-analysis of three comparisons from two studies (n = 150) found that exposure to fewer options resulted in a moderate reduction in consumption of those foods, but with considerable uncertainty: SMD -0.55 (95% CI -1.27 to 0.18) (low certainty evidence).Eighteen studies investigated proximity interventions. Most (14/18) changed the distance at which a snack food or drink was placed from the participants, whilst four studies changed the order of meal components encountered along a line. For selection outcomes, only one study with one comparison (n = 41) was identified, which found that food placed farther away resulted in a moderate reduction in its selection: SMD -0.65 (95% CI -1.29 to -0.01) (very low certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias. AUTHORS' CONCLUSIONS: The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2016
DA  - 2016-09-01
JO  - {'id': 'https://openalex.org/S64418186', 'issn_l': '0895-4356', 'issn': ['1878-5921', '0895-4356'], 'display_name': 'Journal of Clinical Epidemiology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'http://www.jclinepi.com/article/S0895435616301342/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc-nd'}
DP  - OpenAlex
AU  - Elke Hausner
AU  - Charlotte Guddat
AU  - Tatjana Hermanns
AU  - Ulrike Lampert
AU  - Siw Waffenschmidt
ER  - 

456.
TY  - journal-article
ID  - https://openalex.org/W2952174148
DO  - https://doi.org/10.1093/bib/bbx057
TI  - Biomedical text mining for research rigor and integrity: tasks, challenges, directions
AB  - An estimated quarter of a trillion US dollars is invested in the biomedical research enterprise annually. There is growing alarm that a significant portion of this investment is wasted because of problems in reproducibility of research findings and in the rigor and integrity of research conduct and reporting. Recent years have seen a flurry of activities focusing on standardization and guideline development to enhance the reproducibility and rigor of biomedical research. Research activity is primarily communicated via textual artifacts, ranging from grant applications to journal publications. These artifacts can be both the source and the manifestation of practices leading to research waste. For example, an article may describe a poorly designed experiment, or the authors may reach conclusions not supported by the evidence presented. In this article, we pose the question of whether biomedical text mining techniques can assist the stakeholders in the biomedical research enterprise in doing their part toward enhancing research integrity and rigor. In particular, we identify four key areas in which text mining techniques can make a significant contribution: plagiarism/fraud detection, ensuring adherence to reporting guidelines, managing information overload and accurate citation/enhanced bibliometrics. We review the existing methods and tools for specific tasks, if they exist, or discuss relevant research that can provide guidance for future work. With the exponential increase in biomedical research output and the ability of text mining approaches to perform automatic tasks at large scale, we propose that such approaches can support tools that promote responsible research practices, providing significant benefits for the biomedical research enterprise. handle and screen big data for relevant information in conservation science. differences (SMDs)) and to investigate associations between summary effect sizes and selected study, intervention, or participant characteristics. We rated the certainty of evidence for each outcome using GRADE. MAIN RESULTS: We included 24 studies, with the majority (20/24) giving concerns about risk of bias. All of the included studies investigated food products; none investigated alcohol or tobacco. The majority were conducted in laboratory settings (14/24), with adult participants (17/24), and used between-participants designs (19/24). All studies were conducted in high-income countries, predominantly in the USA (14/24).Six studies investigated availability interventions, of which two changed the absolute number of different options available, and four altered the relative proportion of less-healthy (to healthier) options. Most studies (4/6) manipulated snack foods or drinks. For selection outcomes, meta-analysis of three comparisons from three studies (n = 154) found that exposure to fewer options resulted in a large reduction in selection of the targeted food(s): SMD -1.13 (95% confidence interval (CI) -1.90 to -0.37) (low certainty evidence). For consumption outcomes, meta-analysis of three comparisons from two studies (n = 150) found that exposure to fewer options resulted in a moderate reduction in consumption of those foods, but with considerable uncertainty: SMD -0.55 (95% CI -1.27 to 0.18) (low certainty evidence).Eighteen studies investigated proximity interventions. Most (14/18) changed the distance at which a snack food or drink was placed from the participants, whilst four studies changed the order of meal components encountered along a line. For selection outcomes, only one study with one comparison (n = 41) was identified, which found that food placed farther away resulted in a moderate reduction in its selection: SMD -0.65 (95% CI -1.29 to -0.01) (very low certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias. AUTHORS' CONCLUSIONS: The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2017
DA  - 2017-02-14
JO  - {'id': 'https://openalex.org/V91767247', 'issn_l': '1467-5463', 'issn': ['1467-5463', '1477-4054'], 'display_name': 'Briefings in Bioinformatics', 'publisher': 'Oxford University Press', 'type': 'journal', 'url': 'https://academic.oup.com/bib/article-pdf/19/6/1400/27118801/bbx057.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'pd'}
DP  - OpenAlex
AU  - Halil Kilicoglu
ER  - 

457.
TY  - journal-article
ID  - https://openalex.org/W2954093663
DO  - https://doi.org/10.1016/j.jss.2019.07.002
TI  - Evolution of statistical analysis in empirical software engineering research: Current state and steps forward
AB  - Software engineering research is evolving and papers are increasingly based on empirical data from a multitude of sources, using statistical tests to determine if and to what degree empirical evidence supports their hypotheses. To investigate the practices and trends of statistical analysis in empirical software engineering (ESE), this paper presents a review of a large pool of papers from top-ranked software engineering journals. First, we manually reviewed 161 papers and in the second phase of our method, we conducted a more extensive semi-automatic classification of papers spanning the years 2001--2015 and 5,196 papers. Results from both review steps was used to: i) identify and analyze the predominant practices in ESE (e.g., using t-test or ANOVA), as well as relevant trends in usage of specific statistical methods (e.g., nonparametric tests and effect size measures) and, ii) develop a conceptual model for a statistical analysis workflow with suggestions on how to apply different statistical methods as well as guidelines to avoid pitfalls. Lastly, we confirm existing claims that current ESE practices lack a standard to report practical significance of results. We illustrate how practical significance can be discussed in terms of both the statistical analysis and in the practitioner's context. they exist, or discuss relevant research that can provide guidance for future work. With the exponential increase in biomedical research output and the ability of text mining approaches to perform automatic tasks at large scale, we propose that such approaches can support tools that promote responsible research practices, providing significant benefits for the biomedical research enterprise. handle and screen big data for relevant information in conservation science. differences (SMDs)) and to investigate associations between summary effect sizes and selected study, intervention, or participant characteristics. We rated the certainty of evidence for each outcome using GRADE. MAIN RESULTS: We included 24 studies, with the majority (20/24) giving concerns about risk of bias. All of the included studies investigated food products; none investigated alcohol or tobacco. The majority were conducted in laboratory settings (14/24), with adult participants (17/24), and used between-participants designs (19/24). All studies were conducted in high-income countries, predominantly in the USA (14/24).Six studies investigated availability interventions, of which two changed the absolute number of different options available, and four altered the relative proportion of less-healthy (to healthier) options. Most studies (4/6) manipulated snack foods or drinks. For selection outcomes, meta-analysis of three comparisons from three studies (n = 154) found that exposure to fewer options resulted in a large reduction in selection of the targeted food(s): SMD -1.13 (95% confidence interval (CI) -1.90 to -0.37) (low certainty evidence). For consumption outcomes, meta-analysis of three comparisons from two studies (n = 150) found that exposure to fewer options resulted in a moderate reduction in consumption of those foods, but with considerable uncertainty: SMD -0.55 (95% CI -1.27 to 0.18) (low certainty evidence).Eighteen studies investigated proximity interventions. Most (14/18) changed the distance at which a snack food or drink was placed from the participants, whilst four studies changed the order of meal components encountered along a line. For selection outcomes, only one study with one comparison (n = 41) was identified, which found that food placed farther away resulted in a moderate reduction in its selection: SMD -0.65 (95% CI -1.29 to -0.01) (very low certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias. AUTHORS' CONCLUSIONS: The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2019
DA  - 2019-10-01
JO  - {'id': 'https://openalex.org/S37879656', 'issn_l': '0164-1212', 'issn': ['0164-1212', '1873-1228'], 'display_name': 'Journal of Systems and Software', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Francisco Gomes de Oliveira Neto
AU  - Richard Torkar
AU  - Robert Feldt
AU  - Lucas Gren
AU  - Carlo A. Furia
AU  - Z. L. Huang
ER  - 

458.
TY  - journal-article
ID  - https://openalex.org/W2896286428
DO  - https://doi.org/10.1007/s00500-018-3568-0
TI  - Information retrieval methodology for aiding scientific database search
AB  - During literature reviews, and specially when conducting systematic literature reviews, finding and screening relevant papers during scientific document search may involve managing and processing large amounts of unstructured text data. In those cases where the search topic is difficult to establish or has fuzzy limits, researchers require to broaden the scope of the search and, in consequence, data from retrieved scientific publications may become huge and uncorrelated. However, through a convenient analysis of these data the researcher may be able to discover new knowledge which may be hidden within the search output, thus exploring the limits of the search and enhancing the review scope. With that aim, this paper presents an iterative methodology that applies text mining and machine learning techniques to a downloaded corpus of abstracts from scientific databases, combining automatic processing algorithms with tools for supervised decision-making in an iterative process sustained on the researchers’ judgement, so as to adapt, screen and tune the search output. The paper ends showing a working example that employs a set of developed scripts that implement the different stages of the proposed methodology. practical significance can be discussed in terms of both the statistical analysis and in the practitioner's context. they exist, or discuss relevant research that can provide guidance for future work. With the exponential increase in biomedical research output and the ability of text mining approaches to perform automatic tasks at large scale, we propose that such approaches can support tools that promote responsible research practices, providing significant benefits for the biomedical research enterprise. handle and screen big data for relevant information in conservation science. differences (SMDs)) and to investigate associations between summary effect sizes and selected study, intervention, or participant characteristics. We rated the certainty of evidence for each outcome using GRADE. MAIN RESULTS: We included 24 studies, with the majority (20/24) giving concerns about risk of bias. All of the included studies investigated food products; none investigated alcohol or tobacco. The majority were conducted in laboratory settings (14/24), with adult participants (17/24), and used between-participants designs (19/24). All studies were conducted in high-income countries, predominantly in the USA (14/24).Six studies investigated availability interventions, of which two changed the absolute number of different options available, and four altered the relative proportion of less-healthy (to healthier) options. Most studies (4/6) manipulated snack foods or drinks. For selection outcomes, meta-analysis of three comparisons from three studies (n = 154) found that exposure to fewer options resulted in a large reduction in selection of the targeted food(s): SMD -1.13 (95% confidence interval (CI) -1.90 to -0.37) (low certainty evidence). For consumption outcomes, meta-analysis of three comparisons from two studies (n = 150) found that exposure to fewer options resulted in a moderate reduction in consumption of those foods, but with considerable uncertainty: SMD -0.55 (95% CI -1.27 to 0.18) (low certainty evidence).Eighteen studies investigated proximity interventions. Most (14/18) changed the distance at which a snack food or drink was placed from the participants, whilst four studies changed the order of meal components encountered along a line. For selection outcomes, only one study with one comparison (n = 41) was identified, which found that food placed farther away resulted in a moderate reduction in its selection: SMD -0.65 (95% CI -1.29 to -0.01) (very low certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias. AUTHORS' CONCLUSIONS: The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2020
DA  - 2020-04-01
JO  - {'id': 'https://openalex.org/S65753830', 'issn_l': '1432-7643', 'issn': ['1433-7479', '1432-7643'], 'display_name': 'Soft Computing', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Samuel Marcos-Pablos
AU  - Francisco José García-Peñalvo
ER  - 

459.
TY  - journal-article
ID  - https://openalex.org/W2336096000
DO  - https://doi.org/10.1002/rev3.3068
TI  - Systematic reviews of research in education: aims, myths and multiple methods
AB  - Systematic reviews are still a controversial topic in some quarters, with the arguments for and against their use being well-rehearsed. In an attempt to advance a more nuanced approach to thinking about systematic reviewing, this paper illustrates the wide range of theoretical perspectives, methodologies and purposes that underpin the vast range of systematic review approaches now available; and in the light of this picture, re-examines some of the perennial arguments against reviews, arguing that they are often poorly targeted, based on a misreading of what systematic reviews aim to do, or simply incommensurable with the tenets that underpin academic enquiry. enhancing the review scope. With that aim, this paper presents an iterative methodology that applies text mining and machine learning techniques to a downloaded corpus of abstracts from scientific databases, combining automatic processing algorithms with tools for supervised decision-making in an iterative process sustained on the researchers’ judgement, so as to adapt, screen and tune the search output. The paper ends showing a working example that employs a set of developed scripts that implement the different stages of the proposed methodology. practical significance can be discussed in terms of both the statistical analysis and in the practitioner's context. they exist, or discuss relevant research that can provide guidance for future work. With the exponential increase in biomedical research output and the ability of text mining approaches to perform automatic tasks at large scale, we propose that such approaches can support tools that promote responsible research practices, providing significant benefits for the biomedical research enterprise. handle and screen big data for relevant information in conservation science. differences (SMDs)) and to investigate associations between summary effect sizes and selected study, intervention, or participant characteristics. We rated the certainty of evidence for each outcome using GRADE. MAIN RESULTS: We included 24 studies, with the majority (20/24) giving concerns about risk of bias. All of the included studies investigated food products; none investigated alcohol or tobacco. The majority were conducted in laboratory settings (14/24), with adult participants (17/24), and used between-participants designs (19/24). All studies were conducted in high-income countries, predominantly in the USA (14/24).Six studies investigated availability interventions, of which two changed the absolute number of different options available, and four altered the relative proportion of less-healthy (to healthier) options. Most studies (4/6) manipulated snack foods or drinks. For selection outcomes, meta-analysis of three comparisons from three studies (n = 154) found that exposure to fewer options resulted in a large reduction in selection of the targeted food(s): SMD -1.13 (95% confidence interval (CI) -1.90 to -0.37) (low certainty evidence). For consumption outcomes, meta-analysis of three comparisons from two studies (n = 150) found that exposure to fewer options resulted in a moderate reduction in consumption of those foods, but with considerable uncertainty: SMD -0.55 (95% CI -1.27 to 0.18) (low certainty evidence).Eighteen studies investigated proximity interventions. Most (14/18) changed the distance at which a snack food or drink was placed from the participants, whilst four studies changed the order of meal components encountered along a line. For selection outcomes, only one study with one comparison (n = 41) was identified, which found that food placed farther away resulted in a moderate reduction in its selection: SMD -0.65 (95% CI -1.29 to -0.01) (very low certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias. AUTHORS' CONCLUSIONS: The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2016
DA  - 2016-02-01
JO  - {'id': 'https://openalex.org/S4210183019', 'issn_l': '2049-6613', 'issn': ['2049-6613'], 'display_name': 'Review of education', 'publisher': 'Wiley', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - David Gough
AU  - James D. Thomas
ER  - 

460.
TY  - journal-article
ID  - https://openalex.org/W2942642522
DO  - https://doi.org/10.2196/12953
TI  - Crowdsourcing the Citation Screening Process for Systematic Reviews: Validation Study
AB  - Background: Systematic reviews (SRs) are often cited as the highest level of evidence available as they involve the identification and synthesis of published studies on a topic. Unfortunately, it is increasingly challenging for small teams to complete SR procedures in a reasonable time period, given the exponential rise in the volume of primary literature. Crowdsourcing has been postulated as a potential solution. Objective: The feasibility objective of this study was to determine whether a crowd would be willing to perform and complete abstract and full text screening. The validation objective was to assess the quality of the crowd’s work, including retention of eligible citations (sensitivity) and work performed for the investigative team, defined as the percentage of citations excluded by the crowd. Methods: We performed a prospective study evaluating crowdsourcing essential components of an SR, including abstract screening, document retrieval, and full text assessment. Using CrowdScreenSR citation screening software, 2323 articles from 6 SRs were available to an online crowd. Citations excluded by less than or equal to 75% of the crowd were moved forward for full text assessment. For the validation component, performance of the crowd was compared with citation review through the accepted, gold standard, trained expert approach. Results: Of 312 potential crowd members, 117 (37.5%) commenced abstract screening and 71 (22.8%) completed the minimum requirement of 50 citation assessments. The majority of participants were undergraduate or medical students (192/312, 61.5%). The crowd screened 16,988 abstracts (median: 8 per citation; interquartile range [IQR] 7-8), and all citations achieved the minimum of 4 assessments after a median of 42 days (IQR 26-67). Crowd members retrieved 83.5% (774/927) of the articles that progressed to the full text phase. A total of 7604 full text assessments were completed (median: 7 per citation; IQR 3-11). Citations from all but 1 review achieved the minimum of 4 assessments after a median of 36 days (IQR 24-70), with 1 review remaining incomplete after 3 months. When complete crowd member agreement at both levels was required for exclusion, sensitivity was 100% (95% CI 97.9-100) and work performed was calculated at 68.3% (95% CI 66.4-70.1). Using the predefined alternative 75% exclusion threshold, sensitivity remained 100% and work performed increased to 72.9% (95% CI 71.0-74.6; P<.001). Finally, when a simple majority threshold was considered, sensitivity decreased marginally to 98.9% (95% CI 96.0-99.7; P=.25) and work performed increased substantially to 80.4% (95% CI 78.7-82.0; P<.001). Conclusions: Crowdsourcing of citation screening for SRs is feasible and has reasonable sensitivity and specificity. By expediting the screening process, crowdsourcing could permit the investigative team to focus on more complex SR tasks. Future directions should focus on developing a user-friendly online platform that allows research teams to crowdsource their reviews. a moderate reduction in consumption of those foods, but with considerable uncertainty: SMD -0.55 (95% CI -1.27 to 0.18) (low certainty evidence).Eighteen studies investigated proximity interventions. Most (14/18) changed the distance at which a snack food or drink was placed from the participants, whilst four studies changed the order of meal components encountered along a line. For selection outcomes, only one study with one comparison (n = 41) was identified, which found that food placed farther away resulted in a moderate reduction in its selection: SMD -0.65 (95% CI -1.29 to -0.01) (very low certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias. AUTHORS' CONCLUSIONS: The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2019
DA  - 2019-04-29
JO  - {'id': 'https://openalex.org/V17147534', 'issn_l': '1438-8871', 'issn': ['1439-4456', '1438-8871'], 'display_name': 'Journal of Medical Internet Research', 'publisher': 'JMIR Publications', 'type': 'journal', 'url': 'https://www.jmir.org/2019/4/e12953/PDF', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Nassr Nama
AU  - Margaret Sampson
AU  - Nick Barrowman
AU  - Ryan Sandarage
AU  - Kusum Menon
AU  - Gail Macartney
AU  - Kimmo Murto
AU  - Peter D. Sly
AU  - Sherri L. Katz
AU  - Roger Zemek
AU  - Ahmed Nasr
AU  - James G. McNally
ER  - 

461.
TY  - journal-article
ID  - https://openalex.org/W4246349412
DO  - https://doi.org/10.1002/14651858.cd012573.pub3
TI  - Altering the availability or proximity of food, alcohol, and tobacco products to change their selection and consumption
AB  - Overconsumption of food, alcohol, and tobacco products increases the risk of non-communicable diseases. Interventions to change characteristics of physical micro-environments where people may select or consume these products - including shops, restaurants, workplaces, and schools - are of considerable public health policy and research interest. This review addresses two types of intervention within such environments: altering the availability (the range and/or amount of options) of these products, or their proximity (the distance at which they are positioned) to potential consumers.1. To assess the impact on selection and consumption of altering the availability or proximity of (a) food (including non-alcoholic beverages), (b) alcohol, and (c) tobacco products.2. To assess the extent to which the impact of these interventions is modified by characteristics of: i. studies, ii. interventions, and iii.We searched CENTRAL, MEDLINE, Embase, PsycINFO, and seven other published or grey literature databases, as well as trial registries and key websites, up to 23 July 2018, followed by citation searches.We included randomised controlled trials with between-participants (parallel group) or within-participants (cross-over) designs. Eligible studies compared effects of exposure to at least two different levels of availability of a product or its proximity, and included a measure of selection or consumption of the manipulated product.We used a novel semi-automated screening workflow and applied standard Cochrane methods to select eligible studies, collect data, and assess risk of bias. In separate analyses for availability interventions and proximity interventions, we combined results using random-effects meta-analysis and meta-regression models to estimate summary effect sizes (as standardised mean differences (SMDs)) and to investigate associations between summary effect sizes and selected study, intervention, or participant characteristics. We rated the certainty of evidence for each outcome using GRADE.We included 24 studies, with the majority (20/24) giving concerns about risk of bias. All of the included studies investigated food products; none investigated alcohol or tobacco. The majority were conducted in laboratory settings (14/24), with adult participants (17/24), and used between-participants designs (19/24). All studies were conducted in high-income countries, predominantly in the USA (14/24).Six studies investigated availability interventions, of which two changed the absolute number of different options available, and four altered the relative proportion of less-healthy (to healthier) options. Most studies (4/6) manipulated snack foods or drinks. For selection outcomes, meta-analysis of three comparisons from three studies (n = 154) found that exposure to fewer options resulted in a large reduction in selection of the targeted food(s): SMD -1.13 (95% confidence interval (CI) -1.90 to -0.37) (low certainty evidence). For consumption outcomes, meta-analysis of three comparisons from two studies (n = 150) found that exposure to fewer options resulted in a moderate reduction in consumption of those foods, but with considerable uncertainty: SMD -0.55 (95% CI -1.27 to 0.18) (low certainty evidence).Eighteen studies investigated proximity interventions. Most (14/18) changed the distance at which a snack food or drink was placed from the participants, whilst four studies changed the order of meal components encountered along a line. For selection outcomes, only one study with one comparison (n = 41) was identified, which found that food placed farther away resulted in a moderate reduction in its selection: SMD -0.65 (95% CI -1.29 to -0.01) (very low certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2019
DA  - 2019-09-04
JO  - {'id': 'https://openalex.org/V4210172715', 'issn_l': '1464-780X', 'issn': ['1464-780X', '1465-184X', '1465-1858'], 'display_name': 'The Cochrane library', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Gareth J Hollands
AU  - Patrice Carter
AU  - Sumayya Anwer
AU  - Sarah R. B. King
AU  - Susan A. Jebb
AU  - David Ogilvie
AU  - Ian Shemilt
AU  - Julian P T Higgins
AU  - Theresa M. Marteau
ER  - 

462.
TY  - journal-article
ID  - https://openalex.org/W2735984040
DO  - https://doi.org/10.1016/j.jbi.2017.07.010
TI  - Reproducibility of studies on text mining for citation screening in systematic reviews: Evaluation and checklist
AB  - Independent validation of published scientific results through study replication is a pre-condition for accepting the validity of such results. In computation research, full replication is often unrealistic for independent results validation, therefore, study reproduction has been justified as the minimum acceptable standard to evaluate the validity of scientific claims. The application of text mining techniques to citation screening in the context of systematic literature reviews is a relatively young and growing computational field with high relevance for software engineering, medical research and other fields. However, there is little work so far on reproduction studies in the field.In this paper, we investigate the reproducibility of studies in this area based on information contained in published articles and we propose reporting guidelines that could improve reproducibility.The study was approached in two ways. Initially we attempted to reproduce results from six studies, which were based on the same raw dataset. Then, based on this experience, we identified steps considered essential to successful reproduction of text mining experiments and characterized them to measure how reproducible is a study given the information provided on these steps. 33 articles were systematically assessed for reproducibility using this approach.Our work revealed that it is currently difficult if not impossible to independently reproduce the results published in any of the studies investigated. The lack of information about the datasets used limits reproducibility of about 80% of the studies assessed. Also, information about the machine learning algorithms is inadequate in about 27% of the papers. On the plus side, the third party software tools used are mostly free and available.The reproducibility potential of most of the studies can be significantly improved if more attention is paid to information provided on the datasets used, how they were partitioned and utilized, and how any randomization was controlled. We introduce a checklist of information that needs to be provided in order to ensure that a published study can be reproduced. used between-participants designs (19/24). All studies were conducted in high-income countries, predominantly in the USA (14/24).Six studies investigated availability interventions, of which two changed the absolute number of different options available, and four altered the relative proportion of less-healthy (to healthier) options. Most studies (4/6) manipulated snack foods or drinks. For selection outcomes, meta-analysis of three comparisons from three studies (n = 154) found that exposure to fewer options resulted in a large reduction in selection of the targeted food(s): SMD -1.13 (95% confidence interval (CI) -1.90 to -0.37) (low certainty evidence). For consumption outcomes, meta-analysis of three comparisons from two studies (n = 150) found that exposure to fewer options resulted in a moderate reduction in consumption of those foods, but with considerable uncertainty: SMD -0.55 (95% CI -1.27 to 0.18) (low certainty evidence).Eighteen studies investigated proximity interventions. Most (14/18) changed the distance at which a snack food or drink was placed from the participants, whilst four studies changed the order of meal components encountered along a line. For selection outcomes, only one study with one comparison (n = 41) was identified, which found that food placed farther away resulted in a moderate reduction in its selection: SMD -0.65 (95% CI -1.29 to -0.01) (very low certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2017
DA  - 2017-09-01
JO  - {'id': 'https://openalex.org/S11622463', 'issn_l': '1532-0464', 'issn': ['1532-0480', '1532-0464'], 'display_name': 'Journal of Biomedical Informatics', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'https://doi.org/10.1016/j.jbi.2017.07.010', 'is_oa': True, 'version': 'publishedVersion', 'license': 'elsevier-specific'}
DP  - OpenAlex
AU  - Babatunde K. Olorisade
AU  - Pearl Brereton
AU  - Peter Andras
ER  - 

463.
TY  - journal-article
ID  - https://openalex.org/W2905431510
DO  - https://doi.org/10.1002/jrsm.1335
TI  - Usage of automation tools in systematic reviews
AB  - Systematic reviews are a cornerstone of today's evidence-informed decision making. With the rapid expansion of questions to be addressed and scientific information produced, there is a growing workload on reviewers, making the current practice unsustainable without the aid of automation tools. While many automation tools have been developed and are available, uptake seems to be lagging. For this reason, we set out to investigate the current level of uptake and what the potential barriers and facilitators are for the adoption of automation tools in systematic reviews. We deployed surveys among systematic reviewers that gathered information on tool uptake, demographics, systematic review characteristics, and barriers and facilitators for uptake. Systematic reviewers from multiple domains were targeted during recruitment; however, responders were predominantly from the biomedical sciences. We found that automation tools are currently not widely used among the participants. When tools are used, participants mostly learn about them from their environment, for example, through colleagues, peers, or organization. Tools are often chosen on the basis of user experience, either by own experience or from colleagues or peers. Lastly, licensing, steep learning curve, lack of support, and mismatch to workflow are often reported by participants as relevant barriers. While conclusions can only be drawn for the biomedical field, our work provides evidence and confirms the conclusions and recommendations of previous work, which was based on expert opinions. Furthermore, our study highlights the importance that organizations and best practices in a field can have for the uptake of automation tools for systematic reviews. third party software tools used are mostly free and available.The reproducibility potential of most of the studies can be significantly improved if more attention is paid to information provided on the datasets used, how they were partitioned and utilized, and how any randomization was controlled. We introduce a checklist of information that needs to be provided in order to ensure that a published study can be reproduced. used between-participants designs (19/24). All studies were conducted in high-income countries, predominantly in the USA (14/24).Six studies investigated availability interventions, of which two changed the absolute number of different options available, and four altered the relative proportion of less-healthy (to healthier) options. Most studies (4/6) manipulated snack foods or drinks. For selection outcomes, meta-analysis of three comparisons from three studies (n = 154) found that exposure to fewer options resulted in a large reduction in selection of the targeted food(s): SMD -1.13 (95% confidence interval (CI) -1.90 to -0.37) (low certainty evidence). For consumption outcomes, meta-analysis of three comparisons from two studies (n = 150) found that exposure to fewer options resulted in a moderate reduction in consumption of those foods, but with considerable uncertainty: SMD -0.55 (95% CI -1.27 to 0.18) (low certainty evidence).Eighteen studies investigated proximity interventions. Most (14/18) changed the distance at which a snack food or drink was placed from the participants, whilst four studies changed the order of meal components encountered along a line. For selection outcomes, only one study with one comparison (n = 41) was identified, which found that food placed farther away resulted in a moderate reduction in its selection: SMD -0.65 (95% CI -1.29 to -0.01) (very low certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2019
DA  - 2019-03-01
JO  - {'id': 'https://openalex.org/S205768342', 'issn_l': '1759-2879', 'issn': ['1759-2879', '1759-2887'], 'display_name': 'Research Synthesis Methods', 'publisher': 'Wiley-Blackwell', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Allard J. van Altena
AU  - René Spijker
AU  - Silvia D. Olabarriaga
ER  - 

464.
TY  - journal-article
ID  - https://openalex.org/W3093336514
DO  - https://doi.org/10.1186/s12874-020-01129-1
TI  - An evaluation of DistillerSR’s machine learning-based prioritization tool for title/abstract screening – impact on reviewer-relevant outcomes
AB  - Abstract Background Systematic reviews often require substantial resources, partially due to the large number of records identified during searching. Although artificial intelligence may not be ready to fully replace human reviewers, it may accelerate and reduce the screening burden. Using DistillerSR (May 2020 release), we evaluated the performance of the prioritization simulation tool to determine the reduction in screening burden and time savings. Methods Using a true recall @ 95%, response sets from 10 completed systematic reviews were used to evaluate: (i) the reduction of screening burden; (ii) the accuracy of the prioritization algorithm; and (iii) the hours saved when a modified screening approach was implemented. To account for variation in the simulations, and to introduce randomness (through shuffling the references), 10 simulations were run for each review. Means, standard deviations, medians and interquartile ranges (IQR) are presented. Results Among the 10 systematic reviews, using true recall @ 95% there was a median reduction in screening burden of 47.1% (IQR: 37.5 to 58.0%). A median of 41.2% (IQR: 33.4 to 46.9%) of the excluded records needed to be screened to achieve true recall @ 95%. The median title/abstract screening hours saved using a modified screening approach at a true recall @ 95% was 29.8 h (IQR: 28.1 to 74.7 h). This was increased to a median of 36 h (IQR: 32.2 to 79.7 h) when considering the time saved not retrieving and screening full texts of the remaining 5% of records not yet identified as included at title/abstract. Among the 100 simulations (10 simulations per review), none of these 5% of records were a final included study in the systematic review. The reduction in screening burden to achieve true recall @ 95% compared to @ 100% resulted in a reduced screening burden median of 40.6% (IQR: 38.3 to 54.2%). Conclusions The prioritization tool in DistillerSR can reduce screening burden. A modified or stop screening approach once a true recall @ 95% is achieved appears to be a valid method for rapid reviews, and perhaps systematic reviews. This needs to be further evaluated in prospective reviews using the estimated recall. four altered the relative proportion of less-healthy (to healthier) options. Most studies (4/6) manipulated snack foods or drinks. For selection outcomes, meta-analysis of three comparisons from three studies (n = 154) found that exposure to fewer options resulted in a large reduction in selection of the targeted food(s): SMD -1.13 (95% confidence interval (CI) -1.90 to -0.37) (low certainty evidence). For consumption outcomes, meta-analysis of three comparisons from two studies (n = 150) found that exposure to fewer options resulted in a moderate reduction in consumption of those foods, but with considerable uncertainty: SMD -0.55 (95% CI -1.27 to 0.18) (low certainty evidence).Eighteen studies investigated proximity interventions. Most (14/18) changed the distance at which a snack food or drink was placed from the participants, whilst four studies changed the order of meal components encountered along a line. For selection outcomes, only one study with one comparison (n = 41) was identified, which found that food placed farther away resulted in a moderate reduction in its selection: SMD -0.65 (95% CI -1.29 to -0.01) (very low certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2020
DA  - 2020-10-15
JO  - {'id': 'https://openalex.org/S185874209', 'issn_l': '1471-2288', 'issn': ['1471-2288'], 'display_name': 'BMC Medical Research Methodology', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://doi.org/10.1186/s12874-020-01129-1', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Candyce Hamel
AU  - Shannon Kelly
AU  - Walter P. Wodchis
AU  - Danielle B. Rice
AU  - George A. Wells
AU  - Brian Hutton
ER  - 

465.
TY  - journal-article
ID  - https://openalex.org/W4254918213
DO  - https://doi.org/10.1002/14651858.cd012573.pub2
TI  - Altering the availability or proximity of food, alcohol, and tobacco products to change their selection and consumption
AB  - Overconsumption of food, alcohol, and tobacco products increases the risk of non-communicable diseases. Interventions to change characteristics of physical micro-environments where people may select or consume these products - including shops, restaurants, workplaces, and schools - are of considerable public health policy and research interest. This review addresses two types of intervention within such environments: altering the availability (the range and/or amount of options) of these products, or their proximity (the distance at which they are positioned) to potential consumers.1. To assess the impact on selection and consumption of altering the availability or proximity of (a) food (including non-alcoholic beverages), (b) alcohol, and (c) tobacco products.2. To assess the extent to which the impact of these interventions is modified by characteristics of: i. studies, ii. interventions, and iii.We searched CENTRAL, MEDLINE, Embase, PsycINFO, and seven other published or grey literature databases, as well as trial registries and key websites, up to 23 July 2018, followed by citation searches.We included randomised controlled trials with between-participants (parallel group) or within-participants (cross-over) designs. Eligible studies compared effects of exposure to at least two different levels of availability of a product or its proximity, and included a measure of selection or consumption of the manipulated product.We used a novel semi-automated screening workflow and applied standard Cochrane methods to select eligible studies, collect data, and assess risk of bias. In separate analyses for availability interventions and proximity interventions, we combined results using random-effects meta-analysis and meta-regression models to estimate summary effect sizes (as standardised mean differences (SMDs)) and to investigate associations between summary effect sizes and selected study, intervention, or participant characteristics. We rated the certainty of evidence for each outcome using GRADE.We included 24 studies, with the majority (20/24) giving concerns about risk of bias. All of the included studies investigated food products; none investigated alcohol or tobacco. The majority were conducted in laboratory settings (14/24), with adult participants (17/24), and used between-participants designs (19/24). All studies were conducted in high-income countries, predominantly in the USA (14/24).Six studies investigated availability interventions, of which two changed the absolute number of different options available, and four altered the relative proportion of less-healthy (to healthier) options. Most studies (4/6) manipulated snack foods or drinks. For selection outcomes, meta-analysis of three comparisons from three studies (n = 154) found that exposure to fewer options resulted in a large reduction in selection of the targeted food(s): SMD -1.13 (95% confidence interval (CI) -1.90 to -0.37) (low certainty evidence). For consumption outcomes, meta-analysis of three comparisons from two studies (n = 150) found that exposure to fewer options resulted in a moderate reduction in consumption of those foods, but with considerable uncertainty: SMD -0.55 (95% CI -1.27 to 0.18) (low certainty evidence).Eighteen studies investigated proximity interventions. Most (14/18) changed the distance at which a snack food or drink was placed from the participants, whilst four studies changed the order of meal components encountered along a line. For selection outcomes, only one study with one comparison (n = 41) was identified, which found that food placed farther away resulted in a moderate reduction in its selection: SMD -0.65 (95% CI -1.29 to -0.01) (very low certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2019
DA  - 2019-08-27
JO  - {'id': 'https://openalex.org/V4210172715', 'issn_l': '1464-780X', 'issn': ['1464-780X', '1465-184X', '1465-1858'], 'display_name': 'The Cochrane library', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Gareth J Hollands
AU  - Patrice Carter
AU  - Sumayya Anwer
AU  - Sarah R. B. King
AU  - Susan A. Jebb
AU  - David Ogilvie
AU  - Ian Shemilt
AU  - Julian P T Higgins
AU  - Theresa M. Marteau
ER  - 

466.
TY  - journal-article
ID  - https://openalex.org/W2789984239
DO  - https://doi.org/10.1111/clr.13143
TI  - Diagnostic performance of cone beam computed tomography in assessing peri-implant bone loss: A systematic review
AB  - To evaluate the diagnostic performance of cone beam computed tomography (CBCT) in the assessment of peri-implant bone loss and analyze its influencing factors.Clinical and preclinical studies reporting diagnostic outcomes of CBCT imaging of peri-implant bone loss compared to direct reference measurements were sought by searching five electronic databases, PubMed, MEDLINE, EMBASE, Web of Science, and CINAHL Plus, and OpenGrey. QUADAS-2 criteria were adapted for quality analysis of the included studies. A qualitative synthesis was performed. Two meta-analysis models (random-effects and mixed-effects) summarized the area under receiver operating characteristic (AUC) curve observations reported in the selected studies. The mixed-effects meta-analysis model evaluated three possible influencing factors, "defect type," "defect size," and "study effect."The initial search yielded 3,716 titles, from which 18 studies (13 in vitro and 5 animal) were included. Diagnostic accuracy of CBCT was fair to excellent in detecting in vitro circumferential-intrabony and fenestration defects, but moderate to low for peri-implant dehiscences, and tended to be higher for larger defect sizes. Both, over- and underestimation of linear measurements were reported for the animal models. The meta-analyses included 37 AUC observations from eight studies. The random-effects model showed significant heterogeneity. The mixed-effects model exhibited also significant but lower heterogeneity, and "defect type" and "study effect" significantly influenced the variability of AUC observations.In vitro, CBCT performs well in detecting peri-implant circumferential-intrabony or fenestration defects but less in depicting dehiscences. Influencing factors due to other site-related and technical parameters on the diagnostic outcome need to be addressed further in the future studies. mean differences (SMDs)) and to investigate associations between summary effect sizes and selected study, intervention, or participant characteristics. We rated the certainty of evidence for each outcome using GRADE.We included 24 studies, with the majority (20/24) giving concerns about risk of bias. All of the included studies investigated food products; none investigated alcohol or tobacco. The majority were conducted in laboratory settings (14/24), with adult participants (17/24), and used between-participants designs (19/24). All studies were conducted in high-income countries, predominantly in the USA (14/24).Six studies investigated availability interventions, of which two changed the absolute number of different options available, and four altered the relative proportion of less-healthy (to healthier) options. Most studies (4/6) manipulated snack foods or drinks. For selection outcomes, meta-analysis of three comparisons from three studies (n = 154) found that exposure to fewer options resulted in a large reduction in selection of the targeted food(s): SMD -1.13 (95% confidence interval (CI) -1.90 to -0.37) (low certainty evidence). For consumption outcomes, meta-analysis of three comparisons from two studies (n = 150) found that exposure to fewer options resulted in a moderate reduction in consumption of those foods, but with considerable uncertainty: SMD -0.55 (95% CI -1.27 to 0.18) (low certainty evidence).Eighteen studies investigated proximity interventions. Most (14/18) changed the distance at which a snack food or drink was placed from the participants, whilst four studies changed the order of meal components encountered along a line. For selection outcomes, only one study with one comparison (n = 41) was identified, which found that food placed farther away resulted in a moderate reduction in its selection: SMD -0.65 (95% CI -1.29 to -0.01) (very low certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2018
DA  - 2018-05-01
JO  - {'id': 'https://openalex.org/S122069063', 'issn_l': '0905-7161', 'issn': ['1600-0501', '0905-7161'], 'display_name': 'Clinical Oral Implants Research', 'publisher': 'Wiley', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - George Pelekos
AU  - Aneesha Acharya
AU  - Maurizio S. Tonetti
AU  - Michael M. Bornstein
ER  - 

467.
TY  - journal-article
ID  - https://openalex.org/W2801856446
DO  - https://doi.org/10.1186/s13643-018-0724-7
TI  - Automated screening of research studies for systematic reviews using study characteristics
AB  - Screening candidate studies for inclusion in a systematic review is time-consuming when conducted manually. Automation tools could reduce the human effort devoted to screening. Existing methods use supervised machine learning which train classifiers to identify relevant words in the abstracts of candidate articles that have previously been labelled by a human reviewer for inclusion or exclusion. Such classifiers typically reduce the number of abstracts requiring manual screening by about 50%.We extracted four key characteristics of observational studies (population, exposure, confounders and outcomes) from the text of titles and abstracts for all articles retrieved using search strategies from systematic reviews. Our screening method excluded studies if they did not meet a predefined set of characteristics. The method was evaluated using three systematic reviews. Screening results were compared to the actual inclusion list of the reviews.The best screening threshold rule identified studies that mentioned both exposure (E) and outcome (O) in the study abstract. This screening rule excluded 93.7% of retrieved studies with a recall of 98%.Filtering studies for inclusion in a systematic review based on the detection of key study characteristics in abstracts significantly outperformed standard approaches to automated screening and appears worthy of further development and evaluation. heterogeneity, and "defect type" and "study effect" significantly influenced the variability of AUC observations.In vitro, CBCT performs well in detecting peri-implant circumferential-intrabony or fenestration defects but less in depicting dehiscences. Influencing factors due to other site-related and technical parameters on the diagnostic outcome need to be addressed further in the future studies. mean differences (SMDs)) and to investigate associations between summary effect sizes and selected study, intervention, or participant characteristics. We rated the certainty of evidence for each outcome using GRADE.We included 24 studies, with the majority (20/24) giving concerns about risk of bias. All of the included studies investigated food products; none investigated alcohol or tobacco. The majority were conducted in laboratory settings (14/24), with adult participants (17/24), and used between-participants designs (19/24). All studies were conducted in high-income countries, predominantly in the USA (14/24).Six studies investigated availability interventions, of which two changed the absolute number of different options available, and four altered the relative proportion of less-healthy (to healthier) options. Most studies (4/6) manipulated snack foods or drinks. For selection outcomes, meta-analysis of three comparisons from three studies (n = 154) found that exposure to fewer options resulted in a large reduction in selection of the targeted food(s): SMD -1.13 (95% confidence interval (CI) -1.90 to -0.37) (low certainty evidence). For consumption outcomes, meta-analysis of three comparisons from two studies (n = 150) found that exposure to fewer options resulted in a moderate reduction in consumption of those foods, but with considerable uncertainty: SMD -0.55 (95% CI -1.27 to 0.18) (low certainty evidence).Eighteen studies investigated proximity interventions. Most (14/18) changed the distance at which a snack food or drink was placed from the participants, whilst four studies changed the order of meal components encountered along a line. For selection outcomes, only one study with one comparison (n = 41) was identified, which found that food placed farther away resulted in a moderate reduction in its selection: SMD -0.65 (95% CI -1.29 to -0.01) (very low certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2018
DA  - 2018-04-25
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://systematicreviewsjournal.biomedcentral.com/track/pdf/10.1186/s13643-018-0724-7', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Guy Tsafnat
AU  - Paul Glasziou
AU  - George Karystianis
AU  - Enrico Coiera
ER  - 

468.
TY  - journal-article
ID  - https://openalex.org/W3001091824
DO  - https://doi.org/10.1016/j.jclinepi.2020.01.009
TI  - Title, abstract, and keyword searching resulted in poor recovery of articles in systematic reviews of epidemiologic practice
AB  - Abstract candidate studies Objective inclusion Article full texts are often inaccessible via the standard search engines of biomedical literature, such as PubMed and Embase, which are commonly used for systematic reviews. Excluding the full-text bodies from a literature search may result in a small or selective subset of articles being included in the review because of the limited information that is available in only title, abstract, and keywords. This article describes a comparison of search strategies based on a systematic literature review of all articles published in 5 top-ranked epidemiology journals between 2000 and 2017. search strategies from Study Design and Setting method Based on a text-mining approach, we studied how nine different methodological topics were mentioned across text fields (title, abstract, keywords, and text body). The following methodological topics were studied: propensity score methods, inverse probability weighting, marginal structural modeling, multiple imputation, Kaplan-Meier estimation, number needed to treat, measurement error, randomized controlled trial, and latent class analysis. of retrieved studies Results a In total, 31,641 Hypertext Markup Language (HTML) files were downloaded from the journals’ websites. For all methodological topics and journals, at most 50% of articles with a mention of a topic in the text body also mentioned the topic in the title, abstract, or keywords. For several topics, a gradual decrease over calendar time was observed of reporting in the title, abstract, or keywords. dehiscences. Influencing factors Conclusion to Literature searches based on title, abstract, and keywords alone may not be sufficiently sensitive for studies of epidemiological research practice. This study also illustrates the potential value of full-text literature searches, provided there is accessibility of full-text bodies for literature searches. evidence for each outcome using GRADE.We included 24 studies, with the majority (20/24) giving concerns about risk of bias. All of the included studies investigated food products; none investigated alcohol or tobacco. The majority were conducted in laboratory settings (14/24), with adult participants (17/24), and used between-participants designs (19/24). All studies were conducted in high-income countries, predominantly in the USA (14/24).Six studies investigated availability interventions, of which two changed the absolute number of different options available, and four altered the relative proportion of less-healthy (to healthier) options. Most studies (4/6) manipulated snack foods or drinks. For selection outcomes, meta-analysis of three comparisons from three studies (n = 154) found that exposure to fewer options resulted in a large reduction in selection of the targeted food(s): SMD -1.13 (95% confidence interval (CI) -1.90 to -0.37) (low certainty evidence). For consumption outcomes, meta-analysis of three comparisons from two studies (n = 150) found that exposure to fewer options resulted in a moderate reduction in consumption of those foods, but with considerable uncertainty: SMD -0.55 (95% CI -1.27 to 0.18) (low certainty evidence).Eighteen studies investigated proximity interventions. Most (14/18) changed the distance at which a snack food or drink was placed from the participants, whilst four studies changed the order of meal components encountered along a line. For selection outcomes, only one study with one comparison (n = 41) was identified, which found that food placed farther away resulted in a moderate reduction in its selection: SMD -0.65 (95% CI -1.29 to -0.01) (very low certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2020
DA  - 2020-05-01
JO  - {'id': 'https://openalex.org/V64418186', 'issn_l': '0895-4356', 'issn': ['1878-5921', '0895-4356'], 'display_name': 'Journal of Clinical Epidemiology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'http://www.jclinepi.com/article/S0895435619306018/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Bas B.L. Penning de Vries
AU  - Maarten van Smeden
AU  - Frits R. Rosendaal
AU  - Rolf H.H. Groenwold
ER  - 

469.
TY  - journal-article
ID  - https://openalex.org/W2775952591
DO  - https://doi.org/10.1007/s10669-017-9670-5
TI  - Supervised clustering for automated document classification and prioritization: a case study using toxicological abstracts
AB  - No Abstract Found
PY  - 2018
DA  - 2018-09-01
JO  - {'id': 'https://openalex.org/S2764812402', 'issn_l': '2194-5411', 'issn': ['2194-5403', '2194-5411'], 'display_name': 'Environment Systems and Decisions', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Arun Varghese
AU  - Michelle Cawley
AU  - Tao Hong
ER  - 

470.
TY  - journal-article
ID  - https://openalex.org/W3014512586
DO  - https://doi.org/10.1186/s13643-020-01324-7
TI  - Machine learning for screening prioritization in systematic reviews: comparative performance of Abstrackr and EPPI-Reviewer
AB  - Abstract Background Improving the speed of systematic review (SR) development is key to supporting evidence-based medicine. Machine learning tools which semi-automate citation screening might improve efficiency. Few studies have assessed use of screening prioritization functionality or compared two tools head to head. In this project, we compared performance of two machine-learning tools for potential use in citation screening. Methods Using 9 evidence reports previously completed by the ECRI Institute Evidence-based Practice Center team, we compared performance of Abstrackr and EPPI-Reviewer, two off-the-shelf citations screening tools, for identifying relevant citations. Screening prioritization functionality was tested for 3 large reports and 6 small reports on a range of clinical topics. Large report topics were imaging for pancreatic cancer, indoor allergen reduction, and inguinal hernia repair. We trained Abstrackr and EPPI-Reviewer and screened all citations in 10% increments. In Task 1, we inputted whether an abstract was ordered for full-text screening; in Task 2, we inputted whether an abstract was included in the final report. For both tasks, screening continued until all studies ordered and included for the actual reports were identified. We assessed potential reductions in hypothetical screening burden (proportion of citations screened to identify all included studies) offered by each tool for all 9 reports. Results For the 3 large reports, both EPPI-Reviewer and Abstrackr performed well with potential reductions in screening burden of 4 to 49% (Abstrackr) and 9 to 60% (EPPI-Reviewer). Both tools had markedly poorer performance for 1 large report (inguinal hernia), possibly due to its heterogeneous key questions. Based on McNemar’s test for paired proportions in the 3 large reports, EPPI-Reviewer outperformed Abstrackr for identifying articles ordered for full-text review, but Abstrackr performed better in 2 of 3 reports for identifying articles included in the final report. For small reports, both tools provided benefits but EPPI-Reviewer generally outperformed Abstrackr in both tasks, although these results were often not statistically significant. Conclusions Abstrackr and EPPI-Reviewer performed well, but prioritization accuracy varied greatly across reports. Our work suggests screening prioritization functionality is a promising modality offering efficiency gains without giving up human involvement in the screening process. and four altered the relative proportion of less-healthy (to healthier) options. Most studies (4/6) manipulated snack foods or drinks. For selection outcomes, meta-analysis of three comparisons from three studies (n = 154) found that exposure to fewer options resulted in a large reduction in selection of the targeted food(s): SMD -1.13 (95% confidence interval (CI) -1.90 to -0.37) (low certainty evidence). For consumption outcomes, meta-analysis of three comparisons from two studies (n = 150) found that exposure to fewer options resulted in a moderate reduction in consumption of those foods, but with considerable uncertainty: SMD -0.55 (95% CI -1.27 to 0.18) (low certainty evidence).Eighteen studies investigated proximity interventions. Most (14/18) changed the distance at which a snack food or drink was placed from the participants, whilst four studies changed the order of meal components encountered along a line. For selection outcomes, only one study with one comparison (n = 41) was identified, which found that food placed farther away resulted in a moderate reduction in its selection: SMD -0.65 (95% CI -1.29 to -0.01) (very low certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2020
DA  - 2020-04-02
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://doi.org/10.1186/s13643-020-01324-7', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Amy Tsou
AU  - Jonathan Treadwell
AU  - Eileen Erinoff
AU  - Karen M Schoelles
ER  - 

471.
TY  - journal-article
ID  - https://openalex.org/W2886527588
DO  - https://doi.org/10.1002/jrsm.1317
TI  - Discriminating between empirical studies and nonempirical works using automated text classification
AB  - OBJECTIVE Identify the most performant automated text classification method (eg, algorithm) for differentiating empirical studies from nonempirical works in order to facilitate systematic mixed studies reviews. METHODS The algorithms were trained and validated with 8050 database records, which had previously been manually categorized as empirical or nonempirical. A Boolean mixed filter developed for filtering MEDLINE records (title, abstract, keywords, and full texts) was used as a baseline. The set of features (eg, characteristics from the data) included observable terms and concepts extracted from a metathesaurus. The efficiency of the approaches was measured using sensitivity, precision, specificity, and accuracy. RESULTS The decision trees algorithm demonstrated the highest performance, surpassing the accuracy of the Boolean mixed filter by 30%. The use of full texts did not result in significant gains compared with title, abstract, keywords, and records. Results also showed that mixing concepts with observable terms can improve the classification. SIGNIFICANCE Screening of records, identified in bibliographic databases, for relevant studies to include in systematic reviews can be accelerated with automated text classification. and included for the actual reports were identified. We assessed potential reductions in hypothetical screening burden (proportion of citations screened to identify all included studies) offered by each tool for all 9 reports. Results For the 3 large reports, both EPPI-Reviewer and Abstrackr performed well with potential reductions in screening burden of 4 to 49% (Abstrackr) and 9 to 60% (EPPI-Reviewer). Both tools had markedly poorer performance for 1 large report (inguinal hernia), possibly due to its heterogeneous key questions. Based on McNemar’s test for paired proportions in the 3 large reports, EPPI-Reviewer outperformed Abstrackr for identifying articles ordered for full-text review, but Abstrackr performed better in 2 of 3 reports for identifying articles included in the final report. For small reports, both tools provided benefits but EPPI-Reviewer generally outperformed Abstrackr in both tasks, although these results were often not statistically significant. Conclusions Abstrackr and EPPI-Reviewer performed well, but prioritization accuracy varied greatly across reports. Our work suggests screening prioritization functionality is a promising modality offering efficiency gains without giving up human involvement in the screening process. and four altered the relative proportion of less-healthy (to healthier) options. Most studies (4/6) manipulated snack foods or drinks. For selection outcomes, meta-analysis of three comparisons from three studies (n = 154) found that exposure to fewer options resulted in a large reduction in selection of the targeted food(s): SMD -1.13 (95% confidence interval (CI) -1.90 to -0.37) (low certainty evidence). For consumption outcomes, meta-analysis of three comparisons from two studies (n = 150) found that exposure to fewer options resulted in a moderate reduction in consumption of those foods, but with considerable uncertainty: SMD -0.55 (95% CI -1.27 to 0.18) (low certainty evidence).Eighteen studies investigated proximity interventions. Most (14/18) changed the distance at which a snack food or drink was placed from the participants, whilst four studies changed the order of meal components encountered along a line. For selection outcomes, only one study with one comparison (n = 41) was identified, which found that food placed farther away resulted in a moderate reduction in its selection: SMD -0.65 (95% CI -1.29 to -0.01) (very low certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2018
DA  - 2018-12-01
JO  - {'id': 'https://openalex.org/S205768342', 'issn_l': '1759-2879', 'issn': ['1759-2879', '1759-2887'], 'display_name': 'Research Synthesis Methods', 'publisher': 'Wiley-Blackwell', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Alexis Langlois
AU  - Jian-Yun Nie
AU  - James D. Thomas
AU  - Quan Hong
AU  - Pierre Pluye
ER  - 

472.
TY  - journal-article
ID  - https://openalex.org/W2992824360
DO  - https://doi.org/10.1186/s12911-019-0992-8
TI  - Improving reference prioritisation with PICO recognition
AB  - Machine learning can assist with multiple tasks during systematic reviews to facilitate the rapid retrieval of relevant references during screening and to identify and extract information relevant to the study characteristics, which include the PICO elements of patient/population, intervention, comparator, and outcomes. The latter requires techniques for identifying and categorising fragments of text, known as named entity recognition.A publicly available corpus of PICO annotations on biomedical abstracts is used to train a named entity recognition model, which is implemented as a recurrent neural network. This model is then applied to a separate collection of abstracts for references from systematic reviews within biomedical and health domains. The occurrences of words tagged in the context of specific PICO contexts are used as additional features for a relevancy classification model. Simulations of the machine learning-assisted screening are used to evaluate the work saved by the relevancy model with and without the PICO features. Chi-squared and statistical significance of positive predicted values are used to identify words that are more indicative of relevancy within PICO contexts.Inclusion of PICO features improves the performance metric on 15 of the 20 collections, with substantial gains on certain systematic reviews. Examples of words whose PICO context are more precise can explain this increase.Words within PICO tagged segments in abstracts are predictive features for determining inclusion. Combining PICO annotation model into the relevancy classification pipeline is a promising approach. The annotations may be useful on their own to aid users in pinpointing necessary information for data extraction, or to facilitate semantic search. McNemar’s test for paired proportions in the 3 large reports, EPPI-Reviewer outperformed Abstrackr for identifying articles ordered for full-text review, but Abstrackr performed better in 2 of 3 reports for identifying articles included in the final report. For small reports, both tools provided benefits but EPPI-Reviewer generally outperformed Abstrackr in both tasks, although these results were often not statistically significant. Conclusions Abstrackr and EPPI-Reviewer performed well, but prioritization accuracy varied greatly across reports. Our work suggests screening prioritization functionality is a promising modality offering efficiency gains without giving up human involvement in the screening process. and four altered the relative proportion of less-healthy (to healthier) options. Most studies (4/6) manipulated snack foods or drinks. For selection outcomes, meta-analysis of three comparisons from three studies (n = 154) found that exposure to fewer options resulted in a large reduction in selection of the targeted food(s): SMD -1.13 (95% confidence interval (CI) -1.90 to -0.37) (low certainty evidence). For consumption outcomes, meta-analysis of three comparisons from two studies (n = 150) found that exposure to fewer options resulted in a moderate reduction in consumption of those foods, but with considerable uncertainty: SMD -0.55 (95% CI -1.27 to 0.18) (low certainty evidence).Eighteen studies investigated proximity interventions. Most (14/18) changed the distance at which a snack food or drink was placed from the participants, whilst four studies changed the order of meal components encountered along a line. For selection outcomes, only one study with one comparison (n = 41) was identified, which found that food placed farther away resulted in a moderate reduction in its selection: SMD -0.65 (95% CI -1.29 to -0.01) (very low certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2019
DA  - 2019-12-05
JO  - {'id': 'https://openalex.org/V107516304', 'issn_l': '1472-6947', 'issn': ['1472-6947'], 'display_name': 'BMC Medical Informatics and Decision Making', 'publisher': 'BioMed Central', 'type': 'journal', 'url': 'https://bmcmedinformdecismak.biomedcentral.com/track/pdf/10.1186/s12911-019-0992-8', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - John McNaught
AU  - Meizhi Ju
AU  - Piotr Przybyła
AU  - Sophia Ananiadou
ER  - 

473.
TY  - journal-article
ID  - https://openalex.org/W3209408247
DO  - https://doi.org/10.1088/1748-9326/ac1b58
TI  - Coal transitions—part 1: a systematic map and review of case study learnings from regional, national, and local coal phase-out experiences
AB  - No Abstract Found
PY  - 2021
DA  - 2021-10-21
JO  - {'id': 'https://openalex.org/S139338987', 'issn_l': '1748-9326', 'issn': ['1748-9326'], 'display_name': 'Environmental Research Letters', 'publisher': 'IOP Publishing', 'type': 'journal', 'url': 'https://doi.org/10.1088/1748-9326/ac1b58', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Francesca Diluiso
AU  - Paula Walk
AU  - Niccolò Manych
AU  - Nicola Cerutti
AU  - Vladislav Chipiga
AU  - Annabelle Workman
AU  - Ceren Ayas
AU  - Ryna Yiyun Cui
AU  - Diyang Cui
AU  - Kaihui Song
AU  - Lucy Banisch
AU  - Nikolaj Moretti
AU  - Max Callaghan
AU  - Leon Clarke
AU  - Felix Creutzig
AU  - Jérôme Hilaire
AU  - Frank Jotzo
AU  - Matthias Kalkuhl
AU  - William F. Lamb
AU  - Andreas Löschel
AU  - Finn Müller-Hansen
AU  - Gregory F. Nemet
AU  - Pao-Yu Oei
AU  - Benjamin K. Sovacool
AU  - Jan Christoph Steckel
AU  - Sebastian Thomas
AU  - John Wiseman
AU  - Jan C. Minx
ER  - 

474.
TY  - journal-article
ID  - https://openalex.org/W2981308999
DO  - https://doi.org/10.1111/ecog.04532
TI  - Text‐analysis reveals taxonomic and geographic disparities in animal pollination literature
AB  - Ecological systematic reviews and meta‐analyses have significantly increased our understanding of global biodiversity decline. However, for some ecological groups, incomplete and biased datasets have hindered our ability to construct robust, predictive models. One such group consists of the animal pollinators. Approximately 88% of wild plant species are thought to be pollinated by animals, with an estimated annual value of $230–410 billion dollars. Here we apply text‐analysis to quantify the taxonomic and geographical distribution of the animal pollinator literature, both temporally and spatially. We show that the publication of pollinator literature increased rapidly in the 1980s and 1990s. Taxonomically, we show that the distribution of pollinator literature is concentrated in the honey bees (Apis) and bumble bees (Bombus), and geographically in North America and Europe. At least 25% of pollination‐related abstracts mention a species of honey bee and at least 20% a species of bumble bee, and approximately 46% of abstracts are focussed on either North America (32%) or Europe (14%). Although these results indicate strong taxonomic and geographic biases in the pollinator literature, a large number of studies outside North America and Europe do exist. We then discuss how text‐analysis could be used to shorten the literature search for ecological systematic reviews and meta‐analyses, and to address more applied questions related to pollinator biodiversity, such as the identification of likely interacting plant–pollinator pairs and the number of pollinating species. promising approach. The annotations may be useful on their own to aid users in pinpointing necessary information for data extraction, or to facilitate semantic search. McNemar’s test for paired proportions in the 3 large reports, EPPI-Reviewer outperformed Abstrackr for identifying articles ordered for full-text review, but Abstrackr performed better in 2 of 3 reports for identifying articles included in the final report. For small reports, both tools provided benefits but EPPI-Reviewer generally outperformed Abstrackr in both tasks, although these results were often not statistically significant. Conclusions Abstrackr and EPPI-Reviewer performed well, but prioritization accuracy varied greatly across reports. Our work suggests screening prioritization functionality is a promising modality offering efficiency gains without giving up human involvement in the screening process. and four altered the relative proportion of less-healthy (to healthier) options. Most studies (4/6) manipulated snack foods or drinks. For selection outcomes, meta-analysis of three comparisons from three studies (n = 154) found that exposure to fewer options resulted in a large reduction in selection of the targeted food(s): SMD -1.13 (95% confidence interval (CI) -1.90 to -0.37) (low certainty evidence). For consumption outcomes, meta-analysis of three comparisons from two studies (n = 150) found that exposure to fewer options resulted in a moderate reduction in consumption of those foods, but with considerable uncertainty: SMD -0.55 (95% CI -1.27 to 0.18) (low certainty evidence).Eighteen studies investigated proximity interventions. Most (14/18) changed the distance at which a snack food or drink was placed from the participants, whilst four studies changed the order of meal components encountered along a line. For selection outcomes, only one study with one comparison (n = 41) was identified, which found that food placed farther away resulted in a moderate reduction in its selection: SMD -0.65 (95% CI -1.29 to -0.01) (very low certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2020
DA  - 2020-01-01
JO  - {'id': 'https://openalex.org/S25093289', 'issn_l': '0906-7590', 'issn': ['0906-7590', '1600-0587'], 'display_name': 'Ecography', 'publisher': 'Wiley-Blackwell', 'type': 'journal', 'url': 'https://doi.org/10.1111/ecog.04532', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Joseph W. Millard
AU  - Robin Freeman
AU  - Amanda E. Bates
ER  - 

475.
TY  - journal-article
ID  - https://openalex.org/W3029811621
DO  - https://doi.org/10.1186/s12874-020-01031-w
TI  - The semi-automation of title and abstract screening: a retrospective exploration of ways to leverage Abstrackr’s relevance predictions in systematic and rapid reviews
AB  - Abstract Background We investigated the feasibility of using a machine learning tool’s relevance predictions to expedite title and abstract screening. Methods We subjected 11 systematic reviews and six rapid reviews to four retrospective screening simulations (automated and semi-automated approaches to single-reviewer and dual independent screening) in Abstrackr, a freely-available machine learning software. We calculated the proportion missed, workload savings, and time savings compared to single-reviewer and dual independent screening by human reviewers. We performed cited reference searches to determine if missed studies would be identified via reference list scanning. Results For systematic reviews, the semi-automated, dual independent screening approach provided the best balance of time savings (median (range) 20 (3–82) hours) and reliability (median (range) proportion missed records, 1 (0–14)%). The cited references search identified 59% ( n = 10/17) of the records missed. For the rapid reviews, the fully and semi-automated approaches saved time (median (range) 9 (2–18) hours and 3 (1–10) hours, respectively), but less so than for the systematic reviews. The median (range) proportion missed records for both approaches was 6 (0–22)%. Conclusion Using Abstrackr to assist one of two reviewers in systematic reviews saves time with little risk of missing relevant records. Many missed records would be identified via other means. address more applied questions related to pollinator biodiversity, such as the identification of likely interacting plant–pollinator pairs and the number of pollinating species. promising approach. The annotations may be useful on their own to aid users in pinpointing necessary information for data extraction, or to facilitate semantic search. McNemar’s test for paired proportions in the 3 large reports, EPPI-Reviewer outperformed Abstrackr for identifying articles ordered for full-text review, but Abstrackr performed better in 2 of 3 reports for identifying articles included in the final report. For small reports, both tools provided benefits but EPPI-Reviewer generally outperformed Abstrackr in both tasks, although these results were often not statistically significant. Conclusions Abstrackr and EPPI-Reviewer performed well, but prioritization accuracy varied greatly across reports. Our work suggests screening prioritization functionality is a promising modality offering efficiency gains without giving up human involvement in the screening process. and four altered the relative proportion of less-healthy (to healthier) options. Most studies (4/6) manipulated snack foods or drinks. For selection outcomes, meta-analysis of three comparisons from three studies (n = 154) found that exposure to fewer options resulted in a large reduction in selection of the targeted food(s): SMD -1.13 (95% confidence interval (CI) -1.90 to -0.37) (low certainty evidence). For consumption outcomes, meta-analysis of three comparisons from two studies (n = 150) found that exposure to fewer options resulted in a moderate reduction in consumption of those foods, but with considerable uncertainty: SMD -0.55 (95% CI -1.27 to 0.18) (low certainty evidence).Eighteen studies investigated proximity interventions. Most (14/18) changed the distance at which a snack food or drink was placed from the participants, whilst four studies changed the order of meal components encountered along a line. For selection outcomes, only one study with one comparison (n = 41) was identified, which found that food placed farther away resulted in a moderate reduction in its selection: SMD -0.65 (95% CI -1.29 to -0.01) (very low certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2020
DA  - 2020-06-03
JO  - {'id': 'https://openalex.org/S185874209', 'issn_l': '1471-2288', 'issn': ['1471-2288'], 'display_name': 'BMC Medical Research Methodology', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://doi.org/10.1186/s12874-020-01031-w', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Allison Gates
AU  - Michelle Gates
AU  - Meghan Sebastianski
AU  - Samantha Guitard
AU  - Sarah A. Elliott
AU  - Lisa Hartling
ER  - 

476.
TY  - journal-article
ID  - https://openalex.org/W2590968081
DO  - https://doi.org/10.1186/s13643-017-0427-5
TI  - Documenting research with transgender and gender diverse people: protocol for an evidence map and thematic analysis
AB  - There is limited information about how transgender, gender diverse, and Two-Spirit (trans) people have been represented and studied by researchers. The objectives of this study are to (1) map and describe trans research in the social sciences, sciences, humanities, health, education, and business, (2) identify evidence gaps and opportunities for more responsible research with trans people, (3) assess the use of text mining for study identification, and (4) increase access to trans research for key stakeholders through the creation of a web-based evidence map.Study design was informed by community consultations and pilot searches. Eligibility criteria were established to include all original research of any design, including trans people or their health information, and published in English in peer-reviewed journals. A complex electronic search strategy based on relevant concepts in 15 databases was developed to obtain a broad range of results linked to transgender, gender diverse, and Two-Spirit individuals and communities. Searches conducted in early 2015 resulted in 25,242 references after removal of duplicates. Based on the number of references, resources, and an objective to capture upwards of 90% of the existing literature, this study is a good candidate for text mining using Latent Dirichlet Allocation to improve efficiency of the screening process. The following information will be collected for evidence mapping: study topic, study design, methods and data sources, recruitment strategies, sample size, sample demographics, researcher name and affiliation, country where research was conducted, funding source, and year of publication.The proposed research incorporates an extensive search strategy, text mining, and evidence map; it therefore has the potential to build on knowledge in several fields. Review results will increase awareness of existing trans research, identify evidence gaps, and inform strategic research prioritization. Publishing the map online will improve access to research for key stakeholders including community members, policy makers, and healthcare providers. This study will also contribute to knowledge in the area of text mining for study identification by providing an example of how semi-automation performs for screening on title and abstract and on full text. modality offering efficiency gains without giving up human involvement in the screening process. and four altered the relative proportion of less-healthy (to healthier) options. Most studies (4/6) manipulated snack foods or drinks. For selection outcomes, meta-analysis of three comparisons from three studies (n = 154) found that exposure to fewer options resulted in a large reduction in selection of the targeted food(s): SMD -1.13 (95% confidence interval (CI) -1.90 to -0.37) (low certainty evidence). For consumption outcomes, meta-analysis of three comparisons from two studies (n = 150) found that exposure to fewer options resulted in a moderate reduction in consumption of those foods, but with considerable uncertainty: SMD -0.55 (95% CI -1.27 to 0.18) (low certainty evidence).Eighteen studies investigated proximity interventions. Most (14/18) changed the distance at which a snack food or drink was placed from the participants, whilst four studies changed the order of meal components encountered along a line. For selection outcomes, only one study with one comparison (n = 41) was identified, which found that food placed farther away resulted in a moderate reduction in its selection: SMD -0.65 (95% CI -1.29 to -0.01) (very low certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2017
DA  - 2017-02-20
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://doi.org/10.1186/s13643-017-0427-5', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Zack Marshall
AU  - Vivian Welch
AU  - James D. Thomas
AU  - Fern Brunger
AU  - Michelle Swab
AU  - Ian Shemilt
AU  - Chris Kaposy
ER  - 

477.
TY  - journal-article
ID  - https://openalex.org/W2776402781
DO  - https://doi.org/10.1007/s41060-017-0087-5
TI  - Big Text advantages and challenges: classification perspective
AB  - No Abstract Found
PY  - 2018
DA  - 2018-02-01
JO  - {'id': 'https://openalex.org/S4210195017', 'issn_l': '2364-4168', 'issn': ['2364-415X', '2364-4168'], 'display_name': 'International journal of data science and analytics', 'publisher': 'Springer International Publishing', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Marina Sokolova
ER  - 

478.
TY  - journal-article
ID  - https://openalex.org/W2903961062
DO  - https://doi.org/10.1016/j.jclinepi.2018.12.001
TI  - Automatic screening using word embeddings achieved high sensitivity and workload reduction for updating living network meta-analyses
AB  - We aimed to develop and evaluate an algorithm for automatically screening citations when updating living network meta-analysis (NMA).Our algorithm learns from the initial screening of citations conducted when creating an NMA to automatically identify eligible citations (i.e., needing full-text consideration) when updating the NMA. We evaluated our algorithm on four NMAs from different medical domains. For each NMA we constructed sets of initially screened citations and citations to screen during an update that took place 2 years after the conduct of the NMA. We encoded free text of citations (title and abstract) using word embeddings. On top of this vectorized representation, we fitted a logistic regression model to the set of initially screened citations to predict the eligibility of citations screened during an update.Our algorithm achieved 100% sensitivity on two NMAs (100% [95% confidence interval 93-100] and 100% [40-100] sensitivity), and 94% (81-99) and 97% (86-100) on the remaining two others. For all NMAs, our algorithm would have spared to manually screen 1,345 of 2,530 citations, decreasing the workload by 53% (51-55), while missing 3 of 124 eligible citations (2% [1-7]), none of which were finally included in the NMAs after full-text consideration.For updating an NMA after 2 years, our algorithm considerably diminished the workload required for screening, and the number of missed eligible citations remained low. data sources, recruitment strategies, sample size, sample demographics, researcher name and affiliation, country where research was conducted, funding source, and year of publication.The proposed research incorporates an extensive search strategy, text mining, and evidence map; it therefore has the potential to build on knowledge in several fields. Review results will increase awareness of existing trans research, identify evidence gaps, and inform strategic research prioritization. Publishing the map online will improve access to research for key stakeholders including community members, policy makers, and healthcare providers. This study will also contribute to knowledge in the area of text mining for study identification by providing an example of how semi-automation performs for screening on title and abstract and on full text. modality offering efficiency gains without giving up human involvement in the screening process. and four altered the relative proportion of less-healthy (to healthier) options. Most studies (4/6) manipulated snack foods or drinks. For selection outcomes, meta-analysis of three comparisons from three studies (n = 154) found that exposure to fewer options resulted in a large reduction in selection of the targeted food(s): SMD -1.13 (95% confidence interval (CI) -1.90 to -0.37) (low certainty evidence). For consumption outcomes, meta-analysis of three comparisons from two studies (n = 150) found that exposure to fewer options resulted in a moderate reduction in consumption of those foods, but with considerable uncertainty: SMD -0.55 (95% CI -1.27 to 0.18) (low certainty evidence).Eighteen studies investigated proximity interventions. Most (14/18) changed the distance at which a snack food or drink was placed from the participants, whilst four studies changed the order of meal components encountered along a line. For selection outcomes, only one study with one comparison (n = 41) was identified, which found that food placed farther away resulted in a moderate reduction in its selection: SMD -0.65 (95% CI -1.29 to -0.01) (very low certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2019
DA  - 2019-04-01
JO  - {'id': 'https://openalex.org/V64418186', 'issn_l': '0895-4356', 'issn': ['1878-5921', '0895-4356'], 'display_name': 'Journal of Clinical Epidemiology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Xavier Tannier
AU  - Perrine Créquit
AU  - Philippe Ravaud
AU  - Ignacio Atal
ER  - 

479.
TY  - journal-article
ID  - https://openalex.org/W2955310318
DO  - https://doi.org/10.7326/m19-0458
TI  - Self-management of Epilepsy
AB  - Although self-management is recommended for persons with epilepsy, its optimal strategies and effects are uncertain.To evaluate the components and efficacy of self-management interventions in the treatment of epilepsy in community-dwelling persons.English-language searches of MEDLINE, Cochrane Central Register of Controlled Trials, PsycINFO, and CINAHL in April 2018; the MEDLINE search was updated in March 2019.Randomized and nonrandomized comparative studies of self-management interventions for adults with epilepsy.An investigator assessed study characteristics; intervention details, including 6 components of self-management; and outcomes, which were verified by a second reviewer. Risk of bias (ROB) was assessed independently by 2 investigators.13 randomized and 2 nonrandomized studies (2514 patients) evaluated self-management interventions. Interventions were delivered primarily in group settings, used a median of 4 components, and followed 2 general strategies: 1 based on education and the other on psychosocial therapy. Education-based approaches improved self-management behaviors (standardized mean difference, 0.52 [95% CI, 0.0 to 1.04]), and psychosocial therapy-based approaches improved quality of life (mean difference, 6.64 [CI, 2.51 to 10.77]). Overall, self-management interventions did not reduce seizure rates, but 1 educational intervention decreased a composite of seizures, emergency department visits, and hospitalizations.High ROB in most studies, incomplete intervention descriptions, and studies limited to English-language publications.There is limited evidence that self-management strategies modestly improve some patient outcomes that are important to persons with epilepsy. Overall, self-management research in epilepsy is limited by the range of interventions tested, the small number of studies using self-monitoring technology, and uncertainty about components and strategies associated with benefit.U.S. Department of Veterans Affairs. (PROSPERO: CRD42018098604). map; it therefore has the potential to build on knowledge in several fields. Review results will increase awareness of existing trans research, identify evidence gaps, and inform strategic research prioritization. Publishing the map online will improve access to research for key stakeholders including community members, policy makers, and healthcare providers. This study will also contribute to knowledge in the area of text mining for study identification by providing an example of how semi-automation performs for screening on title and abstract and on full text. modality offering efficiency gains without giving up human involvement in the screening process. and four altered the relative proportion of less-healthy (to healthier) options. Most studies (4/6) manipulated snack foods or drinks. For selection outcomes, meta-analysis of three comparisons from three studies (n = 154) found that exposure to fewer options resulted in a large reduction in selection of the targeted food(s): SMD -1.13 (95% confidence interval (CI) -1.90 to -0.37) (low certainty evidence). For consumption outcomes, meta-analysis of three comparisons from two studies (n = 150) found that exposure to fewer options resulted in a moderate reduction in consumption of those foods, but with considerable uncertainty: SMD -0.55 (95% CI -1.27 to 0.18) (low certainty evidence).Eighteen studies investigated proximity interventions. Most (14/18) changed the distance at which a snack food or drink was placed from the participants, whilst four studies changed the order of meal components encountered along a line. For selection outcomes, only one study with one comparison (n = 41) was identified, which found that food placed farther away resulted in a moderate reduction in its selection: SMD -0.65 (95% CI -1.29 to -0.01) (very low certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2019
DA  - 2019-07-16
JO  - {'id': 'https://openalex.org/S119722071', 'issn_l': '0003-4819', 'issn': ['0003-4819', '1539-3704'], 'display_name': 'Annals of Internal Medicine', 'publisher': 'American College of Physicians', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Matthew Luedke
AU  - Dan V. Blalock
AU  - Karen M. Goldstein
AU  - Andrzej S. Kosinski
AU  - Saurabh Sinha
AU  - Connor Drake
AU  - Jeffrey A. Lewis
AU  - Aatif M. Husain
AU  - Allison A. Lewinski
AU  - Abigail Shapiro
AU  - Jennifer M Gierisch
AU  - Tung Thanh Tran
AU  - Adelaide M. Gordon
AU  - Megan Van Noord
AU  - Hayden B. Bosworth
AU  - John W Williams
ER  - 

480.
TY  - journal-article
ID  - https://openalex.org/W2970557058
DO  - https://doi.org/10.1136/injuryprev-2019-043247
TI  - Evaluation of text mining to reduce screening workload for injury-focused systematic reviews
AB  - Introduction Text mining to support screening in large-scale systematic reviews has been recommended; however, their suitability for reviews in injury research is not known. We examined the performance of text mining in supporting the second reviewer in a systematic review examining associations between fault attribution and health and work-related outcomes after transport injury. Methods Citations were independently screened in Abstrackr in full (reviewer 1; 10 559 citations), and until no more citations were predicted to be relevant (reviewer 2; 1809 citations, 17.1%). All potentially relevant full-text articles were assessed by reviewer 1 (555 articles). Reviewer 2 used text mining (Wordstat, QDA Miner) to reduce assessment to full-text articles containing ≥1 fault-related exposure term (367 articles, 66.1%). Results Abstrackr offered excellent workload savings: 82.7% of citations did not require screening by reviewer 2, and total screening time was reduced by 36.6% compared with traditional dual screening of all citations. Abstrackr predictions had high specificity (83.7%), and low false negatives (0.3%), but overestimated citation relevance, probably due to the complexity of the review with multiple outcomes and high imbalance of relevant to irrelevant records, giving low sensitivity (29.7%) and precision (14.5%). Text mining of full-text articles reduced the number needing to be screened by 33.9%, and reduced total full-text screening time by 38.7% compared with traditional dual screening. Conclusions Overall, text mining offered important benefits to systematic review workflow, but should not replace full screening by one reviewer, especially for complex reviews examining multiple health or injury outcomes. Trial registration number CRD42018084123. CRD42018098604). map; it therefore has the potential to build on knowledge in several fields. Review results will increase awareness of existing trans research, identify evidence gaps, and inform strategic research prioritization. Publishing the map online will improve access to research for key stakeholders including community members, policy makers, and healthcare providers. This study will also contribute to knowledge in the area of text mining for study identification by providing an example of how semi-automation performs for screening on title and abstract and on full text. modality offering efficiency gains without giving up human involvement in the screening process. and four altered the relative proportion of less-healthy (to healthier) options. Most studies (4/6) manipulated snack foods or drinks. For selection outcomes, meta-analysis of three comparisons from three studies (n = 154) found that exposure to fewer options resulted in a large reduction in selection of the targeted food(s): SMD -1.13 (95% confidence interval (CI) -1.90 to -0.37) (low certainty evidence). For consumption outcomes, meta-analysis of three comparisons from two studies (n = 150) found that exposure to fewer options resulted in a moderate reduction in consumption of those foods, but with considerable uncertainty: SMD -0.55 (95% CI -1.27 to 0.18) (low certainty evidence).Eighteen studies investigated proximity interventions. Most (14/18) changed the distance at which a snack food or drink was placed from the participants, whilst four studies changed the order of meal components encountered along a line. For selection outcomes, only one study with one comparison (n = 41) was identified, which found that food placed farther away resulted in a moderate reduction in its selection: SMD -0.65 (95% CI -1.29 to -0.01) (very low certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2020
DA  - 2020-02-01
JO  - {'id': 'https://openalex.org/S81674035', 'issn_l': '1353-8047', 'issn': ['1475-5785', '1353-8047'], 'display_name': 'Injury Prevention', 'publisher': 'BMJ', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Melita J. Giummarra
AU  - Georgina Lau
AU  - Belinda J. Gabbe
ER  - 

481.
TY  - journal-article
ID  - https://openalex.org/W2911208765
DO  - https://doi.org/10.1093/jamiaopen/ooy062
TI  - Trial2rev: Combining machine learning and crowd-sourcing to create a shared space for updating systematic reviews
AB  - Abstract Objectives Systematic reviews of clinical trials could be updated faster by automatically monitoring relevant trials as they are registered, completed, and reported. Our aim was to provide a public interface to a database of curated links between systematic reviews and trial registrations. Materials and Methods We developed the server-side system components in Python, connected them to a PostgreSQL database, and implemented the web-based user interface using Javascript, HTML, and CSS. All code is available on GitHub under an open source MIT license and registered users can access and download all available data. Results The trial2rev system is a web-based interface to a database that collates and augments information from multiple sources including bibliographic databases, the ClinicalTrials.gov registry, and the actions of registered users. Users interact with the system by browsing, searching, or adding systematic reviews, verifying links to trials included in the review, and adding or voting on trials that they would expect to include in an update of the systematic review. The system can trigger the actions of software agents that add or vote on included and relevant trials, in response to user interactions or by scheduling updates from external resources. Discussion and Conclusion We designed a publicly-accessible resource to help systematic reviewers make decisions about systematic review updates. Where previous approaches have sought to reactively filter published reports of trials for inclusion in systematic reviews, our approach is to proactively monitor for relevant trials as they are registered and completed. or injury outcomes. Trial registration number CRD42018084123. CRD42018098604). map; it therefore has the potential to build on knowledge in several fields. Review results will increase awareness of existing trans research, identify evidence gaps, and inform strategic research prioritization. Publishing the map online will improve access to research for key stakeholders including community members, policy makers, and healthcare providers. This study will also contribute to knowledge in the area of text mining for study identification by providing an example of how semi-automation performs for screening on title and abstract and on full text. modality offering efficiency gains without giving up human involvement in the screening process. and four altered the relative proportion of less-healthy (to healthier) options. Most studies (4/6) manipulated snack foods or drinks. For selection outcomes, meta-analysis of three comparisons from three studies (n = 154) found that exposure to fewer options resulted in a large reduction in selection of the targeted food(s): SMD -1.13 (95% confidence interval (CI) -1.90 to -0.37) (low certainty evidence). For consumption outcomes, meta-analysis of three comparisons from two studies (n = 150) found that exposure to fewer options resulted in a moderate reduction in consumption of those foods, but with considerable uncertainty: SMD -0.55 (95% CI -1.27 to 0.18) (low certainty evidence).Eighteen studies investigated proximity interventions. Most (14/18) changed the distance at which a snack food or drink was placed from the participants, whilst four studies changed the order of meal components encountered along a line. For selection outcomes, only one study with one comparison (n = 41) was identified, which found that food placed farther away resulted in a moderate reduction in its selection: SMD -0.65 (95% CI -1.29 to -0.01) (very low certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2019
DA  - 2019-01-11
JO  - {'id': 'https://openalex.org/V4210237468', 'issn_l': '2574-2531', 'issn': ['2574-2531'], 'display_name': 'JAMIA open', 'publisher': 'University of Oxford', 'type': 'journal', 'url': 'https://academic.oup.com/jamiaopen/article-pdf/2/1/15/31501530/ooy062.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc'}
DP  - OpenAlex
AU  - Paige Martin
AU  - Didi Surian
AU  - Rabia Bashir
AU  - Florence T. Bourgeois
AU  - Adam G. Dunn
ER  - 

482.
TY  - journal-article
ID  - https://openalex.org/W3010563038
DO  - https://doi.org/10.1016/j.jclinepi.2020.01.023
TI  - Future of evidence ecosystem series: 2. current opportunities and need for better tools and methods
AB  - <h2>Abstract</h2> To become user driven and more useful for decision-making, the current evidence synthesis ecosystem requires significant changes (Paper 1. Future of evidence ecosystem series). Reviewers have access to new sources of data (clinical trial registries, protocols, and clinical study reports from regulatory agencies or pharmaceutical companies) for more information on randomized control trials. With all these newly available data, the management of multiple and scattered trial reports is even more challenging. New types of data are also becoming available: individual patient data and routinely collected data. With the increasing number of diverse sources to be searched and the amount of data to be extracted, the process needs to be rethought. New approaches and tools, such as automation technologies and crowdsourcing, should help accelerate the process. The implementation of these new approaches and methods requires a substantial rethinking and redesign of the current evidence synthesis ecosystem. The concept of a "living" evidence synthesis enterprise, with living systematic review and living network meta-analysis, has recently emerged. Such an evidence synthesis ecosystem implies conceptualizing evidence synthesis as a continuous process built around a clinical question of interest and no longer as a small team independently answering a specific clinical question at a single point in time. reviewers make decisions about systematic review updates. Where previous approaches have sought to reactively filter published reports of trials for inclusion in systematic reviews, our approach is to proactively monitor for relevant trials as they are registered and completed. or injury outcomes. Trial registration number CRD42018084123. CRD42018098604). map; it therefore has the potential to build on knowledge in several fields. Review results will increase awareness of existing trans research, identify evidence gaps, and inform strategic research prioritization. Publishing the map online will improve access to research for key stakeholders including community members, policy makers, and healthcare providers. This study will also contribute to knowledge in the area of text mining for study identification by providing an example of how semi-automation performs for screening on title and abstract and on full text. modality offering efficiency gains without giving up human involvement in the screening process. and four altered the relative proportion of less-healthy (to healthier) options. Most studies (4/6) manipulated snack foods or drinks. For selection outcomes, meta-analysis of three comparisons from three studies (n = 154) found that exposure to fewer options resulted in a large reduction in selection of the targeted food(s): SMD -1.13 (95% confidence interval (CI) -1.90 to -0.37) (low certainty evidence). For consumption outcomes, meta-analysis of three comparisons from two studies (n = 150) found that exposure to fewer options resulted in a moderate reduction in consumption of those foods, but with considerable uncertainty: SMD -0.55 (95% CI -1.27 to 0.18) (low certainty evidence).Eighteen studies investigated proximity interventions. Most (14/18) changed the distance at which a snack food or drink was placed from the participants, whilst four studies changed the order of meal components encountered along a line. For selection outcomes, only one study with one comparison (n = 41) was identified, which found that food placed farther away resulted in a moderate reduction in its selection: SMD -0.65 (95% CI -1.29 to -0.01) (very low certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2020
DA  - 2020-03-04
JO  - {'id': 'https://openalex.org/S64418186', 'issn_l': '0895-4356', 'issn': ['1878-5921', '0895-4356'], 'display_name': 'Journal of Clinical Epidemiology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Perrine Créquit
AU  - Isabelle Boutron
AU  - Joerg J Meerpohl
AU  - Hywel C Williams
AU  - Jonathan C. Craig
AU  - Philippe Ravaud
ER  - 

483.
TY  - journal-article
ID  - https://openalex.org/W3089621169
DO  - https://doi.org/10.1145/3411755
TI  - When to Stop Reviewing in Technology-Assisted Reviews
AB  - Technology-Assisted Reviews (TAR) aim to expedite document reviewing (e.g., medical articles or legal documents) by iteratively incorporating machine learning algorithms and human feedback on document relevance. Continuous Active Learning (CAL) algorithms have demonstrated superior performance compared to other methods in efficiently identifying relevant documents. One of the key challenges for CAL algorithms is deciding when to stop displaying documents to reviewers. Existing work either lacks transparency—it provides an ad-hoc stopping point, without indicating how many relevant documents are still not found, or lacks efficiency by paying an extra cost to estimate the total number of relevant documents in the collection prior to the actual review. In this article, we handle the problem of deciding the stopping point of TAR under the continuous active learning framework by jointly training a ranking model to rank documents, and by conducting a “greedy” sampling to estimate the total number of relevant documents in the collection. We prove the unbiasedness of the proposed estimators under a with-replacement sampling design, while experimental results demonstrate that the proposed approach, similar to CAL, effectively retrieves relevant documents; but it also provides a transparent, accurate, and effective stopping point. small team independently answering a specific clinical question at a single point in time. reviewers make decisions about systematic review updates. Where previous approaches have sought to reactively filter published reports of trials for inclusion in systematic reviews, our approach is to proactively monitor for relevant trials as they are registered and completed. or injury outcomes. Trial registration number CRD42018084123. CRD42018098604). map; it therefore has the potential to build on knowledge in several fields. Review results will increase awareness of existing trans research, identify evidence gaps, and inform strategic research prioritization. Publishing the map online will improve access to research for key stakeholders including community members, policy makers, and healthcare providers. This study will also contribute to knowledge in the area of text mining for study identification by providing an example of how semi-automation performs for screening on title and abstract and on full text. modality offering efficiency gains without giving up human involvement in the screening process. and four altered the relative proportion of less-healthy (to healthier) options. Most studies (4/6) manipulated snack foods or drinks. For selection outcomes, meta-analysis of three comparisons from three studies (n = 154) found that exposure to fewer options resulted in a large reduction in selection of the targeted food(s): SMD -1.13 (95% confidence interval (CI) -1.90 to -0.37) (low certainty evidence). For consumption outcomes, meta-analysis of three comparisons from two studies (n = 150) found that exposure to fewer options resulted in a moderate reduction in consumption of those foods, but with considerable uncertainty: SMD -0.55 (95% CI -1.27 to 0.18) (low certainty evidence).Eighteen studies investigated proximity interventions. Most (14/18) changed the distance at which a snack food or drink was placed from the participants, whilst four studies changed the order of meal components encountered along a line. For selection outcomes, only one study with one comparison (n = 41) was identified, which found that food placed farther away resulted in a moderate reduction in its selection: SMD -0.65 (95% CI -1.29 to -0.01) (very low certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2020
DA  - 2020-09-30
JO  - {'id': 'https://openalex.org/S87067389', 'issn_l': '0734-2047', 'issn': ['1558-1152', '1558-2868', '1046-8188', '0734-2047'], 'display_name': 'ACM Transactions on Information Systems', 'publisher': 'Association for Computing Machinery', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Dan Li
AU  - Evangelos Kanoulas
ER  - 

484.
TY  - journal-article
ID  - https://openalex.org/W3164510435
DO  - https://doi.org/10.1016/j.ijepes.2021.107176
TI  - A taxonomical review on recent artificial intelligence applications to PV integration into power grids
AB  - • Review artificial intelligence application papers in solar photovoltaic systems. • Using text mining to collect, analyze, and categorize a large volume of papers. • Reviews focus on solar forecasting, detection, design optimization, and optimal control. The exponential growth of solar power has been witnessed in the past decade and is projected by the ambitious policy targets. Nevertheless, the proliferation of solar energy poses challenges to power system operations, mostly due to its uncertainty, locational specificity, and variability. The prevalence of smart grids enables artificial intelligence (AI) techniques to mitigate solar integration problems with massive amounts of solar energy data. Different AI subfields (e.g., machine learning, deep learning, ensemble learning, and metaheuristic learning) have brought breakthroughs in solar energy, especially in its grid integration. However, AI research in solar integration is still at the preliminary stage, and is lagging behind the AI mainstream. Aiming to inspire deep AI involvement in the solar energy domain, this paper presents a taxonomical overview of AI applications in solar photovoltaic (PV) systems. Text mining techniques are first used as an assistive tool to collect, analyze, and categorize a large volume of literature in this field. Then, based on the constructed literature infrastructure, recent advancements in AI applications to solar forecasting, PV array detection, PV system fault detection, design optimization, and maximum power point tracking control problems are comprehensively reviewed. Current challenges and future trends of AI applications in solar integration are also discussed for each application theme. or injury outcomes. Trial registration number CRD42018084123. CRD42018098604). map; it therefore has the potential to build on knowledge in several fields. Review results will increase awareness of existing trans research, identify evidence gaps, and inform strategic research prioritization. Publishing the map online will improve access to research for key stakeholders including community members, policy makers, and healthcare providers. This study will also contribute to knowledge in the area of text mining for study identification by providing an example of how semi-automation performs for screening on title and abstract and on full text. modality offering efficiency gains without giving up human involvement in the screening process. and four altered the relative proportion of less-healthy (to healthier) options. Most studies (4/6) manipulated snack foods or drinks. For selection outcomes, meta-analysis of three comparisons from three studies (n = 154) found that exposure to fewer options resulted in a large reduction in selection of the targeted food(s): SMD -1.13 (95% confidence interval (CI) -1.90 to -0.37) (low certainty evidence). For consumption outcomes, meta-analysis of three comparisons from two studies (n = 150) found that exposure to fewer options resulted in a moderate reduction in consumption of those foods, but with considerable uncertainty: SMD -0.55 (95% CI -1.27 to 0.18) (low certainty evidence).Eighteen studies investigated proximity interventions. Most (14/18) changed the distance at which a snack food or drink was placed from the participants, whilst four studies changed the order of meal components encountered along a line. For selection outcomes, only one study with one comparison (n = 41) was identified, which found that food placed farther away resulted in a moderate reduction in its selection: SMD -0.65 (95% CI -1.29 to -0.01) (very low certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2021
DA  - 2021-11-01
JO  - {'id': 'https://openalex.org/S168377509', 'issn_l': '0142-0615', 'issn': ['1879-3517', '0142-0615'], 'display_name': 'International Journal of Electrical Power & Energy Systems', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Cong Feng
AU  - Yuanzhi Liu
AU  - Jie Zhang
ER  - 

485.
TY  - journal-article
ID  - https://openalex.org/W2945947126
DO  - https://doi.org/10.1002/asi.24248
TI  - Survival analysis of author keywords: An application to the library and information sciences area
AB  - • is the peer reviewed version of the following article: Peset, F, F Garzon-Farinos, LM Gonzalez, X Garcia-Masso, A Ferrer-Sapena, JL Toca-Herrera, and EA Sanchez-Perez. 2019. Survival Analysis of Author Keywords: An Application to the Library and Information Sciences Area. Journal of the Association for Information Science and Technology 71 (4). Wiley: 462-73. doi:10.1002/asi.24248, which has been published in final form at https://doi.org/10.1002/asi.24248. This article may be used for non-commercial purposes in accordance with Wiley Terms and Conditions for Self-Archiving. of smart grids enables artificial intelligence (AI) techniques to mitigate solar integration problems with massive amounts of solar energy data. Different AI subfields (e.g., machine learning, deep learning, ensemble learning, and metaheuristic learning) have brought breakthroughs in solar energy, especially in its grid integration. However, AI research in solar integration is still at the preliminary stage, and is lagging behind the AI mainstream. Aiming to inspire deep AI involvement in the solar energy domain, this paper presents a taxonomical overview of AI applications in solar photovoltaic (PV) systems. Text mining techniques are first used as an assistive tool to collect, analyze, and categorize a large volume of literature in this field. Then, based on the constructed literature infrastructure, recent advancements in AI applications to solar forecasting, PV array detection, PV system fault detection, design optimization, and maximum power point tracking control problems are comprehensively reviewed. Current challenges and future trends of AI applications in solar integration are also discussed for each application theme. or injury outcomes. Trial registration number CRD42018084123. CRD42018098604). map; it therefore has the potential to build on knowledge in several fields. Review results will increase awareness of existing trans research, identify evidence gaps, and inform strategic research prioritization. Publishing the map online will improve access to research for key stakeholders including community members, policy makers, and healthcare providers. This study will also contribute to knowledge in the area of text mining for study identification by providing an example of how semi-automation performs for screening on title and abstract and on full text. modality offering efficiency gains without giving up human involvement in the screening process. and four altered the relative proportion of less-healthy (to healthier) options. Most studies (4/6) manipulated snack foods or drinks. For selection outcomes, meta-analysis of three comparisons from three studies (n = 154) found that exposure to fewer options resulted in a large reduction in selection of the targeted food(s): SMD -1.13 (95% confidence interval (CI) -1.90 to -0.37) (low certainty evidence). For consumption outcomes, meta-analysis of three comparisons from two studies (n = 150) found that exposure to fewer options resulted in a moderate reduction in consumption of those foods, but with considerable uncertainty: SMD -0.55 (95% CI -1.27 to 0.18) (low certainty evidence).Eighteen studies investigated proximity interventions. Most (14/18) changed the distance at which a snack food or drink was placed from the participants, whilst four studies changed the order of meal components encountered along a line. For selection outcomes, only one study with one comparison (n = 41) was identified, which found that food placed farther away resulted in a moderate reduction in its selection: SMD -0.65 (95% CI -1.29 to -0.01) (very low certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2020
DA  - 2020-04-01
JO  - {'id': 'https://openalex.org/S4210197613', 'issn_l': '2330-1635', 'issn': ['2330-1643', '2330-1635'], 'display_name': 'Journal of the Association for Information Science and Technology', 'publisher': 'Wiley-Blackwell', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Fernanda Peset
AU  - Fernanda Garzón-Farinós
AU  - Luis-Millán González
AU  - Xavier García-Massó
AU  - Antonia Ferrer-Sapena
AU  - José L. Toca-Herrera
AU  - Enrique Alfonso Sánchez Pérez
ER  - 

486.
TY  - journal-article
ID  - https://openalex.org/W2949926253
DO  - https://doi.org/10.1093/bioinformatics/bty722
TI  - Adjutant: an R-based tool to support topic discovery for systematic and literature reviews
AB  - Adjutant is an open-source, interactive and R-based application to support mining PubMed for literature reviews. Given a PubMed-compatible search query, Adjutant downloads the relevant articles and allows the user to perform an unsupervised clustering analysis to identify data-driven topic clusters. Following clustering, users can also sample documents using different strategies to obtain a more manageable dataset for further analysis. Adjutant makes explicit trade-offs between speed and accuracy, which are modifiable by the user, such that a complete analysis of several thousand documents can take a few minutes. All analytic datasets generated by Adjutant are saved, allowing users to easily conduct other downstream analyses that Adjutant does not explicitly support.Adjutant is implemented in R, using Shiny, and is available at https://github.com/amcrisan/Adjutant.Supplementary data are available at Bioinformatics online. research in solar integration is still at the preliminary stage, and is lagging behind the AI mainstream. Aiming to inspire deep AI involvement in the solar energy domain, this paper presents a taxonomical overview of AI applications in solar photovoltaic (PV) systems. Text mining techniques are first used as an assistive tool to collect, analyze, and categorize a large volume of literature in this field. Then, based on the constructed literature infrastructure, recent advancements in AI applications to solar forecasting, PV array detection, PV system fault detection, design optimization, and maximum power point tracking control problems are comprehensively reviewed. Current challenges and future trends of AI applications in solar integration are also discussed for each application theme. or injury outcomes. Trial registration number CRD42018084123. CRD42018098604). map; it therefore has the potential to build on knowledge in several fields. Review results will increase awareness of existing trans research, identify evidence gaps, and inform strategic research prioritization. Publishing the map online will improve access to research for key stakeholders including community members, policy makers, and healthcare providers. This study will also contribute to knowledge in the area of text mining for study identification by providing an example of how semi-automation performs for screening on title and abstract and on full text. modality offering efficiency gains without giving up human involvement in the screening process. and four altered the relative proportion of less-healthy (to healthier) options. Most studies (4/6) manipulated snack foods or drinks. For selection outcomes, meta-analysis of three comparisons from three studies (n = 154) found that exposure to fewer options resulted in a large reduction in selection of the targeted food(s): SMD -1.13 (95% confidence interval (CI) -1.90 to -0.37) (low certainty evidence). For consumption outcomes, meta-analysis of three comparisons from two studies (n = 150) found that exposure to fewer options resulted in a moderate reduction in consumption of those foods, but with considerable uncertainty: SMD -0.55 (95% CI -1.27 to 0.18) (low certainty evidence).Eighteen studies investigated proximity interventions. Most (14/18) changed the distance at which a snack food or drink was placed from the participants, whilst four studies changed the order of meal components encountered along a line. For selection outcomes, only one study with one comparison (n = 41) was identified, which found that food placed farther away resulted in a moderate reduction in its selection: SMD -0.65 (95% CI -1.29 to -0.01) (very low certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2019
DA  - 2019-03-15
JO  - {'id': 'https://openalex.org/V52395412', 'issn_l': '1367-4803', 'issn': ['1367-4811', '1367-4803'], 'display_name': 'Bioinformatics', 'publisher': 'Oxford University Press', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Anamaria Crisan
AU  - Tamara Munzner
AU  - Jennifer L. Gardy
ER  - 

487.
TY  - journal-article
ID  - https://openalex.org/W2970074717
DO  - https://doi.org/10.1016/j.jbi.2019.103275
TI  - Towards a characterization of apparent contradictions in the biomedical literature using context analysis
AB  - • Semantic predications to identify candidate contradictions in biomedical literature. • Automatic and manual filtering steps identify apparent contradictions from candidates. • Contextual characteristics can explain apparent contradictions or indicate true ones. With the substantial growth in the biomedical research literature, a larger number of claims are published daily, some of which seemingly disagree with or contradict prior claims on the same topics. Resolving such contradictions is critical to advancing our understanding of human disease and developing effective treatments. Automated text analysis techniques can facilitate such analysis by extracting claims from the literature, flagging those that are potentially contradictory, and identifying any study characteristics that may explain such contradictions. Using SemMedDB, our own PubMed-scale repository of semantic predications (subject-relation-object triples), we identified apparent contradictions in the biomedical research literature and developed a categorization of contextual characteristics that explain such contradictions. Clinically relevant semantic predications relating to 20 diseases and involving opposing predicate pairs (e.g., an intervention treats or causes a disease) were retrieved from SemMedDB. After addressing inference, uncertainty, generic concepts, and NLP errors through automatic and manual filtering steps, a set of apparent contradictions were identified and characterized. We retrieved 117,676 predication instances from 62,360 PubMed abstracts (Jan 1980-Dec 2016). From these instances, automatic filtering steps generated 2236 candidate contradictory pairs. Through manual analysis, we determined that 58 of these pairs (2.6%) were apparent contradictions. We identified five main categories of contextual characteristics that explain these contradictions: (a) internal to the patient, (b) external to the patient, (c) endogenous/exogenous, (d) known controversy, and (e) contradictions in literature. Categories (a) and (b) were subcategorized further (e.g., species, dosage) and accounted for the bulk of the contradictory information. Semantic predications, by accounting for lexical variability, and SemMedDB, owing to its literature scale, can support identification and elucidation of potentially contradictory claims across the biomedical domain. Further filtering and classification steps are needed to distinguish among them the true contradictory claims. The ability to detect contradictions automatically can facilitate important biomedical knowledge management tasks, such as tracking and verifying scientific claims, summarizing research on a given topic, identifying knowledge gaps, and assessing evidence for systematic reviews, with potential benefits to the scientific community. Future work will focus on automating these steps for fully automatic recognition of contradictions from the biomedical research literature. found that exposure to fewer options resulted in a large reduction in selection of the targeted food(s): SMD -1.13 (95% confidence interval (CI) -1.90 to -0.37) (low certainty evidence). For consumption outcomes, meta-analysis of three comparisons from two studies (n = 150) found that exposure to fewer options resulted in a moderate reduction in consumption of those foods, but with considerable uncertainty: SMD -0.55 (95% CI -1.27 to 0.18) (low certainty evidence).Eighteen studies investigated proximity interventions. Most (14/18) changed the distance at which a snack food or drink was placed from the participants, whilst four studies changed the order of meal components encountered along a line. For selection outcomes, only one study with one comparison (n = 41) was identified, which found that food placed farther away resulted in a moderate reduction in its selection: SMD -0.65 (95% CI -1.29 to -0.01) (very low certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2019
DA  - 2019-08-29
JO  - {'id': 'https://openalex.org/S11622463', 'issn_l': '1532-0464', 'issn': ['1532-0480', '1532-0464'], 'display_name': 'Journal of Biomedical Informatics', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'https://doi.org/10.1016/j.jbi.2019.103275', 'is_oa': True, 'version': 'publishedVersion', 'license': 'elsevier-specific'}
DP  - OpenAlex
AU  - Graciela Rosemblat
AU  - Marcelo Fiszman
AU  - Dongwook Shin
AU  - Halil Kilicoglu
ER  - 

488.
TY  - journal-article
ID  - https://openalex.org/W2989461521
DO  - https://doi.org/10.1016/j.envint.2019.105228
TI  - Novel text analytics approach to identify relevant literature for human health risk assessments: A pilot study with health effects of in utero exposures
AB  - Systematic reviews involve mining literature databases to identify relevant studies. Identifying potentially relevant studies can be informed by computational tools comparing text similarity between candidate studies and selected key (i.e., seed) references. Challenge Using computational approaches to identify relevant studies for risk assessments is challenging, as these assessments examine multiple chemical effects across lifestages (e.g., human health risk assessments) or specific effects of multiple chemicals (e.g., cumulative risk). The broad scope of potentially relevant literature can make selection of seed references difficult. Approach We developed a generalized computational scoping strategy to identify human health relevant studies for multiple chemicals and multiple effects. We used semi-supervised machine learning to prioritize studies to review manually with training data derived from references cited in the hazard identification sections of several US EPA Integrated Risk Information System (IRIS) assessments. These generic training data or seed studies were clustered with the unclassified corpus to group studies based on text similarity. Clusters containing a high proportion of seed studies were prioritized for manual review. Chemical names were removed from seed studies prior to clustering resulting in a generic, chemical-independent method for identifying potentially human health relevant studies. We developed a case study that focused on identifying the array of chemicals that have been studied with respect to in utero exposure to test the recall of this novel literature searching strategy. We then evaluated the general strategy of using generic, chemical-independent training data with two previous IRIS assessments by comparing studies predicted relevant to those used in the assessments (i.e., total relevant). Outcome A keyword search designed to retrieve studies that examined the in utero effects of environmental chemicals identified over 54,000 candidate references. Clustering algorithms were applied using 1456 studies from multiple IRIS assessments with chemical names removed as training data or seeds (i.e., semi-supervised learning). Using a six-algorithm ensemble approach 2602 articles, or approximately 5% of candidate references, were "voted" relevant by four or more clustering algorithms and manual review confirmed nearly 50% of these studies were relevant. Further evaluations on two IRIS assessments, using a nine-algorithm ensemble approach and a set of generic, chemical-independent, externally-derived seed studies correctly identified 77-83% of hazard identification studies published in the assessments and eliminated the need to manually screen more than 75% of search results on average. Limitations The chemical-independent approach used to build the training literature set provides a broad and unbiased picture across a variety of endpoints and environmental exposures but does not systematically identify all available data. Variance between actual and predicted relevant studies will be greater because of the external and non-random origin of seed study selection. This approach depends on access to readily available generic training data that can be used to locate relevant references in an unclassified corpus. Impact A generic approach to identifying human health relevant studies could be an important first step in literature evaluation for risk assessments. This initial scoping approach could facilitate faster literature evaluation by focusing reviewer efforts, as well as potentially minimize reviewer bias in selection of key studies. Using externally-derived training data has applicability particularly for databases with very low search precision where identifying training data may be cost-prohibitive. certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2020
DA  - 2020-01-01
JO  - {'id': 'https://openalex.org/S143381477', 'issn_l': '0160-4120', 'issn': ['0160-4120', '1873-6750'], 'display_name': 'Environment International', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'https://doi.org/10.1016/j.envint.2019.105228', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Michelle Cawley
AU  - R. A. Beardslee
AU  - Brandy Beverly
AU  - Andrew K. Hotchkiss
AU  - Ellen Kirrane
AU  - Reeder Sams
AU  - Arun Varghese
AU  - Jessica A. Wignall
AU  - John D. Cowden
ER  - 

489.
TY  - journal-article
ID  - https://openalex.org/W2999105954
DO  - https://doi.org/10.1080/17437199.2020.1716198
TI  - Semi-Automated evidence synthesis in health psychology: current methods and future prospects
AB  - The evidence base in health psychology is vast and growing rapidly. These factors make it difficult (and sometimes practically impossible) to consider all available evidence when making decisions about the state of knowledge on a given phenomenon (e.g., associations of variables, effects of interventions on particular outcomes). Systematic reviews, meta-analyses, and other rigorous syntheses of the research mitigate this problem by providing concise, actionable summaries of knowledge in a given area of study. Yet, conducting these syntheses has grown increasingly laborious owing to the fast accumulation of new evidence; existing, manual methods for synthesis do not scale well. In this article, we discuss how semi-automation via machine learning and natural language processing methods may help researchers and practitioners to review evidence more efficiently. We outline concrete examples in health psychology, highlighting practical, open-source technologies available now. We indicate the potential of more advanced methods and discuss how to avoid the pitfalls of automated reviews. similarity. Clusters containing a high proportion of seed studies were prioritized for manual review. Chemical names were removed from seed studies prior to clustering resulting in a generic, chemical-independent method for identifying potentially human health relevant studies. We developed a case study that focused on identifying the array of chemicals that have been studied with respect to in utero exposure to test the recall of this novel literature searching strategy. We then evaluated the general strategy of using generic, chemical-independent training data with two previous IRIS assessments by comparing studies predicted relevant to those used in the assessments (i.e., total relevant). Outcome A keyword search designed to retrieve studies that examined the in utero effects of environmental chemicals identified over 54,000 candidate references. Clustering algorithms were applied using 1456 studies from multiple IRIS assessments with chemical names removed as training data or seeds (i.e., semi-supervised learning). Using a six-algorithm ensemble approach 2602 articles, or approximately 5% of candidate references, were "voted" relevant by four or more clustering algorithms and manual review confirmed nearly 50% of these studies were relevant. Further evaluations on two IRIS assessments, using a nine-algorithm ensemble approach and a set of generic, chemical-independent, externally-derived seed studies correctly identified 77-83% of hazard identification studies published in the assessments and eliminated the need to manually screen more than 75% of search results on average. Limitations The chemical-independent approach used to build the training literature set provides a broad and unbiased picture across a variety of endpoints and environmental exposures but does not systematically identify all available data. Variance between actual and predicted relevant studies will be greater because of the external and non-random origin of seed study selection. This approach depends on access to readily available generic training data that can be used to locate relevant references in an unclassified corpus. Impact A generic approach to identifying human health relevant studies could be an important first step in literature evaluation for risk assessments. This initial scoping approach could facilitate faster literature evaluation by focusing reviewer efforts, as well as potentially minimize reviewer bias in selection of key studies. Using externally-derived training data has applicability particularly for databases with very low search precision where identifying training data may be cost-prohibitive. certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2020
DA  - 2020-01-29
JO  - {'id': 'https://openalex.org/S111502347', 'issn_l': '1743-7199', 'issn': ['1743-7199', '1743-7202'], 'display_name': 'Health Psychology Review', 'publisher': 'Taylor & Francis', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Iain J. Marshall
AU  - Blair T. Johnson
AU  - Zigeng Wang
AU  - Sanguthevar Rajasekaran
AU  - Byron C. Wallace
ER  - 

490.
TY  - journal-article
ID  - https://openalex.org/W3143985904
DO  - https://doi.org/10.1186/s13643-021-01635-3
TI  - Research Screener: a machine learning tool to semi-automate abstract screening for systematic reviews
AB  - Systematic reviews and meta-analyses provide the highest level of evidence to help inform policy and practice, yet their rigorous nature is associated with significant time and economic demands. The screening of titles and abstracts is the most time consuming part of the review process with analysts required review thousands of articles manually, taking on average 33 days. New technologies aimed at streamlining the screening process have provided initial promising findings, yet there are limitations with current approaches and barriers to the widespread use of these tools. In this paper, we introduce and report initial evidence on the utility of Research Screener, a semi-automated machine learning tool to facilitate abstract screening.Three sets of analyses (simulation, interactive and sensitivity) were conducted to provide evidence of the utility of the tool through both simulated and real-world examples.Research Screener delivered a workload saving of between 60 and 96% across nine systematic reviews and two scoping reviews. Findings from the real-world interactive analysis demonstrated a time saving of 12.53 days compared to the manual screening, which equates to a financial saving of USD 2444. Conservatively, our results suggest that analysts who scan 50% of the total pool of articles identified via a systematic search are highly likely to have identified 100% of eligible papers.In light of these findings, Research Screener is able to reduce the burden for researchers wishing to conduct a comprehensive systematic review without reducing the scientific rigour for which they strive to achieve. by comparing studies predicted relevant to those used in the assessments (i.e., total relevant). Outcome A keyword search designed to retrieve studies that examined the in utero effects of environmental chemicals identified over 54,000 candidate references. Clustering algorithms were applied using 1456 studies from multiple IRIS assessments with chemical names removed as training data or seeds (i.e., semi-supervised learning). Using a six-algorithm ensemble approach 2602 articles, or approximately 5% of candidate references, were "voted" relevant by four or more clustering algorithms and manual review confirmed nearly 50% of these studies were relevant. Further evaluations on two IRIS assessments, using a nine-algorithm ensemble approach and a set of generic, chemical-independent, externally-derived seed studies correctly identified 77-83% of hazard identification studies published in the assessments and eliminated the need to manually screen more than 75% of search results on average. Limitations The chemical-independent approach used to build the training literature set provides a broad and unbiased picture across a variety of endpoints and environmental exposures but does not systematically identify all available data. Variance between actual and predicted relevant studies will be greater because of the external and non-random origin of seed study selection. This approach depends on access to readily available generic training data that can be used to locate relevant references in an unclassified corpus. Impact A generic approach to identifying human health relevant studies could be an important first step in literature evaluation for risk assessments. This initial scoping approach could facilitate faster literature evaluation by focusing reviewer efforts, as well as potentially minimize reviewer bias in selection of key studies. Using externally-derived training data has applicability particularly for databases with very low search precision where identifying training data may be cost-prohibitive. certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2021
DA  - 2021-04-01
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://systematicreviewsjournal.biomedcentral.com/counter/pdf/10.1186/s13643-021-01635-3', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Kevin Chai
AU  - Robin L. J. Lines
AU  - Daniel F. Gucciardi
AU  - Leo Ng
ER  - 

491.
TY  - journal-article
ID  - https://openalex.org/W2294602088
DO  - https://doi.org/10.1016/j.jclinepi.2016.03.004
TI  - Complementary approaches to searching MEDLINE may be sufficient for updating systematic reviews
AB  - To maximize the proportion of relevant studies identified for inclusion in systematic reviews (recall), complex time-consuming Boolean searches across multiple databases are common. Although MEDLINE provides excellent coverage of health science evidence, it has proved challenging to achieve high levels of recall through Boolean searches alone.Recall of one Boolean search method, the clinical query (CQ), combined with a ranking method, support vector machine (SVM), or PubMed-related articles, was tested against a gold standard of studies added to 6 updated Cochrane reviews and 10 Agency for Healthcare Research and Quality (AHRQ) evidence reviews. For the AHRQ sample, precision and temporal stability were examined for each method.Recall of new studies was 0.69 for the CQ, 0.66 for related articles, 0.50 for SVM, 0.91 for the combination of CQ and related articles, and 0.89 for the combination of CQ and SVM. Precision was 0.11 for CQ and related articles combined, and 0.11 for CQ and SVM combined. Related articles showed least stability over time.The complementary combination of a Boolean search strategy and a ranking strategy appears to provide a robust method for identifying relevant studies in MEDLINE. analysts who scan 50% of the total pool of articles identified via a systematic search are highly likely to have identified 100% of eligible papers.In light of these findings, Research Screener is able to reduce the burden for researchers wishing to conduct a comprehensive systematic review without reducing the scientific rigour for which they strive to achieve. by comparing studies predicted relevant to those used in the assessments (i.e., total relevant). Outcome A keyword search designed to retrieve studies that examined the in utero effects of environmental chemicals identified over 54,000 candidate references. Clustering algorithms were applied using 1456 studies from multiple IRIS assessments with chemical names removed as training data or seeds (i.e., semi-supervised learning). Using a six-algorithm ensemble approach 2602 articles, or approximately 5% of candidate references, were "voted" relevant by four or more clustering algorithms and manual review confirmed nearly 50% of these studies were relevant. Further evaluations on two IRIS assessments, using a nine-algorithm ensemble approach and a set of generic, chemical-independent, externally-derived seed studies correctly identified 77-83% of hazard identification studies published in the assessments and eliminated the need to manually screen more than 75% of search results on average. Limitations The chemical-independent approach used to build the training literature set provides a broad and unbiased picture across a variety of endpoints and environmental exposures but does not systematically identify all available data. Variance between actual and predicted relevant studies will be greater because of the external and non-random origin of seed study selection. This approach depends on access to readily available generic training data that can be used to locate relevant references in an unclassified corpus. Impact A generic approach to identifying human health relevant studies could be an important first step in literature evaluation for risk assessments. This initial scoping approach could facilitate faster literature evaluation by focusing reviewer efforts, as well as potentially minimize reviewer bias in selection of key studies. Using externally-derived training data has applicability particularly for databases with very low search precision where identifying training data may be cost-prohibitive. certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2016
DA  - 2016-10-01
JO  - {'id': 'https://openalex.org/S64418186', 'issn_l': '0895-4356', 'issn': ['1878-5921', '0895-4356'], 'display_name': 'Journal of Clinical Epidemiology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Margaret Sampson
AU  - Berry de Bruijn
AU  - Christine Urquhart
AU  - Kaveh G. Shojania
ER  - 

492.
TY  - journal-article
ID  - https://openalex.org/W2398422715
DO  - https://doi.org/10.1371/journal.pone.0156031
TI  - Text Mining of Journal Articles for Sleep Disorder Terminologies
AB  - Research on publication trends in journal articles on sleep disorders (SDs) and the associated methodologies by using text mining has been limited. The present study involved text mining for terms to determine the publication trends in sleep-related journal articles published during 2000-2013 and to identify associations between SD and methodology terms as well as conducting statistical analyses of the text mining findings.SD and methodology terms were extracted from 3,720 sleep-related journal articles in the PubMed database by using MetaMap. The extracted data set was analyzed using hierarchical cluster analyses and adjusted logistic regression models to investigate publication trends and associations between SD and methodology terms.MetaMap had a text mining precision, recall, and false positive rate of 0.70, 0.77, and 11.51%, respectively. The most common SD term was breathing-related sleep disorder, whereas narcolepsy was the least common. Cluster analyses showed similar methodology clusters for each SD term, except narcolepsy. The logistic regression models showed an increasing prevalence of insomnia, parasomnia, and other sleep disorders but a decreasing prevalence of breathing-related sleep disorder during 2000-2013. Different SD terms were positively associated with different methodology terms regarding research design terms, measure terms, and analysis terms.Insomnia-, parasomnia-, and other sleep disorder-related articles showed an increasing publication trend, whereas those related to breathing-related sleep disorder showed a decreasing trend. Furthermore, experimental studies more commonly focused on hypersomnia and other SDs and less commonly on insomnia, breathing-related sleep disorder, narcolepsy, and parasomnia. Thus, text mining may facilitate the exploration of the publication trends in SDs and the associated methodologies. total relevant). Outcome A keyword search designed to retrieve studies that examined the in utero effects of environmental chemicals identified over 54,000 candidate references. Clustering algorithms were applied using 1456 studies from multiple IRIS assessments with chemical names removed as training data or seeds (i.e., semi-supervised learning). Using a six-algorithm ensemble approach 2602 articles, or approximately 5% of candidate references, were "voted" relevant by four or more clustering algorithms and manual review confirmed nearly 50% of these studies were relevant. Further evaluations on two IRIS assessments, using a nine-algorithm ensemble approach and a set of generic, chemical-independent, externally-derived seed studies correctly identified 77-83% of hazard identification studies published in the assessments and eliminated the need to manually screen more than 75% of search results on average. Limitations The chemical-independent approach used to build the training literature set provides a broad and unbiased picture across a variety of endpoints and environmental exposures but does not systematically identify all available data. Variance between actual and predicted relevant studies will be greater because of the external and non-random origin of seed study selection. This approach depends on access to readily available generic training data that can be used to locate relevant references in an unclassified corpus. Impact A generic approach to identifying human health relevant studies could be an important first step in literature evaluation for risk assessments. This initial scoping approach could facilitate faster literature evaluation by focusing reviewer efforts, as well as potentially minimize reviewer bias in selection of key studies. Using externally-derived training data has applicability particularly for databases with very low search precision where identifying training data may be cost-prohibitive. certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2016
DA  - 2016-05-20
JO  - {'id': 'https://openalex.org/S202381698', 'issn_l': '1932-6203', 'issn': ['1932-6203'], 'display_name': 'PLOS ONE', 'publisher': 'Public Library of Science', 'type': 'journal', 'url': 'https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0156031&type=printable', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Calvin Lam
AU  - Fu-Chih Lai
AU  - Chia-Hui Wang
AU  - Mei-Hsin Lai
AU  - Nanly Hsu
AU  - Min Huey Chung
ER  - 

493.
TY  - journal-article
ID  - https://openalex.org/W2778841805
DO  - https://doi.org/10.1016/j.jclinepi.2017.12.007
TI  - Unreported links between trial registrations and published articles were identified using document similarity measures in a cross-sectional analysis of ClinicalTrials.gov
AB  - Objectives: Trial registries can be used to measure reporting biases and support systematic reviews but 45% of registrations do not provide a link to the article reporting on the trial. We evaluated the use of document similarity methods to identify unreported links between ClinicalTrials.gov and PubMed. Study Design and Setting: We extracted terms and concepts from a dataset of 72,469 ClinicalTrials.gov registrations and 276,307 PubMed articles, and tested methods for ranking articles across 16,005 reported links and 90 manually-identified unreported links. Performance was measured by the median rank of matching articles, and the proportion of unreported links that could be found by screening ranked candidate articles in order. Results: The best performing concept-based representation produced a median rank of 3 (IQR 1-21) for reported links and 3 (IQR 1-19) for the manually-identified unreported links, and term-based representations produced a median rank of 2 (1-20) for reported links and 2 (IQR 1-12) in unreported links. The matching article was ranked first for 40% of registrations, and screening 50 candidate articles per registration identified 86% of the unreported links. Conclusions: Leveraging the growth in the corpus of reported links between ClinicalTrials.gov and PubMed, we found that document similarity methods can assist in the identification of unreported links between trial registrations and corresponding articles. a decreasing trend. Furthermore, experimental studies more commonly focused on hypersomnia and other SDs and less commonly on insomnia, breathing-related sleep disorder, narcolepsy, and parasomnia. Thus, text mining may facilitate the exploration of the publication trends in SDs and the associated methodologies. total relevant). Outcome A keyword search designed to retrieve studies that examined the in utero effects of environmental chemicals identified over 54,000 candidate references. Clustering algorithms were applied using 1456 studies from multiple IRIS assessments with chemical names removed as training data or seeds (i.e., semi-supervised learning). Using a six-algorithm ensemble approach 2602 articles, or approximately 5% of candidate references, were "voted" relevant by four or more clustering algorithms and manual review confirmed nearly 50% of these studies were relevant. Further evaluations on two IRIS assessments, using a nine-algorithm ensemble approach and a set of generic, chemical-independent, externally-derived seed studies correctly identified 77-83% of hazard identification studies published in the assessments and eliminated the need to manually screen more than 75% of search results on average. Limitations The chemical-independent approach used to build the training literature set provides a broad and unbiased picture across a variety of endpoints and environmental exposures but does not systematically identify all available data. Variance between actual and predicted relevant studies will be greater because of the external and non-random origin of seed study selection. This approach depends on access to readily available generic training data that can be used to locate relevant references in an unclassified corpus. Impact A generic approach to identifying human health relevant studies could be an important first step in literature evaluation for risk assessments. This initial scoping approach could facilitate faster literature evaluation by focusing reviewer efforts, as well as potentially minimize reviewer bias in selection of key studies. Using externally-derived training data has applicability particularly for databases with very low search precision where identifying training data may be cost-prohibitive. certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2018
DA  - 2018-03-01
JO  - {'id': 'https://openalex.org/S64418186', 'issn_l': '0895-4356', 'issn': ['1878-5921', '0895-4356'], 'display_name': 'Journal of Clinical Epidemiology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Adam G. Dunn
AU  - Enrico Coiera
AU  - Florence T. Bourgeois
ER  - 

494.
TY  - journal-article
ID  - https://openalex.org/W2994586973
DO  - https://doi.org/10.1186/s13643-019-1245-8
TI  - Screening PubMed abstracts: is class imbalance always a challenge to machine learning?
AB  - The growing number of medical literature and textual data in online repositories led to an exponential increase in the workload of researchers involved in citation screening for systematic reviews. This work aims to combine machine learning techniques and data preprocessing for class imbalance to identify the outperforming strategy to screen articles in PubMed for inclusion in systematic reviews.We trained four binary text classifiers (support vector machines, k-nearest neighbor, random forest, and elastic-net regularized generalized linear models) in combination with four techniques for class imbalance: random undersampling and oversampling with 50:50 and 35:65 positive to negative class ratios and none as a benchmark. We used textual data of 14 systematic reviews as case studies. Difference between cross-validated area under the receiver operating characteristic curve (AUC-ROC) for machine learning techniques with and without preprocessing (delta AUC) was estimated within each systematic review, separately for each classifier. Meta-analytic fixed-effect models were used to pool delta AUCs separately by classifier and strategy.Cross-validated AUC-ROC for machine learning techniques (excluding k-nearest neighbor) without preprocessing was prevalently above 90%. Except for k-nearest neighbor, machine learning techniques achieved the best improvement in conjunction with random oversampling 50:50 and random undersampling 35:65.Resampling techniques slightly improved the performance of the investigated machine learning techniques. From a computational perspective, random undersampling 35:65 may be preferred. Furthermore, experimental studies more commonly focused on hypersomnia and other SDs and less commonly on insomnia, breathing-related sleep disorder, narcolepsy, and parasomnia. Thus, text mining may facilitate the exploration of the publication trends in SDs and the associated methodologies. total relevant). Outcome A keyword search designed to retrieve studies that examined the in utero effects of environmental chemicals identified over 54,000 candidate references. Clustering algorithms were applied using 1456 studies from multiple IRIS assessments with chemical names removed as training data or seeds (i.e., semi-supervised learning). Using a six-algorithm ensemble approach 2602 articles, or approximately 5% of candidate references, were "voted" relevant by four or more clustering algorithms and manual review confirmed nearly 50% of these studies were relevant. Further evaluations on two IRIS assessments, using a nine-algorithm ensemble approach and a set of generic, chemical-independent, externally-derived seed studies correctly identified 77-83% of hazard identification studies published in the assessments and eliminated the need to manually screen more than 75% of search results on average. Limitations The chemical-independent approach used to build the training literature set provides a broad and unbiased picture across a variety of endpoints and environmental exposures but does not systematically identify all available data. Variance between actual and predicted relevant studies will be greater because of the external and non-random origin of seed study selection. This approach depends on access to readily available generic training data that can be used to locate relevant references in an unclassified corpus. Impact A generic approach to identifying human health relevant studies could be an important first step in literature evaluation for risk assessments. This initial scoping approach could facilitate faster literature evaluation by focusing reviewer efforts, as well as potentially minimize reviewer bias in selection of key studies. Using externally-derived training data has applicability particularly for databases with very low search precision where identifying training data may be cost-prohibitive. certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2019
DA  - 2019-12-06
JO  - {'id': 'https://openalex.org/V82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://systematicreviewsjournal.biomedcentral.com/track/pdf/10.1186/s13643-019-1245-8', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Corrado Lanera
AU  - Paola Berchialla
AU  - Abhinav Sharma
AU  - Clara Minto
AU  - Dario Gregori
AU  - Ileana Baldi
ER  - 

495.
TY  - journal-article
ID  - https://openalex.org/W2994661761
DO  - https://doi.org/10.1016/j.aap.2019.105333
TI  - A systematic review of the association between fault or blame-related attributions and procedures after transport injury and health and work-related outcomes
AB  - Attributions of fault are often associated with worse injury outcomes; however, the consistency and magnitude of these impacts is not known. This review examined the prognostic role of fault on health, mental health, pain and work outcomes after transport injury. A systematic search of five electronic databases (Medline, Embase, CINAHL, PsycINFO, Cochrane Library) yielded 16,324 records published between 2000 and January 2018. Eligibility criteria were: adult transport injury survivors; prospective design; multivariable analysis; fault-related factor analysed; pain, mental health, general health or work-related outcome. Citations (n = 10,558, excluding duplicates) and full text articles (n = 555) were screened manually (Reviewer 1), and using concurrent machine learning and text mining (Reviewer 2; using Abstrackr, WordStat and QDA miner). Data from 55 papers that met all inclusion criteria were extracted, papers were evaluated for risk of bias using the QUIPS tool, and overall level of evidence was assessed using the GRADE tool. There were six main fault-related factors classified as: fault or responsibility, fault-based compensation, lawyer involvement or litigation, blame or guilt, road user or position in vehicle, and impact direction. Overall there were inconsistent associations between fault and transport injury outcomes, and 60% of papers had high risk of bias. There was moderate evidence that fault-based compensation claims were associated with poorer health-related outcomes, and that lawyer involvement was associated with poorer work outcomes beyond 12 months post-injury. However, the evidence of negative associations between fault-based compensation claims and work-related outcomes was limited. Lawyer involvement and fault-based compensation claims were associated with adverse mental health outcomes six months post-injury, but not beyond 12 months. The most consistent associations between fault and negative outcomes were not for fault attributions, per se, but were related to fault-related procedures (e.g., lawyer engagement, fault-based compensation claims). as training data or seeds (i.e., semi-supervised learning). Using a six-algorithm ensemble approach 2602 articles, or approximately 5% of candidate references, were "voted" relevant by four or more clustering algorithms and manual review confirmed nearly 50% of these studies were relevant. Further evaluations on two IRIS assessments, using a nine-algorithm ensemble approach and a set of generic, chemical-independent, externally-derived seed studies correctly identified 77-83% of hazard identification studies published in the assessments and eliminated the need to manually screen more than 75% of search results on average. Limitations The chemical-independent approach used to build the training literature set provides a broad and unbiased picture across a variety of endpoints and environmental exposures but does not systematically identify all available data. Variance between actual and predicted relevant studies will be greater because of the external and non-random origin of seed study selection. This approach depends on access to readily available generic training data that can be used to locate relevant references in an unclassified corpus. Impact A generic approach to identifying human health relevant studies could be an important first step in literature evaluation for risk assessments. This initial scoping approach could facilitate faster literature evaluation by focusing reviewer efforts, as well as potentially minimize reviewer bias in selection of key studies. Using externally-derived training data has applicability particularly for databases with very low search precision where identifying training data may be cost-prohibitive. certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2020
DA  - 2020-02-01
JO  - {'id': 'https://openalex.org/S188336720', 'issn_l': '0001-4575', 'issn': ['1879-2057', '0001-4575'], 'display_name': 'Accident Analysis & Prevention', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Melita J. Giummarra
AU  - Georgina Lau
AU  - Genevieve Grant
AU  - Belinda J. Gabbe
ER  - 

496.
TY  - journal-article
ID  - https://openalex.org/W3023106114
DO  - https://doi.org/10.1108/ijqss-12-2019-0133
TI  - Research trends in quality management in years 2000-2019
AB  - Purpose This study aims to demonstrate the suitability of text-mining toolset for the discovery of trends in quality management (QM) literature in 2000-2019. The hypothesis was formulated that as the field of study is mature, the most important trends are related to deepening and broadening of the knowledge. Design/methodology/approach A novel approach to trend discovery was proposed. The computer-aided analysis of full-texts of papers led to increased reliability and level of detail of the achieved results and helped significantly reduce researchers’ bias. Overall, 4,833 papers from 8 journal dedicated to QM were analysed. Findings Trends discovery led to the identification of 45 trends: 17 long-lasting trends, 4 declining trends, 11 emerging trends and 13 ephemeris trends. They were compared to the results of earlier studies. New trends and potential gaps were discussed. Practical implications The results highlight the trends that gain or lose popularity, thus they can be used to focus studies, as well as find new subjects, which are not so popular yet. The knowledge about emerging trends is also important for those quality managers who strive for improvement of their efficiency. Originality/value The research was designed to bypass the limitations of previous studies. The use of text mining methods and analysis of full texts of papers delivered more detailed and reliable data. Resignation from predefinition of classification criteria significantly reduced researchers’ bias and allowed the discovery of new trends, not identified in previous studies. compensation claims and work-related outcomes was limited. Lawyer involvement and fault-based compensation claims were associated with adverse mental health outcomes six months post-injury, but not beyond 12 months. The most consistent associations between fault and negative outcomes were not for fault attributions, per se, but were related to fault-related procedures (e.g., lawyer engagement, fault-based compensation claims). as training data or seeds (i.e., semi-supervised learning). Using a six-algorithm ensemble approach 2602 articles, or approximately 5% of candidate references, were "voted" relevant by four or more clustering algorithms and manual review confirmed nearly 50% of these studies were relevant. Further evaluations on two IRIS assessments, using a nine-algorithm ensemble approach and a set of generic, chemical-independent, externally-derived seed studies correctly identified 77-83% of hazard identification studies published in the assessments and eliminated the need to manually screen more than 75% of search results on average. Limitations The chemical-independent approach used to build the training literature set provides a broad and unbiased picture across a variety of endpoints and environmental exposures but does not systematically identify all available data. Variance between actual and predicted relevant studies will be greater because of the external and non-random origin of seed study selection. This approach depends on access to readily available generic training data that can be used to locate relevant references in an unclassified corpus. Impact A generic approach to identifying human health relevant studies could be an important first step in literature evaluation for risk assessments. This initial scoping approach could facilitate faster literature evaluation by focusing reviewer efforts, as well as potentially minimize reviewer bias in selection of key studies. Using externally-derived training data has applicability particularly for databases with very low search precision where identifying training data may be cost-prohibitive. certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2020
DA  - 2020-05-04
JO  - {'id': 'https://openalex.org/S103309803', 'issn_l': '1756-669X', 'issn': ['1756-669X', '1756-6703'], 'display_name': 'International Journal of Quality and Service Sciences', 'publisher': 'Emerald Publishing Limited', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Sławomir Wawak
AU  - Piotr Rogala
AU  - Su Mi Dahlgaard-Park
ER  - 

497.
TY  - journal-article
ID  - https://openalex.org/W3185296261
DO  - https://doi.org/10.1145/3462477
TI  - Text Mining in Cybersecurity
AB  - The growth of data volume has changed cybersecurity activities, demanding a higher level of automation. In this new cybersecurity landscape, text mining emerged as an alternative to improve the efficiency of the activities involving unstructured data. This article proposes a Systematic Literature Review ( SLR ) to present the application of text mining in the cybersecurity domain. Using a systematic protocol, we identified 2,196 studies, out of which 83 were summarized. As a contribution, we propose a taxonomy to demonstrate the different activities in the cybersecurity domain supported by text mining. We also detail the strategies evaluated in the application of text mining tasks and the use of neural networks to support activities involving unstructured data. The work also discusses text classification performance aiming its application in real-world solutions. The SLR also highlights open gaps for future research, such as the analysis of non-English content and the intensification in the usage of neural networks. as find new subjects, which are not so popular yet. The knowledge about emerging trends is also important for those quality managers who strive for improvement of their efficiency. Originality/value The research was designed to bypass the limitations of previous studies. The use of text mining methods and analysis of full texts of papers delivered more detailed and reliable data. Resignation from predefinition of classification criteria significantly reduced researchers’ bias and allowed the discovery of new trends, not identified in previous studies. compensation claims and work-related outcomes was limited. Lawyer involvement and fault-based compensation claims were associated with adverse mental health outcomes six months post-injury, but not beyond 12 months. The most consistent associations between fault and negative outcomes were not for fault attributions, per se, but were related to fault-related procedures (e.g., lawyer engagement, fault-based compensation claims). as training data or seeds (i.e., semi-supervised learning). Using a six-algorithm ensemble approach 2602 articles, or approximately 5% of candidate references, were "voted" relevant by four or more clustering algorithms and manual review confirmed nearly 50% of these studies were relevant. Further evaluations on two IRIS assessments, using a nine-algorithm ensemble approach and a set of generic, chemical-independent, externally-derived seed studies correctly identified 77-83% of hazard identification studies published in the assessments and eliminated the need to manually screen more than 75% of search results on average. Limitations The chemical-independent approach used to build the training literature set provides a broad and unbiased picture across a variety of endpoints and environmental exposures but does not systematically identify all available data. Variance between actual and predicted relevant studies will be greater because of the external and non-random origin of seed study selection. This approach depends on access to readily available generic training data that can be used to locate relevant references in an unclassified corpus. Impact A generic approach to identifying human health relevant studies could be an important first step in literature evaluation for risk assessments. This initial scoping approach could facilitate faster literature evaluation by focusing reviewer efforts, as well as potentially minimize reviewer bias in selection of key studies. Using externally-derived training data has applicability particularly for databases with very low search precision where identifying training data may be cost-prohibitive. certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2021
DA  - 2021-07-18
JO  - {'id': 'https://openalex.org/S157921468', 'issn_l': '0360-0300', 'issn': ['0360-0300', '1557-7341'], 'display_name': 'ACM Computing Surveys', 'publisher': 'Association for Computing Machinery', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Luciano Ignaczak
AU  - Guilherme Goldschmidt
AU  - Cristiano André da Costa
AU  - Rodrigo da Rosa Righi
ER  - 

498.
TY  - journal-article
ID  - https://openalex.org/W2802420380
DO  - https://doi.org/10.1093/jamia/ocy038
TI  - Automatic recognition of self-acknowledged limitations in clinical research literature
AB  - Abstract Objective To automatically recognize self-acknowledged limitations in clinical research publications to support efforts in improving research transparency. Methods To develop our recognition methods, we used a set of 8431 sentences from 1197 PubMed Central articles. A subset of these sentences was manually annotated for training/testing, and inter-annotator agreement was calculated. We cast the recognition problem as a binary classification task, in which we determine whether a given sentence from a publication discusses self-acknowledged limitations or not. We experimented with three methods: a rule-based approach based on document structure, supervised machine learning, and a semi-supervised method that uses self-training to expand the training set in order to improve classification performance. The machine learning algorithms used were logistic regression (LR) and support vector machines (SVM). Results Annotators had good agreement in labeling limitation sentences (Krippendorff’s α = 0.781). Of the three methods used, the rule-based method yielded the best performance with 91.5% accuracy (95% CI [90.1-92.9]), while self-training with SVM led to a small improvement over fully supervised learning (89.9%, 95% CI [88.4-91.4] vs 89.6%, 95% CI [88.1-91.1]). Conclusions The approach presented can be incorporated into the workflows of stakeholders focusing on research transparency to improve reporting of limitations in clinical studies. and analysis of full texts of papers delivered more detailed and reliable data. Resignation from predefinition of classification criteria significantly reduced researchers’ bias and allowed the discovery of new trends, not identified in previous studies. compensation claims and work-related outcomes was limited. Lawyer involvement and fault-based compensation claims were associated with adverse mental health outcomes six months post-injury, but not beyond 12 months. The most consistent associations between fault and negative outcomes were not for fault attributions, per se, but were related to fault-related procedures (e.g., lawyer engagement, fault-based compensation claims). as training data or seeds (i.e., semi-supervised learning). Using a six-algorithm ensemble approach 2602 articles, or approximately 5% of candidate references, were "voted" relevant by four or more clustering algorithms and manual review confirmed nearly 50% of these studies were relevant. Further evaluations on two IRIS assessments, using a nine-algorithm ensemble approach and a set of generic, chemical-independent, externally-derived seed studies correctly identified 77-83% of hazard identification studies published in the assessments and eliminated the need to manually screen more than 75% of search results on average. Limitations The chemical-independent approach used to build the training literature set provides a broad and unbiased picture across a variety of endpoints and environmental exposures but does not systematically identify all available data. Variance between actual and predicted relevant studies will be greater because of the external and non-random origin of seed study selection. This approach depends on access to readily available generic training data that can be used to locate relevant references in an unclassified corpus. Impact A generic approach to identifying human health relevant studies could be an important first step in literature evaluation for risk assessments. This initial scoping approach could facilitate faster literature evaluation by focusing reviewer efforts, as well as potentially minimize reviewer bias in selection of key studies. Using externally-derived training data has applicability particularly for databases with very low search precision where identifying training data may be cost-prohibitive. certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2018
DA  - 2018-07-01
JO  - {'id': 'https://openalex.org/V129839026', 'issn_l': '1067-5027', 'issn': ['1067-5027', '1527-974X'], 'display_name': 'Journal of the American Medical Informatics Association', 'publisher': 'Oxford University Press', 'type': 'journal', 'url': 'https://academic.oup.com/jamia/article-pdf/25/7/855/25080478/ocy038.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'pd'}
DP  - OpenAlex
AU  - Halil Kilicoglu
AU  - Graciela Rosemblat
AU  - Mario Malički
AU  - Gerben ter Riet
ER  - 

499.
TY  - journal-article
ID  - https://openalex.org/W2918301483
DO  - https://doi.org/10.1016/j.jclinepi.2019.02.015
TI  - The risk of conclusion change in systematic review updates can be estimated by learning from a database of published examples
AB  - To determine which systematic review characteristics are needed to estimate the risk of conclusion change in systematic review updates.We applied classification trees (a machine learning method) to model the risk of conclusion change in systematic review updates, using pairs of systematic reviews and their updates as samples. The classifiers were constructed using a set of features extracted from systematic reviews and the relevant trials added in published updates. Model performance was measured by recall, precision, and area under the receiver operating characteristic curve (AUC).We identified 63 pairs of systematic reviews and updates, of which 20 (32%) exhibited a change in conclusion in their updates. A classifier using information about new trials exhibited the highest performance (AUC: 0.71; recall: 0.75; precision: 0.43) compared to a classifier that used fewer features (AUC: 0.65; recall: 0.75; precision: 0.39).When estimating the risk of conclusion change in systematic review updates, information about the sizes of trials that will be added in an update are most useful. Future tools aimed at signaling conclusion change risks would benefit from complementary tools that automate screening of relevant trials. presented can be incorporated into the workflows of stakeholders focusing on research transparency to improve reporting of limitations in clinical studies. and analysis of full texts of papers delivered more detailed and reliable data. Resignation from predefinition of classification criteria significantly reduced researchers’ bias and allowed the discovery of new trends, not identified in previous studies. compensation claims and work-related outcomes was limited. Lawyer involvement and fault-based compensation claims were associated with adverse mental health outcomes six months post-injury, but not beyond 12 months. The most consistent associations between fault and negative outcomes were not for fault attributions, per se, but were related to fault-related procedures (e.g., lawyer engagement, fault-based compensation claims). as training data or seeds (i.e., semi-supervised learning). Using a six-algorithm ensemble approach 2602 articles, or approximately 5% of candidate references, were "voted" relevant by four or more clustering algorithms and manual review confirmed nearly 50% of these studies were relevant. Further evaluations on two IRIS assessments, using a nine-algorithm ensemble approach and a set of generic, chemical-independent, externally-derived seed studies correctly identified 77-83% of hazard identification studies published in the assessments and eliminated the need to manually screen more than 75% of search results on average. Limitations The chemical-independent approach used to build the training literature set provides a broad and unbiased picture across a variety of endpoints and environmental exposures but does not systematically identify all available data. Variance between actual and predicted relevant studies will be greater because of the external and non-random origin of seed study selection. This approach depends on access to readily available generic training data that can be used to locate relevant references in an unclassified corpus. Impact A generic approach to identifying human health relevant studies could be an important first step in literature evaluation for risk assessments. This initial scoping approach could facilitate faster literature evaluation by focusing reviewer efforts, as well as potentially minimize reviewer bias in selection of key studies. Using externally-derived training data has applicability particularly for databases with very low search precision where identifying training data may be cost-prohibitive. certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2019
DA  - 2019-06-01
JO  - {'id': 'https://openalex.org/S64418186', 'issn_l': '0895-4356', 'issn': ['1878-5921', '0895-4356'], 'display_name': 'Journal of Clinical Epidemiology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Rabia Bashir
AU  - Didi Surian
AU  - Adam G. Dunn
ER  - 

500.
TY  - journal-article
ID  - https://openalex.org/W2573112476
DO  - https://doi.org/10.1016/j.jclinepi.2016.11.019
TI  - Commentary on EPC methods: an exploration of the use of text-mining software in systematic reviews
AB  - • determine which The Agency for Healthcare Research and Quality Evidence-based Practice Center program recently published a methods white paper on the (a machine effectivehealthcare.ahrq.gov method) to web site which focused on a preliminary exploration of the use of text-mining in evidence synthesis. their updates as samples. The classifiers were constructed using a set of features extracted from systematic reviews and the relevant trials added in published updates. Model performance was measured by recall, precision, and area under the receiver operating characteristic curve (AUC).We identified 63 pairs of systematic reviews and updates, of which 20 (32%) exhibited a change in conclusion in their updates. A classifier using information about new trials exhibited the highest performance (AUC: 0.71; recall: 0.75; precision: 0.43) compared to a classifier that used fewer features (AUC: 0.65; recall: 0.75; precision: 0.39).When estimating the risk of conclusion change in systematic review updates, information about the sizes of trials that will be added in an update are most useful. Future tools aimed at signaling conclusion change risks would benefit from complementary tools that automate screening of relevant trials. presented can be incorporated into the workflows of stakeholders focusing on research transparency to improve reporting of limitations in clinical studies. and analysis of full texts of papers delivered more detailed and reliable data. Resignation from predefinition of classification criteria significantly reduced researchers’ bias and allowed the discovery of new trends, not identified in previous studies. compensation claims and work-related outcomes was limited. Lawyer involvement and fault-based compensation claims were associated with adverse mental health outcomes six months post-injury, but not beyond 12 months. The most consistent associations between fault and negative outcomes were not for fault attributions, per se, but were related to fault-related procedures (e.g., lawyer engagement, fault-based compensation claims). as training data or seeds (i.e., semi-supervised learning). Using a six-algorithm ensemble approach 2602 articles, or approximately 5% of candidate references, were "voted" relevant by four or more clustering algorithms and manual review confirmed nearly 50% of these studies were relevant. Further evaluations on two IRIS assessments, using a nine-algorithm ensemble approach and a set of generic, chemical-independent, externally-derived seed studies correctly identified 77-83% of hazard identification studies published in the assessments and eliminated the need to manually screen more than 75% of search results on average. Limitations The chemical-independent approach used to build the training literature set provides a broad and unbiased picture across a variety of endpoints and environmental exposures but does not systematically identify all available data. Variance between actual and predicted relevant studies will be greater because of the external and non-random origin of seed study selection. This approach depends on access to readily available generic training data that can be used to locate relevant references in an unclassified corpus. Impact A generic approach to identifying human health relevant studies could be an important first step in literature evaluation for risk assessments. This initial scoping approach could facilitate faster literature evaluation by focusing reviewer efforts, as well as potentially minimize reviewer bias in selection of key studies. Using externally-derived training data has applicability particularly for databases with very low search precision where identifying training data may be cost-prohibitive. certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2017
DA  - 2017-01-18
JO  - {'id': 'https://openalex.org/S64418186', 'issn_l': '0895-4356', 'issn': ['1878-5921', '0895-4356'], 'display_name': 'Journal of Clinical Epidemiology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Robin Paynter
AU  - Lionel L. Bañez
AU  - Eileen Erinoff
AU  - Jennifer Lege-Matsuura
AU  - Shannon A Potter
ER  - 

501.
TY  - journal-article
ID  - https://openalex.org/W2979996416
DO  - https://doi.org/10.1186/s13750-019-0177-z
TI  - Use of literature mining for early identification of emerging contaminants in freshwater resources
AB  - Abstract Chemical and microbial contaminants in the aquatic environment pose a potential threat to humans and to ecosystems. Humans may be exposed to contaminants in water resources when used for drinking water production, agriculture, aquaculture or recreation. Climatological, social and demographic changes, as well as the increasing sensitivity of analytical techniques, may result in the augmented detection of contaminants. Recent research has shown that it takes about 15 years from the time of the first scientific study mentioning the presence of a contaminant in the environment for the issue to peak in scientific attention and regulatory action. One possible factor influencing this lengthy period is that the first article becomes lost in the vast number of publications. In this study, we therefore developed a methodology using literature mining to identify the first scientific study which reports the presence of a contaminant in the aquatic environment. The developed semi-automated methodology enables health and environment agencies to inform policy makers about contaminants in the aquatic environment that could be significant for public and environmental health in national, international and river basin settings. The methodology thereby assists the proactive governance of emerging contaminants in the aquatic environment. This was illustrated by a retrospective analysis of the period of emergence in the Netherlands of: (1) perfluorooctanoic acid in surface water, and (2) biological industrial wastewater treatment systems as potential infection sources for Legionnaires´ disease. trends, not identified in previous studies. compensation claims and work-related outcomes was limited. Lawyer involvement and fault-based compensation claims were associated with adverse mental health outcomes six months post-injury, but not beyond 12 months. The most consistent associations between fault and negative outcomes were not for fault attributions, per se, but were related to fault-related procedures (e.g., lawyer engagement, fault-based compensation claims). as training data or seeds (i.e., semi-supervised learning). Using a six-algorithm ensemble approach 2602 articles, or approximately 5% of candidate references, were "voted" relevant by four or more clustering algorithms and manual review confirmed nearly 50% of these studies were relevant. Further evaluations on two IRIS assessments, using a nine-algorithm ensemble approach and a set of generic, chemical-independent, externally-derived seed studies correctly identified 77-83% of hazard identification studies published in the assessments and eliminated the need to manually screen more than 75% of search results on average. Limitations The chemical-independent approach used to build the training literature set provides a broad and unbiased picture across a variety of endpoints and environmental exposures but does not systematically identify all available data. Variance between actual and predicted relevant studies will be greater because of the external and non-random origin of seed study selection. This approach depends on access to readily available generic training data that can be used to locate relevant references in an unclassified corpus. Impact A generic approach to identifying human health relevant studies could be an important first step in literature evaluation for risk assessments. This initial scoping approach could facilitate faster literature evaluation by focusing reviewer efforts, as well as potentially minimize reviewer bias in selection of key studies. Using externally-derived training data has applicability particularly for databases with very low search precision where identifying training data may be cost-prohibitive. certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2019
DA  - 2019-10-28
JO  - {'id': 'https://openalex.org/S2737036037', 'issn_l': '2047-2382', 'issn': ['2047-2382'], 'display_name': 'Environmental Evidence', 'publisher': 'BioMed Central', 'type': 'journal', 'url': 'https://doi.org/10.1186/s13750-019-0177-z', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Julia Hartmann
AU  - Susanne Wuijts
AU  - J.P. van der Hoek
AU  - Ana Maria de Roda Husman
ER  - 

502.
TY  - journal-article
ID  - https://openalex.org/W3105741911
DO  - https://doi.org/10.1111/geb.13219
TI  - Fast, scalable, and automated identification of articles for biodiversity and macroecological datasets
AB  - Aim:
Understanding broad‐scale ecological patterns and processes is necessary if we are to mitigate the consequences of anthropogenically driven biodiversity degradation. However, such analyses require large datasets and current data collation methods can be slow, involving extensive human input. Given rapid and ever‐increasing rates of scientific publication, manually identifying data sources among hundreds of thousands of articles is a significant challenge, which can create a bottleneck in the generation of ecological databases.
/
Innovation:
Here, we demonstrate the use of general, text‐classification approaches to identify relevant biodiversity articles. We apply this to two freely available example databases, the Living Planet Database and the database of the PREDICTS (Projecting Responses of Ecological Diversity in Changing Terrestrial Systems) project, both of which underpin important biodiversity indicators. We assess machine‐learning classifiers based on logistic regression (LR) and convolutional neural networks, and identify aspects of the text‐processing workflow that influence classification performance.
/
Main conclusions:
Our best classifiers can distinguish relevant from non‐relevant articles with over 90% accuracy. Using readily available abstracts and titles or abstracts alone produces significantly better results than using titles alone. LR and neural network models performed similarly. Crucially, we show that deploying such models on real‐world search results can significantly increase the rate at which potentially relevant papers are recovered compared to a current manual protocol. Furthermore, our results indicate that, given a modest initial sample of 100 relevant papers, high‐performing classifiers could be generated quickly through iteratively updating the training texts based on targeted literature searches. These findings clearly demonstrate the usefulness of text‐mining methods for constructing and enhancing ecological datasets, and wider application of these techniques has the potential to benefit large‐scale analyses more broadly. We provide source code and examples that can be used to create new classifiers for other datasets. engagement, fault-based compensation claims). as training data or seeds (i.e., semi-supervised learning). Using a six-algorithm ensemble approach 2602 articles, or approximately 5% of candidate references, were "voted" relevant by four or more clustering algorithms and manual review confirmed nearly 50% of these studies were relevant. Further evaluations on two IRIS assessments, using a nine-algorithm ensemble approach and a set of generic, chemical-independent, externally-derived seed studies correctly identified 77-83% of hazard identification studies published in the assessments and eliminated the need to manually screen more than 75% of search results on average. Limitations The chemical-independent approach used to build the training literature set provides a broad and unbiased picture across a variety of endpoints and environmental exposures but does not systematically identify all available data. Variance between actual and predicted relevant studies will be greater because of the external and non-random origin of seed study selection. This approach depends on access to readily available generic training data that can be used to locate relevant references in an unclassified corpus. Impact A generic approach to identifying human health relevant studies could be an important first step in literature evaluation for risk assessments. This initial scoping approach could facilitate faster literature evaluation by focusing reviewer efforts, as well as potentially minimize reviewer bias in selection of key studies. Using externally-derived training data has applicability particularly for databases with very low search precision where identifying training data may be cost-prohibitive. certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2021
DA  - 2021-01-01
JO  - {'id': 'https://openalex.org/S169694011', 'issn_l': '1466-822X', 'issn': ['1466-8238', '1466-822X'], 'display_name': 'Global Ecology and Biogeography', 'publisher': 'Wiley-Blackwell', 'type': 'journal', 'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/geb.13219', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Richard Cornford
AU  - Stefanie Deinet
AU  - Adriana De Palma
AU  - Samantha L. L. Hill
AU  - Louise McRae
AU  - Benjamin Pettit
AU  - Valentina Marconi
AU  - Andy Purvis
AU  - Robin Freeman
ER  - 

503.
TY  - journal-article
ID  - https://openalex.org/W2805975171
DO  - https://doi.org/10.1016/j.ijpe.2018.06.006
TI  - A text mining based overview of inventory research in the ISIR special issues 1994–2016
AB  - Abstract broad‐scale ecological When a research field achieves a certain maturity, it becomes useful for future research to obtain a structured overview of the field: how did it evolve in the past? Where does it currently stand? In what direction does it (possibly) evolve? The purpose of our paper is to offer an overview of inventory research published in the special issues of ISIR (International Society for Inventory Research) Symposia, one of the most important forums of leading inventory research. This paper focuses on the following two research questions: (1) what are the major topics of inventory research in ISIR special issues? and (2) how do important research topics within ISIR special issues evolve over time? underpin We apply text mining as a novel method of content analysis, relying on the 12 special issues of ISIR published in the International Journal of Production Economics between 1994 and 2016, covering 566 papers. The relevance of text mining is based on a structured analysis of literature review type papers in the field of inventory research; this offers a basis for identifying the main topics and terms in the field. Text mining results are further investigated by statistical methods to identify key research areas and their evolution over time. a current manual protocol. Furthermore, our results indicate that, given a modest initial sample of 100 relevant papers, high‐performing classifiers could be generated quickly through iteratively updating the training texts based on targeted literature searches. These findings clearly demonstrate the usefulness of text‐mining methods for constructing and enhancing ecological datasets, and wider application of these techniques has the potential to benefit large‐scale analyses more broadly. We provide source code and examples that can be used to create new classifiers for other datasets. engagement, fault-based compensation claims). as training data or seeds (i.e., semi-supervised learning). Using a six-algorithm ensemble approach 2602 articles, or approximately 5% of candidate references, were "voted" relevant by four or more clustering algorithms and manual review confirmed nearly 50% of these studies were relevant. Further evaluations on two IRIS assessments, using a nine-algorithm ensemble approach and a set of generic, chemical-independent, externally-derived seed studies correctly identified 77-83% of hazard identification studies published in the assessments and eliminated the need to manually screen more than 75% of search results on average. Limitations The chemical-independent approach used to build the training literature set provides a broad and unbiased picture across a variety of endpoints and environmental exposures but does not systematically identify all available data. Variance between actual and predicted relevant studies will be greater because of the external and non-random origin of seed study selection. This approach depends on access to readily available generic training data that can be used to locate relevant references in an unclassified corpus. Impact A generic approach to identifying human health relevant studies could be an important first step in literature evaluation for risk assessments. This initial scoping approach could facilitate faster literature evaluation by focusing reviewer efforts, as well as potentially minimize reviewer bias in selection of key studies. Using externally-derived training data has applicability particularly for databases with very low search precision where identifying training data may be cost-prohibitive. certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2019
DA  - 2019-03-01
JO  - {'id': 'https://openalex.org/S184816971', 'issn_l': '0925-5273', 'issn': ['0925-5273', '1873-7579'], 'display_name': 'International Journal of Production Economics', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Krisztina Demeter
AU  - Levente Szász
AU  - Andrea Kő
ER  - 

504.
TY  - journal-article
ID  - https://openalex.org/W2920689551
DO  - https://doi.org/10.1177/1359104519827631
TI  - Review of services to inform clinical frameworks for adolescents and young adults with severe, persistent and complex mental illness
AB  - Severe, persistent and complex mental illness (SPCMI) affects a small proportion of young people but is associated with severe disability and a large burden on families and health services. This article identifies and describes service models for adolescents and young adults with SPCMI.A systematic search was conducted for services for young people aged 12-25 years with SPCMI. The review sought service models providing extended care and/or multidisciplinary services to meet the complex and long-term needs of this population.A total of 43 sources were identified. Evidence of effectiveness was found for both community- and bed-based services. Specific components suggested as important in service delivery included care provided by multidisciplinary teams, consumer and family involvement in care planning, intensive case management and service integration through the continuum of care.Clinical frameworks for this population must incorporate effective community care integrated with inpatient treatment of short duration. Frameworks require consumer and family-centred care with flexibility to support progression through developmental stages and tasks while addressing issues related to risk management, fluctuation in illness severity and stages of recovery. A continuum of care is necessary to meet the needs that arise from SPCMI in adolescents and young adults. by statistical methods to identify key research areas and their evolution over time. a current manual protocol. Furthermore, our results indicate that, given a modest initial sample of 100 relevant papers, high‐performing classifiers could be generated quickly through iteratively updating the training texts based on targeted literature searches. These findings clearly demonstrate the usefulness of text‐mining methods for constructing and enhancing ecological datasets, and wider application of these techniques has the potential to benefit large‐scale analyses more broadly. We provide source code and examples that can be used to create new classifiers for other datasets. engagement, fault-based compensation claims). as training data or seeds (i.e., semi-supervised learning). Using a six-algorithm ensemble approach 2602 articles, or approximately 5% of candidate references, were "voted" relevant by four or more clustering algorithms and manual review confirmed nearly 50% of these studies were relevant. Further evaluations on two IRIS assessments, using a nine-algorithm ensemble approach and a set of generic, chemical-independent, externally-derived seed studies correctly identified 77-83% of hazard identification studies published in the assessments and eliminated the need to manually screen more than 75% of search results on average. Limitations The chemical-independent approach used to build the training literature set provides a broad and unbiased picture across a variety of endpoints and environmental exposures but does not systematically identify all available data. Variance between actual and predicted relevant studies will be greater because of the external and non-random origin of seed study selection. This approach depends on access to readily available generic training data that can be used to locate relevant references in an unclassified corpus. Impact A generic approach to identifying human health relevant studies could be an important first step in literature evaluation for risk assessments. This initial scoping approach could facilitate faster literature evaluation by focusing reviewer efforts, as well as potentially minimize reviewer bias in selection of key studies. Using externally-derived training data has applicability particularly for databases with very low search precision where identifying training data may be cost-prohibitive. certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2019
DA  - 2019-02-28
JO  - {'id': 'https://openalex.org/S25859030', 'issn_l': '1359-1045', 'issn': ['1461-7021', '1359-1045'], 'display_name': 'Clinical Child Psychology and Psychiatry', 'publisher': 'SAGE Publishing', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Charlotte Woody
AU  - Amanda J Baxter
AU  - Eryn Wright
AU  - Kate Gossip
AU  - Elizabeth Leitch
AU  - Harvey Whiteford
AU  - James Scott
ER  - 

505.
TY  - journal-article
ID  - https://openalex.org/W3023715695
DO  - https://doi.org/10.1016/j.eswax.2020.100030
TI  - Using a neural network-based feature extraction method to facilitate citation screening for systematic reviews
AB  - • A novel neural network-based feature extraction method is presented. • Proposed method is used for efficient semi-automatic citation screening. • Performance of our method is evaluated on 23 systematic review datasets. Citation screening is a labour-intensive part of the process of a systematic literature review that identifies citations eligible for inclusion in the review. In this paper, we present an automatic text classification approach that aims to prioritise eligible citations earlier than ineligible ones and thus reduces the manual labelling effort that is involved in the screening process. e.g. by automatically excluding lower ranked citations. To improve the performance of the text classifier, we develop a novel neural network-based feature extraction method. Unlike previous approaches to citation screening that employ unsupervised feature extraction methods to address a supervised classification task, our proposed method extracts document features in a supervised setting. In particular, our method generates a feature representation for documents, which is explicitly optimised to discriminate between eligible and ineligible citations. The generated document representation is subsequently used to train a text classifier. Experiments show that our feature extraction method obtains average workload savings of 56% when evaluated across 23 medical systematic reviews. The proposed method outperforms 10 baseline feature extraction methods by approximately 6% in terms of the WSS @95% metric. indicate that, given a modest initial sample of 100 relevant papers, high‐performing classifiers could be generated quickly through iteratively updating the training texts based on targeted literature searches. These findings clearly demonstrate the usefulness of text‐mining methods for constructing and enhancing ecological datasets, and wider application of these techniques has the potential to benefit large‐scale analyses more broadly. We provide source code and examples that can be used to create new classifiers for other datasets. engagement, fault-based compensation claims). as training data or seeds (i.e., semi-supervised learning). Using a six-algorithm ensemble approach 2602 articles, or approximately 5% of candidate references, were "voted" relevant by four or more clustering algorithms and manual review confirmed nearly 50% of these studies were relevant. Further evaluations on two IRIS assessments, using a nine-algorithm ensemble approach and a set of generic, chemical-independent, externally-derived seed studies correctly identified 77-83% of hazard identification studies published in the assessments and eliminated the need to manually screen more than 75% of search results on average. Limitations The chemical-independent approach used to build the training literature set provides a broad and unbiased picture across a variety of endpoints and environmental exposures but does not systematically identify all available data. Variance between actual and predicted relevant studies will be greater because of the external and non-random origin of seed study selection. This approach depends on access to readily available generic training data that can be used to locate relevant references in an unclassified corpus. Impact A generic approach to identifying human health relevant studies could be an important first step in literature evaluation for risk assessments. This initial scoping approach could facilitate faster literature evaluation by focusing reviewer efforts, as well as potentially minimize reviewer bias in selection of key studies. Using externally-derived training data has applicability particularly for databases with very low search precision where identifying training data may be cost-prohibitive. certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2020
DA  - 2020-07-01
JO  - {'id': 'https://openalex.org/V4210185740', 'issn_l': '2590-1885', 'issn': ['2590-1885'], 'display_name': 'Expert systems with applications', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'https://doi.org/10.1016/j.eswax.2020.100030', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc-nd'}
DP  - OpenAlex
AU  - Georgios Kontonatsios
AU  - Sally Spencer
AU  - Peter Matthew
AU  - Ioannis Korkontzelos
ER  - 

506.
TY  - journal-article
ID  - https://openalex.org/W3094744218
DO  - https://doi.org/10.1007/s10791-020-09381-1
TI  - A comparison of automatic Boolean query formulation for systematic reviews
AB  - No Abstract Found
PY  - 2021
DA  - 2021-02-01
JO  - {'id': 'https://openalex.org/S79460864', 'issn_l': '1386-4564', 'issn': ['1386-4564', '1573-7659'], 'display_name': 'Information Retrieval', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Harrisen Scells
AU  - Guido Zuccon
AU  - Bevan Koopman
ER  - 

507.
TY  - journal-article
ID  - https://openalex.org/W3165135368
DO  - https://doi.org/10.1186/s13643-021-01700-x
TI  - Text mining to support abstract screening for knowledge syntheses: a semi-automated workflow
AB  - Abstract Background Current text mining tools supporting abstract screening in systematic reviews are not widely used, in part because they lack sensitivity and precision. We set out to develop an accessible, semi-automated “workflow” to conduct abstract screening for systematic reviews and other knowledge synthesis methods. Methods We adopt widely recommended text-mining and machine-learning methods to (1) process title-abstracts into numerical training data; and (2) train a classification model to predict eligible abstracts. The predicted abstracts are screened by human reviewers for (“true”) eligibility, and the newly eligible abstracts are used to identify similar abstracts, using near-neighbor methods, which are also screened. These abstracts, as well as their eligibility results, are used to update the classification model, and the above steps are iterated until no new eligible abstracts are identified. The workflow was implemented in R and evaluated using a systematic review of insulin formulations for type-1 diabetes (14,314 abstracts) and a scoping review of knowledge-synthesis methods (17,200 abstracts). Workflow performance was evaluated against the recommended practice of screening abstracts by 2 reviewers, independently. Standard measures were examined: sensitivity (inclusion of all truly eligible abstracts), specificity (exclusion of all truly ineligible abstracts), precision (inclusion of all truly eligible abstracts among all abstracts screened as eligible), F1-score (harmonic average of sensitivity and precision), and accuracy (correctly predicted eligible or ineligible abstracts). Workload reduction was measured as the hours the workflow saved, given only a subset of abstracts needed human screening. Results With respect to the systematic and scoping reviews respectively, the workflow attained 88%/89% sensitivity, 99%/99% specificity, 71%/72% precision, an F1-score of 79%/79%, 98%/97% accuracy, 63%/55% workload reduction, with 12%/11% fewer abstracts for full-text retrieval and screening, and 0%/1.5% missed studies in the completed reviews. Conclusion The workflow was a sensitive, precise, and efficient alternative to the recommended practice of screening abstracts with 2 reviewers. All eligible studies were identified in the first case, while 6 studies (1.5%) were missed in the second that would likely not impact the review’s conclusions. We have described the workflow in language accessible to reviewers with limited exposure to natural language processing and machine learning, and have made the code available to reviewers. hazard identification studies published in the assessments and eliminated the need to manually screen more than 75% of search results on average. Limitations The chemical-independent approach used to build the training literature set provides a broad and unbiased picture across a variety of endpoints and environmental exposures but does not systematically identify all available data. Variance between actual and predicted relevant studies will be greater because of the external and non-random origin of seed study selection. This approach depends on access to readily available generic training data that can be used to locate relevant references in an unclassified corpus. Impact A generic approach to identifying human health relevant studies could be an important first step in literature evaluation for risk assessments. This initial scoping approach could facilitate faster literature evaluation by focusing reviewer efforts, as well as potentially minimize reviewer bias in selection of key studies. Using externally-derived training data has applicability particularly for databases with very low search precision where identifying training data may be cost-prohibitive. certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2021
DA  - 2021-05-26
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://systematicreviewsjournal.biomedcentral.com/counter/pdf/10.1186/s13643-021-01700-x', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Ba' Pham
AU  - Jelena Jovanovic
AU  - Ebrahim Bagheri
AU  - Jesmin Antony
AU  - Huda M. Ashoor
AU  - Tam V. Nguyen
AU  - Patricia Rios
AU  - Reid Robson
AU  - Sonia M. Thomas
AU  - Jennifer Watt
AU  - Sharon E. Straus
AU  - Andrea C. Tricco
ER  - 

508.
TY  - journal-article
ID  - https://openalex.org/W3016641399
DO  - https://doi.org/10.1108/ijmpb-01-2020-0002
TI  - Evolution of project management studies in the XXI century
AB  - Purpose The objectives of the study were to demonstrate the suitability of methodology based on a text mining toolset for detecting trends in scientific papers and to find trends that were present in the field of project management during the research time span (2000–2019). Design/methodology/approach An approach based on text mining tools supported by expert analysis was adopted due to an extensive number of publications in the field of project management. The novelty of the approach lies in the proposed method of trends discovery instead of the commonly used trends predefinition. The use of computer support allowed the full texts of papers, and not only abstracts, to be analysed, which significantly increased the reliability of the achieved results. Overall, 3,544 papers from seven journals were analysed. Findings As a result, 43 trends were discovered including seven long-lasting, four declining, 17 emerging and 15 ephemeris trends. Trends were analysed in comparison with the results of previous studies and project management frameworks. New trends and potential gaps were discussed. Originality/value The results highlight the topics of research that gain popularity among researchers, and which are related to the current problems that arise in project management. Therefore, the results can help focus studies on the most important areas, as well as find new ones which are not so popular yet. The knowledge of current trends is also important for those project managers who seek to improve the efficiency of their work. Results With respect to the systematic and scoping reviews respectively, the workflow attained 88%/89% sensitivity, 99%/99% specificity, 71%/72% precision, an F1-score of 79%/79%, 98%/97% accuracy, 63%/55% workload reduction, with 12%/11% fewer abstracts for full-text retrieval and screening, and 0%/1.5% missed studies in the completed reviews. Conclusion The workflow was a sensitive, precise, and efficient alternative to the recommended practice of screening abstracts with 2 reviewers. All eligible studies were identified in the first case, while 6 studies (1.5%) were missed in the second that would likely not impact the review’s conclusions. We have described the workflow in language accessible to reviewers with limited exposure to natural language processing and machine learning, and have made the code available to reviewers. hazard identification studies published in the assessments and eliminated the need to manually screen more than 75% of search results on average. Limitations The chemical-independent approach used to build the training literature set provides a broad and unbiased picture across a variety of endpoints and environmental exposures but does not systematically identify all available data. Variance between actual and predicted relevant studies will be greater because of the external and non-random origin of seed study selection. This approach depends on access to readily available generic training data that can be used to locate relevant references in an unclassified corpus. Impact A generic approach to identifying human health relevant studies could be an important first step in literature evaluation for risk assessments. This initial scoping approach could facilitate faster literature evaluation by focusing reviewer efforts, as well as potentially minimize reviewer bias in selection of key studies. Using externally-derived training data has applicability particularly for databases with very low search precision where identifying training data may be cost-prohibitive. certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2020
DA  - 2020-04-10
JO  - {'id': 'https://openalex.org/S81125728', 'issn_l': '1753-8378', 'issn': ['1753-8386', '1753-8378'], 'display_name': 'International Journal of Managing Projects in Business', 'publisher': 'Emerald Publishing Limited', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Sławomir Wawak
AU  - Krzysztof Woźniak
ER  - 

509.
TY  - journal-article
ID  - https://openalex.org/W3017880416
DO  - https://doi.org/10.1093/jamia/ocaa035
TI  - Is it time for computable evidence synthesis?
AB  - Abstract Efforts aimed at increasing the pace of evidence synthesis have been primarily focused on the use of published articles, but these are a relatively delayed, incomplete, and at times biased source of study results data. Compared to those in bibliographic databases, structured results data available in trial registries may be more timely, complete, and accessible, but these data remain underutilized. Key advantages of using structured results data include the potential to automatically monitor the accumulation of relevant evidence and use it to signal when a systematic review requires updating, as well as to prospectively assign trials to already published reviews. Shifting focus to emerging sources of structured trial data may provide the impetus to build a more proactive and efficient system of continuous evidence surveillance. Findings As a result, 43 trends were discovered including seven long-lasting, four declining, 17 emerging and 15 ephemeris trends. Trends were analysed in comparison with the results of previous studies and project management frameworks. New trends and potential gaps were discussed. Originality/value The results highlight the topics of research that gain popularity among researchers, and which are related to the current problems that arise in project management. Therefore, the results can help focus studies on the most important areas, as well as find new ones which are not so popular yet. The knowledge of current trends is also important for those project managers who seek to improve the efficiency of their work. Results With respect to the systematic and scoping reviews respectively, the workflow attained 88%/89% sensitivity, 99%/99% specificity, 71%/72% precision, an F1-score of 79%/79%, 98%/97% accuracy, 63%/55% workload reduction, with 12%/11% fewer abstracts for full-text retrieval and screening, and 0%/1.5% missed studies in the completed reviews. Conclusion The workflow was a sensitive, precise, and efficient alternative to the recommended practice of screening abstracts with 2 reviewers. All eligible studies were identified in the first case, while 6 studies (1.5%) were missed in the second that would likely not impact the review’s conclusions. We have described the workflow in language accessible to reviewers with limited exposure to natural language processing and machine learning, and have made the code available to reviewers. hazard identification studies published in the assessments and eliminated the need to manually screen more than 75% of search results on average. Limitations The chemical-independent approach used to build the training literature set provides a broad and unbiased picture across a variety of endpoints and environmental exposures but does not systematically identify all available data. Variance between actual and predicted relevant studies will be greater because of the external and non-random origin of seed study selection. This approach depends on access to readily available generic training data that can be used to locate relevant references in an unclassified corpus. Impact A generic approach to identifying human health relevant studies could be an important first step in literature evaluation for risk assessments. This initial scoping approach could facilitate faster literature evaluation by focusing reviewer efforts, as well as potentially minimize reviewer bias in selection of key studies. Using externally-derived training data has applicability particularly for databases with very low search precision where identifying training data may be cost-prohibitive. certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2020
DA  - 2020-06-01
JO  - {'id': 'https://openalex.org/S129839026', 'issn_l': '1067-5027', 'issn': ['1067-5027', '1527-974X'], 'display_name': 'Journal of the American Medical Informatics Association', 'publisher': 'Oxford University Press', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Adam G. Dunn
AU  - Florence T. Bourgeois
ER  - 

510.
TY  - journal-article
ID  - https://openalex.org/W3034100208
DO  - https://doi.org/10.1007/s11192-020-03490-w
TI  - Constructing and evaluating automated literature review systems
AB  - No Abstract Found
PY  - 2020
DA  - 2020-12-01
JO  - {'id': 'https://openalex.org/S148561398', 'issn_l': '0138-9130', 'issn': ['1588-2861', '0138-9130'], 'display_name': 'Scientometrics', 'publisher': 'Springer Nature (Netherlands)', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Jason Portenoy
AU  - Jevin D. West
ER  - 

511.
TY  - journal-article
ID  - https://openalex.org/W3139443298
DO  - https://doi.org/10.1016/j.jclinepi.2021.03.013
TI  - A prospective comparison of evidence synthesis search strategies developed with and without text-mining tools
AB  - We compared the process of developing searches with and without using text-mining tools (TMTs) for evidence synthesis products.This descriptive comparative analysis included seven systematic reviews, classified as simple or complex. Two librarians created MEDLINE strategies for each review, using either usual practice (UP) or TMTs. For each search we calculated sensitivity, number-needed-to-read (NNR) and time spent developing the search strategy.We found UP searches were more sensitive (UP 92% (95% CI, 85-99); TMT 84.9% (95% CI, 74.4-95.4)), with lower NNR (UP 83 (SD 34); TMT 90 (SD 68)). UP librarians spent an average of 12 h (SD 8) developing search strategies, compared to TMT librarians' 5 hours (SD 2).Across all reviews, TMT searches were less sensitive than UP searches, but confidence intervals overlapped. For simple SR topics, TMT searches were faster and slightly less sensitive than UP. For complex SR topics, TMT searches were faster and less sensitive than UP searches but identified unique eligible citations not found by the UP searches. trends and potential gaps were discussed. Originality/value The results highlight the topics of research that gain popularity among researchers, and which are related to the current problems that arise in project management. Therefore, the results can help focus studies on the most important areas, as well as find new ones which are not so popular yet. The knowledge of current trends is also important for those project managers who seek to improve the efficiency of their work. Results With respect to the systematic and scoping reviews respectively, the workflow attained 88%/89% sensitivity, 99%/99% specificity, 71%/72% precision, an F1-score of 79%/79%, 98%/97% accuracy, 63%/55% workload reduction, with 12%/11% fewer abstracts for full-text retrieval and screening, and 0%/1.5% missed studies in the completed reviews. Conclusion The workflow was a sensitive, precise, and efficient alternative to the recommended practice of screening abstracts with 2 reviewers. All eligible studies were identified in the first case, while 6 studies (1.5%) were missed in the second that would likely not impact the review’s conclusions. We have described the workflow in language accessible to reviewers with limited exposure to natural language processing and machine learning, and have made the code available to reviewers. hazard identification studies published in the assessments and eliminated the need to manually screen more than 75% of search results on average. Limitations The chemical-independent approach used to build the training literature set provides a broad and unbiased picture across a variety of endpoints and environmental exposures but does not systematically identify all available data. Variance between actual and predicted relevant studies will be greater because of the external and non-random origin of seed study selection. This approach depends on access to readily available generic training data that can be used to locate relevant references in an unclassified corpus. Impact A generic approach to identifying human health relevant studies could be an important first step in literature evaluation for risk assessments. This initial scoping approach could facilitate faster literature evaluation by focusing reviewer efforts, as well as potentially minimize reviewer bias in selection of key studies. Using externally-derived training data has applicability particularly for databases with very low search precision where identifying training data may be cost-prohibitive. certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2021
DA  - 2021-03-20
JO  - {'id': 'https://openalex.org/S64418186', 'issn_l': '0895-4356', 'issn': ['1878-5921', '0895-4356'], 'display_name': 'Journal of Clinical Epidemiology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'http://www.jclinepi.com/article/S0895435621000858/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Robin Paynter
AU  - Robin Featherstone
AU  - Elizabeth Stoeger
AU  - Celia Fiordalisi
AU  - Christiane Voisin
AU  - Gaelen P Adam
ER  - 

512.
TY  - journal-article
ID  - https://openalex.org/W2983931015
DO  - https://doi.org/10.1093/database/baz109
TI  - Evaluation of an automatic article selection method for timelier updates of the Comet Core Outcome Set database
AB  - Abstract Curated databases of scientific literature play an important role in helping researchers find relevant literature, but populating such databases is a labour intensive and time-consuming process. One such database is the freely accessible Comet Core Outcome Set database, which was originally populated using manual screening in an annually updated systematic review. In order to reduce the workload and facilitate more timely updates we are evaluating machine learning methods to reduce the number of references needed to screen. In this study we have evaluated a machine learning approach based on logistic regression to automatically rank the candidate articles. Data from the original systematic review and its four first review updates were used to train the model and evaluate performance. We estimated that using automatic screening would yield a workload reduction of at least 75% while keeping the number of missed references around 2%. We judged this to be an acceptable trade-off for this systematic review, and the method is now being used for the next round of the Comet database update. the topics of research that gain popularity among researchers, and which are related to the current problems that arise in project management. Therefore, the results can help focus studies on the most important areas, as well as find new ones which are not so popular yet. The knowledge of current trends is also important for those project managers who seek to improve the efficiency of their work. Results With respect to the systematic and scoping reviews respectively, the workflow attained 88%/89% sensitivity, 99%/99% specificity, 71%/72% precision, an F1-score of 79%/79%, 98%/97% accuracy, 63%/55% workload reduction, with 12%/11% fewer abstracts for full-text retrieval and screening, and 0%/1.5% missed studies in the completed reviews. Conclusion The workflow was a sensitive, precise, and efficient alternative to the recommended practice of screening abstracts with 2 reviewers. All eligible studies were identified in the first case, while 6 studies (1.5%) were missed in the second that would likely not impact the review’s conclusions. We have described the workflow in language accessible to reviewers with limited exposure to natural language processing and machine learning, and have made the code available to reviewers. hazard identification studies published in the assessments and eliminated the need to manually screen more than 75% of search results on average. Limitations The chemical-independent approach used to build the training literature set provides a broad and unbiased picture across a variety of endpoints and environmental exposures but does not systematically identify all available data. Variance between actual and predicted relevant studies will be greater because of the external and non-random origin of seed study selection. This approach depends on access to readily available generic training data that can be used to locate relevant references in an unclassified corpus. Impact A generic approach to identifying human health relevant studies could be an important first step in literature evaluation for risk assessments. This initial scoping approach could facilitate faster literature evaluation by focusing reviewer efforts, as well as potentially minimize reviewer bias in selection of key studies. Using externally-derived training data has applicability particularly for databases with very low search precision where identifying training data may be cost-prohibitive. certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2019
DA  - 2019-01-01
JO  - {'id': 'https://openalex.org/S4210201630', 'issn_l': '1758-0463', 'issn': ['1758-0463'], 'display_name': 'Database', 'publisher': 'University of Oxford', 'type': 'journal', 'url': 'https://academic.oup.com/database/article-pdf/doi/10.1093/database/baz109/30457495/baz109.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Christopher R. Norman
AU  - Elizabeth Gargon
AU  - Mariska M.G. Leeflang
AU  - Aurélie Névéol
AU  - Paula R Williamson
ER  - 

513.
TY  - journal-article
ID  - https://openalex.org/W3093173351
DO  - https://doi.org/10.1186/s13643-020-01450-2
TI  - Comparison of a traditional systematic review approach with review-of-reviews and semi-automation as strategies to update the evidence
AB  - Abstract Background The exponential growth of the biomedical literature necessitates investigating strategies to reduce systematic reviewer burden while maintaining the high standards of systematic review validity and comprehensiveness. Methods We compared the traditional systematic review screening process with (1) a review-of-reviews (ROR) screening approach and (2) a semi-automation screening approach using two publicly available tools (RobotAnalyst and AbstrackR) and different types of training sets (randomly selected citations subjected to dual-review at the title-abstract stage, highly curated citations dually reviewed at the full-text stage, and a combination of the two). We evaluated performance measures of sensitivity, specificity, missed citations, and workload burden Results The ROR approach for treatments of early-stage prostate cancer had a poor sensitivity (0.54) and studies missed by the ROR approach tended to be of head-to-head comparisons of active treatments, observational studies, and outcomes of physical harms and quality of life. Title and abstract screening incorporating semi-automation only resulted in a sensitivity of 100% at high levels of reviewer burden (review of 99% of citations). A highly curated, smaller-sized, training set ( n = 125) performed similarly to a larger training set of random citations ( n = 938). Conclusion Two approaches to rapidly update SRs—review-of-reviews and semi-automation—failed to demonstrate reduced workload burden while maintaining an acceptable level of sensitivity. We suggest careful evaluation of the ROR approach through comparison of inclusion criteria and targeted searches to fill evidence gaps as well as further research of semi-automation use, including more study of highly curated training sets. the workflow attained 88%/89% sensitivity, 99%/99% specificity, 71%/72% precision, an F1-score of 79%/79%, 98%/97% accuracy, 63%/55% workload reduction, with 12%/11% fewer abstracts for full-text retrieval and screening, and 0%/1.5% missed studies in the completed reviews. Conclusion The workflow was a sensitive, precise, and efficient alternative to the recommended practice of screening abstracts with 2 reviewers. All eligible studies were identified in the first case, while 6 studies (1.5%) were missed in the second that would likely not impact the review’s conclusions. We have described the workflow in language accessible to reviewers with limited exposure to natural language processing and machine learning, and have made the code available to reviewers. hazard identification studies published in the assessments and eliminated the need to manually screen more than 75% of search results on average. Limitations The chemical-independent approach used to build the training literature set provides a broad and unbiased picture across a variety of endpoints and environmental exposures but does not systematically identify all available data. Variance between actual and predicted relevant studies will be greater because of the external and non-random origin of seed study selection. This approach depends on access to readily available generic training data that can be used to locate relevant references in an unclassified corpus. Impact A generic approach to identifying human health relevant studies could be an important first step in literature evaluation for risk assessments. This initial scoping approach could facilitate faster literature evaluation by focusing reviewer efforts, as well as potentially minimize reviewer bias in selection of key studies. Using externally-derived training data has applicability particularly for databases with very low search precision where identifying training data may be cost-prohibitive. certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2020
DA  - 2020-10-19
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://systematicreviewsjournal.biomedcentral.com/track/pdf/10.1186/s13643-020-01450-2', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Shivani M. Reddy
AU  - Sheila K Patel
AU  - Meghan S Weyrich
AU  - Joshua J. Fenton
AU  - Meera Viswanathan
ER  - 

514.
TY  - journal-article
ID  - https://openalex.org/W3098697762
DO  - https://doi.org/10.1016/j.actbio.2020.11.011
TI  - Osseointegration Pharmacology: A Systematic Mapping Using Artificial Intelligence
AB  - Clinical performance of osseointegrated implants could be compromised by the medications taken by patients. The effect of a specific medication on osseointegration can be easily investigated using traditional systematic reviews. However, assessment of all known medications requires the use of evidence mapping methods. These methods allow assessment of complex questions, but they are very resource intensive when done manually. The objective of this study was to develop a machine learning algorithm to automatically map the literature assessing the effect of medications on osseointegration. Datasets of articles classified manually were used to train a machine-learning algorithm based on Support Vector Machines. The algorithm was then validated and used to screen 599,604 articles identified with an extremely sensitive search strategy. The algorithm included 281 relevant articles that described the effect of 31 different drugs on osseointegration. This approach achieved an accuracy of 95%, and compared to manual screening, it reduced the workload by 93%. The systematic mapping revealed that the treatment outcomes of osseointegrated medical devices could be influenced by drugs affecting homeostasis, inflammation, cell proliferation and bone remodeling. The effect of all known medications on the performance of osseointegrated medical devices can be assessed using evidence mappings executed with highly accurate machine learning algorithms. workload burden while maintaining an acceptable level of sensitivity. We suggest careful evaluation of the ROR approach through comparison of inclusion criteria and targeted searches to fill evidence gaps as well as further research of semi-automation use, including more study of highly curated training sets. the workflow attained 88%/89% sensitivity, 99%/99% specificity, 71%/72% precision, an F1-score of 79%/79%, 98%/97% accuracy, 63%/55% workload reduction, with 12%/11% fewer abstracts for full-text retrieval and screening, and 0%/1.5% missed studies in the completed reviews. Conclusion The workflow was a sensitive, precise, and efficient alternative to the recommended practice of screening abstracts with 2 reviewers. All eligible studies were identified in the first case, while 6 studies (1.5%) were missed in the second that would likely not impact the review’s conclusions. We have described the workflow in language accessible to reviewers with limited exposure to natural language processing and machine learning, and have made the code available to reviewers. hazard identification studies published in the assessments and eliminated the need to manually screen more than 75% of search results on average. Limitations The chemical-independent approach used to build the training literature set provides a broad and unbiased picture across a variety of endpoints and environmental exposures but does not systematically identify all available data. Variance between actual and predicted relevant studies will be greater because of the external and non-random origin of seed study selection. This approach depends on access to readily available generic training data that can be used to locate relevant references in an unclassified corpus. Impact A generic approach to identifying human health relevant studies could be an important first step in literature evaluation for risk assessments. This initial scoping approach could facilitate faster literature evaluation by focusing reviewer efforts, as well as potentially minimize reviewer bias in selection of key studies. Using externally-derived training data has applicability particularly for databases with very low search precision where identifying training data may be cost-prohibitive. certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2021
DA  - 2021-01-01
JO  - {'id': 'https://openalex.org/S173145877', 'issn_l': '1742-7061', 'issn': ['1742-7061', '1878-7568'], 'display_name': 'Acta Biomaterialia', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Mohammed Mahri
AU  - Nicole Shen
AU  - Francisco Berrizbeitia
AU  - Rania Rodan
AU  - Ammar Daer
AU  - Matthew Faigan
AU  - Doaa Taqi
AU  - Kevin C.-W. Wu
AU  - Motahareh Ahmadi
AU  - Maxime Ducret
AU  - Elham Emami
AU  - Faleh Tamimi
ER  - 

515.
TY  - journal-article
ID  - https://openalex.org/W3133622905
DO  - https://doi.org/10.1016/j.jbi.2021.103717
TI  - Toward assessing clinical trial publications for reporting transparency
AB  - To annotate a corpus of randomized controlled trial (RCT) publications with the checklist items of CONSORT reporting guidelines and using the corpus to develop text mining methods for RCT appraisal.We annotated a corpus of 50 RCT articles at the sentence level using 37 fine-grained CONSORT checklist items. A subset (31 articles) was double-annotated and adjudicated, while 19 were annotated by a single annotator and reconciled by another. We calculated inter-annotator agreement at the article and section level using MASI (Measuring Agreement on Set-Valued Items) and at the CONSORT item level using Krippendorff's α. We experimented with two rule-based methods (phrase-based and section header-based) and two supervised learning approaches (support vector machine and BioBERT-based neural network classifiers), for recognizing 17 methodology-related items in the RCT Methods sections.We created CONSORT-TM consisting of 10,709 sentences, 4,845 (45%) of which were annotated with 5,246 labels. A median of 28 CONSORT items (out of possible 37) were annotated per article. Agreement was moderate at the article and section levels (average MASI: 0.60 and 0.64, respectively). Agreement varied considerably among individual checklist items (Krippendorff's α= 0.06-0.96). The model based on BioBERT performed best overall for recognizing methodology-related items (micro-precision: 0.82, micro-recall: 0.63, micro-F1: 0.71). Combining models using majority vote and label aggregation further improved precision and recall, respectively.Our annotated corpus, CONSORT-TM, contains more fine-grained information than earlier RCT corpora. Low frequency of some CONSORT items made it difficult to train effective text mining models to recognize them. For the items commonly reported, CONSORT-TM can serve as a testbed for text mining methods that assess RCT transparency, rigor, and reliability, and support methods for peer review and authoring assistance. Minor modifications to the annotation scheme and a larger corpus could facilitate improved text mining models. CONSORT-TM is publicly available at https://github.com/kilicogluh/CONSORT-TM. the recommended practice of screening abstracts with 2 reviewers. All eligible studies were identified in the first case, while 6 studies (1.5%) were missed in the second that would likely not impact the review’s conclusions. We have described the workflow in language accessible to reviewers with limited exposure to natural language processing and machine learning, and have made the code available to reviewers. hazard identification studies published in the assessments and eliminated the need to manually screen more than 75% of search results on average. Limitations The chemical-independent approach used to build the training literature set provides a broad and unbiased picture across a variety of endpoints and environmental exposures but does not systematically identify all available data. Variance between actual and predicted relevant studies will be greater because of the external and non-random origin of seed study selection. This approach depends on access to readily available generic training data that can be used to locate relevant references in an unclassified corpus. Impact A generic approach to identifying human health relevant studies could be an important first step in literature evaluation for risk assessments. This initial scoping approach could facilitate faster literature evaluation by focusing reviewer efforts, as well as potentially minimize reviewer bias in selection of key studies. Using externally-derived training data has applicability particularly for databases with very low search precision where identifying training data may be cost-prohibitive. certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2021
DA  - 2021-04-01
JO  - {'id': 'https://openalex.org/S11622463', 'issn_l': '1532-0464', 'issn': ['1532-0480', '1532-0464'], 'display_name': 'Journal of Biomedical Informatics', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'https://doi.org/10.1016/j.jbi.2021.103717', 'is_oa': True, 'version': 'publishedVersion', 'license': 'elsevier-specific'}
DP  - OpenAlex
AU  - Halil Kilicoglu
AU  - Graciela Rosemblat
AU  - Linh Cao Hoang
AU  - Sahil Wadhwa
AU  - Zeshan Peng
AU  - Mario Malički
AU  - Jodi Schneider
AU  - Gerben ter Riet
ER  - 

516.
TY  - book-chapter
ID  - https://openalex.org/W2619638947
DO  - https://doi.org/10.1016/b978-0-12-809633-8.12372-6
TI  - Text Mining Applications
AB  - Text mining applications can help navigate large quantities of text within a range of different biomedical settings, including hospitals, academic laboratories, government safety and regulatory agencies, and pharmaceutical research and development. The development of text mining applications, however, is highly dependent on the availability of sources of textual content and the capabilities of current text mining algorithms. The performance of such algorithms can be highly variable depending on the tasks that need to be addressed. Within such constraints, text mining applications can be deployed for diverse purposes, such as semi-automated curation of biological databases, pharmacovigilance, biomarker discovery, construction of signaling pathways and prediction of protein function and similarity amongst others. As the availability of and need for analyzing large sources of text grows in biomedicine, text mining applications will occupy an increasingly more important role. which were annotated with 5,246 labels. A median of 28 CONSORT items (out of possible 37) were annotated per article. Agreement was moderate at the article and section levels (average MASI: 0.60 and 0.64, respectively). Agreement varied considerably among individual checklist items (Krippendorff's α= 0.06-0.96). The model based on BioBERT performed best overall for recognizing methodology-related items (micro-precision: 0.82, micro-recall: 0.63, micro-F1: 0.71). Combining models using majority vote and label aggregation further improved precision and recall, respectively.Our annotated corpus, CONSORT-TM, contains more fine-grained information than earlier RCT corpora. Low frequency of some CONSORT items made it difficult to train effective text mining models to recognize them. For the items commonly reported, CONSORT-TM can serve as a testbed for text mining methods that assess RCT transparency, rigor, and reliability, and support methods for peer review and authoring assistance. Minor modifications to the annotation scheme and a larger corpus could facilitate improved text mining models. CONSORT-TM is publicly available at https://github.com/kilicogluh/CONSORT-TM. the recommended practice of screening abstracts with 2 reviewers. All eligible studies were identified in the first case, while 6 studies (1.5%) were missed in the second that would likely not impact the review’s conclusions. We have described the workflow in language accessible to reviewers with limited exposure to natural language processing and machine learning, and have made the code available to reviewers. hazard identification studies published in the assessments and eliminated the need to manually screen more than 75% of search results on average. Limitations The chemical-independent approach used to build the training literature set provides a broad and unbiased picture across a variety of endpoints and environmental exposures but does not systematically identify all available data. Variance between actual and predicted relevant studies will be greater because of the external and non-random origin of seed study selection. This approach depends on access to readily available generic training data that can be used to locate relevant references in an unclassified corpus. Impact A generic approach to identifying human health relevant studies could be an important first step in literature evaluation for risk assessments. This initial scoping approach could facilitate faster literature evaluation by focusing reviewer efforts, as well as potentially minimize reviewer bias in selection of key studies. Using externally-derived training data has applicability particularly for databases with very low search precision where identifying training data may be cost-prohibitive. certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2016
DA  - 2016-01-01
JO  - {'id': 'https://openalex.org/V4306463230', 'issn_l': None, 'issn': None, 'display_name': 'Elsevier eBooks', 'publisher': 'Elsevier BV', 'type': 'ebook platform', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Raul Rodriguez-Esteban
ER  - 

517.
TY  - journal-article
ID  - https://openalex.org/W2910177331
DO  - https://doi.org/10.1007/s10669-019-09717-3
TI  - Active learning in automated text classification: a case study exploring bias in predicted model performance metrics
AB  - Machine learning has emerged as a cost-effective innovation to support systematic literature reviews in human health risk assessments and other contexts. Supervised machine learning approaches rely on a training dataset, a relatively small set of documents with human-annotated labels indicating their topic, to build models that automatically classify a larger set of unclassified documents. “Active” machine learning has been proposed as an approach that limits the cost of creating a training dataset by interactively and sequentially focussing on training only the most informative documents. We simulate active learning using a dataset of approximately 7000 abstracts from the scientific literature related to the chemical arsenic. The dataset was previously annotated by subject matter experts with regard to relevance to two topics relating to toxicology and risk assessment. We examine the performance of alternative sampling approaches to sequentially expanding the training dataset, specifically looking at uncertainty-based sampling and probability-based sampling. We discover that while such active learning methods can potentially reduce training dataset size compared to random sampling, predictions of model performance in active learning are likely to suffer from statistical bias that negates the method’s potential benefits. We discuss approaches and the extent to which the bias resulting from skewed sampling can be compensated. We propose a useful role for active learning in contexts in which the accuracy of model performance metrics is not critical and/or where it is beneficial to rapidly create a class-balanced training dataset. mining models to recognize them. For the items commonly reported, CONSORT-TM can serve as a testbed for text mining methods that assess RCT transparency, rigor, and reliability, and support methods for peer review and authoring assistance. Minor modifications to the annotation scheme and a larger corpus could facilitate improved text mining models. CONSORT-TM is publicly available at https://github.com/kilicogluh/CONSORT-TM. the recommended practice of screening abstracts with 2 reviewers. All eligible studies were identified in the first case, while 6 studies (1.5%) were missed in the second that would likely not impact the review’s conclusions. We have described the workflow in language accessible to reviewers with limited exposure to natural language processing and machine learning, and have made the code available to reviewers. hazard identification studies published in the assessments and eliminated the need to manually screen more than 75% of search results on average. Limitations The chemical-independent approach used to build the training literature set provides a broad and unbiased picture across a variety of endpoints and environmental exposures but does not systematically identify all available data. Variance between actual and predicted relevant studies will be greater because of the external and non-random origin of seed study selection. This approach depends on access to readily available generic training data that can be used to locate relevant references in an unclassified corpus. Impact A generic approach to identifying human health relevant studies could be an important first step in literature evaluation for risk assessments. This initial scoping approach could facilitate faster literature evaluation by focusing reviewer efforts, as well as potentially minimize reviewer bias in selection of key studies. Using externally-derived training data has applicability particularly for databases with very low search precision where identifying training data may be cost-prohibitive. certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2019
DA  - 2019-09-01
JO  - {'id': 'https://openalex.org/S2764812402', 'issn_l': '2194-5411', 'issn': ['2194-5403', '2194-5411'], 'display_name': 'Environment Systems and Decisions', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Arun Varghese
AU  - Tao Hong
AU  - C. R. Hunter
AU  - George Agyeman-Badu
AU  - Michelle Cawley
ER  - 

518.
TY  - journal-article
ID  - https://openalex.org/W2981527585
DO  - https://doi.org/10.1186/s13643-019-1162-x
TI  - Measuring the impact of screening automation on meta-analyses of diagnostic test accuracy
AB  - Abstract Background The large and increasing number of new studies published each year is making literature identification in systematic reviews ever more time-consuming and costly. Technological assistance has been suggested as an alternative to the conventional, manual study identification to mitigate the cost, but previous literature has mainly evaluated methods in terms of recall (search sensitivity) and workload reduction. There is a need to also evaluate whether screening prioritization methods leads to the same results and conclusions as exhaustive manual screening. In this study, we examined the impact of one screening prioritization method based on active learning on sensitivity and specificity estimates in systematic reviews of diagnostic test accuracy. Methods We simulated the screening process in 48 Cochrane reviews of diagnostic test accuracy and re-run 400 meta-analyses based on a least 3 studies. We compared screening prioritization (with technological assistance) and screening in randomized order (standard practice without technology assistance). We examined if the screening could have been stopped before identifying all relevant studies while still producing reliable summary estimates. For all meta-analyses, we also examined the relationship between the number of relevant studies and the reliability of the final estimates. Results The main meta-analysis in each systematic review could have been performed after screening an average of 30% of the candidate articles (range 0.07 to 100%). No systematic review would have required screening more than 2308 studies, whereas manual screening would have required screening up to 43,363 studies. Despite an average 70% recall, the estimation error would have been 1.3% on average, compared to an average 2% estimation error expected when replicating summary estimate calculations. Conclusion Screening prioritization coupled with stopping criteria in diagnostic test accuracy reviews can reliably detect when the screening process has identified a sufficient number of studies to perform the main meta-analysis with an accuracy within pre-specified tolerance limits. However, many of the systematic reviews did not identify a sufficient number of studies that the meta-analyses were accurate within a 2% limit even with exhaustive manual screening, i.e., using current practice. accessible to reviewers with limited exposure to natural language processing and machine learning, and have made the code available to reviewers. hazard identification studies published in the assessments and eliminated the need to manually screen more than 75% of search results on average. Limitations The chemical-independent approach used to build the training literature set provides a broad and unbiased picture across a variety of endpoints and environmental exposures but does not systematically identify all available data. Variance between actual and predicted relevant studies will be greater because of the external and non-random origin of seed study selection. This approach depends on access to readily available generic training data that can be used to locate relevant references in an unclassified corpus. Impact A generic approach to identifying human health relevant studies could be an important first step in literature evaluation for risk assessments. This initial scoping approach could facilitate faster literature evaluation by focusing reviewer efforts, as well as potentially minimize reviewer bias in selection of key studies. Using externally-derived training data has applicability particularly for databases with very low search precision where identifying training data may be cost-prohibitive. certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2019
DA  - 2019-10-28
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://doi.org/10.1186/s13643-019-1162-x', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Christopher R. Norman
AU  - Mariska M.G. Leeflang
AU  - Raphaël Porcher
AU  - Aurélie Névéol
ER  - 

519.
TY  - journal-article
ID  - https://openalex.org/W2989786801
DO  - https://doi.org/10.1007/s10531-019-01913-6
TI  - Bioregionalization approaches for conservation: methods, biases, and their implications for Australian biodiversity
AB  - Biogeographic classification schemes have been developed to prioritize biodiversity conservation efforts at large scales, but their efficacy remains understudied. Here we develop a systematic map of the literature on bioregional planning, based on a case study of the Interim Biogeographic Regionalization for Australia (IBRA), to identify where and how such schemes have been used in scientific research. We identified 67 relevant studies, finding that the majority investigated biodiversity exclusively within a single bioregion (65.7%), with 18 of these studies splitting the targeted bioregion based on administrative boundaries. Most used inferential techniques (74.6%) or pattern-based measures (68.7%), and few studies (9%) both considered biodiversity across multiple bioregions and compared findings between bioregions. Species were investigated ten times more frequently than ecosystems attributes, with mammals and birds monopolizing scientists’ attention. These findings show that our knowledge of biodiversity at bioregional scales is patchy, even for well-studied taxa, and that we have a limited understanding of the synthetic relationship between biodiversity and IBRA bioregions (which are demarcated according to other biophysical factors). This creates a barrier for systematic conservation planning, which requires unbiased information on the spatial attributes of biodiversity, and therefore this knowledge deficit warrants more attention. in each systematic review could have been performed after screening an average of 30% of the candidate articles (range 0.07 to 100%). No systematic review would have required screening more than 2308 studies, whereas manual screening would have required screening up to 43,363 studies. Despite an average 70% recall, the estimation error would have been 1.3% on average, compared to an average 2% estimation error expected when replicating summary estimate calculations. Conclusion Screening prioritization coupled with stopping criteria in diagnostic test accuracy reviews can reliably detect when the screening process has identified a sufficient number of studies to perform the main meta-analysis with an accuracy within pre-specified tolerance limits. However, many of the systematic reviews did not identify a sufficient number of studies that the meta-analyses were accurate within a 2% limit even with exhaustive manual screening, i.e., using current practice. accessible to reviewers with limited exposure to natural language processing and machine learning, and have made the code available to reviewers. hazard identification studies published in the assessments and eliminated the need to manually screen more than 75% of search results on average. Limitations The chemical-independent approach used to build the training literature set provides a broad and unbiased picture across a variety of endpoints and environmental exposures but does not systematically identify all available data. Variance between actual and predicted relevant studies will be greater because of the external and non-random origin of seed study selection. This approach depends on access to readily available generic training data that can be used to locate relevant references in an unclassified corpus. Impact A generic approach to identifying human health relevant studies could be an important first step in literature evaluation for risk assessments. This initial scoping approach could facilitate faster literature evaluation by focusing reviewer efforts, as well as potentially minimize reviewer bias in selection of key studies. Using externally-derived training data has applicability particularly for databases with very low search precision where identifying training data may be cost-prohibitive. certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2020
DA  - 2020-01-01
JO  - {'id': 'https://openalex.org/S5043789', 'issn_l': '0960-3115', 'issn': ['1572-9710', '0960-3115'], 'display_name': 'Biodiversity and Conservation', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Cristian S. Montalvo-Mancheno
AU  - Stefania Ondei
AU  - Barry W. Brook
AU  - Jessie C. Buettel
ER  - 

520.
TY  - journal-article
ID  - https://openalex.org/W2989936752
DO  - https://doi.org/10.1177/0894439319888455
TI  - Big Data and Digital Aesthetic, Arts, and Cultural Education: Hot Spots of Current Quantitative Research
AB  - Systematic reviews are the method of choice to synthesize research evidence. To identify main topics (so-called hot spots) relevant to large corpora of original publications in need of a synthesis, one must address the “three Vs” of big data (volume, velocity, and variety), especially in loosely defined or fragmented disciplines. For this purpose, text mining and predictive modeling are very helpful. Thus, we applied these methods to a compilation of documents related to digitalization in aesthetic, arts, and cultural education, as a prototypical, loosely defined, fragmented discipline, and particularly to quantitative research within it (QRD-ACE). By broadly querying the abstract and citation database Scopus with terms indicative of QRD-ACE, we identified a corpus of N = 55,553 publications for the years 2013–2017. As the result of an iterative approach of text mining, priority screening, and predictive modeling, we identified n = 8,304 potentially relevant publications of which n = 1,666 were included after priority screening. Analysis of the subject distribution of the included publications revealed video games as a first hot spot of QRD-ACE. Topic modeling resulted in aesthetics and cultural activities on social media as a second hot spot, related to 4 of k = 8 identified topics. This way, we were able to identify current hot spots of QRD-ACE by screening less than 15% of the corpus. We discuss implications for harnessing text mining, predictive modeling, and priority screening in future research syntheses and avenues for future original research on QRD-ACE. recall, the estimation error would have been 1.3% on average, compared to an average 2% estimation error expected when replicating summary estimate calculations. Conclusion Screening prioritization coupled with stopping criteria in diagnostic test accuracy reviews can reliably detect when the screening process has identified a sufficient number of studies to perform the main meta-analysis with an accuracy within pre-specified tolerance limits. However, many of the systematic reviews did not identify a sufficient number of studies that the meta-analyses were accurate within a 2% limit even with exhaustive manual screening, i.e., using current practice. accessible to reviewers with limited exposure to natural language processing and machine learning, and have made the code available to reviewers. hazard identification studies published in the assessments and eliminated the need to manually screen more than 75% of search results on average. Limitations The chemical-independent approach used to build the training literature set provides a broad and unbiased picture across a variety of endpoints and environmental exposures but does not systematically identify all available data. Variance between actual and predicted relevant studies will be greater because of the external and non-random origin of seed study selection. This approach depends on access to readily available generic training data that can be used to locate relevant references in an unclassified corpus. Impact A generic approach to identifying human health relevant studies could be an important first step in literature evaluation for risk assessments. This initial scoping approach could facilitate faster literature evaluation by focusing reviewer efforts, as well as potentially minimize reviewer bias in selection of key studies. Using externally-derived training data has applicability particularly for databases with very low search precision where identifying training data may be cost-prohibitive. certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2021
DA  - 2021-10-01
JO  - {'id': 'https://openalex.org/V127118166', 'issn_l': '0894-4393', 'issn': ['0894-4393', '1552-8286'], 'display_name': 'Social Science Computer Review', 'publisher': 'SAGE Publishing', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Alexander B. Christ
AU  - Marcus Penthin
AU  - Stephan Kröner
ER  - 

521.
TY  - journal-article
ID  - https://openalex.org/W2997794297
DO  - https://doi.org/10.1016/j.futures.2019.102508
TI  - Accumulating evidence using crowdsourcing and machine learning: A living bibliography about existential risk and global catastrophic risk
AB  - Abstract reviews are The study of existential risk — the risk of human extinction or the collapse of human civilization — has only recently emerged as an integrated field of research, and yet an overwhelming volume of relevant research has already been published. To provide an evidence base for policy and risk analysis, this research should be systematically reviewed. In a systematic review, one of many time-consuming tasks is to read the titles and abstracts of research publications, to see if they meet the inclusion criteria. We show how this task can be shared between multiple people (using crowdsourcing) and partially automated (using machine learning), as methods of handling an overwhelming volume of research. We used these methods to create The Existential Risk Research Assessment (TERRA), which is a living bibliography of relevant publications that gets updated each month ( www.x-risk.net ). We present the results from the first ten months of TERRA, in which 10,001 abstracts were screened by 51 participants. Several challenges need to be met before these methods can be used in systematic reviews. However, we suggest that collaborative and cumulative methods such as these will need to be used in systematic reviews as the volume of research increases. were able to identify current hot spots of QRD-ACE by screening less than 15% of the corpus. We discuss implications for harnessing text mining, predictive modeling, and priority screening in future research syntheses and avenues for future original research on QRD-ACE. recall, the estimation error would have been 1.3% on average, compared to an average 2% estimation error expected when replicating summary estimate calculations. Conclusion Screening prioritization coupled with stopping criteria in diagnostic test accuracy reviews can reliably detect when the screening process has identified a sufficient number of studies to perform the main meta-analysis with an accuracy within pre-specified tolerance limits. However, many of the systematic reviews did not identify a sufficient number of studies that the meta-analyses were accurate within a 2% limit even with exhaustive manual screening, i.e., using current practice. accessible to reviewers with limited exposure to natural language processing and machine learning, and have made the code available to reviewers. hazard identification studies published in the assessments and eliminated the need to manually screen more than 75% of search results on average. Limitations The chemical-independent approach used to build the training literature set provides a broad and unbiased picture across a variety of endpoints and environmental exposures but does not systematically identify all available data. Variance between actual and predicted relevant studies will be greater because of the external and non-random origin of seed study selection. This approach depends on access to readily available generic training data that can be used to locate relevant references in an unclassified corpus. Impact A generic approach to identifying human health relevant studies could be an important first step in literature evaluation for risk assessments. This initial scoping approach could facilitate faster literature evaluation by focusing reviewer efforts, as well as potentially minimize reviewer bias in selection of key studies. Using externally-derived training data has applicability particularly for databases with very low search precision where identifying training data may be cost-prohibitive. certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2020
DA  - 2020-02-01
JO  - {'id': 'https://openalex.org/S130638383', 'issn_l': '0016-3287', 'issn': ['1873-6378', '0016-3287'], 'display_name': 'Futures', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'https://doi.org/10.1016/j.futures.2019.102508', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Gorm E. Shackelford
AU  - Luke Kemp
AU  - Catherine Rhodes
AU  - Lalitha S Sundaram
AU  - Seán S. ÓhÉigeartaigh
AU  - Simon Beard
AU  - Haydn Belfield
AU  - Julius Weitzdörfer
AU  - Shahar Avin
AU  - Dag Sørebø
AU  - Elliot Jones
AU  - John B. Hume
AU  - David Price
AU  - David M. Pyle
AU  - Daniel Hurt
AU  - Theodore Stone
AU  - Harry Watkins
AU  - Lydia Collas
AU  - Bryony C. Cade
AU  - Thomas E. Johnson
AU  - Zachary Freitas-Groff
AU  - David Denkenberger
AU  - Michael R. Levot
AU  - William J. Sutherland
ER  - 

522.
TY  - posted-content
ID  - https://openalex.org/W3098090805
DO  - https://doi.org/10.1101/262881
TI  - revtools: An R package to support article screening for evidence synthesis
AB  - Abstract The field of evidence synthesis is growing rapidly, with a corresponding increase in the number of software tools and workflows to support the construction of systematic reviews, systematic maps, and meta-analyses. Despite much progress, however, a number of problems remain including slow integration of new statistical or methodological approaches into user-friendly software, low prevalence of open-source software, and poor integration among distinct software tools. These issues hinder the utility and transparency of new methods to the research community. Here I present revtools, an R package to support article screening during evidence synthesis projects. It provides tools for the import and de-duplication of bibliographic data, screening of articles by title or abstract, and visualization of article content using topic models. The software is entirely open-source and combines command-line scripting for experienced programmers with custom-built user interfaces for casual users, with further methods to support article screening to be added over time. Revtools provides free access to novel methods in an open-source environment, and represents a valuable step in expanding the capacity of R to support evidence synthesis projects. we suggest that collaborative and cumulative methods such as these will need to be used in systematic reviews as the volume of research increases. were able to identify current hot spots of QRD-ACE by screening less than 15% of the corpus. We discuss implications for harnessing text mining, predictive modeling, and priority screening in future research syntheses and avenues for future original research on QRD-ACE. recall, the estimation error would have been 1.3% on average, compared to an average 2% estimation error expected when replicating summary estimate calculations. Conclusion Screening prioritization coupled with stopping criteria in diagnostic test accuracy reviews can reliably detect when the screening process has identified a sufficient number of studies to perform the main meta-analysis with an accuracy within pre-specified tolerance limits. However, many of the systematic reviews did not identify a sufficient number of studies that the meta-analyses were accurate within a 2% limit even with exhaustive manual screening, i.e., using current practice. accessible to reviewers with limited exposure to natural language processing and machine learning, and have made the code available to reviewers. hazard identification studies published in the assessments and eliminated the need to manually screen more than 75% of search results on average. Limitations The chemical-independent approach used to build the training literature set provides a broad and unbiased picture across a variety of endpoints and environmental exposures but does not systematically identify all available data. Variance between actual and predicted relevant studies will be greater because of the external and non-random origin of seed study selection. This approach depends on access to readily available generic training data that can be used to locate relevant references in an unclassified corpus. Impact A generic approach to identifying human health relevant studies could be an important first step in literature evaluation for risk assessments. This initial scoping approach could facilitate faster literature evaluation by focusing reviewer efforts, as well as potentially minimize reviewer bias in selection of key studies. Using externally-derived training data has applicability particularly for databases with very low search precision where identifying training data may be cost-prohibitive. certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2019
DA  - 2019-07-28
JO  - {'id': 'https://openalex.org/V4306402567', 'issn_l': None, 'issn': None, 'display_name': 'bioRxiv (Cold Spring Harbor Laboratory)', 'publisher': 'Cold Spring Harbor Laboratory', 'type': 'repository', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Martin J. Westgate
ER  - 

523.
TY  - journal-article
ID  - https://openalex.org/W4200398992
DO  - https://doi.org/10.1016/j.jclinepi.2021.12.005
TI  - Tools to support the automation of systematic reviews: a scoping review
AB  - The objectives of this scoping review are to identify the reliability and validity of the available tools, their limitations and any recommendations to further improve the use of these tools.A scoping review methodology was followed to map the literature published on the challenges and solutions of conducting evidence synthesis using the JBI scoping review methodology.A total of 47 publications were included in the review. The current scoping review identified that LitSuggest, Rayyan, Abstractr, BIBOT, R software, RobotAnalyst, DistillerSR, ExaCT and NetMetaXL have potential to be used for the automation of systematic reviews. However, they are not without limitations. The review also identified other studies that employed algorithms that have not yet been developed into user friendly tools. Some of these algorithms showed high validity and reliability but their use is conditional on user knowledge of computer science and algorithms.Abstract screening has reached maturity; data extraction is still an active area. Developing methods to semi-automate different steps of evidence synthesis via machine learning remains an important research direction. Also, it is important to move from the research prototypes currently available to professionally maintained platforms. cumulative methods such as these will need to be used in systematic reviews as the volume of research increases. were able to identify current hot spots of QRD-ACE by screening less than 15% of the corpus. We discuss implications for harnessing text mining, predictive modeling, and priority screening in future research syntheses and avenues for future original research on QRD-ACE. recall, the estimation error would have been 1.3% on average, compared to an average 2% estimation error expected when replicating summary estimate calculations. Conclusion Screening prioritization coupled with stopping criteria in diagnostic test accuracy reviews can reliably detect when the screening process has identified a sufficient number of studies to perform the main meta-analysis with an accuracy within pre-specified tolerance limits. However, many of the systematic reviews did not identify a sufficient number of studies that the meta-analyses were accurate within a 2% limit even with exhaustive manual screening, i.e., using current practice. accessible to reviewers with limited exposure to natural language processing and machine learning, and have made the code available to reviewers. hazard identification studies published in the assessments and eliminated the need to manually screen more than 75% of search results on average. Limitations The chemical-independent approach used to build the training literature set provides a broad and unbiased picture across a variety of endpoints and environmental exposures but does not systematically identify all available data. Variance between actual and predicted relevant studies will be greater because of the external and non-random origin of seed study selection. This approach depends on access to readily available generic training data that can be used to locate relevant references in an unclassified corpus. Impact A generic approach to identifying human health relevant studies could be an important first step in literature evaluation for risk assessments. This initial scoping approach could facilitate faster literature evaluation by focusing reviewer efforts, as well as potentially minimize reviewer bias in selection of key studies. Using externally-derived training data has applicability particularly for databases with very low search precision where identifying training data may be cost-prohibitive. certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2021
DA  - 2021-12-01
JO  - {'id': 'https://openalex.org/V64418186', 'issn_l': '0895-4356', 'issn': ['1878-5921', '0895-4356'], 'display_name': 'Journal of Clinical Epidemiology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - H. P. S. Abdul Khalil
AU  - D Ameen
AU  - Armita Zarnegar
ER  - 

524.
TY  - journal-article
ID  - https://openalex.org/W3006673017
DO  - https://doi.org/10.1002/jrsm.1398
TI  - Comparing machine and human reviewers to evaluate the risk of bias in randomized controlled trials
AB  - Background Evidence from new health technologies is growing, along with demands for evidence to inform policy decisions, creating challenges in completing health technology assessments (HTAs)/systematic reviews (SRs) in a timely manner. Software can decrease the time and burden by automating the process, but evidence validating such software is limited. We tested the accuracy of RobotReviewer, a semi-autonomous risk of bias (RoB) assessment tool, and its agreement with human reviewers. Methods Two reviewers independently conducted RoB assessments on a sample of randomized controlled trials (RCTs), and their consensus ratings were compared with those generated by RobotReviewer. Agreement with the human reviewers was assessed using percent agreement and weighted kappa (κ). The accuracy of RobotReviewer was also assessed by calculating the sensitivity, specificity, and area under the curve in comparison to the consensus agreement of the human reviewers. Results The study included 372 RCTs. Inter-rater reliability ranged from κ = −0.06 (no agreement) for blinding of participants and personnel to κ = 0.62 (good agreement) for random sequence generation (excluding overall RoB). RobotReviewer was found to use a high percentage of “irrelevant supporting quotations” to complement RoB assessments for blinding of participants and personnel (72.6%), blinding of outcome assessment (70.4%), and allocation concealment (54.3%). Conclusion RobotReviewer can help with risk of bias assessment of RCTs but cannot replace human evaluations. Thus, reviewers should check and validate RoB assessments from RobotReviewer by consulting the original article when not relevant supporting quotations are provided by RobotReviewer. This consultation is in line with the recommendation provided by the developers. to an average 2% estimation error expected when replicating summary estimate calculations. Conclusion Screening prioritization coupled with stopping criteria in diagnostic test accuracy reviews can reliably detect when the screening process has identified a sufficient number of studies to perform the main meta-analysis with an accuracy within pre-specified tolerance limits. However, many of the systematic reviews did not identify a sufficient number of studies that the meta-analyses were accurate within a 2% limit even with exhaustive manual screening, i.e., using current practice. accessible to reviewers with limited exposure to natural language processing and machine learning, and have made the code available to reviewers. hazard identification studies published in the assessments and eliminated the need to manually screen more than 75% of search results on average. Limitations The chemical-independent approach used to build the training literature set provides a broad and unbiased picture across a variety of endpoints and environmental exposures but does not systematically identify all available data. Variance between actual and predicted relevant studies will be greater because of the external and non-random origin of seed study selection. This approach depends on access to readily available generic training data that can be used to locate relevant references in an unclassified corpus. Impact A generic approach to identifying human health relevant studies could be an important first step in literature evaluation for risk assessments. This initial scoping approach could facilitate faster literature evaluation by focusing reviewer efforts, as well as potentially minimize reviewer bias in selection of key studies. Using externally-derived training data has applicability particularly for databases with very low search precision where identifying training data may be cost-prohibitive. certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2020
DA  - 2020-03-03
JO  - {'id': 'https://openalex.org/S205768342', 'issn_l': '1759-2879', 'issn': ['1759-2879', '1759-2887'], 'display_name': 'Research Synthesis Methods', 'publisher': 'Wiley-Blackwell', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Susan Armijo-Olivo
AU  - Rodger Craig
AU  - Sandy Campbell
ER  - 

525.
TY  - book-chapter
ID  - https://openalex.org/W3016061304
DO  - https://doi.org/10.1007/978-3-030-45439-5_26
TI  - A Computational Approach for Objectively Derived Systematic Review Search Strategies
AB  - Searching literature for a systematic review begins with a manually constructed search strategy by an expert information specialist. The typical process of constructing search strategies is often undocumented, ad-hoc, and subject to individual expertise, which may introduce bias in the systematic review. A new method for objectively deriving search strategies has arisen from information specialists attempting to address these shortcomings. However, this proposed method still presents a number of manual, ad-hoc interventions, and trial-and-error processes, potentially still introducing bias into systematic reviews. Moreover, this method has not been rigorously evaluated on a large set of systematic review cases, thus its generalisability is unknown. In this work, we present a computational adaptation of this proposed objective method. Our adaptation removes the human-in-the-loop processes involved in the initial steps of creating a search strategy for a systematic review; reducing bias due to human factors and increasing the objectivity of the originally proposed method. Our proposed computational adaptation further enables a formal and rigorous evaluation over a large set of systematic reviews. We find that our computational adaptation of the original objective method provides an effective starting point for information specialists to continue refining. We also identify a number of avenues for extending and improving our adaptation to further promote supporting information specialists. assessment of RCTs but cannot replace human evaluations. Thus, reviewers should check and validate RoB assessments from RobotReviewer by consulting the original article when not relevant supporting quotations are provided by RobotReviewer. This consultation is in line with the recommendation provided by the developers. to an average 2% estimation error expected when replicating summary estimate calculations. Conclusion Screening prioritization coupled with stopping criteria in diagnostic test accuracy reviews can reliably detect when the screening process has identified a sufficient number of studies to perform the main meta-analysis with an accuracy within pre-specified tolerance limits. However, many of the systematic reviews did not identify a sufficient number of studies that the meta-analyses were accurate within a 2% limit even with exhaustive manual screening, i.e., using current practice. accessible to reviewers with limited exposure to natural language processing and machine learning, and have made the code available to reviewers. hazard identification studies published in the assessments and eliminated the need to manually screen more than 75% of search results on average. Limitations The chemical-independent approach used to build the training literature set provides a broad and unbiased picture across a variety of endpoints and environmental exposures but does not systematically identify all available data. Variance between actual and predicted relevant studies will be greater because of the external and non-random origin of seed study selection. This approach depends on access to readily available generic training data that can be used to locate relevant references in an unclassified corpus. Impact A generic approach to identifying human health relevant studies could be an important first step in literature evaluation for risk assessments. This initial scoping approach could facilitate faster literature evaluation by focusing reviewer efforts, as well as potentially minimize reviewer bias in selection of key studies. Using externally-derived training data has applicability particularly for databases with very low search precision where identifying training data may be cost-prohibitive. certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2020
DA  - 2020-04-14
JO  - {'id': 'https://openalex.org/S106296714', 'issn_l': '0302-9743', 'issn': ['1611-3349', '0302-9743'], 'display_name': 'Lecture Notes in Computer Science', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://link.springer.com/content/pdf/10.1007%2F978-3-030-45439-5_26.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': None}
DP  - OpenAlex
AU  - Harrisen Scells
AU  - Guido Zuccon
AU  - Bevan Koopman
AU  - Justin Clark
ER  - 

526.
TY  - posted-content
ID  - https://openalex.org/W3098622247
DO  - https://doi.org/10.1101/255760
TI  - Machine learning algorithms for systematic review: reducing workload in a preclinical review of animal studies and reducing human screening error
AB  - Abstract Background Here we outline a method of applying existing machine learning (ML) approaches to aid citation screening in an on-going broad and shallow systematic review of preclinical animal studies, with the aim of achieving a high performing algorithm comparable to human screening. Methods We applied ML approaches to a broad systematic review of animal models of depression at the citation screening stage. We tested two independently developed ML approaches which used different classification models and feature sets. We recorded the performance of the ML approaches on an unseen validation set of papers using sensitivity, specificity and accuracy. We aimed to achieve 95% sensitivity and to maximise specificity. The classification model providing the most accurate predictions was applied to the remaining unseen records in the dataset and will be used in the next stage of the preclinical biomedical sciences systematic review. We used a cross validation technique to assign ML inclusion likelihood scores to the human screened records, to identify potential errors made during the human screening process (error analysis). Results ML approaches reached 98.7% sensitivity based on learning from a training set of 5749 records, with an inclusion prevalence of 13.2%. The highest level of specificity reached was 86%. Performance was assessed on an independent validation dataset. Human errors in the training and validation sets were successfully identified using assigned the inclusion likelihood from the ML model to highlight discrepancies. Training the ML algorithm on the corrected dataset improved the specificity of the algorithm without compromising sensitivity. Error analysis correction leads to a 3% improvement in sensitivity and specificity, which increases precision and accuracy of the ML algorithm. Conclusions This work has confirmed the performance and application of ML algorithms for screening in systematic reviews of preclinical animal studies. It has highlighted the novel use of ML algorithms to identify human error. This needs to be confirmed in other reviews, , but represents a promising approach to integrating human decisions and automation in systematic review methodology. even with exhaustive manual screening, i.e., using current practice. accessible to reviewers with limited exposure to natural language processing and machine learning, and have made the code available to reviewers. hazard identification studies published in the assessments and eliminated the need to manually screen more than 75% of search results on average. Limitations The chemical-independent approach used to build the training literature set provides a broad and unbiased picture across a variety of endpoints and environmental exposures but does not systematically identify all available data. Variance between actual and predicted relevant studies will be greater because of the external and non-random origin of seed study selection. This approach depends on access to readily available generic training data that can be used to locate relevant references in an unclassified corpus. Impact A generic approach to identifying human health relevant studies could be an important first step in literature evaluation for risk assessments. This initial scoping approach could facilitate faster literature evaluation by focusing reviewer efforts, as well as potentially minimize reviewer bias in selection of key studies. Using externally-derived training data has applicability particularly for databases with very low search precision where identifying training data may be cost-prohibitive. certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2018
DA  - 2018-10-30
JO  - {'id': 'https://openalex.org/S4306402567', 'issn_l': None, 'issn': None, 'display_name': 'bioRxiv (Cold Spring Harbor Laboratory)', 'publisher': 'Cold Spring Harbor Laboratory', 'type': 'repository', 'url': 'https://systematicreviewsjournal.biomedcentral.com/track/pdf/10.1186/s13643-019-0942-7', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Alexandra Bannach-Brown
AU  - Piotr Przybyła
AU  - James D. Thomas
AU  - Andrew S.C. Rice
AU  - Sophia Ananiadou
AU  - Jing Liao
AU  - Malcolm R. Macleod
ER  - 

527.
TY  - journal-article
ID  - https://openalex.org/W3183495504
DO  - https://doi.org/10.2196/30401
TI  - Machine Learning Approaches to Retrieve High-Quality, Clinically Relevant, Evidence from the Biomedical Literature: A Systematic Review (Preprint)
AB  - Background The rapid growth of the biomedical literature makes identifying strong evidence a time-consuming task. Applying machine learning to the process could be a viable solution that limits effort while maintaining accuracy. Objective The goal of the research was to summarize the nature and comparative performance of machine learning approaches that have been applied to retrieve high-quality evidence for clinical consideration from the biomedical literature. Methods We conducted a systematic review of studies that applied machine learning techniques to identify high-quality clinical articles in the biomedical literature. Multiple databases were searched to July 2020. Extracted data focused on the applied machine learning model, steps in the development of the models, and model performance. Results From 3918 retrieved studies, 10 met our inclusion criteria. All followed a supervised machine learning approach and applied, from a limited range of options, a high-quality standard for the training of their model. The results show that machine learning can achieve a sensitivity of 95% while maintaining a high precision of 86%. Conclusions Machine learning approaches perform well in retrieving high-quality clinical studies. Performance may improve by applying more sophisticated approaches such as active learning and unsupervised machine learning approaches. level of specificity reached was 86%. Performance was assessed on an independent validation dataset. Human errors in the training and validation sets were successfully identified using assigned the inclusion likelihood from the ML model to highlight discrepancies. Training the ML algorithm on the corrected dataset improved the specificity of the algorithm without compromising sensitivity. Error analysis correction leads to a 3% improvement in sensitivity and specificity, which increases precision and accuracy of the ML algorithm. Conclusions This work has confirmed the performance and application of ML algorithms for screening in systematic reviews of preclinical animal studies. It has highlighted the novel use of ML algorithms to identify human error. This needs to be confirmed in other reviews, , but represents a promising approach to integrating human decisions and automation in systematic review methodology. even with exhaustive manual screening, i.e., using current practice. accessible to reviewers with limited exposure to natural language processing and machine learning, and have made the code available to reviewers. hazard identification studies published in the assessments and eliminated the need to manually screen more than 75% of search results on average. Limitations The chemical-independent approach used to build the training literature set provides a broad and unbiased picture across a variety of endpoints and environmental exposures but does not systematically identify all available data. Variance between actual and predicted relevant studies will be greater because of the external and non-random origin of seed study selection. This approach depends on access to readily available generic training data that can be used to locate relevant references in an unclassified corpus. Impact A generic approach to identifying human health relevant studies could be an important first step in literature evaluation for risk assessments. This initial scoping approach could facilitate faster literature evaluation by focusing reviewer efforts, as well as potentially minimize reviewer bias in selection of key studies. Using externally-derived training data has applicability particularly for databases with very low search precision where identifying training data may be cost-prohibitive. certainty evidence). For consumption outcomes, meta-analysis of 15 comparisons from 12 studies (n = 1098) found that exposure to food placed farther away resulted in a moderate reduction in its consumption: SMD -0.60 (95% CI -0.84 to -0.36) (low certainty evidence). Meta-regression analyses indicated that this effect was greater: the farther away the product was placed; when only the targeted product(s) was available; when participants were of low deprivation status; and when the study was at high risk of bias.The current evidence suggests that changing the number of available food options or altering the positioning of foods could contribute to meaningful changes in behaviour, justifying policy actions to promote such changes within food environments. However, the certainty of this evidence as assessed by GRADE is low or very low. To enable more certain and generalisable conclusions about these potentially important effects, further research is warranted in real-world settings, intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2021
DA  - 2021-09-09
JO  - {'id': 'https://openalex.org/V2764650051', 'issn_l': '2291-9694', 'issn': ['2291-9694'], 'display_name': 'JMIR medical informatics', 'publisher': 'JMIR Publications', 'type': 'journal', 'url': 'https://jmir.org/api/download?alt_name=medinform_v9i9e30401_app1.pdf&filename=164329bea2cf0835f271b57b67f6fa9e.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Wael Abdelkader
AU  - Tamara Navarro
AU  - Rick Parrish
AU  - Chris Cotoi
AU  - Federico Germini
AU  - Alfonso Iorio
AU  - R. Brian Haynes
AU  - Cynthia Lokker
ER  - 

528.
TY  - journal-article
ID  - https://openalex.org/W3192900442
DO  - https://doi.org/10.3310/phr09080
TI  - School-based interventions to prevent anxiety, depression and conduct disorder in children and young people: a systematic review and network meta-analysis
AB  - Background Schools in the UK increasingly have to respond to anxiety, depression and conduct disorder as key causes of morbidity in children and young people. Objective The objective was to assess the comparative effectiveness of educational setting-based interventions for the prevention of anxiety, depression and conduct disorder in children and young people. Design This study comprised a systematic review, a network meta-analysis and an economic evaluation. Data sources The databases MEDLINE, EMBASE™ (Elsevier, Amsterdam, the Netherlands), PsycInfo ® (American Psychological Association, Washington, DC, USA) and Cochrane Central Register of Controlled Trials (CENTRAL) were searched to 4 April 2018, and the NHS Economic Evaluation Database (NHS EED) was searched on 22 May 2019 for economic evaluations. No language or date filters were applied. Main outcomes The main outcomes were post-intervention self-reported anxiety, depression or conduct disorder symptoms. Review methods Randomised/quasi-randomised trials of universal or targeted interventions for the prevention of anxiety, depression or conduct disorder in children and young people aged 4–18 years were included. Screening was conducted independently by two reviewers. Data extraction was conducted by one reviewer and checked by a second. Intervention- and component-level network meta-analyses were conducted in OpenBUGS. A review of the economic literature and a cost–consequence analysis were conducted. Results A total of 142 studies were included in the review, and 109 contributed to the network meta-analysis. Of the 109 studies, 57 were rated as having an unclear risk of bias for random sequence generation and allocation concealment. Heterogeneity was moderate. In universal secondary school settings, mindfulness/relaxation interventions [standardised mean difference (SMD) –0.65, 95% credible interval (CrI) –1.14 to –0.19] and cognitive–behavioural interventions (SMD –0.15, 95% CrI –0.34 to 0.04) may be effective for anxiety. Cognitive–behavioural interventions incorporating a psychoeducation component may be effective (SMD –0.30, 95% CrI –0.59 to –0.01) at preventing anxiety immediately post intervention. There was evidence that exercise was effective in preventing anxiety in targeted secondary school settings (SMD –0.47, 95% CrI –0.86 to –0.09). There was weak evidence that cognitive–behavioural interventions may prevent anxiety in universal (SMD –0.07, 95% CrI –0.23 to 0.05) and targeted (SMD –0.38, 95% CrI –0.84 to 0.07) primary school settings. There was weak evidence that cognitive–behavioural (SMD –0.04, 95% CrI –0.16 to 0.07) and cognitive–behavioural + interpersonal therapy (SMD –0.18, 95% CrI –0.46 to 0.08) may be effective in preventing depression in universal secondary school settings. Third-wave (SMD –0.35, 95% CrI –0.70 to 0.00) and cognitive–behavioural interventions (SMD –0.11, 95% CrI –0.28 to 0.05) incorporating a psychoeducation component may be effective at preventing depression immediately post intervention. There was no evidence of intervention effectiveness in targeted secondary, targeted primary or universal primary school settings post intervention. The results for university settings were unreliable because of inconsistency in the network meta-analysis. A narrative summary was reported for five conduct disorder prevention studies, all in primary school settings. None reported the primary outcome at the primary post-intervention time point. The economic evidence review reported heterogeneous findings from six studies. Taking the perspective of a single school budget and based on cognitive–behavioural therapy intervention costs in universal secondary school settings, the cost–consequence analysis estimated an intervention cost of £43 per student. Limitations The emphasis on disorder-specific prevention excluded broader mental health interventions and restricted the number of eligible conduct disorder prevention studies. Restricting the study to interventions delivered in the educational setting may have limited the number of eligible university-level interventions. Conclusions There was weak evidence of the effectiveness of school-based, disorder-specific prevention interventions, although effects were modest and the evidence not robust. Cognitive–behavioural therapy-based interventions may be more effective if they include a psychoeducation component. Future work Future trials for prevention of anxiety and depression should evaluate cognitive–behavioural interventions with and without a psychoeducation component, and include mindfulness/relaxation or exercise comparators, with sufficient follow-up. Cost implications must be adequately measured. Study registration This study is registered as PROSPERO CRD42016048184. Funding This project was funded by the National Institute for Health Research (NIHR) Public Health Research programme and will be published in full in Public Health Research ; Vol. 9, No. 8. See the NIHR Journals Library website for further project information. and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2021
DA  - 2021-07-01
JO  - {'id': 'https://openalex.org/S4210192240', 'issn_l': '2050-4381', 'issn': ['2050-439X', '2050-4381'], 'display_name': 'Public health research', 'publisher': 'NIHR Journals Library', 'type': 'journal', 'url': 'https://njl-admin.nihr.ac.uk/document/download/2037240', 'is_oa': True, 'version': 'publishedVersion', 'license': 'publisher-specific license'}
DP  - OpenAlex
AU  - Deborah M Caldwell
AU  - Sarah W. Davies
AU  - Joanna Thorn
AU  - Jennifer A. Palmer
AU  - Paola Caro
AU  - Sarah E Hetrick
AU  - David Gunnell
AU  - Sumayya Anwer
AU  - José López-López
AU  - Clare E French
AU  - Judi Kidger
AU  - Sarah Dawson
AU  - Rachel Churchill
AU  - James D. Thomas
AU  - Rona Campbell
AU  - Nicky J Welton
ER  - 

529.
TY  - proceedings-article
ID  - https://openalex.org/W2324936983
DO  - https://doi.org/10.1145/2837185.2837279
TI  - Using rule-based classifiers in systematic reviews
AB  - Systematic review is the scientific process that provides reliable answers to a particular research question by interpreting the current pertinent literature. There is a significant shift from using manual human approach to decision support tools that provides a semi-automated screening phase by reducing the required time and effort to the group of experts. Most of proposed works apply supervised Machine Learning (ML) algorithms to infer exclusion and inclusion rules by observing a human screener. Unless, these techniques holds very little promise in study identification phase, because the rate of excluding citations erroneously still unreasonable. In this paper, we contribute to this line of works by proposing an alternative approach, not yet tested in this domain based on semantic rule-based classifiers. This approach involved applying a novel Hybrid Feature Selection Method (HFSM) within a Class Association Rules (CARs) algorithm. Experiments are conducted on a corpus resulting from an actual systematic review. The obtained results show that our algorithm outperforms the existing algorithms in the literature. Screening was conducted independently by two reviewers. Data extraction was conducted by one reviewer and checked by a second. Intervention- and component-level network meta-analyses were conducted in OpenBUGS. A review of the economic literature and a cost–consequence analysis were conducted. Results A total of 142 studies were included in the review, and 109 contributed to the network meta-analysis. Of the 109 studies, 57 were rated as having an unclear risk of bias for random sequence generation and allocation concealment. Heterogeneity was moderate. In universal secondary school settings, mindfulness/relaxation interventions [standardised mean difference (SMD) –0.65, 95% credible interval (CrI) –1.14 to –0.19] and cognitive–behavioural interventions (SMD –0.15, 95% CrI –0.34 to 0.04) may be effective for anxiety. Cognitive–behavioural interventions incorporating a psychoeducation component may be effective (SMD –0.30, 95% CrI –0.59 to –0.01) at preventing anxiety immediately post intervention. There was evidence that exercise was effective in preventing anxiety in targeted secondary school settings (SMD –0.47, 95% CrI –0.86 to –0.09). There was weak evidence that cognitive–behavioural interventions may prevent anxiety in universal (SMD –0.07, 95% CrI –0.23 to 0.05) and targeted (SMD –0.38, 95% CrI –0.84 to 0.07) primary school settings. There was weak evidence that cognitive–behavioural (SMD –0.04, 95% CrI –0.16 to 0.07) and cognitive–behavioural + interpersonal therapy (SMD –0.18, 95% CrI –0.46 to 0.08) may be effective in preventing depression in universal secondary school settings. Third-wave (SMD –0.35, 95% CrI –0.70 to 0.00) and cognitive–behavioural interventions (SMD –0.11, 95% CrI –0.28 to 0.05) incorporating a psychoeducation component may be effective at preventing depression immediately post intervention. There was no evidence of intervention effectiveness in targeted secondary, targeted primary or universal primary school settings post intervention. The results for university settings were unreliable because of inconsistency in the network meta-analysis. A narrative summary was reported for five conduct disorder prevention studies, all in primary school settings. None reported the primary outcome at the primary post-intervention time point. The economic evidence review reported heterogeneous findings from six studies. Taking the perspective of a single school budget and based on cognitive–behavioural therapy intervention costs in universal secondary school settings, the cost–consequence analysis estimated an intervention cost of £43 per student. Limitations The emphasis on disorder-specific prevention excluded broader mental health interventions and restricted the number of eligible conduct disorder prevention studies. Restricting the study to interventions delivered in the educational setting may have limited the number of eligible university-level interventions. Conclusions There was weak evidence of the effectiveness of school-based, disorder-specific prevention interventions, although effects were modest and the evidence not robust. Cognitive–behavioural therapy-based interventions may be more effective if they include a psychoeducation component. Future work Future trials for prevention of anxiety and depression should evaluate cognitive–behavioural interventions with and without a psychoeducation component, and include mindfulness/relaxation or exercise comparators, with sufficient follow-up. Cost implications must be adequately measured. Study registration This study is registered as PROSPERO CRD42016048184. Funding This project was funded by the National Institute for Health Research (NIHR) Public Health Research programme and will be published in full in Public Health Research ; Vol. 9, No. 8. See the NIHR Journals Library website for further project information. and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2015
DA  - 2015-12-11
JO  - {'id': 'https://openalex.org/V4306418884', 'issn_l': None, 'issn': None, 'display_name': 'Information Integration and Web-based Applications & Services', 'publisher': None, 'type': 'conference', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Hamza Sellak
AU  - Brahim Ouhbi
AU  - Bouchra Frikh
ER  - 

530.
TY  - posted-content
ID  - https://openalex.org/W2592460572
DO  - https://doi.org/10.1101/108480
TI  - Biomedical Text Mining for Research Rigor and Integrity: Tasks, Challenges, Directions
AB  - Abstract An estimated quarter of a trillion US dollars is invested in the biomedical research enterprise annually. There is growing alarm that a significant portion of this investment is wasted, due to problems in reproducibility of research findings and in the rigor and integrity of research conduct and reporting. Recent years have seen a flurry of activities focusing on standardization and guideline development to enhance the reproducibility and rigor of biomedical research. Research activity is primarily communicated via textual artifacts, ranging from grant applications to journal publications. These artifacts can be both the source and the end result of practices leading to research waste. For example, an article may describe a poorly designed experiment, or the authors may reach conclusions not supported by the evidence presented. In this article, we pose the question of whether biomedical text mining techniques can assist the stakeholders in the biomedical research enterprise in doing their part towards enhancing research integrity and rigor. In particular, we identify four key areas in which text mining techniques can make a significant contribution: plagiarism/fraud detection, ensuring adherence to reporting guidelines, managing information overload, and accurate citation/enhanced bibliometrics. We review the existing methods and tools for specific tasks, if they exist, or discuss relevant research that can provide guidance for future work. With the exponential increase in biomedical research output and the ability of text mining approaches to perform automatic tasks at large scale, we propose that such approaches can add checks and balances that promote responsible research practices and can provide significant benefits for the biomedical research enterprise. Supplementary information Supplementary material is available at BioRxiv . –0.15, 95% CrI –0.34 to 0.04) may be effective for anxiety. Cognitive–behavioural interventions incorporating a psychoeducation component may be effective (SMD –0.30, 95% CrI –0.59 to –0.01) at preventing anxiety immediately post intervention. There was evidence that exercise was effective in preventing anxiety in targeted secondary school settings (SMD –0.47, 95% CrI –0.86 to –0.09). There was weak evidence that cognitive–behavioural interventions may prevent anxiety in universal (SMD –0.07, 95% CrI –0.23 to 0.05) and targeted (SMD –0.38, 95% CrI –0.84 to 0.07) primary school settings. There was weak evidence that cognitive–behavioural (SMD –0.04, 95% CrI –0.16 to 0.07) and cognitive–behavioural + interpersonal therapy (SMD –0.18, 95% CrI –0.46 to 0.08) may be effective in preventing depression in universal secondary school settings. Third-wave (SMD –0.35, 95% CrI –0.70 to 0.00) and cognitive–behavioural interventions (SMD –0.11, 95% CrI –0.28 to 0.05) incorporating a psychoeducation component may be effective at preventing depression immediately post intervention. There was no evidence of intervention effectiveness in targeted secondary, targeted primary or universal primary school settings post intervention. The results for university settings were unreliable because of inconsistency in the network meta-analysis. A narrative summary was reported for five conduct disorder prevention studies, all in primary school settings. None reported the primary outcome at the primary post-intervention time point. The economic evidence review reported heterogeneous findings from six studies. Taking the perspective of a single school budget and based on cognitive–behavioural therapy intervention costs in universal secondary school settings, the cost–consequence analysis estimated an intervention cost of £43 per student. Limitations The emphasis on disorder-specific prevention excluded broader mental health interventions and restricted the number of eligible conduct disorder prevention studies. Restricting the study to interventions delivered in the educational setting may have limited the number of eligible university-level interventions. Conclusions There was weak evidence of the effectiveness of school-based, disorder-specific prevention interventions, although effects were modest and the evidence not robust. Cognitive–behavioural therapy-based interventions may be more effective if they include a psychoeducation component. Future work Future trials for prevention of anxiety and depression should evaluate cognitive–behavioural interventions with and without a psychoeducation component, and include mindfulness/relaxation or exercise comparators, with sufficient follow-up. Cost implications must be adequately measured. Study registration This study is registered as PROSPERO CRD42016048184. Funding This project was funded by the National Institute for Health Research (NIHR) Public Health Research programme and will be published in full in Public Health Research ; Vol. 9, No. 8. See the NIHR Journals Library website for further project information. and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2017
DA  - 2017-02-14
JO  - {'id': 'https://openalex.org/S4306402567', 'issn_l': None, 'issn': None, 'display_name': 'bioRxiv (Cold Spring Harbor Laboratory)', 'publisher': 'Cold Spring Harbor Laboratory', 'type': 'repository', 'url': 'https://academic.oup.com/bib/article-pdf/19/6/1400/27118801/bbx057.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'pd'}
DP  - OpenAlex
AU  - Halil Kilicoglu
ER  - 

531.
TY  - journal-article
ID  - https://openalex.org/W2884413622
DO  - https://doi.org/10.1002/14651858.cd013076
TI  - Overdiagnosis due to screening mammography for women aged 40 years and over
AB  - No Abstract Found
PY  - 2018
DA  - 2018-07-27
JO  - {'id': 'https://openalex.org/V4210172715', 'issn_l': '1464-780X', 'issn': ['1464-780X', '1465-184X', '1465-1858'], 'display_name': 'The Cochrane library', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Gemma Jacklyn
AU  - Kevin McGeechan
AU  - Nehmat Houssami
AU  - Katy J.L. Bell
AU  - Paul Glasziou
AU  - Alexandra Barratt
ER  - 

532.
TY  - journal-article
ID  - https://openalex.org/W3108159568
DO  - https://doi.org/10.2196/22422
TI  - Deep Neural Network for Reducing the Screening Workload in Systematic Reviews for Clinical Guidelines: Algorithm Validation Study
AB  - Background Performing systematic reviews is a time-consuming and resource-intensive process. Objective We investigated whether a machine learning system could perform systematic reviews more efficiently. Methods All systematic reviews and meta-analyses of interventional randomized controlled trials cited in recent clinical guidelines from the American Diabetes Association, American College of Cardiology, American Heart Association (2 guidelines), and American Stroke Association were assessed. After reproducing the primary screening data set according to the published search strategy of each, we extracted correct articles (those actually reviewed) and incorrect articles (those not reviewed) from the data set. These 2 sets of articles were used to train a neural network–based artificial intelligence engine (Concept Encoder, Fronteo Inc). The primary endpoint was work saved over sampling at 95% recall (WSS@95%). Results Among 145 candidate reviews of randomized controlled trials, 8 reviews fulfilled the inclusion criteria. For these 8 reviews, the machine learning system significantly reduced the literature screening workload by at least 6-fold versus that of manual screening based on WSS@95%. When machine learning was initiated using 2 correct articles that were randomly selected by a researcher, a 10-fold reduction in workload was achieved versus that of manual screening based on the WSS@95% value, with high sensitivity for eligible studies. The area under the receiver operating characteristic curve increased dramatically every time the algorithm learned a correct article. Conclusions Concept Encoder achieved a 10-fold reduction of the screening workload for systematic review after learning from 2 randomly selected studies on the target topic. However, few meta-analyses of randomized controlled trials were included. Concept Encoder could facilitate the acquisition of evidence for clinical guidelines. at BioRxiv . –0.15, 95% CrI –0.34 to 0.04) may be effective for anxiety. Cognitive–behavioural interventions incorporating a psychoeducation component may be effective (SMD –0.30, 95% CrI –0.59 to –0.01) at preventing anxiety immediately post intervention. There was evidence that exercise was effective in preventing anxiety in targeted secondary school settings (SMD –0.47, 95% CrI –0.86 to –0.09). There was weak evidence that cognitive–behavioural interventions may prevent anxiety in universal (SMD –0.07, 95% CrI –0.23 to 0.05) and targeted (SMD –0.38, 95% CrI –0.84 to 0.07) primary school settings. There was weak evidence that cognitive–behavioural (SMD –0.04, 95% CrI –0.16 to 0.07) and cognitive–behavioural + interpersonal therapy (SMD –0.18, 95% CrI –0.46 to 0.08) may be effective in preventing depression in universal secondary school settings. Third-wave (SMD –0.35, 95% CrI –0.70 to 0.00) and cognitive–behavioural interventions (SMD –0.11, 95% CrI –0.28 to 0.05) incorporating a psychoeducation component may be effective at preventing depression immediately post intervention. There was no evidence of intervention effectiveness in targeted secondary, targeted primary or universal primary school settings post intervention. The results for university settings were unreliable because of inconsistency in the network meta-analysis. A narrative summary was reported for five conduct disorder prevention studies, all in primary school settings. None reported the primary outcome at the primary post-intervention time point. The economic evidence review reported heterogeneous findings from six studies. Taking the perspective of a single school budget and based on cognitive–behavioural therapy intervention costs in universal secondary school settings, the cost–consequence analysis estimated an intervention cost of £43 per student. Limitations The emphasis on disorder-specific prevention excluded broader mental health interventions and restricted the number of eligible conduct disorder prevention studies. Restricting the study to interventions delivered in the educational setting may have limited the number of eligible university-level interventions. Conclusions There was weak evidence of the effectiveness of school-based, disorder-specific prevention interventions, although effects were modest and the evidence not robust. Cognitive–behavioural therapy-based interventions may be more effective if they include a psychoeducation component. Future work Future trials for prevention of anxiety and depression should evaluate cognitive–behavioural interventions with and without a psychoeducation component, and include mindfulness/relaxation or exercise comparators, with sufficient follow-up. Cost implications must be adequately measured. Study registration This study is registered as PROSPERO CRD42016048184. Funding This project was funded by the National Institute for Health Research (NIHR) Public Health Research programme and will be published in full in Public Health Research ; Vol. 9, No. 8. See the NIHR Journals Library website for further project information. and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2020
DA  - 2020-12-30
JO  - {'id': 'https://openalex.org/S17147534', 'issn_l': '1438-8871', 'issn': ['1439-4456', '1438-8871'], 'display_name': 'Journal of Medical Internet Research', 'publisher': 'JMIR Publications', 'type': 'journal', 'url': 'https://www.jmir.org/2020/12/e22422/PDF', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Tomohide Yamada
AU  - Daisuke Yoneoka
AU  - Yuta Hiraike
AU  - Kimihiro Hino
AU  - Hiroyoshi Toyoshiba
AU  - Akira Shishido
AU  - Hisashi Noma
AU  - Nobuhiro Shojima
AU  - Toshimasa Yamauchi
ER  - 

533.
TY  - journal-article
ID  - https://openalex.org/W3113896843
DO  - https://doi.org/10.1108/ijssp-07-2020-0321
TI  - Regulating religion in a time of COVID-19 pandemic in Indonesia: context, dynamics, and implication
AB  - Purpose This study aims to perform a systematic review of the dialectics and telematics strategy for regulating religion during the COVID-19 pandemic. The study also analyzes some important issues related to religions, state, and society. Design/methodology/approach A critical literature review was performed to complete this study, using media, institutional, national, and international reports, as well as recent and previous studies during the COVID-19 pandemic. Findings Religion was one of the social entities that had a crucial effect on the COVID-19 pandemic. The new system in the form of social distancing affects its performance. Furthermore, the response of religion in Indonesia is unique when its status is considered as the largest Islamic country in the world. Therefore, this study attempts to analyze and demonstrate the dynamics of relationships between actors, religion, and state in the process and strategy of religious regulation. Research limitations/implications This study was carried out using a single methodological approach. Practical implications This study provides input to both religion and the state (government) in building a synergy of constructive responses to the effects of the COVID-19 pandemic. Social implications It provides input to society in understanding the critical intersection between religion, state, and society. Originality/value This may be the first academic study that analyzes the problems of the process of regulating religion in the context of COVID-19. correct article. Conclusions Concept Encoder achieved a 10-fold reduction of the screening workload for systematic review after learning from 2 randomly selected studies on the target topic. However, few meta-analyses of randomized controlled trials were included. Concept Encoder could facilitate the acquisition of evidence for clinical guidelines. at BioRxiv . –0.15, 95% CrI –0.34 to 0.04) may be effective for anxiety. Cognitive–behavioural interventions incorporating a psychoeducation component may be effective (SMD –0.30, 95% CrI –0.59 to –0.01) at preventing anxiety immediately post intervention. There was evidence that exercise was effective in preventing anxiety in targeted secondary school settings (SMD –0.47, 95% CrI –0.86 to –0.09). There was weak evidence that cognitive–behavioural interventions may prevent anxiety in universal (SMD –0.07, 95% CrI –0.23 to 0.05) and targeted (SMD –0.38, 95% CrI –0.84 to 0.07) primary school settings. There was weak evidence that cognitive–behavioural (SMD –0.04, 95% CrI –0.16 to 0.07) and cognitive–behavioural + interpersonal therapy (SMD –0.18, 95% CrI –0.46 to 0.08) may be effective in preventing depression in universal secondary school settings. Third-wave (SMD –0.35, 95% CrI –0.70 to 0.00) and cognitive–behavioural interventions (SMD –0.11, 95% CrI –0.28 to 0.05) incorporating a psychoeducation component may be effective at preventing depression immediately post intervention. There was no evidence of intervention effectiveness in targeted secondary, targeted primary or universal primary school settings post intervention. The results for university settings were unreliable because of inconsistency in the network meta-analysis. A narrative summary was reported for five conduct disorder prevention studies, all in primary school settings. None reported the primary outcome at the primary post-intervention time point. The economic evidence review reported heterogeneous findings from six studies. Taking the perspective of a single school budget and based on cognitive–behavioural therapy intervention costs in universal secondary school settings, the cost–consequence analysis estimated an intervention cost of £43 per student. Limitations The emphasis on disorder-specific prevention excluded broader mental health interventions and restricted the number of eligible conduct disorder prevention studies. Restricting the study to interventions delivered in the educational setting may have limited the number of eligible university-level interventions. Conclusions There was weak evidence of the effectiveness of school-based, disorder-specific prevention interventions, although effects were modest and the evidence not robust. Cognitive–behavioural therapy-based interventions may be more effective if they include a psychoeducation component. Future work Future trials for prevention of anxiety and depression should evaluate cognitive–behavioural interventions with and without a psychoeducation component, and include mindfulness/relaxation or exercise comparators, with sufficient follow-up. Cost implications must be adequately measured. Study registration This study is registered as PROSPERO CRD42016048184. Funding This project was funded by the National Institute for Health Research (NIHR) Public Health Research programme and will be published in full in Public Health Research ; Vol. 9, No. 8. See the NIHR Journals Library website for further project information. and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2021
DA  - 2021-01-01
JO  - {'id': 'https://openalex.org/S84394799', 'issn_l': '0144-333X', 'issn': ['0144-333X', '1758-6720'], 'display_name': 'International Journal of Sociology and Social Policy', 'publisher': 'Emerald Publishing Limited', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Max Regus
ER  - 

534.
TY  - journal-article
ID  - https://openalex.org/W3139104238
DO  - https://doi.org/10.1016/j.intimp.2021.107526
TI  - Protein network exploration prioritizes targets for modulating neuroinflammation in Parkinson’s disease
AB  - • Exploring the neuroinflammation's protein network helps to apprehend its complexity. • TLRs, IL4, IL10 and IL13 are associated to Parkinson's disease neuroinflammation • Caspase-1 and HMOX1 are likely important biomarkers for Parkinson's disease. Parkinson's disease is a progressive neurodegenerative disease associated with a loss of dopaminergic neurons in the substantia nigra of the brain. Neuroinflammation, another hallmark of the disease, is thought to play an important role in the neurodegenerative process. While mitigating neuroinflammation could prove beneficial for Parkinson's disease, identifying the most relevant biological processes and pharmacological targets as well as drugs to modulate them remains highly challenging. The present study aimed to better understand the protein network behind neuroinflammation in Parkinson's disease and to prioritize possible targets for its pharmacological modulation. We first used text-mining to systematically collect the proteins significantly associated to Parkinson's disease neuroinflammation over the scientific literature. The functional interaction network formed by these proteins was then analyzed by integrating functional enrichment, network topology analysis and drug–protein interaction analysis. We identified 57 proteins significantly associated to neuroinflammation in Parkinson's disease. Toll-like Receptor Cascades as well as Interleukin 4, Interleukin 10 and Interleukin 13 signaling appeared as the most significantly enriched biological processes. Protein network analysis using STRING and CentiScaPe identified 8 proteins with the highest ability to control these biological processes underlying neuroinflammation, namely caspase 1, heme oxygenase 1, interleukin 1beta, interleukin 4, interleukin 6, interleukin 10, tumor necrosis factor alpha and toll-like receptor 4. These key proteins were indexed to be targetable by a total of 38 drugs including 27 small compounds 11 protein-based therapies. In conclusion, our study highlights key proteins in Parkinson's disease neuroinflammation as well as pharmacological compounds acting on them. As such, it may facilitate the prioritization of biomarkers for the development of diagnostic, target-engagement assessment and therapeutic tools against Parkinson's disease. was evidence that exercise was effective in preventing anxiety in targeted secondary school settings (SMD –0.47, 95% CrI –0.86 to –0.09). There was weak evidence that cognitive–behavioural interventions may prevent anxiety in universal (SMD –0.07, 95% CrI –0.23 to 0.05) and targeted (SMD –0.38, 95% CrI –0.84 to 0.07) primary school settings. There was weak evidence that cognitive–behavioural (SMD –0.04, 95% CrI –0.16 to 0.07) and cognitive–behavioural + interpersonal therapy (SMD –0.18, 95% CrI –0.46 to 0.08) may be effective in preventing depression in universal secondary school settings. Third-wave (SMD –0.35, 95% CrI –0.70 to 0.00) and cognitive–behavioural interventions (SMD –0.11, 95% CrI –0.28 to 0.05) incorporating a psychoeducation component may be effective at preventing depression immediately post intervention. There was no evidence of intervention effectiveness in targeted secondary, targeted primary or universal primary school settings post intervention. The results for university settings were unreliable because of inconsistency in the network meta-analysis. A narrative summary was reported for five conduct disorder prevention studies, all in primary school settings. None reported the primary outcome at the primary post-intervention time point. The economic evidence review reported heterogeneous findings from six studies. Taking the perspective of a single school budget and based on cognitive–behavioural therapy intervention costs in universal secondary school settings, the cost–consequence analysis estimated an intervention cost of £43 per student. Limitations The emphasis on disorder-specific prevention excluded broader mental health interventions and restricted the number of eligible conduct disorder prevention studies. Restricting the study to interventions delivered in the educational setting may have limited the number of eligible university-level interventions. Conclusions There was weak evidence of the effectiveness of school-based, disorder-specific prevention interventions, although effects were modest and the evidence not robust. Cognitive–behavioural therapy-based interventions may be more effective if they include a psychoeducation component. Future work Future trials for prevention of anxiety and depression should evaluate cognitive–behavioural interventions with and without a psychoeducation component, and include mindfulness/relaxation or exercise comparators, with sufficient follow-up. Cost implications must be adequately measured. Study registration This study is registered as PROSPERO CRD42016048184. Funding This project was funded by the National Institute for Health Research (NIHR) Public Health Research programme and will be published in full in Public Health Research ; Vol. 9, No. 8. See the NIHR Journals Library website for further project information. and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2021
DA  - 2021-03-20
JO  - {'id': 'https://openalex.org/S158377717', 'issn_l': '1567-5769', 'issn': ['1878-1705', '1567-5769'], 'display_name': 'International Immunopharmacology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'https://doi.org/10.1016/j.intimp.2021.107526', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc-nd'}
DP  - OpenAlex
AU  - Marie-Amandine Bonte
AU  - Fatima El Idrissi
AU  - Bernard Gressier
AU  - David Devos
AU  - Karim Belarbi
ER  - 

535.
TY  - journal-article
ID  - https://openalex.org/W4280509609
DO  - https://doi.org/10.1098/rspb.2021.2721
TI  - Past and future uses of text mining in ecology and evolution
AB  - Ecology and evolutionary biology, like other scientific fields, are experiencing an exponential growth of academic manuscripts. As domain knowledge accumulates, scientists will need new computational approaches for identifying relevant literature to read and include in formal literature reviews and meta-analyses. Importantly, these approaches can also facilitate automated, large-scale data synthesis tasks and build structured databases from the information in the texts of primary journal articles, books, grey literature, and websites. The increasing availability of digital text, computational resources, and machine-learning based language models have led to a revolution in text analysis and natural language processing (NLP) in recent years. NLP has been widely adopted across the biomedical sciences but is rarely used in ecology and evolutionary biology. Applying computational tools from text mining and NLP will increase the efficiency of data synthesis, improve the reproducibility of literature reviews, formalize analyses of research biases and knowledge gaps, and promote data-driven discovery of patterns across ecology and evolutionary biology. Here we present recent use cases from ecology and evolution, and discuss future applications, limitations and ethical issues. disease. Toll-like Receptor Cascades as well as Interleukin 4, Interleukin 10 and Interleukin 13 signaling appeared as the most significantly enriched biological processes. Protein network analysis using STRING and CentiScaPe identified 8 proteins with the highest ability to control these biological processes underlying neuroinflammation, namely caspase 1, heme oxygenase 1, interleukin 1beta, interleukin 4, interleukin 6, interleukin 10, tumor necrosis factor alpha and toll-like receptor 4. These key proteins were indexed to be targetable by a total of 38 drugs including 27 small compounds 11 protein-based therapies. In conclusion, our study highlights key proteins in Parkinson's disease neuroinflammation as well as pharmacological compounds acting on them. As such, it may facilitate the prioritization of biomarkers for the development of diagnostic, target-engagement assessment and therapeutic tools against Parkinson's disease. was evidence that exercise was effective in preventing anxiety in targeted secondary school settings (SMD –0.47, 95% CrI –0.86 to –0.09). There was weak evidence that cognitive–behavioural interventions may prevent anxiety in universal (SMD –0.07, 95% CrI –0.23 to 0.05) and targeted (SMD –0.38, 95% CrI –0.84 to 0.07) primary school settings. There was weak evidence that cognitive–behavioural (SMD –0.04, 95% CrI –0.16 to 0.07) and cognitive–behavioural + interpersonal therapy (SMD –0.18, 95% CrI –0.46 to 0.08) may be effective in preventing depression in universal secondary school settings. Third-wave (SMD –0.35, 95% CrI –0.70 to 0.00) and cognitive–behavioural interventions (SMD –0.11, 95% CrI –0.28 to 0.05) incorporating a psychoeducation component may be effective at preventing depression immediately post intervention. There was no evidence of intervention effectiveness in targeted secondary, targeted primary or universal primary school settings post intervention. The results for university settings were unreliable because of inconsistency in the network meta-analysis. A narrative summary was reported for five conduct disorder prevention studies, all in primary school settings. None reported the primary outcome at the primary post-intervention time point. The economic evidence review reported heterogeneous findings from six studies. Taking the perspective of a single school budget and based on cognitive–behavioural therapy intervention costs in universal secondary school settings, the cost–consequence analysis estimated an intervention cost of £43 per student. Limitations The emphasis on disorder-specific prevention excluded broader mental health interventions and restricted the number of eligible conduct disorder prevention studies. Restricting the study to interventions delivered in the educational setting may have limited the number of eligible university-level interventions. Conclusions There was weak evidence of the effectiveness of school-based, disorder-specific prevention interventions, although effects were modest and the evidence not robust. Cognitive–behavioural therapy-based interventions may be more effective if they include a psychoeducation component. Future work Future trials for prevention of anxiety and depression should evaluate cognitive–behavioural interventions with and without a psychoeducation component, and include mindfulness/relaxation or exercise comparators, with sufficient follow-up. Cost implications must be adequately measured. Study registration This study is registered as PROSPERO CRD42016048184. Funding This project was funded by the National Institute for Health Research (NIHR) Public Health Research programme and will be published in full in Public Health Research ; Vol. 9, No. 8. See the NIHR Journals Library website for further project information. and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2022
DA  - 2022-05-18
JO  - {'id': 'https://openalex.org/S3006207977', 'issn_l': '0962-8452', 'issn': ['1471-2954', '0962-8452'], 'display_name': 'Proceedings of The Royal Society B: Biological Sciences', 'publisher': 'Royal Society', 'type': 'journal', 'url': 'https://doi.org/10.1098/rspb.2021.2721', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Maxwell J. Farrell
AU  - Liam Brierley
AU  - Anna R. Willoughby
AU  - Andrew R. Yates
AU  - Nicole Mideo
ER  - 

536.
TY  - journal-article
ID  - https://openalex.org/W4281788268
DO  - https://doi.org/10.1016/j.iswa.2022.200091
TI  - Search strategy formulation for systematic reviews: Issues, challenges and opportunities
AB  - • Boolean logic is dominant in the formulation of search strategies for evidence synthesis in professional search, notably healthcare, but in other domains such as law, patents and recruitment. • Boolean methods are complex, time consuming, resource intensive and error prone, and a new approach is required. • Alternative approaches either suffer from the same problems as Boolean methods or introduce further problems such as lack of trust and transparency. • We propose a set of design principles to address the shortcomings of Boolean logic when formulating search strategies for evidence synthesis. Systematic literature reviews play a vital role in identifying the best available evidence for health and social care research, policy, and practice. The resources required to produce systematic reviews can be significant, and a key to the success of any review is the search strategy used to identify relevant literature. However, the methods used to construct search strategies can be complex, time consuming, resource intensive and error prone. In this review, we examine the state of the art in resolving complex structured information needs, focusing primarily on the healthcare context. We analyse the literature to identify key challenges and issues and explore appropriate solutions and workarounds. From this analysis we propose a way forward to facilitate trust and to aid explainability and transparency, reproducibility and replicability through a set of key design principles for tools to support the development of search strategies in systematic literature reviews. toll-like receptor 4. These key proteins were indexed to be targetable by a total of 38 drugs including 27 small compounds 11 protein-based therapies. In conclusion, our study highlights key proteins in Parkinson's disease neuroinflammation as well as pharmacological compounds acting on them. As such, it may facilitate the prioritization of biomarkers for the development of diagnostic, target-engagement assessment and therapeutic tools against Parkinson's disease. was evidence that exercise was effective in preventing anxiety in targeted secondary school settings (SMD –0.47, 95% CrI –0.86 to –0.09). There was weak evidence that cognitive–behavioural interventions may prevent anxiety in universal (SMD –0.07, 95% CrI –0.23 to 0.05) and targeted (SMD –0.38, 95% CrI –0.84 to 0.07) primary school settings. There was weak evidence that cognitive–behavioural (SMD –0.04, 95% CrI –0.16 to 0.07) and cognitive–behavioural + interpersonal therapy (SMD –0.18, 95% CrI –0.46 to 0.08) may be effective in preventing depression in universal secondary school settings. Third-wave (SMD –0.35, 95% CrI –0.70 to 0.00) and cognitive–behavioural interventions (SMD –0.11, 95% CrI –0.28 to 0.05) incorporating a psychoeducation component may be effective at preventing depression immediately post intervention. There was no evidence of intervention effectiveness in targeted secondary, targeted primary or universal primary school settings post intervention. The results for university settings were unreliable because of inconsistency in the network meta-analysis. A narrative summary was reported for five conduct disorder prevention studies, all in primary school settings. None reported the primary outcome at the primary post-intervention time point. The economic evidence review reported heterogeneous findings from six studies. Taking the perspective of a single school budget and based on cognitive–behavioural therapy intervention costs in universal secondary school settings, the cost–consequence analysis estimated an intervention cost of £43 per student. Limitations The emphasis on disorder-specific prevention excluded broader mental health interventions and restricted the number of eligible conduct disorder prevention studies. Restricting the study to interventions delivered in the educational setting may have limited the number of eligible university-level interventions. Conclusions There was weak evidence of the effectiveness of school-based, disorder-specific prevention interventions, although effects were modest and the evidence not robust. Cognitive–behavioural therapy-based interventions may be more effective if they include a psychoeducation component. Future work Future trials for prevention of anxiety and depression should evaluate cognitive–behavioural interventions with and without a psychoeducation component, and include mindfulness/relaxation or exercise comparators, with sufficient follow-up. Cost implications must be adequately measured. Study registration This study is registered as PROSPERO CRD42016048184. Funding This project was funded by the National Institute for Health Research (NIHR) Public Health Research programme and will be published in full in Public Health Research ; Vol. 9, No. 8. See the NIHR Journals Library website for further project information. and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2022
DA  - 2022-06-01
JO  - {'id': 'https://openalex.org/V4210234522', 'issn_l': '2667-3053', 'issn': ['2667-3053'], 'display_name': 'Intelligent systems with applications', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'https://doi.org/10.1016/j.iswa.2022.200091', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc-nd'}
DP  - OpenAlex
AU  - Andrew MacFarlane
AU  - Tony Russell-Rose
AU  - Farhad Shokraneh
ER  - 

537.
TY  - journal-article
ID  - https://openalex.org/W4281827825
DO  - https://doi.org/10.1186/s12874-022-01649-y
TI  - Automating risk of bias assessment in systematic reviews: a real-time mixed methods comparison of human researchers to a machine learning system
AB  - Machine learning and automation are increasingly used to make the evidence synthesis process faster and more responsive to policymakers' needs. In systematic reviews of randomized controlled trials (RCTs), risk of bias assessment is a resource-intensive task that typically requires two trained reviewers. One function of RobotReviewer, an off-the-shelf machine learning system, is an automated risk of bias assessment.We assessed the feasibility of adopting RobotReviewer within a national public health institute using a randomized, real-time, user-centered study. The study included 26 RCTs and six reviewers from two projects examining health and social interventions. We randomized these studies to one of two RobotReviewer platforms. We operationalized feasibility as accuracy, time use, and reviewer acceptability. We measured accuracy by the number of corrections made by human reviewers (either to automated assessments or another human reviewer's assessments). We explored acceptability through group discussions and individual email responses after presenting the quantitative results.Reviewers were equally likely to accept judgment by RobotReviewer as each other's judgement during the consensus process when measured dichotomously; risk ratio 1.02 (95% CI 0.92 to 1.13; p = 0.33). We were not able to compare time use. The acceptability of the program by researchers was mixed. Less experienced reviewers were generally more positive, and they saw more benefits and were able to use the tool more flexibly. Reviewers positioned human input and human-to-human interaction as superior to even a semi-automation of this process.Despite being presented with evidence of RobotReviewer's equal performance to humans, participating reviewers were not interested in modifying standard procedures to include automation. If further studies confirm equal accuracy and reduced time compared to manual practices, we suggest that the benefits of RobotReviewer may support its future implementation as one of two assessors, despite reviewer ambivalence. Future research should study barriers to adopting automated tools and how highly educated and experienced researchers can adapt to a job market that is increasingly challenged by new technologies. settings (SMD –0.47, 95% CrI –0.86 to –0.09). There was weak evidence that cognitive–behavioural interventions may prevent anxiety in universal (SMD –0.07, 95% CrI –0.23 to 0.05) and targeted (SMD –0.38, 95% CrI –0.84 to 0.07) primary school settings. There was weak evidence that cognitive–behavioural (SMD –0.04, 95% CrI –0.16 to 0.07) and cognitive–behavioural + interpersonal therapy (SMD –0.18, 95% CrI –0.46 to 0.08) may be effective in preventing depression in universal secondary school settings. Third-wave (SMD –0.35, 95% CrI –0.70 to 0.00) and cognitive–behavioural interventions (SMD –0.11, 95% CrI –0.28 to 0.05) incorporating a psychoeducation component may be effective at preventing depression immediately post intervention. There was no evidence of intervention effectiveness in targeted secondary, targeted primary or universal primary school settings post intervention. The results for university settings were unreliable because of inconsistency in the network meta-analysis. A narrative summary was reported for five conduct disorder prevention studies, all in primary school settings. None reported the primary outcome at the primary post-intervention time point. The economic evidence review reported heterogeneous findings from six studies. Taking the perspective of a single school budget and based on cognitive–behavioural therapy intervention costs in universal secondary school settings, the cost–consequence analysis estimated an intervention cost of £43 per student. Limitations The emphasis on disorder-specific prevention excluded broader mental health interventions and restricted the number of eligible conduct disorder prevention studies. Restricting the study to interventions delivered in the educational setting may have limited the number of eligible university-level interventions. Conclusions There was weak evidence of the effectiveness of school-based, disorder-specific prevention interventions, although effects were modest and the evidence not robust. Cognitive–behavioural therapy-based interventions may be more effective if they include a psychoeducation component. Future work Future trials for prevention of anxiety and depression should evaluate cognitive–behavioural interventions with and without a psychoeducation component, and include mindfulness/relaxation or exercise comparators, with sufficient follow-up. Cost implications must be adequately measured. Study registration This study is registered as PROSPERO CRD42016048184. Funding This project was funded by the National Institute for Health Research (NIHR) Public Health Research programme and will be published in full in Public Health Research ; Vol. 9, No. 8. See the NIHR Journals Library website for further project information. and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2022
DA  - 2022-06-08
JO  - {'id': 'https://openalex.org/S185874209', 'issn_l': '1471-2288', 'issn': ['1471-2288'], 'display_name': 'BMC Medical Research Methodology', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://bmcmedresmethodol.biomedcentral.com/counter/pdf/10.1186/s12874-022-01649-y', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Patricia Sofia Jacobsen Jardim
AU  - Christopher F. Rose
AU  - Heather M. Ames
AU  - Jose Francisco Meneses Echavez
AU  - Stijn Van de Velde
AU  - Ashley Elizabeth Muller
ER  - 

538.
TY  - journal-article
ID  - https://openalex.org/W3105442727
DO  - https://doi.org/10.1049/iet-sen.2020.0109
TI  - Retrieving and mining professional experience of software practice from grey literature: an exploratory review
AB  - © 2020 Institution of Engineering and Technology. All rights reserved. Retrieving and mining practitioners' self-reports of their professional experience of software practice could provide valuable evidence for research. The authors are, however, unaware of any existing reviews of research conducted in this area. The authors reviewed and classified previous research, and identified insights into the challenges research confronts when retrieving and mining practitioners' self-reports of their experience of software practice. They conducted an exploratory review to identify and classify 42 studies. They analysed a selection of those studies for insights on challenges to mining professional experience. They identified only one directly relevant study. Even then this study concerns the software professional's emotional experiences rather than the professional's reporting of behaviour and events occurring during software practice. They discussed the challenges concerning: the prevalence of professional experience; definitions, models and theories; the sparseness of data; units of discourse analysis; annotator agreement; evaluation of the performance of algorithms; and the lack of replications. No directly relevant prior research appears to have been conducted in this area. They discussed the value of reporting negative results in secondary studies. There are a range of research opportunities but also considerable challenges. They formulated a set of guiding questions for further research in this area. able to use the tool more flexibly. Reviewers positioned human input and human-to-human interaction as superior to even a semi-automation of this process.Despite being presented with evidence of RobotReviewer's equal performance to humans, participating reviewers were not interested in modifying standard procedures to include automation. If further studies confirm equal accuracy and reduced time compared to manual practices, we suggest that the benefits of RobotReviewer may support its future implementation as one of two assessors, despite reviewer ambivalence. Future research should study barriers to adopting automated tools and how highly educated and experienced researchers can adapt to a job market that is increasingly challenged by new technologies. settings (SMD –0.47, 95% CrI –0.86 to –0.09). There was weak evidence that cognitive–behavioural interventions may prevent anxiety in universal (SMD –0.07, 95% CrI –0.23 to 0.05) and targeted (SMD –0.38, 95% CrI –0.84 to 0.07) primary school settings. There was weak evidence that cognitive–behavioural (SMD –0.04, 95% CrI –0.16 to 0.07) and cognitive–behavioural + interpersonal therapy (SMD –0.18, 95% CrI –0.46 to 0.08) may be effective in preventing depression in universal secondary school settings. Third-wave (SMD –0.35, 95% CrI –0.70 to 0.00) and cognitive–behavioural interventions (SMD –0.11, 95% CrI –0.28 to 0.05) incorporating a psychoeducation component may be effective at preventing depression immediately post intervention. There was no evidence of intervention effectiveness in targeted secondary, targeted primary or universal primary school settings post intervention. The results for university settings were unreliable because of inconsistency in the network meta-analysis. A narrative summary was reported for five conduct disorder prevention studies, all in primary school settings. None reported the primary outcome at the primary post-intervention time point. The economic evidence review reported heterogeneous findings from six studies. Taking the perspective of a single school budget and based on cognitive–behavioural therapy intervention costs in universal secondary school settings, the cost–consequence analysis estimated an intervention cost of £43 per student. Limitations The emphasis on disorder-specific prevention excluded broader mental health interventions and restricted the number of eligible conduct disorder prevention studies. Restricting the study to interventions delivered in the educational setting may have limited the number of eligible university-level interventions. Conclusions There was weak evidence of the effectiveness of school-based, disorder-specific prevention interventions, although effects were modest and the evidence not robust. Cognitive–behavioural therapy-based interventions may be more effective if they include a psychoeducation component. Future work Future trials for prevention of anxiety and depression should evaluate cognitive–behavioural interventions with and without a psychoeducation component, and include mindfulness/relaxation or exercise comparators, with sufficient follow-up. Cost implications must be adequately measured. Study registration This study is registered as PROSPERO CRD42016048184. Funding This project was funded by the National Institute for Health Research (NIHR) Public Health Research programme and will be published in full in Public Health Research ; Vol. 9, No. 8. See the NIHR Journals Library website for further project information. and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2020
DA  - 2020-10-14
JO  - {'id': 'https://openalex.org/S164201770', 'issn_l': '1751-8806', 'issn': ['1751-8806', '1751-8814'], 'display_name': 'IET Software', 'publisher': 'Institution of Engineering and Technology', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Austen Rainer
AU  - Ashley J. Williams
AU  - Vahid Garousi
AU  - Michael Felderer
ER  - 

539.
TY  - journal-article
ID  - https://openalex.org/W3138718357
DO  - https://doi.org/10.1021/acs.jcim.0c01054
TI  - Extraction of Data on Parent Compounds and Their Metabolites from Texts of Scientific Abstracts
AB  - The growing amount of experimental data on chemical objects includes properties of small molecules, results of studies of their interaction with human and animal proteins, and methods of synthesis of organic compounds (OCs). The data obtained can be used to identify the names of OCs automatically, including all possible synonyms and relevant data on the molecular properties and biological activity. Utilization of different synonymic names of chemical compounds allows researchers to increase the completeness of data on their properties available from publications. Enrichment of the data on the names of chemical compounds by information about their possible metabolites can help estimate the biological effects of parent compounds and their metabolites more thoroughly. Therefore, an attempt at automated extraction of the names of parent compounds and their metabolites from the texts is a rather important task. In our study, we aimed at developing a method that provides the extraction of the named entities (NEs) of parent compounds and their metabolites from abstracts of scientific publications. Based on the application of the conditional random fields' algorithm, we extracted the NEs of chemical compounds. We developed a set of rules allowing identification of parent compound NEs and their metabolites in the texts. We evaluated the possibility of extracting the names of potential metabolites based on cosine similarity between strings representing names of parent compounds and all other chemical NEs found in the text. Additionally, we used conditional random fields to fetch the names of parent compounds and their metabolites from the texts based on the corpus of texts labeled manually. Our computational experiments showed that usage of rules in combination with cosine similarity could increase the accuracy of recognition of the names of metabolites compared to the rule-based algorithm and application of a machine-learning algorithm (conditional random fields). tools and how highly educated and experienced researchers can adapt to a job market that is increasingly challenged by new technologies. settings (SMD –0.47, 95% CrI –0.86 to –0.09). There was weak evidence that cognitive–behavioural interventions may prevent anxiety in universal (SMD –0.07, 95% CrI –0.23 to 0.05) and targeted (SMD –0.38, 95% CrI –0.84 to 0.07) primary school settings. There was weak evidence that cognitive–behavioural (SMD –0.04, 95% CrI –0.16 to 0.07) and cognitive–behavioural + interpersonal therapy (SMD –0.18, 95% CrI –0.46 to 0.08) may be effective in preventing depression in universal secondary school settings. Third-wave (SMD –0.35, 95% CrI –0.70 to 0.00) and cognitive–behavioural interventions (SMD –0.11, 95% CrI –0.28 to 0.05) incorporating a psychoeducation component may be effective at preventing depression immediately post intervention. There was no evidence of intervention effectiveness in targeted secondary, targeted primary or universal primary school settings post intervention. The results for university settings were unreliable because of inconsistency in the network meta-analysis. A narrative summary was reported for five conduct disorder prevention studies, all in primary school settings. None reported the primary outcome at the primary post-intervention time point. The economic evidence review reported heterogeneous findings from six studies. Taking the perspective of a single school budget and based on cognitive–behavioural therapy intervention costs in universal secondary school settings, the cost–consequence analysis estimated an intervention cost of £43 per student. Limitations The emphasis on disorder-specific prevention excluded broader mental health interventions and restricted the number of eligible conduct disorder prevention studies. Restricting the study to interventions delivered in the educational setting may have limited the number of eligible university-level interventions. Conclusions There was weak evidence of the effectiveness of school-based, disorder-specific prevention interventions, although effects were modest and the evidence not robust. Cognitive–behavioural therapy-based interventions may be more effective if they include a psychoeducation component. Future work Future trials for prevention of anxiety and depression should evaluate cognitive–behavioural interventions with and without a psychoeducation component, and include mindfulness/relaxation or exercise comparators, with sufficient follow-up. Cost implications must be adequately measured. Study registration This study is registered as PROSPERO CRD42016048184. Funding This project was funded by the National Institute for Health Research (NIHR) Public Health Research programme and will be published in full in Public Health Research ; Vol. 9, No. 8. See the NIHR Journals Library website for further project information. and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2021
DA  - 2021-03-16
JO  - {'id': 'https://openalex.org/S167262187', 'issn_l': '1549-9596', 'issn': ['1549-960X', '1549-9596'], 'display_name': 'Journal of Chemical Information and Modeling', 'publisher': 'American Chemical Society', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Olga S. Tarasova
AU  - Nadezhda Biziukova
AU  - A. V. Rudik
AU  - Alexandre Dmitriev
AU  - Dmitry Filimonov
AU  - Vladimir Poroikov
ER  - 

540.
TY  - journal-article
ID  - https://openalex.org/W3185952937
DO  - https://doi.org/10.1002/cl2.1195
TI  - Aquaculture for improving productivity, income, nutrition and women's empowerment in low‐ and middle‐income countries: A systematic review and meta‐analysis
AB  - Background A steady increase in the international production and consumption of fish has positioned aquaculture as a development option. Previous literature has highlighted the potential of aquaculture to improve economic, nutritional and gender equality outcomes, however, the evidence on the effectiveness of these programmes remains unclear. Objectives The review assessed whether aquaculture interventions increase the productivity, income, nutrition, and women's empowerment of individuals. We additionally aimed to identify barriers and facilitators that could affect the effectiveness of these interventions, and the cost-effectiveness of such programmes. Methods We searched for experimental and quasi-experimental studies focused on low- and middle-income countries. We used standard methodological procedures expected by The Campbell Collaboration for the data collection and analysis. Results We identified 21 impact evaluations assessing the effect of 13 aquaculture interventions in low- and lower-middle income countries. Twelve of these studies have a high risk of bias. Aquaculture interventions lead to a small increase in the production value, income, total expenditures and food consumption of participants. The limited availability of evidence prevented us from assessing other nutritional and women's empowerment outcomes. We identified barriers and facilitators affecting the programmes' set up, the participation of beneficiaries, and the level of productive activities. Insufficient cost data hindered full comparisons across programmes. Conclusions The review suggests a lack of rigorous evidence assessing the effectiveness of aquaculture programmes. Future research could focus on evaluating nutrition and women's empowerment impacts, promoting reporting standards, and the use of cost data to continue building quality evidence around aquaculture interventions. based on the corpus of texts labeled manually. Our computational experiments showed that usage of rules in combination with cosine similarity could increase the accuracy of recognition of the names of metabolites compared to the rule-based algorithm and application of a machine-learning algorithm (conditional random fields). tools and how highly educated and experienced researchers can adapt to a job market that is increasingly challenged by new technologies. settings (SMD –0.47, 95% CrI –0.86 to –0.09). There was weak evidence that cognitive–behavioural interventions may prevent anxiety in universal (SMD –0.07, 95% CrI –0.23 to 0.05) and targeted (SMD –0.38, 95% CrI –0.84 to 0.07) primary school settings. There was weak evidence that cognitive–behavioural (SMD –0.04, 95% CrI –0.16 to 0.07) and cognitive–behavioural + interpersonal therapy (SMD –0.18, 95% CrI –0.46 to 0.08) may be effective in preventing depression in universal secondary school settings. Third-wave (SMD –0.35, 95% CrI –0.70 to 0.00) and cognitive–behavioural interventions (SMD –0.11, 95% CrI –0.28 to 0.05) incorporating a psychoeducation component may be effective at preventing depression immediately post intervention. There was no evidence of intervention effectiveness in targeted secondary, targeted primary or universal primary school settings post intervention. The results for university settings were unreliable because of inconsistency in the network meta-analysis. A narrative summary was reported for five conduct disorder prevention studies, all in primary school settings. None reported the primary outcome at the primary post-intervention time point. The economic evidence review reported heterogeneous findings from six studies. Taking the perspective of a single school budget and based on cognitive–behavioural therapy intervention costs in universal secondary school settings, the cost–consequence analysis estimated an intervention cost of £43 per student. Limitations The emphasis on disorder-specific prevention excluded broader mental health interventions and restricted the number of eligible conduct disorder prevention studies. Restricting the study to interventions delivered in the educational setting may have limited the number of eligible university-level interventions. Conclusions There was weak evidence of the effectiveness of school-based, disorder-specific prevention interventions, although effects were modest and the evidence not robust. Cognitive–behavioural therapy-based interventions may be more effective if they include a psychoeducation component. Future work Future trials for prevention of anxiety and depression should evaluate cognitive–behavioural interventions with and without a psychoeducation component, and include mindfulness/relaxation or exercise comparators, with sufficient follow-up. Cost implications must be adequately measured. Study registration This study is registered as PROSPERO CRD42016048184. Funding This project was funded by the National Institute for Health Research (NIHR) Public Health Research programme and will be published in full in Public Health Research ; Vol. 9, No. 8. See the NIHR Journals Library website for further project information. and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2021
DA  - 2021-12-01
JO  - {'id': 'https://openalex.org/S2739193000', 'issn_l': '1891-1803', 'issn': ['1891-1803'], 'display_name': 'Campbell Systematic Reviews', 'publisher': 'The Campbell Collaboration', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Constanza Gonzalez Parrao
AU  - Shannon Shisler
AU  - Marta Moratti
AU  - Cem Yavuz
AU  - Arnab Acharya
AU  - John Eyers
AU  - Birte Snilstveit
ER  - 

541.
TY  - journal-article
ID  - https://openalex.org/W3202798799
DO  - https://doi.org/10.1177/02611929211048447
TI  - The Use of Artificial Intelligence for the Fast and Effective Identification of Three Rs-based Literature
AB  - No Abstract Found
PY  - 2021
DA  - 2021-09-28
JO  - {'id': 'https://openalex.org/S35160907', 'issn_l': '0261-1929', 'issn': ['2632-3559', '0261-1929'], 'display_name': 'Atla-alternatives To Laboratory Animals', 'publisher': 'Fund for the Replacement of Animals in Medical Experiments', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Merel Ritskes-Hoitinga
AU  - Wynand Alkema
ER  - 

542.
TY  - journal-article
ID  - https://openalex.org/W4225123286
DO  - https://doi.org/10.1145/3522586
TI  - Defining a Knowledge Graph Development Process Through a Systematic Review
AB  - Knowledge graphs are widely used in industry and studied within the academic community. However, the models applied in the development of knowledge graphs vary. Analysing and providing a synthesis of the commonly used approaches to knowledge graph development would provide researchers and practitioners a better understanding of the overall process and methods involved. Hence, this article aims at defining the overall process of knowledge graph development and its key constituent steps. For this purpose, a systematic review and a conceptual analysis of the literature was conducted. The resulting process was compared to case studies to evaluate its applicability. The proposed process suggests a unified approach and provides guidance for both researchers and practitioners when constructing and managing knowledge graphs. impact evaluations assessing the effect of 13 aquaculture interventions in low- and lower-middle income countries. Twelve of these studies have a high risk of bias. Aquaculture interventions lead to a small increase in the production value, income, total expenditures and food consumption of participants. The limited availability of evidence prevented us from assessing other nutritional and women's empowerment outcomes. We identified barriers and facilitators affecting the programmes' set up, the participation of beneficiaries, and the level of productive activities. Insufficient cost data hindered full comparisons across programmes. Conclusions The review suggests a lack of rigorous evidence assessing the effectiveness of aquaculture programmes. Future research could focus on evaluating nutrition and women's empowerment impacts, promoting reporting standards, and the use of cost data to continue building quality evidence around aquaculture interventions. based on the corpus of texts labeled manually. Our computational experiments showed that usage of rules in combination with cosine similarity could increase the accuracy of recognition of the names of metabolites compared to the rule-based algorithm and application of a machine-learning algorithm (conditional random fields). tools and how highly educated and experienced researchers can adapt to a job market that is increasingly challenged by new technologies. settings (SMD –0.47, 95% CrI –0.86 to –0.09). There was weak evidence that cognitive–behavioural interventions may prevent anxiety in universal (SMD –0.07, 95% CrI –0.23 to 0.05) and targeted (SMD –0.38, 95% CrI –0.84 to 0.07) primary school settings. There was weak evidence that cognitive–behavioural (SMD –0.04, 95% CrI –0.16 to 0.07) and cognitive–behavioural + interpersonal therapy (SMD –0.18, 95% CrI –0.46 to 0.08) may be effective in preventing depression in universal secondary school settings. Third-wave (SMD –0.35, 95% CrI –0.70 to 0.00) and cognitive–behavioural interventions (SMD –0.11, 95% CrI –0.28 to 0.05) incorporating a psychoeducation component may be effective at preventing depression immediately post intervention. There was no evidence of intervention effectiveness in targeted secondary, targeted primary or universal primary school settings post intervention. The results for university settings were unreliable because of inconsistency in the network meta-analysis. A narrative summary was reported for five conduct disorder prevention studies, all in primary school settings. None reported the primary outcome at the primary post-intervention time point. The economic evidence review reported heterogeneous findings from six studies. Taking the perspective of a single school budget and based on cognitive–behavioural therapy intervention costs in universal secondary school settings, the cost–consequence analysis estimated an intervention cost of £43 per student. Limitations The emphasis on disorder-specific prevention excluded broader mental health interventions and restricted the number of eligible conduct disorder prevention studies. Restricting the study to interventions delivered in the educational setting may have limited the number of eligible university-level interventions. Conclusions There was weak evidence of the effectiveness of school-based, disorder-specific prevention interventions, although effects were modest and the evidence not robust. Cognitive–behavioural therapy-based interventions may be more effective if they include a psychoeducation component. Future work Future trials for prevention of anxiety and depression should evaluate cognitive–behavioural interventions with and without a psychoeducation component, and include mindfulness/relaxation or exercise comparators, with sufficient follow-up. Cost implications must be adequately measured. Study registration This study is registered as PROSPERO CRD42016048184. Funding This project was funded by the National Institute for Health Research (NIHR) Public Health Research programme and will be published in full in Public Health Research ; Vol. 9, No. 8. See the NIHR Journals Library website for further project information. and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2022
DA  - 2022-04-30
JO  - {'id': 'https://openalex.org/S142627899', 'issn_l': '1049-331X', 'issn': ['1049-331X', '1557-7392'], 'display_name': 'ACM Transactions on Software Engineering and Methodology', 'publisher': 'Association for Computing Machinery', 'type': 'journal', 'url': 'https://dl.acm.org/doi/pdf/10.1145/3522586', 'is_oa': True, 'version': 'publishedVersion', 'license': None}
DP  - OpenAlex
AU  - Gytė Tamašauskaitė
AU  - Paul Groth
ER  - 

543.
TY  - journal-article
ID  - https://openalex.org/W3137020110
DO  - https://doi.org/10.1002/jrsm.1486
TI  - Machine learning for identifying relevant publications in updates of systematic reviews of diagnostic test studies
AB  - Updating systematic reviews is often a time-consuming process that involves a lot of human effort and is therefore not conducted as often as it should be. The aim of our research project was to explore the potential of machine learning methods to reduce human workload. Furthermore, we evaluated the performance of deep learning methods in comparison to more established machine learning methods. We used three available reviews of diagnostic test studies as the data set. In order to identify relevant publications, we used typical text pre-processing methods. The reference standard for the evaluation was the human-consensus based on binary classification (inclusion, exclusion). For the evaluation of the models, various scenarios were generated using a grid of combinations of data preprocessing steps. Moreover, we evaluated each machine learning approach with an approach-specific predefined grid of tuning parameters using the Brier score metric. The best performance was obtained with an ensemble method for two of the reviews, and by a deep learning approach for the other review. Yet, the final performance of approaches strongly depends on data preparation. Overall, machine learning methods provided reasonable classification. It seems possible to reduce human workload in updating systematic reviews by using machine learning methods. Yet, as the influence of data preprocessing on the final performance seems to be at least as important as choosing the specific machine learning approach, users should not blindly expect a good performance by solely using approaches from a popular class, such as deep learning. quality evidence around aquaculture interventions. based on the corpus of texts labeled manually. Our computational experiments showed that usage of rules in combination with cosine similarity could increase the accuracy of recognition of the names of metabolites compared to the rule-based algorithm and application of a machine-learning algorithm (conditional random fields). tools and how highly educated and experienced researchers can adapt to a job market that is increasingly challenged by new technologies. settings (SMD –0.47, 95% CrI –0.86 to –0.09). There was weak evidence that cognitive–behavioural interventions may prevent anxiety in universal (SMD –0.07, 95% CrI –0.23 to 0.05) and targeted (SMD –0.38, 95% CrI –0.84 to 0.07) primary school settings. There was weak evidence that cognitive–behavioural (SMD –0.04, 95% CrI –0.16 to 0.07) and cognitive–behavioural + interpersonal therapy (SMD –0.18, 95% CrI –0.46 to 0.08) may be effective in preventing depression in universal secondary school settings. Third-wave (SMD –0.35, 95% CrI –0.70 to 0.00) and cognitive–behavioural interventions (SMD –0.11, 95% CrI –0.28 to 0.05) incorporating a psychoeducation component may be effective at preventing depression immediately post intervention. There was no evidence of intervention effectiveness in targeted secondary, targeted primary or universal primary school settings post intervention. The results for university settings were unreliable because of inconsistency in the network meta-analysis. A narrative summary was reported for five conduct disorder prevention studies, all in primary school settings. None reported the primary outcome at the primary post-intervention time point. The economic evidence review reported heterogeneous findings from six studies. Taking the perspective of a single school budget and based on cognitive–behavioural therapy intervention costs in universal secondary school settings, the cost–consequence analysis estimated an intervention cost of £43 per student. Limitations The emphasis on disorder-specific prevention excluded broader mental health interventions and restricted the number of eligible conduct disorder prevention studies. Restricting the study to interventions delivered in the educational setting may have limited the number of eligible university-level interventions. Conclusions There was weak evidence of the effectiveness of school-based, disorder-specific prevention interventions, although effects were modest and the evidence not robust. Cognitive–behavioural therapy-based interventions may be more effective if they include a psychoeducation component. Future work Future trials for prevention of anxiety and depression should evaluate cognitive–behavioural interventions with and without a psychoeducation component, and include mindfulness/relaxation or exercise comparators, with sufficient follow-up. Cost implications must be adequately measured. Study registration This study is registered as PROSPERO CRD42016048184. Funding This project was funded by the National Institute for Health Research (NIHR) Public Health Research programme and will be published in full in Public Health Research ; Vol. 9, No. 8. See the NIHR Journals Library website for further project information. and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2021
DA  - 2021-03-15
JO  - {'id': 'https://openalex.org/S205768342', 'issn_l': '1759-2879', 'issn': ['1759-2879', '1759-2887'], 'display_name': 'Research Synthesis Methods', 'publisher': 'Wiley-Blackwell', 'type': 'journal', 'url': 'https://doi.org/10.1002/jrsm.1486', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Toni Lange
AU  - Guido Schwarzer
AU  - Thomas Datzmann
AU  - Harald Binder
ER  - 

544.
TY  - journal-article
ID  - https://openalex.org/W3190241871
DO  - https://doi.org/10.1002/cl2.1180
TI  - PROTOCOL: Strengthening women's empowerment and gender equality in fragile contexts towards peaceful and inclusive societies: A systematic review and meta‐analysis
AB  - This review builds on 3ie's (international initiative for impact evaluation) evidence gap map (EGM) of the impact evaluation and systematic review (SR) evidence base of interventions aiming to promote peaceful and inclusive societies in fragile contexts. The EGM identified a cluster of studies evaluating gender equality-focused behaviour change communication programmes and raised interest in investigating the evidence base for understanding the role of women more broadly as agents of change in developing peaceful and inclusive societies. Building on the cluster of evidence identified in the EGM, our review will increase generalisability of findings from single studies and focus on interventions across a broad range of geographical locations, settings and populations, types of implementations and outcomes. We will also address (when possible) the identified gaps in literature regarding metaanalysis in conflict-affected contexts. As such, we propose the following objectives: (1) The primary objective of this review is to identify, assess and synthesise evidence on the effect of gender specific and gender transformative interventions within the context of the four pillars of United Nations Security Council Resolution (UNSCR) 1325 on women's empowerment and gender equality in Fragile and Conflict Affected States/Situations (FCAS). The SR will facilitate the use of evidence in informing policy and practice decisions within the field of transition aid, particularly as it relates to gender focused programming. (2) Our second objective is to assess how these interventions contribute to inclusive and sustainable peace in conflict affected situations. We will compare the effectiveness of these different types of interventions through the lenses of their ecological level, types of impact on women's empowerment, local context of gender inequality and conflict. To achieve these objectives we aim to answer the following questions: (1) What are the impacts of gender transformative and specific interventions on women's empowerment and gender equality in FCAS? (2) What are the effects of these interventions on sustainable peace? (3) To what extent do effects vary by population group, ecological level and types of interventions? (4) What are contextual barriers to and facilitators of intervention effectiveness? –0.07, 95% CrI –0.23 to 0.05) and targeted (SMD –0.38, 95% CrI –0.84 to 0.07) primary school settings. There was weak evidence that cognitive–behavioural (SMD –0.04, 95% CrI –0.16 to 0.07) and cognitive–behavioural + interpersonal therapy (SMD –0.18, 95% CrI –0.46 to 0.08) may be effective in preventing depression in universal secondary school settings. Third-wave (SMD –0.35, 95% CrI –0.70 to 0.00) and cognitive–behavioural interventions (SMD –0.11, 95% CrI –0.28 to 0.05) incorporating a psychoeducation component may be effective at preventing depression immediately post intervention. There was no evidence of intervention effectiveness in targeted secondary, targeted primary or universal primary school settings post intervention. The results for university settings were unreliable because of inconsistency in the network meta-analysis. A narrative summary was reported for five conduct disorder prevention studies, all in primary school settings. None reported the primary outcome at the primary post-intervention time point. The economic evidence review reported heterogeneous findings from six studies. Taking the perspective of a single school budget and based on cognitive–behavioural therapy intervention costs in universal secondary school settings, the cost–consequence analysis estimated an intervention cost of £43 per student. Limitations The emphasis on disorder-specific prevention excluded broader mental health interventions and restricted the number of eligible conduct disorder prevention studies. Restricting the study to interventions delivered in the educational setting may have limited the number of eligible university-level interventions. Conclusions There was weak evidence of the effectiveness of school-based, disorder-specific prevention interventions, although effects were modest and the evidence not robust. Cognitive–behavioural therapy-based interventions may be more effective if they include a psychoeducation component. Future work Future trials for prevention of anxiety and depression should evaluate cognitive–behavioural interventions with and without a psychoeducation component, and include mindfulness/relaxation or exercise comparators, with sufficient follow-up. Cost implications must be adequately measured. Study registration This study is registered as PROSPERO CRD42016048184. Funding This project was funded by the National Institute for Health Research (NIHR) Public Health Research programme and will be published in full in Public Health Research ; Vol. 9, No. 8. See the NIHR Journals Library website for further project information. and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2021
DA  - 2021-09-01
JO  - {'id': 'https://openalex.org/S2739193000', 'issn_l': '1891-1803', 'issn': ['1891-1803'], 'display_name': 'Campbell Systematic Reviews', 'publisher': 'The Campbell Collaboration', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Etienne Lwamba
AU  - Will Ridlehoover
AU  - Meital Kupfer
AU  - Shannon Shisler
AU  - Ada Sonnenfeld
AU  - Laurenz Langer
AU  - John Eyers
AU  - Sean Grant
AU  - Bidisha Barooah
ER  - 

545.
TY  - journal-article
ID  - https://openalex.org/W3193696667
DO  - https://doi.org/10.12688/wellcomeopenres.17141.1
TI  - Cost-effectiveness of Microsoft Academic Graph with machine learning for automated study identification in a living map of coronavirus disease 2019 (COVID-19) research
AB  - <ns4:p><ns4:bold>Background:</ns4:bold> Conventionally, searching for eligible articles to include in systematic reviews and maps of research has relied primarily on information specialists conducting Boolean searches of multiple databases and manually processing the results, including deduplication between these multiple sources. Searching one, comprehensive source, rather than multiple databases, could save time and resources. Microsoft Academic Graph (MAG) is potentially such a source, containing a network graph structure which provides metadata that can be exploited in machine learning processes. Research is needed to establish the relative advantage of using MAG as a single source, compared with conventional searches of multiple databases. This study sought to establish whether: (a) MAG is sufficiently comprehensive to maintain our living map of coronavirus disease 2019 (COVID-19) research; and (b) eligible records can be identified with an acceptably high level of specificity.</ns4:p><ns4:p> <ns4:bold>Methods: </ns4:bold>We conducted a pragmatic, eight-arm cost-effectiveness analysis (simulation study) to assess the costs, recall and precision of our semi-automated MAG-enabled workflow versus conventional searches of MEDLINE and Embase (with and without machine learning classifiers, active learning and/or fixed screening targets) for maintaining a living map of COVID-19 research. Resource use data (time use) were collected from information specialists and other researchers involved in map production.</ns4:p><ns4:p> <ns4:bold>Results: </ns4:bold>MAG-enabled workflows dominated MEDLINE-Embase workflows in both the base case and sensitivity analyses. At one month (base case analysis) our MAG-enabled workflow with machine learning, active learning and fixed screening targets identified n=469 more new, eligible articles for inclusion in our living map – and cost £3,179 GBP ($5,691 AUD) less – than conventional MEDLINE-Embase searches without any automation or fixed screening targets.</ns4:p><ns4:p> <ns4:bold>Conclusions: </ns4:bold>MAG-enabled continuous surveillance workflows have potential to revolutionise study identification methods for living maps, specialised registers, databases of research studies and/or collections of systematic reviews, by increasing their recall and coverage, whilst reducing production costs.</ns4:p> What are the effects of these interventions on sustainable peace? (3) To what extent do effects vary by population group, ecological level and types of interventions? (4) What are contextual barriers to and facilitators of intervention effectiveness? –0.07, 95% CrI –0.23 to 0.05) and targeted (SMD –0.38, 95% CrI –0.84 to 0.07) primary school settings. There was weak evidence that cognitive–behavioural (SMD –0.04, 95% CrI –0.16 to 0.07) and cognitive–behavioural + interpersonal therapy (SMD –0.18, 95% CrI –0.46 to 0.08) may be effective in preventing depression in universal secondary school settings. Third-wave (SMD –0.35, 95% CrI –0.70 to 0.00) and cognitive–behavioural interventions (SMD –0.11, 95% CrI –0.28 to 0.05) incorporating a psychoeducation component may be effective at preventing depression immediately post intervention. There was no evidence of intervention effectiveness in targeted secondary, targeted primary or universal primary school settings post intervention. The results for university settings were unreliable because of inconsistency in the network meta-analysis. A narrative summary was reported for five conduct disorder prevention studies, all in primary school settings. None reported the primary outcome at the primary post-intervention time point. The economic evidence review reported heterogeneous findings from six studies. Taking the perspective of a single school budget and based on cognitive–behavioural therapy intervention costs in universal secondary school settings, the cost–consequence analysis estimated an intervention cost of £43 per student. Limitations The emphasis on disorder-specific prevention excluded broader mental health interventions and restricted the number of eligible conduct disorder prevention studies. Restricting the study to interventions delivered in the educational setting may have limited the number of eligible university-level interventions. Conclusions There was weak evidence of the effectiveness of school-based, disorder-specific prevention interventions, although effects were modest and the evidence not robust. Cognitive–behavioural therapy-based interventions may be more effective if they include a psychoeducation component. Future work Future trials for prevention of anxiety and depression should evaluate cognitive–behavioural interventions with and without a psychoeducation component, and include mindfulness/relaxation or exercise comparators, with sufficient follow-up. Cost implications must be adequately measured. Study registration This study is registered as PROSPERO CRD42016048184. Funding This project was funded by the National Institute for Health Research (NIHR) Public Health Research programme and will be published in full in Public Health Research ; Vol. 9, No. 8. See the NIHR Journals Library website for further project information. and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2021
DA  - 2021-08-19
JO  - {'id': 'https://openalex.org/S4306534713', 'issn_l': '2398-502X', 'issn': ['2398-502X'], 'display_name': 'Wellcome Open Research', 'publisher': 'Wellcome', 'type': 'journal', 'url': 'https://doi.org/10.12688/wellcomeopenres.17141.1', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Ian Shemilt
AU  - Anneliese Arno
AU  - James D. Thomas
AU  - Theo Lorenc
AU  - Claire Louise Khouja
AU  - Gary Raine
AU  - Katy Sutcliffe
AU  - D'Souza Preethy
AU  - Irene Kwan
AU  - Kath Wright
AU  - Amanda Sowden
ER  - 

546.
TY  - journal-article
ID  - https://openalex.org/W4205109317
DO  - https://doi.org/10.1002/jrsm.1545
TI  - Identifying unreported links between ClinicalTrials.gov trial registrations and their published results
AB  - A substantial proportion of trial registrations are not linked to corresponding published articles, limiting analyses and new tools. Our aim was to develop a method for finding articles reporting the results of trials that are registered on ClinicalTrials.gov when they do not include metadata links. We used a set of 27,280 trial registration and article pairs to train and evaluate methods for identifying missing links in both directions-from articles to registrations and from registrations to articles. We trained a classifier with six distance metrics as feature representations to rank the correct article or registration, using recall@K to evaluate performance and compare to baseline methods. When identifying links from registrations to published articles, the classifier ranked the correct article first (recall@1) among 378,048 articles in 80.8% of evaluation cases and 34.9% in the baseline method. Recall@10 was 85.1% compared to 60.7% in the baseline. When predicting links from articles to registrations, recall@1 was 83.4% for the classifier and 39.8% in the baseline. Recall@10 was 89.5% compared to 65.8% in the baseline. The proposed method improves on our baseline document similarity method to be feasible for identifying missing links in practice. Given a ClinicalTrials.gov registration, a user checking 10 ranked articles can expect to identify the matching article in at least 85% of cases, if the trial has been published. The proposed method can be used to improve the coupling of ClinicalTrials.gov and PubMed, with applications related to automating systematic review and evidence synthesis processes. map – and cost £3,179 GBP ($5,691 AUD) less – than conventional MEDLINE-Embase searches without any automation or fixed screening targets.</ns4:p><ns4:p> <ns4:bold>Conclusions: </ns4:bold>MAG-enabled continuous surveillance workflows have potential to revolutionise study identification methods for living maps, specialised registers, databases of research studies and/or collections of systematic reviews, by increasing their recall and coverage, whilst reducing production costs.</ns4:p> What are the effects of these interventions on sustainable peace? (3) To what extent do effects vary by population group, ecological level and types of interventions? (4) What are contextual barriers to and facilitators of intervention effectiveness? –0.07, 95% CrI –0.23 to 0.05) and targeted (SMD –0.38, 95% CrI –0.84 to 0.07) primary school settings. There was weak evidence that cognitive–behavioural (SMD –0.04, 95% CrI –0.16 to 0.07) and cognitive–behavioural + interpersonal therapy (SMD –0.18, 95% CrI –0.46 to 0.08) may be effective in preventing depression in universal secondary school settings. Third-wave (SMD –0.35, 95% CrI –0.70 to 0.00) and cognitive–behavioural interventions (SMD –0.11, 95% CrI –0.28 to 0.05) incorporating a psychoeducation component may be effective at preventing depression immediately post intervention. There was no evidence of intervention effectiveness in targeted secondary, targeted primary or universal primary school settings post intervention. The results for university settings were unreliable because of inconsistency in the network meta-analysis. A narrative summary was reported for five conduct disorder prevention studies, all in primary school settings. None reported the primary outcome at the primary post-intervention time point. The economic evidence review reported heterogeneous findings from six studies. Taking the perspective of a single school budget and based on cognitive–behavioural therapy intervention costs in universal secondary school settings, the cost–consequence analysis estimated an intervention cost of £43 per student. Limitations The emphasis on disorder-specific prevention excluded broader mental health interventions and restricted the number of eligible conduct disorder prevention studies. Restricting the study to interventions delivered in the educational setting may have limited the number of eligible university-level interventions. Conclusions There was weak evidence of the effectiveness of school-based, disorder-specific prevention interventions, although effects were modest and the evidence not robust. Cognitive–behavioural therapy-based interventions may be more effective if they include a psychoeducation component. Future work Future trials for prevention of anxiety and depression should evaluate cognitive–behavioural interventions with and without a psychoeducation component, and include mindfulness/relaxation or exercise comparators, with sufficient follow-up. Cost implications must be adequately measured. Study registration This study is registered as PROSPERO CRD42016048184. Funding This project was funded by the National Institute for Health Research (NIHR) Public Health Research programme and will be published in full in Public Health Research ; Vol. 9, No. 8. See the NIHR Journals Library website for further project information. and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2021
DA  - 2021-12-30
JO  - {'id': 'https://openalex.org/V205768342', 'issn_l': '1759-2879', 'issn': ['1759-2879', '1759-2887'], 'display_name': 'Research Synthesis Methods', 'publisher': 'Wiley-Blackwell', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Shifeng Liu
AU  - Florence T. Bourgeois
AU  - Adam G. Dunn
ER  - 

547.
TY  - journal-article
ID  - https://openalex.org/W4206524740
DO  - https://doi.org/10.3233/efi-211567
TI  - Creation of an online inventory for choosing critical appraisal tools
AB  - Critical appraisal of evidence is performed to assess its validity, trustworthiness and usefulness in evidence-based practice. There currently exists a large number and variety of critical appraisal tools (also named risk of bias tools and quality assessment instruments), which makes it challenging to identify and choose an appropriate tool to use. We sought to develop an online inventory to inform librarians, practitioners, graduate students, and researchers about critical appraisal tools. This online inventory was developed from a literature review on critical appraisal tools and is kept up to date using a crowdsourcing collaborative web tool (eSRAP-DIY). To date, 40 tools have been added to the inventory (www.catevaluation.ca), and grouped according to five general categories: (a) quantitative studies, (b) qualitative studies, (c) mixed methods studies, (d) systematic reviews and (e) others. For each tool, a summary is provided with the following information: tool name, study designs, number of items, rating scale, validity, reliability, other information (such as existing websites or previous versions), and main references. Further studies are needed to test and improve the usability of the online inventory, and to find solutions to reduce to monitoring and update workload. Given a ClinicalTrials.gov registration, a user checking 10 ranked articles can expect to identify the matching article in at least 85% of cases, if the trial has been published. The proposed method can be used to improve the coupling of ClinicalTrials.gov and PubMed, with applications related to automating systematic review and evidence synthesis processes. map – and cost £3,179 GBP ($5,691 AUD) less – than conventional MEDLINE-Embase searches without any automation or fixed screening targets.</ns4:p><ns4:p> <ns4:bold>Conclusions: </ns4:bold>MAG-enabled continuous surveillance workflows have potential to revolutionise study identification methods for living maps, specialised registers, databases of research studies and/or collections of systematic reviews, by increasing their recall and coverage, whilst reducing production costs.</ns4:p> What are the effects of these interventions on sustainable peace? (3) To what extent do effects vary by population group, ecological level and types of interventions? (4) What are contextual barriers to and facilitators of intervention effectiveness? –0.07, 95% CrI –0.23 to 0.05) and targeted (SMD –0.38, 95% CrI –0.84 to 0.07) primary school settings. There was weak evidence that cognitive–behavioural (SMD –0.04, 95% CrI –0.16 to 0.07) and cognitive–behavioural + interpersonal therapy (SMD –0.18, 95% CrI –0.46 to 0.08) may be effective in preventing depression in universal secondary school settings. Third-wave (SMD –0.35, 95% CrI –0.70 to 0.00) and cognitive–behavioural interventions (SMD –0.11, 95% CrI –0.28 to 0.05) incorporating a psychoeducation component may be effective at preventing depression immediately post intervention. There was no evidence of intervention effectiveness in targeted secondary, targeted primary or universal primary school settings post intervention. The results for university settings were unreliable because of inconsistency in the network meta-analysis. A narrative summary was reported for five conduct disorder prevention studies, all in primary school settings. None reported the primary outcome at the primary post-intervention time point. The economic evidence review reported heterogeneous findings from six studies. Taking the perspective of a single school budget and based on cognitive–behavioural therapy intervention costs in universal secondary school settings, the cost–consequence analysis estimated an intervention cost of £43 per student. Limitations The emphasis on disorder-specific prevention excluded broader mental health interventions and restricted the number of eligible conduct disorder prevention studies. Restricting the study to interventions delivered in the educational setting may have limited the number of eligible university-level interventions. Conclusions There was weak evidence of the effectiveness of school-based, disorder-specific prevention interventions, although effects were modest and the evidence not robust. Cognitive–behavioural therapy-based interventions may be more effective if they include a psychoeducation component. Future work Future trials for prevention of anxiety and depression should evaluate cognitive–behavioural interventions with and without a psychoeducation component, and include mindfulness/relaxation or exercise comparators, with sufficient follow-up. Cost implications must be adequately measured. Study registration This study is registered as PROSPERO CRD42016048184. Funding This project was funded by the National Institute for Health Research (NIHR) Public Health Research programme and will be published in full in Public Health Research ; Vol. 9, No. 8. See the NIHR Journals Library website for further project information. and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2021
DA  - 2021-12-31
JO  - {'id': 'https://openalex.org/S2764383307', 'issn_l': '0167-8329', 'issn': ['1875-8649', '0167-8329'], 'display_name': 'Education for Information', 'publisher': 'IOS Press', 'type': 'journal', 'url': 'https://content.iospress.com:443/download/education-for-information/efi211567?id=education-for-information%2Fefi211567', 'is_oa': True, 'version': 'publishedVersion', 'license': 'implied-oa'}
DP  - OpenAlex
AU  - Quan Hong
AU  - Julien Bouix-Picasso
AU  - Christian Ruchon
ER  - 

548.
TY  - posted-content
ID  - https://openalex.org/W3199007285
DO  - https://doi.org/10.1101/2021.09.14.21263586
TI  - Investigating the impact of weakly supervised data on text mining models of publication transparency: a case study on randomized controlled trials
AB  - Abstract Lack of large quantities of annotated data is a major barrier in developing effective text mining models of biomedical literature. In this study, we explored weak supervision strategies to improve the accuracy of text classification models developed for assessing methodological transparency of randomized controlled trial (RCT) publications. Specifically, we used Snorkel, a framework to programmatically build training sets, and UMLS-EDA, a data augmentation method that leverages a small number of existing examples to generate new training instances, for weak supervision and assessed their effect on a BioBERT-based text classification model proposed for the task in previous work. Performance improvements due to weak supervision were limited and were surpassed by gains from hyperparameter tuning. Our analysis suggests that refinements to the weak supervision strategies to better deal with multi-label case could be beneficial. a summary is provided with the following information: tool name, study designs, number of items, rating scale, validity, reliability, other information (such as existing websites or previous versions), and main references. Further studies are needed to test and improve the usability of the online inventory, and to find solutions to reduce to monitoring and update workload. Given a ClinicalTrials.gov registration, a user checking 10 ranked articles can expect to identify the matching article in at least 85% of cases, if the trial has been published. The proposed method can be used to improve the coupling of ClinicalTrials.gov and PubMed, with applications related to automating systematic review and evidence synthesis processes. map – and cost £3,179 GBP ($5,691 AUD) less – than conventional MEDLINE-Embase searches without any automation or fixed screening targets.</ns4:p><ns4:p> <ns4:bold>Conclusions: </ns4:bold>MAG-enabled continuous surveillance workflows have potential to revolutionise study identification methods for living maps, specialised registers, databases of research studies and/or collections of systematic reviews, by increasing their recall and coverage, whilst reducing production costs.</ns4:p> What are the effects of these interventions on sustainable peace? (3) To what extent do effects vary by population group, ecological level and types of interventions? (4) What are contextual barriers to and facilitators of intervention effectiveness? –0.07, 95% CrI –0.23 to 0.05) and targeted (SMD –0.38, 95% CrI –0.84 to 0.07) primary school settings. There was weak evidence that cognitive–behavioural (SMD –0.04, 95% CrI –0.16 to 0.07) and cognitive–behavioural + interpersonal therapy (SMD –0.18, 95% CrI –0.46 to 0.08) may be effective in preventing depression in universal secondary school settings. Third-wave (SMD –0.35, 95% CrI –0.70 to 0.00) and cognitive–behavioural interventions (SMD –0.11, 95% CrI –0.28 to 0.05) incorporating a psychoeducation component may be effective at preventing depression immediately post intervention. There was no evidence of intervention effectiveness in targeted secondary, targeted primary or universal primary school settings post intervention. The results for university settings were unreliable because of inconsistency in the network meta-analysis. A narrative summary was reported for five conduct disorder prevention studies, all in primary school settings. None reported the primary outcome at the primary post-intervention time point. The economic evidence review reported heterogeneous findings from six studies. Taking the perspective of a single school budget and based on cognitive–behavioural therapy intervention costs in universal secondary school settings, the cost–consequence analysis estimated an intervention cost of £43 per student. Limitations The emphasis on disorder-specific prevention excluded broader mental health interventions and restricted the number of eligible conduct disorder prevention studies. Restricting the study to interventions delivered in the educational setting may have limited the number of eligible university-level interventions. Conclusions There was weak evidence of the effectiveness of school-based, disorder-specific prevention interventions, although effects were modest and the evidence not robust. Cognitive–behavioural therapy-based interventions may be more effective if they include a psychoeducation component. Future work Future trials for prevention of anxiety and depression should evaluate cognitive–behavioural interventions with and without a psychoeducation component, and include mindfulness/relaxation or exercise comparators, with sufficient follow-up. Cost implications must be adequately measured. Study registration This study is registered as PROSPERO CRD42016048184. Funding This project was funded by the National Institute for Health Research (NIHR) Public Health Research programme and will be published in full in Public Health Research ; Vol. 9, No. 8. See the NIHR Journals Library website for further project information. and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2021
DA  - 2021-09-22
JO  - {'id': 'https://openalex.org/S4306400573', 'issn_l': None, 'issn': None, 'display_name': 'medRxiv (Cold Spring Harbor Laboratory)', 'publisher': 'Cold Spring Harbor Laboratory', 'type': 'repository', 'url': 'https://doi.org/10.1101/2021.09.14.21263586', 'is_oa': True, 'version': 'submittedVersion', 'license': None}
DP  - OpenAlex
AU  - Linh Cao Hoang
AU  - Lan Jiang
AU  - Halil Kilicoglu
ER  - 

549.
TY  - journal-article
ID  - https://openalex.org/W4200536079
DO  - https://doi.org/10.1080/03007995.2021.2015160
TI  - Conducting and critically appraising a high-quality systematic review and Meta-analysis pertaining to COVID-19
AB  - With constantly emerging new information regarding the epidemiology, pathogenesis, diagnosis and management of Coronavirus Disease 2019 (COVID-19), reviewing literature related to it has become increasingly complicated and resource-intensive. In the setting of this global pandemic, clinical decisions are being guided by the results of multiple pertinent studies; however, it has been observed that these studies are often heterogenous in design and population characteristics and results of initial trials may not be replicated in subsequent studies. The resulting clinical conundrum can be resolved by high-quality systematic review and meta-analysis with a robust and reliable methodology, encapsulating and critically appraising all the available literature relevant to the clinical scenario under scrutiny. It can condense the large volume of scientific information available and can also identify the cause of differences in the degree of effect under consideration across different studies. It can identify optimal diagnostic algorithms, assess efficacy of treatment strategies, and analyze inherent factors influencing the efficacy of treatment for COVID-19. The current review aims to provide a basic guide to plan and conduct a high-quality systematic review and meta-analysis pertaining to COVID-19, describing the main steps and addressing the pitfalls commonly encountered at each step. Knowledge of the basic steps would also allow the reader to critically appraise published systematic review and meta-analysis and the quality of evidence provided therein. proposed method can be used to improve the coupling of ClinicalTrials.gov and PubMed, with applications related to automating systematic review and evidence synthesis processes. map – and cost £3,179 GBP ($5,691 AUD) less – than conventional MEDLINE-Embase searches without any automation or fixed screening targets.</ns4:p><ns4:p> <ns4:bold>Conclusions: </ns4:bold>MAG-enabled continuous surveillance workflows have potential to revolutionise study identification methods for living maps, specialised registers, databases of research studies and/or collections of systematic reviews, by increasing their recall and coverage, whilst reducing production costs.</ns4:p> What are the effects of these interventions on sustainable peace? (3) To what extent do effects vary by population group, ecological level and types of interventions? (4) What are contextual barriers to and facilitators of intervention effectiveness? –0.07, 95% CrI –0.23 to 0.05) and targeted (SMD –0.38, 95% CrI –0.84 to 0.07) primary school settings. There was weak evidence that cognitive–behavioural (SMD –0.04, 95% CrI –0.16 to 0.07) and cognitive–behavioural + interpersonal therapy (SMD –0.18, 95% CrI –0.46 to 0.08) may be effective in preventing depression in universal secondary school settings. Third-wave (SMD –0.35, 95% CrI –0.70 to 0.00) and cognitive–behavioural interventions (SMD –0.11, 95% CrI –0.28 to 0.05) incorporating a psychoeducation component may be effective at preventing depression immediately post intervention. There was no evidence of intervention effectiveness in targeted secondary, targeted primary or universal primary school settings post intervention. The results for university settings were unreliable because of inconsistency in the network meta-analysis. A narrative summary was reported for five conduct disorder prevention studies, all in primary school settings. None reported the primary outcome at the primary post-intervention time point. The economic evidence review reported heterogeneous findings from six studies. Taking the perspective of a single school budget and based on cognitive–behavioural therapy intervention costs in universal secondary school settings, the cost–consequence analysis estimated an intervention cost of £43 per student. Limitations The emphasis on disorder-specific prevention excluded broader mental health interventions and restricted the number of eligible conduct disorder prevention studies. Restricting the study to interventions delivered in the educational setting may have limited the number of eligible university-level interventions. Conclusions There was weak evidence of the effectiveness of school-based, disorder-specific prevention interventions, although effects were modest and the evidence not robust. Cognitive–behavioural therapy-based interventions may be more effective if they include a psychoeducation component. Future work Future trials for prevention of anxiety and depression should evaluate cognitive–behavioural interventions with and without a psychoeducation component, and include mindfulness/relaxation or exercise comparators, with sufficient follow-up. Cost implications must be adequately measured. Study registration This study is registered as PROSPERO CRD42016048184. Funding This project was funded by the National Institute for Health Research (NIHR) Public Health Research programme and will be published in full in Public Health Research ; Vol. 9, No. 8. See the NIHR Journals Library website for further project information. and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2021
DA  - 2021-12-06
JO  - {'id': 'https://openalex.org/S206643269', 'issn_l': '0300-7995', 'issn': ['0300-7995', '1473-4877'], 'display_name': 'Current Medical Research and Opinion', 'publisher': 'Informa', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Niraj Nirmal Pandey
AU  - Sanjiv Sharma
ER  - 

550.
TY  - journal-article
ID  - https://openalex.org/W4214574206
DO  - https://doi.org/10.35713/aic.v3.i1.1
TI  - Potential and role of artificial intelligence in current medical healthcare
AB  - No Abstract Found
PY  - 2022
DA  - 2022-02-28
JO  - {'id': 'https://openalex.org/S4210236699', 'issn_l': '2644-3228', 'issn': ['2644-3228'], 'display_name': 'Artificial intelligence in cancer', 'publisher': 'Artificial Intelligence in Cancer', 'type': 'journal', 'url': 'https://doi.org/10.35713/aic.v3.i1.1', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc'}
DP  - OpenAlex
AU  - Chao-Ming Hung
AU  - Hon-Yi Shi
AU  - Po-Huang Lee
AU  - Chao-Sung Chang
AU  - Kun-Ming Rau
AU  - Hui-Ming Lee
AU  - Cheng-Hao Tseng
AU  - Sung-Nan Pei
AU  - Kuen-Jang Tsai
AU  - Chong-Chi Chiu
ER  - 

551.
TY  - journal-article
ID  - https://openalex.org/W4220927925
DO  - https://doi.org/10.1002/cl2.1214
TI  - Strengthening women's empowerment and gender equality in fragile contexts towards peaceful and inclusive societies: A systematic review and meta‐analysis
AB  - Background Across the globe, gender disparities still exist with regard to equitable access to resources, participation in decision-making processes, and gender and sexual-based violence. This is particularly true in fragile and conflict-affected settings, where women and girls are affected by both fragility and conflict in unique ways. While women have been acknowledged as key actors in peace processes and post-conflict reconstruction (e.g., through the United Nations Security Council Resolution 1325 and the Women, Peace and Security Agenda) evidence on the effectiveness of gender-specific and gender-transformative interventions to improve women's empowerment in fragile and conflict-affected states and situations (FCAS) remains understudied. Objectives The purpose of this review was to synthesize the body of evidence around gender-specific and gender-transformative interventions aimed at improving women's empowerment in fragile and conflict-affected settings with high levels of gender inequality. We also aimed to identify barriers and facilitators that could affect the effectiveness of these interventions and to provide implications for policy, practice and research designs within the field of transitional aid. Methods We searched for and screened over 100,000 experimental and quasi-experimental studies focused on FCAS at the individual and community levels. We used standard methodological procedures outlined by the Campbell Collaboration for the data collection and analysis, including quantitative and qualitative analyses, and completed the Grading of Recommendations, Assessment, Development and Evaluations (GRADE) methodology to assess the certainty around each body of evidence. Results We identified 104 impact evaluations (75% randomised controlled trials) assessing the effects of 14 different types of interventions in FCAS. About 28% of included studies were assessed as having a high risk of bias (45% among quasi-experimental designs). Interventions supporting women's empowerment and gender equality in FCAS produced positive effects on the outcomes related to the primary focus of the intervention. There are no significant negative effects of any included interventions. However, we observe smaller effects on behavioural outcomes further along the causal chain of empowerment. Qualitative syntheses indicated that gender norms and practices are potential barriers to intervention effectiveness, while working with local powers and institutions can facilitate the uptake and legitimacy of interventions. Conclusions We observe gaps of rigorous evidence in certain regions (notably MENA and Latin America) and in interventions specifically targeting women as actors of peacebuilding. Gender norms and practices are important elements to consider in programme design and implementation to maximise potential benefits: focusing on empowerment only might not be enough in the absence of targeting the restrictive gender norms and practices that may undermine intervention effectiveness. Lastly, programme designers and implementation should consider explicitly targeting specific empowerment outcomes, promoting social capital and exchange, and tailoring the intervention components to the desired empowerment-related outcomes. post intervention. The results for university settings were unreliable because of inconsistency in the network meta-analysis. A narrative summary was reported for five conduct disorder prevention studies, all in primary school settings. None reported the primary outcome at the primary post-intervention time point. The economic evidence review reported heterogeneous findings from six studies. Taking the perspective of a single school budget and based on cognitive–behavioural therapy intervention costs in universal secondary school settings, the cost–consequence analysis estimated an intervention cost of £43 per student. Limitations The emphasis on disorder-specific prevention excluded broader mental health interventions and restricted the number of eligible conduct disorder prevention studies. Restricting the study to interventions delivered in the educational setting may have limited the number of eligible university-level interventions. Conclusions There was weak evidence of the effectiveness of school-based, disorder-specific prevention interventions, although effects were modest and the evidence not robust. Cognitive–behavioural therapy-based interventions may be more effective if they include a psychoeducation component. Future work Future trials for prevention of anxiety and depression should evaluate cognitive–behavioural interventions with and without a psychoeducation component, and include mindfulness/relaxation or exercise comparators, with sufficient follow-up. Cost implications must be adequately measured. Study registration This study is registered as PROSPERO CRD42016048184. Funding This project was funded by the National Institute for Health Research (NIHR) Public Health Research programme and will be published in full in Public Health Research ; Vol. 9, No. 8. See the NIHR Journals Library website for further project information. and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2022
DA  - 2022-03-01
JO  - {'id': 'https://openalex.org/V2739193000', 'issn_l': '1891-1803', 'issn': ['1891-1803'], 'display_name': 'Campbell Systematic Reviews', 'publisher': 'The Campbell Collaboration', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Etienne Lwamba
AU  - Shannon Shisler
AU  - Will Ridlehoover
AU  - Meital Kupfer
AU  - Nkululeko Tshabalala
AU  - Promise Nduku
AU  - Laurenz Langer
AU  - Sean Grant
AU  - Ada Sonnenfeld
AU  - Daniela Ruiz-De Anda
AU  - John Eyers
AU  - Birte Snilstveit
ER  - 

552.
TY  - book-chapter
ID  - https://openalex.org/W4224885865
DO  - https://doi.org/10.4018/978-1-7998-9702-6.ch008
TI  - Using Machine Learning to Locate Evidence More Efficiently
AB  - Evidence that machine learning can assist article selection and minimize manual screening burden for scholarly research has been documented in the peer-reviewed literature for more than 20 years. Despite the robust evidence and continual technological advances, uptake has been slow among research teams. This chapter discusses the benefits of using machine learning (ML) and other automation tools on bibliographic data and argues that academic librarians are well-positioned to partner with research teams around this application of ML. An overview of the automation approaches used at UNC's Health Sciences Library (HSL) is discussed along with detailed accounts of multiple success stories of when HSL librarians partnered with research teams to locate evidence more efficiently. Finally, a discussion of likely barriers and possible solutions to increase uptake of this technology among academic librarians is provided. inequality. We also aimed to identify barriers and facilitators that could affect the effectiveness of these interventions and to provide implications for policy, practice and research designs within the field of transitional aid. Methods We searched for and screened over 100,000 experimental and quasi-experimental studies focused on FCAS at the individual and community levels. We used standard methodological procedures outlined by the Campbell Collaboration for the data collection and analysis, including quantitative and qualitative analyses, and completed the Grading of Recommendations, Assessment, Development and Evaluations (GRADE) methodology to assess the certainty around each body of evidence. Results We identified 104 impact evaluations (75% randomised controlled trials) assessing the effects of 14 different types of interventions in FCAS. About 28% of included studies were assessed as having a high risk of bias (45% among quasi-experimental designs). Interventions supporting women's empowerment and gender equality in FCAS produced positive effects on the outcomes related to the primary focus of the intervention. There are no significant negative effects of any included interventions. However, we observe smaller effects on behavioural outcomes further along the causal chain of empowerment. Qualitative syntheses indicated that gender norms and practices are potential barriers to intervention effectiveness, while working with local powers and institutions can facilitate the uptake and legitimacy of interventions. Conclusions We observe gaps of rigorous evidence in certain regions (notably MENA and Latin America) and in interventions specifically targeting women as actors of peacebuilding. Gender norms and practices are important elements to consider in programme design and implementation to maximise potential benefits: focusing on empowerment only might not be enough in the absence of targeting the restrictive gender norms and practices that may undermine intervention effectiveness. Lastly, programme designers and implementation should consider explicitly targeting specific empowerment outcomes, promoting social capital and exchange, and tailoring the intervention components to the desired empowerment-related outcomes. post intervention. The results for university settings were unreliable because of inconsistency in the network meta-analysis. A narrative summary was reported for five conduct disorder prevention studies, all in primary school settings. None reported the primary outcome at the primary post-intervention time point. The economic evidence review reported heterogeneous findings from six studies. Taking the perspective of a single school budget and based on cognitive–behavioural therapy intervention costs in universal secondary school settings, the cost–consequence analysis estimated an intervention cost of £43 per student. Limitations The emphasis on disorder-specific prevention excluded broader mental health interventions and restricted the number of eligible conduct disorder prevention studies. Restricting the study to interventions delivered in the educational setting may have limited the number of eligible university-level interventions. Conclusions There was weak evidence of the effectiveness of school-based, disorder-specific prevention interventions, although effects were modest and the evidence not robust. Cognitive–behavioural therapy-based interventions may be more effective if they include a psychoeducation component. Future work Future trials for prevention of anxiety and depression should evaluate cognitive–behavioural interventions with and without a psychoeducation component, and include mindfulness/relaxation or exercise comparators, with sufficient follow-up. Cost implications must be adequately measured. Study registration This study is registered as PROSPERO CRD42016048184. Funding This project was funded by the National Institute for Health Research (NIHR) Public Health Research programme and will be published in full in Public Health Research ; Vol. 9, No. 8. See the NIHR Journals Library website for further project information. and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2022
DA  - 2022-05-06
JO  - {'id': 'https://openalex.org/S4306463409', 'issn_l': None, 'issn': None, 'display_name': 'IGI Global eBooks', 'publisher': 'IGI Global', 'type': 'ebook platform', 'url': 'https://doi.org/10.4018/978-1-7998-9702-6.ch008', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Michelle Cawley
ER  - 

553.
TY  - journal-article
ID  - https://openalex.org/W4281789780
DO  - https://doi.org/10.1016/j.jclinepi.2022.05.017
TI  - A text-mining tool generated title-abstract screening workload savings: performance evaluation versus single-human screening
AB  - <h2>Abstract</h2><h3>Background and Objectives</h3> Text-mining tool, Abstrackr, may potentially reduce the workload burden of title and abstract screening (Stage 1), using screening prioritization and truncation. This study aimed to evaluate the performance of Abstrackr's text-mining functions (‘Abstrackr-assisted screening'; screening undertaken by a single-human screener and Abstrackr) vs. Single-human screening. <h3>Methods</h3> A systematic review of treatments for relapsed/refractory diffuse large B cell lymphoma (<i>n</i> = 7,723) was used. Citations, uploaded to Abstrackr, were screened by a human screener until a pre-specified maximum prediction score of 0.39540 was reached. Abstrackr's predictions were compared with the judgments of a second, human screener (who screened all citations in Covidence). The performance metrics were sensitivity, specificity, precision, false negative rate, proportion of relevant citations missed, workload savings, and time savings. <h3>Results</h3> Abstrackr reduced Stage 1 workload by 67% (5.4 days), when compared with Single-human screening. Sensitivity was high (91%). The false negative rate at Stage 1 was 9%; however, none of those citations were included following full-text screening. The high proportion of false positives (<i>n</i> = 2,001) resulted in low specificity (72%) and precision (15.5%). <h3>Conclusion</h3> Abstrackr-assisted screening provided Stage 1 workload savings that did not come at the expense of omitting relevant citations. However, Abstrackr overestimated citation relevance, which may have negative workload implications at full-text screening. of Recommendations, Assessment, Development and Evaluations (GRADE) methodology to assess the certainty around each body of evidence. Results We identified 104 impact evaluations (75% randomised controlled trials) assessing the effects of 14 different types of interventions in FCAS. About 28% of included studies were assessed as having a high risk of bias (45% among quasi-experimental designs). Interventions supporting women's empowerment and gender equality in FCAS produced positive effects on the outcomes related to the primary focus of the intervention. There are no significant negative effects of any included interventions. However, we observe smaller effects on behavioural outcomes further along the causal chain of empowerment. Qualitative syntheses indicated that gender norms and practices are potential barriers to intervention effectiveness, while working with local powers and institutions can facilitate the uptake and legitimacy of interventions. Conclusions We observe gaps of rigorous evidence in certain regions (notably MENA and Latin America) and in interventions specifically targeting women as actors of peacebuilding. Gender norms and practices are important elements to consider in programme design and implementation to maximise potential benefits: focusing on empowerment only might not be enough in the absence of targeting the restrictive gender norms and practices that may undermine intervention effectiveness. Lastly, programme designers and implementation should consider explicitly targeting specific empowerment outcomes, promoting social capital and exchange, and tailoring the intervention components to the desired empowerment-related outcomes. post intervention. The results for university settings were unreliable because of inconsistency in the network meta-analysis. A narrative summary was reported for five conduct disorder prevention studies, all in primary school settings. None reported the primary outcome at the primary post-intervention time point. The economic evidence review reported heterogeneous findings from six studies. Taking the perspective of a single school budget and based on cognitive–behavioural therapy intervention costs in universal secondary school settings, the cost–consequence analysis estimated an intervention cost of £43 per student. Limitations The emphasis on disorder-specific prevention excluded broader mental health interventions and restricted the number of eligible conduct disorder prevention studies. Restricting the study to interventions delivered in the educational setting may have limited the number of eligible university-level interventions. Conclusions There was weak evidence of the effectiveness of school-based, disorder-specific prevention interventions, although effects were modest and the evidence not robust. Cognitive–behavioural therapy-based interventions may be more effective if they include a psychoeducation component. Future work Future trials for prevention of anxiety and depression should evaluate cognitive–behavioural interventions with and without a psychoeducation component, and include mindfulness/relaxation or exercise comparators, with sufficient follow-up. Cost implications must be adequately measured. Study registration This study is registered as PROSPERO CRD42016048184. Funding This project was funded by the National Institute for Health Research (NIHR) Public Health Research programme and will be published in full in Public Health Research ; Vol. 9, No. 8. See the NIHR Journals Library website for further project information. and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2022
DA  - 2022-05-01
JO  - {'id': 'https://openalex.org/S64418186', 'issn_l': '0895-4356', 'issn': ['1878-5921', '0895-4356'], 'display_name': 'Journal of Clinical Epidemiology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'http://www.jclinepi.com/article/S0895435622001391/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Niamh Carey
AU  - Marie T. Harte
AU  - Laura Mc Cullagh
ER  - 

554.
TY  - journal-article
ID  - https://openalex.org/W4283159388
DO  - https://doi.org/10.1016/j.jclinepi.2022.06.007
TI  - A novel tool that allows interactive screening of PubMed citations showed promise for the semi-automation of identification of Biomedical Literature
AB  - Systematic reviews form the basis of evidence-based medicine, but are expensive and time-consuming to produce. To address this burden, we have developed a literature identification system (Pythia) that combines the query formulation and citation screening steps.Pythia incorporates a set of natural-language questions with machine-learning algorithms to rank all PubMed citations based on relevance, returning the 100 top-ranked citations for human screening. The tagged citations are iteratively exploited by Pythia to refine the search and re-rank the citations.Across seven systematic reviews, the ability of Pythia to identify the relevant citations (sensitivity) ranged from 0.09 to 0.58. The number of abstracts reviewed per relevant abstract number needed to read (NNR) was lower than in the manually screened project in four reviews, higher in two, and had mixed results in one. The reviews that had greater overall sensitivity retrieved more relevant citations in early batches, but retrieval was generally unaffected by other aspects, such as study design, study size, and specific key question.Due to its low sensitivity, Pythia is not ready for widespread use. Future research should explore ways to encode domain knowledge in query formulation to better enrich the questions used in the search. the expense of omitting relevant citations. However, Abstrackr overestimated citation relevance, which may have negative workload implications at full-text screening. of Recommendations, Assessment, Development and Evaluations (GRADE) methodology to assess the certainty around each body of evidence. Results We identified 104 impact evaluations (75% randomised controlled trials) assessing the effects of 14 different types of interventions in FCAS. About 28% of included studies were assessed as having a high risk of bias (45% among quasi-experimental designs). Interventions supporting women's empowerment and gender equality in FCAS produced positive effects on the outcomes related to the primary focus of the intervention. There are no significant negative effects of any included interventions. However, we observe smaller effects on behavioural outcomes further along the causal chain of empowerment. Qualitative syntheses indicated that gender norms and practices are potential barriers to intervention effectiveness, while working with local powers and institutions can facilitate the uptake and legitimacy of interventions. Conclusions We observe gaps of rigorous evidence in certain regions (notably MENA and Latin America) and in interventions specifically targeting women as actors of peacebuilding. Gender norms and practices are important elements to consider in programme design and implementation to maximise potential benefits: focusing on empowerment only might not be enough in the absence of targeting the restrictive gender norms and practices that may undermine intervention effectiveness. Lastly, programme designers and implementation should consider explicitly targeting specific empowerment outcomes, promoting social capital and exchange, and tailoring the intervention components to the desired empowerment-related outcomes. post intervention. The results for university settings were unreliable because of inconsistency in the network meta-analysis. A narrative summary was reported for five conduct disorder prevention studies, all in primary school settings. None reported the primary outcome at the primary post-intervention time point. The economic evidence review reported heterogeneous findings from six studies. Taking the perspective of a single school budget and based on cognitive–behavioural therapy intervention costs in universal secondary school settings, the cost–consequence analysis estimated an intervention cost of £43 per student. Limitations The emphasis on disorder-specific prevention excluded broader mental health interventions and restricted the number of eligible conduct disorder prevention studies. Restricting the study to interventions delivered in the educational setting may have limited the number of eligible university-level interventions. Conclusions There was weak evidence of the effectiveness of school-based, disorder-specific prevention interventions, although effects were modest and the evidence not robust. Cognitive–behavioural therapy-based interventions may be more effective if they include a psychoeducation component. Future work Future trials for prevention of anxiety and depression should evaluate cognitive–behavioural interventions with and without a psychoeducation component, and include mindfulness/relaxation or exercise comparators, with sufficient follow-up. Cost implications must be adequately measured. Study registration This study is registered as PROSPERO CRD42016048184. Funding This project was funded by the National Institute for Health Research (NIHR) Public Health Research programme and will be published in full in Public Health Research ; Vol. 9, No. 8. See the NIHR Journals Library website for further project information. and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2022
DA  - 2022-06-01
JO  - {'id': 'https://openalex.org/S64418186', 'issn_l': '0895-4356', 'issn': ['1878-5921', '0895-4356'], 'display_name': 'Journal of Clinical Epidemiology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Gaelen P Adam
AU  - Dimitris Pappas
AU  - Haris Papageorgiou
AU  - Evangelos Evangelou
AU  - Thomas A Trikalinos
ER  - 

555.
TY  - posted-content
ID  - https://openalex.org/W4292764307
DO  - https://doi.org/10.1101/2022.08.22.22279090
TI  - Mapping topography and network of brain injury in patients with disorders of consciousness
AB  - Abstract There is growing interest in the topography of brain regions associated with disorders of consciousness. This has caused increased research output, yielding many publications investigating the topic with varying methodologies. The objective of this study was to ascertain the topographical regions of the brain most frequently associated with disorders of consciousness. We performed a cross-sectional text mining analysis of disorders of consciousness studies. A text mining algorithm built in the Python programming language searched documents for anatomical brain terminology. We reviewed PubMed studies up to 9 th July 2021 for the search query “Disorders of Consciousness.” The frequency of brain regions mentioned in these articles was recorded, ranked, then built into a graphical network. Subgroup analysis was performed by evaluating the impact on our results if analyses were based on abstracts, full-texts, or topic modelled groups (non-negative matric factorization was used to create subgroups of each collection based on their key topics). Brain terms were ranked by their frequency and concordance was measured between subgroups. Graphical analysis was performed to explore relationships between anatomical regions mentioned. The PageRank algorithm (used by Google to list search results in order of relevance) was used to determine global importance of the regions. The PubMed search yielded 14,945 abstracts and 2178 full-texts. The topic-modelled subgroups contained 2440 abstracts and 367 full-texts. Text Mining across all document groups concordantly ranked the thalamus the highest (Savage score = 14.191). Graphical analysis had 4 clusters: cluster 1 had 20 members with the insular cortex [PageRank =0.167] as the most important member; cluster 2 had 29 members with the amygdala [PageRank =0.0199] being most important; cluster 3 had 10 members with the thalamus [PageRank = 0. 0205] being most important; cluster 4 had 19 members with the cingulate cortex [PageRank = 0. 0.020] being the most important. The cingulate cortex and thalamus are strongly associated with disorders of consciousness, likely due to the roles they play in maintaining awareness and involvement in the Default Mode Network respectively. Other areas of the brain like the cuneus, amygdala and hippocampus should be further investigated. Conclusions We observe gaps of rigorous evidence in certain regions (notably MENA and Latin America) and in interventions specifically targeting women as actors of peacebuilding. Gender norms and practices are important elements to consider in programme design and implementation to maximise potential benefits: focusing on empowerment only might not be enough in the absence of targeting the restrictive gender norms and practices that may undermine intervention effectiveness. Lastly, programme designers and implementation should consider explicitly targeting specific empowerment outcomes, promoting social capital and exchange, and tailoring the intervention components to the desired empowerment-related outcomes. post intervention. The results for university settings were unreliable because of inconsistency in the network meta-analysis. A narrative summary was reported for five conduct disorder prevention studies, all in primary school settings. None reported the primary outcome at the primary post-intervention time point. The economic evidence review reported heterogeneous findings from six studies. Taking the perspective of a single school budget and based on cognitive–behavioural therapy intervention costs in universal secondary school settings, the cost–consequence analysis estimated an intervention cost of £43 per student. Limitations The emphasis on disorder-specific prevention excluded broader mental health interventions and restricted the number of eligible conduct disorder prevention studies. Restricting the study to interventions delivered in the educational setting may have limited the number of eligible university-level interventions. Conclusions There was weak evidence of the effectiveness of school-based, disorder-specific prevention interventions, although effects were modest and the evidence not robust. Cognitive–behavioural therapy-based interventions may be more effective if they include a psychoeducation component. Future work Future trials for prevention of anxiety and depression should evaluate cognitive–behavioural interventions with and without a psychoeducation component, and include mindfulness/relaxation or exercise comparators, with sufficient follow-up. Cost implications must be adequately measured. Study registration This study is registered as PROSPERO CRD42016048184. Funding This project was funded by the National Institute for Health Research (NIHR) Public Health Research programme and will be published in full in Public Health Research ; Vol. 9, No. 8. See the NIHR Journals Library website for further project information. and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2022
DA  - 2022-08-23
JO  - {'id': 'https://openalex.org/S4306400573', 'issn_l': None, 'issn': None, 'display_name': 'medRxiv (Cold Spring Harbor Laboratory)', 'publisher': 'Cold Spring Harbor Laboratory', 'type': 'repository', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Manoj Liyana Arachige
AU  - Udaya Seneviratne
AU  - Nevin John
AU  - Henry Ma
AU  - Thanh G. Phan
ER  - 

556.
TY  - journal-article
ID  - https://openalex.org/W4296546700
DO  - https://doi.org/10.12688/f1000research.125198.1
TI  - (Semi)automated approaches to data extraction for systematic reviews and meta-analyses in social sciences: A living review protocol
AB  - <ns3:p><ns3:bold>Background</ns3:bold>: An abundance of rapidly accumulating scientific evidence presents novel opportunities for researchers and practitioners alike, yet such advantages are often overshadowed by resource demands associated with finding and aggregating a continually expanding body of scientific information. Across social science disciplines, the use of automation technologies for timely and accurate knowledge synthesis can enhance research translation value, better inform key policy development, and expand the current understanding of human interactions, organizations, and systems. Ongoing developments surrounding automation are highly concentrated in research for evidence-based medicine with limited evidence surrounding tools and techniques applied outside of the clinical research community. Our objective is to conduct a living systematic review of automated data extraction techniques supporting systematic reviews and meta-analyses in the social sciences. The aim of this study is to extend the automation knowledge base by synthesizing current trends in the application of extraction technologies of key data elements of interest for social scientists.</ns3:p><ns3:p> <ns3:bold>Methods</ns3:bold>: The proposed study is a living systematic review employing a partial replication framework based on extant literature surrounding automation of data extraction for systematic reviews and meta-analyses. Protocol development, base review, and updates follow PRISMA standards for reporting systematic reviews. This protocol is preregistered in OSF: <ns3:ext-link xmlns:ns4="http://www.w3.org/1999/xlink" ext-link-type="uri" ns4:href="https://doi.org/10.17605/OSF.IO/YWTF9">(Semi)Automated Approaches to Data Extraction for Systematic Reviews and Meta-Analyses in Social Sciences: A Living Review Protocol</ns3:ext-link> on August 14, 2022.</ns3:p><ns3:p> <ns3:bold>Conclusions</ns3:bold>: Anticipated outcomes of this study include: (a) generate insights supporting advancement in transferring existing reliable methods to social science research; (b) provide a foundation for protocol development leading to enhancement of comparability and benchmarking standards across disciplines; and (c) uncover exigencies that spur continued value-adding innovation and interdisciplinary collaboration for the benefit of the collective systematic review community.</ns3:p> cluster 4 had 19 members with the cingulate cortex [PageRank = 0. 0.020] being the most important. The cingulate cortex and thalamus are strongly associated with disorders of consciousness, likely due to the roles they play in maintaining awareness and involvement in the Default Mode Network respectively. Other areas of the brain like the cuneus, amygdala and hippocampus should be further investigated. Conclusions We observe gaps of rigorous evidence in certain regions (notably MENA and Latin America) and in interventions specifically targeting women as actors of peacebuilding. Gender norms and practices are important elements to consider in programme design and implementation to maximise potential benefits: focusing on empowerment only might not be enough in the absence of targeting the restrictive gender norms and practices that may undermine intervention effectiveness. Lastly, programme designers and implementation should consider explicitly targeting specific empowerment outcomes, promoting social capital and exchange, and tailoring the intervention components to the desired empowerment-related outcomes. post intervention. The results for university settings were unreliable because of inconsistency in the network meta-analysis. A narrative summary was reported for five conduct disorder prevention studies, all in primary school settings. None reported the primary outcome at the primary post-intervention time point. The economic evidence review reported heterogeneous findings from six studies. Taking the perspective of a single school budget and based on cognitive–behavioural therapy intervention costs in universal secondary school settings, the cost–consequence analysis estimated an intervention cost of £43 per student. Limitations The emphasis on disorder-specific prevention excluded broader mental health interventions and restricted the number of eligible conduct disorder prevention studies. Restricting the study to interventions delivered in the educational setting may have limited the number of eligible university-level interventions. Conclusions There was weak evidence of the effectiveness of school-based, disorder-specific prevention interventions, although effects were modest and the evidence not robust. Cognitive–behavioural therapy-based interventions may be more effective if they include a psychoeducation component. Future work Future trials for prevention of anxiety and depression should evaluate cognitive–behavioural interventions with and without a psychoeducation component, and include mindfulness/relaxation or exercise comparators, with sufficient follow-up. Cost implications must be adequately measured. Study registration This study is registered as PROSPERO CRD42016048184. Funding This project was funded by the National Institute for Health Research (NIHR) Public Health Research programme and will be published in full in Public Health Research ; Vol. 9, No. 8. See the NIHR Journals Library website for further project information. and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2022
DA  - 2022-09-12
JO  - {'id': 'https://openalex.org/S4210239046', 'issn_l': '2046-1402', 'issn': ['2046-1402'], 'display_name': 'F1000Research', 'publisher': 'Faculty of 1000', 'type': 'journal', 'url': 'https://f1000research.com/articles/11-1036/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Amanda Legate
AU  - Kim Nimon
ER  - 

557.
TY  - journal-article
ID  - https://openalex.org/W4297860676
DO  - https://doi.org/10.1016/j.jclinepi.2022.08.013
TI  - In a pilot study, automated real-time systematic review updates were feasible, accurate, and work-saving
AB  - <h2>Abstract</h2><h3>Objectives</h3> The aim of this study is to describe and pilot a novel method for continuously identifying newly published trials relevant to a systematic review, enabled by combining artificial intelligence (AI) with human expertise. <h3>Study Design and Setting</h3> We used RobotReviewer LIVE to keep a review of COVID-19 vaccination trials updated from February to August 2021. We compared the papers identified by the system with those found by the conventional manual process by the review team. <h3>Results</h3> The manual update searches (last search date July 2021) retrieved 135 abstracts, of which 31 were included after screening (23% precision, 100% recall). By the same date, the automated system retrieved 56 abstracts, of which 31 were included after manual screening (55% precision, 100% recall). Key limitations of the system include that it is limited to searches of PubMed/MEDLINE, and considers only randomized controlled trial reports. We aim to address these limitations in future. The system is available as open-source software for further piloting and evaluation. <h3>Conclusion</h3> Our system identified all relevant studies, reduced manual screening work, and enabled rolling updates on publication of new primary research. review, and updates follow PRISMA standards for reporting systematic reviews. This protocol is preregistered in OSF: <ns3:ext-link xmlns:ns4="http://www.w3.org/1999/xlink" ext-link-type="uri" ns4:href="https://doi.org/10.17605/OSF.IO/YWTF9">(Semi)Automated Approaches to Data Extraction for Systematic Reviews and Meta-Analyses in Social Sciences: A Living Review Protocol</ns3:ext-link> on August 14, 2022.</ns3:p><ns3:p> <ns3:bold>Conclusions</ns3:bold>: Anticipated outcomes of this study include: (a) generate insights supporting advancement in transferring existing reliable methods to social science research; (b) provide a foundation for protocol development leading to enhancement of comparability and benchmarking standards across disciplines; and (c) uncover exigencies that spur continued value-adding innovation and interdisciplinary collaboration for the benefit of the collective systematic review community.</ns3:p> cluster 4 had 19 members with the cingulate cortex [PageRank = 0. 0.020] being the most important. The cingulate cortex and thalamus are strongly associated with disorders of consciousness, likely due to the roles they play in maintaining awareness and involvement in the Default Mode Network respectively. Other areas of the brain like the cuneus, amygdala and hippocampus should be further investigated. Conclusions We observe gaps of rigorous evidence in certain regions (notably MENA and Latin America) and in interventions specifically targeting women as actors of peacebuilding. Gender norms and practices are important elements to consider in programme design and implementation to maximise potential benefits: focusing on empowerment only might not be enough in the absence of targeting the restrictive gender norms and practices that may undermine intervention effectiveness. Lastly, programme designers and implementation should consider explicitly targeting specific empowerment outcomes, promoting social capital and exchange, and tailoring the intervention components to the desired empowerment-related outcomes. post intervention. The results for university settings were unreliable because of inconsistency in the network meta-analysis. A narrative summary was reported for five conduct disorder prevention studies, all in primary school settings. None reported the primary outcome at the primary post-intervention time point. The economic evidence review reported heterogeneous findings from six studies. Taking the perspective of a single school budget and based on cognitive–behavioural therapy intervention costs in universal secondary school settings, the cost–consequence analysis estimated an intervention cost of £43 per student. Limitations The emphasis on disorder-specific prevention excluded broader mental health interventions and restricted the number of eligible conduct disorder prevention studies. Restricting the study to interventions delivered in the educational setting may have limited the number of eligible university-level interventions. Conclusions There was weak evidence of the effectiveness of school-based, disorder-specific prevention interventions, although effects were modest and the evidence not robust. Cognitive–behavioural therapy-based interventions may be more effective if they include a psychoeducation component. Future work Future trials for prevention of anxiety and depression should evaluate cognitive–behavioural interventions with and without a psychoeducation component, and include mindfulness/relaxation or exercise comparators, with sufficient follow-up. Cost implications must be adequately measured. Study registration This study is registered as PROSPERO CRD42016048184. Funding This project was funded by the National Institute for Health Research (NIHR) Public Health Research programme and will be published in full in Public Health Research ; Vol. 9, No. 8. See the NIHR Journals Library website for further project information. and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2022
DA  - 2022-09-01
JO  - {'id': 'https://openalex.org/S64418186', 'issn_l': '0895-4356', 'issn': ['1878-5921', '0895-4356'], 'display_name': 'Journal of Clinical Epidemiology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'http://www.jclinepi.com/article/S089543562200213X/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Iain J Marshall
AU  - Thomas A Trikalinos
AU  - Frank Soboczenski
AU  - Hye Sun Yun
AU  - Gregory Kell
AU  - Rachel Marshall
AU  - Byron C Wallace
ER  - 

558.
TY  - journal-article
ID  - https://openalex.org/W4307482990
DO  - https://doi.org/10.1016/j.asr.2022.10.051
TI  - The LIKED resource - a LIbrary KnowledgE and discovery online resource for discovering and implementing knowledge, data, and infrastructure resources
AB  - Access points to Heliophysics information are often poorly inter-linked to one another, making it challenging for researchers to integrate information, mature their understanding, and incorporate more complex ideas and relationships into their analyses. The authors reason this behavior to be a direct conseaquence of the lack of infrastructure for knowledge and data discovery in Heliophysics. Building an online library resource for Heliophysics addresses this gap in resources, and can also address other troublesome gaps related to community-building, such as access to help from other scientists, example analysis tutorials, and collaboration opportunities. This paper envisions a resource that better connects existing Heliophysics information and knowledge sources, the LIbrary for KnowledgE and Discovery (LIKED), which will be an online resource that interlinks information across databases (e.g., observational and publication), researcher interactions (e.g., conferences and discussion boards), and educational materials. The result is a rich and searchable environment to provide users a more productive experience for research and collaboration. In this paper, we provide the conceptual model for LIKED. We expand to detail how LIKED will serve to connect the various knowledge and research components available internationally together in an uniformly searchable manner. Finally, this work outlines various contributions the community can make towards this goal. ns4:href="https://doi.org/10.17605/OSF.IO/YWTF9">(Semi)Automated Approaches to Data Extraction for Systematic Reviews and Meta-Analyses in Social Sciences: A Living Review Protocol</ns3:ext-link> on August 14, 2022.</ns3:p><ns3:p> <ns3:bold>Conclusions</ns3:bold>: Anticipated outcomes of this study include: (a) generate insights supporting advancement in transferring existing reliable methods to social science research; (b) provide a foundation for protocol development leading to enhancement of comparability and benchmarking standards across disciplines; and (c) uncover exigencies that spur continued value-adding innovation and interdisciplinary collaboration for the benefit of the collective systematic review community.</ns3:p> cluster 4 had 19 members with the cingulate cortex [PageRank = 0. 0.020] being the most important. The cingulate cortex and thalamus are strongly associated with disorders of consciousness, likely due to the roles they play in maintaining awareness and involvement in the Default Mode Network respectively. Other areas of the brain like the cuneus, amygdala and hippocampus should be further investigated. Conclusions We observe gaps of rigorous evidence in certain regions (notably MENA and Latin America) and in interventions specifically targeting women as actors of peacebuilding. Gender norms and practices are important elements to consider in programme design and implementation to maximise potential benefits: focusing on empowerment only might not be enough in the absence of targeting the restrictive gender norms and practices that may undermine intervention effectiveness. Lastly, programme designers and implementation should consider explicitly targeting specific empowerment outcomes, promoting social capital and exchange, and tailoring the intervention components to the desired empowerment-related outcomes. post intervention. The results for university settings were unreliable because of inconsistency in the network meta-analysis. A narrative summary was reported for five conduct disorder prevention studies, all in primary school settings. None reported the primary outcome at the primary post-intervention time point. The economic evidence review reported heterogeneous findings from six studies. Taking the perspective of a single school budget and based on cognitive–behavioural therapy intervention costs in universal secondary school settings, the cost–consequence analysis estimated an intervention cost of £43 per student. Limitations The emphasis on disorder-specific prevention excluded broader mental health interventions and restricted the number of eligible conduct disorder prevention studies. Restricting the study to interventions delivered in the educational setting may have limited the number of eligible university-level interventions. Conclusions There was weak evidence of the effectiveness of school-based, disorder-specific prevention interventions, although effects were modest and the evidence not robust. Cognitive–behavioural therapy-based interventions may be more effective if they include a psychoeducation component. Future work Future trials for prevention of anxiety and depression should evaluate cognitive–behavioural interventions with and without a psychoeducation component, and include mindfulness/relaxation or exercise comparators, with sufficient follow-up. Cost implications must be adequately measured. Study registration This study is registered as PROSPERO CRD42016048184. Funding This project was funded by the National Institute for Health Research (NIHR) Public Health Research programme and will be published in full in Public Health Research ; Vol. 9, No. 8. See the NIHR Journals Library website for further project information. and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2022
DA  - 2022-10-01
JO  - {'id': 'https://openalex.org/V113313948', 'issn_l': '0273-1177', 'issn': ['0273-1177', '1879-1948'], 'display_name': 'Advances in Space Research', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'https://doi.org/10.1016/j.asr.2022.10.051', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Rebecca Ringuette
AU  - Ryan M. McGranaghan
AU  - B.J. Thompson
ER  - 

559.
TY  - journal-article
ID  - https://openalex.org/W4308922056
DO  - https://doi.org/10.1016/j.yrtph.2022.105287
TI  - Development of benchmark datasets for text mining and sentiment analysis to accelerate regulatory literature review
AB  - In the field of regulatory science, reviewing literature is an essential and important step, which most of the time is conducted by manually reading hundreds of articles. Although this process is highly time-consuming and labor-intensive, most output of this process is not well transformed into machine-readable format. The limited availability of data has largely constrained the artificial intelligence (AI) system development to facilitate this literature reviewing in the regulatory process. In the past decade, AI has revolutionized the area of text mining as many deep learning approaches have been developed to search, annotate, and classify relevant documents. After the great advancement of AI algorithms, a lack of high-quality data instead of the algorithms has recently become the bottleneck of AI system development. Herein, we constructed two large benchmark datasets, Chlorine Efficacy dataset (CHE) and Chlorine Safety dataset (CHS), under a regulatory scenario that sought to assess the antiseptic efficacy and toxicity of chlorine. For each dataset, ∼10,000 scientific articles were initially collected, manually reviewed, and their relevance to the review task were labeled. To ensure high data quality, each paper was labeled by a consensus among multiple experienced reviewers. The overall relevance rate was 27.21% (2,663 of 9,788) for CHE and 7.50% (761 of 10,153) for CHS, respectively. Furthermore, the relevant articles were categorized into five subgroups based on the focus of their content. Next, we developed an attention-based classification language model using these two datasets. The proposed classification model yielded 0.857 and 0.908 of Area Under the Curve (AUC) for CHE and CHS dataset, respectively. This performance was significantly better than permutation test (p < 10E-9), demonstrating that the labeling processes were valid. To conclude, our datasets can be used as benchmark to develop AI systems, which can further facilitate the literature review process in regulatory science. most important. The cingulate cortex and thalamus are strongly associated with disorders of consciousness, likely due to the roles they play in maintaining awareness and involvement in the Default Mode Network respectively. Other areas of the brain like the cuneus, amygdala and hippocampus should be further investigated. Conclusions We observe gaps of rigorous evidence in certain regions (notably MENA and Latin America) and in interventions specifically targeting women as actors of peacebuilding. Gender norms and practices are important elements to consider in programme design and implementation to maximise potential benefits: focusing on empowerment only might not be enough in the absence of targeting the restrictive gender norms and practices that may undermine intervention effectiveness. Lastly, programme designers and implementation should consider explicitly targeting specific empowerment outcomes, promoting social capital and exchange, and tailoring the intervention components to the desired empowerment-related outcomes. post intervention. The results for university settings were unreliable because of inconsistency in the network meta-analysis. A narrative summary was reported for five conduct disorder prevention studies, all in primary school settings. None reported the primary outcome at the primary post-intervention time point. The economic evidence review reported heterogeneous findings from six studies. Taking the perspective of a single school budget and based on cognitive–behavioural therapy intervention costs in universal secondary school settings, the cost–consequence analysis estimated an intervention cost of £43 per student. Limitations The emphasis on disorder-specific prevention excluded broader mental health interventions and restricted the number of eligible conduct disorder prevention studies. Restricting the study to interventions delivered in the educational setting may have limited the number of eligible university-level interventions. Conclusions There was weak evidence of the effectiveness of school-based, disorder-specific prevention interventions, although effects were modest and the evidence not robust. Cognitive–behavioural therapy-based interventions may be more effective if they include a psychoeducation component. Future work Future trials for prevention of anxiety and depression should evaluate cognitive–behavioural interventions with and without a psychoeducation component, and include mindfulness/relaxation or exercise comparators, with sufficient follow-up. Cost implications must be adequately measured. Study registration This study is registered as PROSPERO CRD42016048184. Funding This project was funded by the National Institute for Health Research (NIHR) Public Health Research programme and will be published in full in Public Health Research ; Vol. 9, No. 8. See the NIHR Journals Library website for further project information. and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2022
DA  - 2022-11-01
JO  - {'id': 'https://openalex.org/S87719511', 'issn_l': '0273-2300', 'issn': ['0273-2300', '1096-0295'], 'display_name': 'Regulatory Toxicology and Pharmacology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'https://doi.org/10.1016/j.yrtph.2022.105287', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc-nd'}
DP  - OpenAlex
AU  - Leihong Wu
AU  - Si Chen
AU  - Lei Guo
AU  - Svitlana Shpyleva
AU  - Kelly Harris
AU  - Tariq Fahmi
AU  - Timothy Flanigan
AU  - Weida Tong
AU  - Joshua Xu
AU  - Zhen Ren
ER  - 

560.
TY  - posted-content
ID  - https://openalex.org/W4309542200
DO  - https://doi.org/10.1101/2022.11.17.22282374
TI  - Validation of semi-automatic citation screening software for creating clinical practice guidelines: A protocol for a prospective observational study
AB  - Abstract Background This study aims to investigate the quality of the literature search and workload saving using the semi-automatic software for citation screening in the development of the Japanese Clinical Practice Guidelines for Management of Sepsis and Septic Shock (J-SSCG). Methods We will conduct a prospective study to compare the efficiency of citation screening between the conventional method using Rayyan and semi-automatic citation screening using ASReview. The two independent reviewers will conduct literature searches for clinical questions. During the session, we objectively measure the time to accomplish the citation screening. After the citation screening, we will calculate the sensitivity and specificity from the results of the conventional and semi-automatic procedures. Also, we will compare the accumulated time between the two methods. Trial registration This research is submitted with the University hospital medical information network clinical trial registry (UMIN-CTR) [UMIN000049366]. Conflicts of interest All authors declare no conflicts of interest to have. Funding None For each dataset, ∼10,000 scientific articles were initially collected, manually reviewed, and their relevance to the review task were labeled. To ensure high data quality, each paper was labeled by a consensus among multiple experienced reviewers. The overall relevance rate was 27.21% (2,663 of 9,788) for CHE and 7.50% (761 of 10,153) for CHS, respectively. Furthermore, the relevant articles were categorized into five subgroups based on the focus of their content. Next, we developed an attention-based classification language model using these two datasets. The proposed classification model yielded 0.857 and 0.908 of Area Under the Curve (AUC) for CHE and CHS dataset, respectively. This performance was significantly better than permutation test (p < 10E-9), demonstrating that the labeling processes were valid. To conclude, our datasets can be used as benchmark to develop AI systems, which can further facilitate the literature review process in regulatory science. most important. The cingulate cortex and thalamus are strongly associated with disorders of consciousness, likely due to the roles they play in maintaining awareness and involvement in the Default Mode Network respectively. Other areas of the brain like the cuneus, amygdala and hippocampus should be further investigated. Conclusions We observe gaps of rigorous evidence in certain regions (notably MENA and Latin America) and in interventions specifically targeting women as actors of peacebuilding. Gender norms and practices are important elements to consider in programme design and implementation to maximise potential benefits: focusing on empowerment only might not be enough in the absence of targeting the restrictive gender norms and practices that may undermine intervention effectiveness. Lastly, programme designers and implementation should consider explicitly targeting specific empowerment outcomes, promoting social capital and exchange, and tailoring the intervention components to the desired empowerment-related outcomes. post intervention. The results for university settings were unreliable because of inconsistency in the network meta-analysis. A narrative summary was reported for five conduct disorder prevention studies, all in primary school settings. None reported the primary outcome at the primary post-intervention time point. The economic evidence review reported heterogeneous findings from six studies. Taking the perspective of a single school budget and based on cognitive–behavioural therapy intervention costs in universal secondary school settings, the cost–consequence analysis estimated an intervention cost of £43 per student. Limitations The emphasis on disorder-specific prevention excluded broader mental health interventions and restricted the number of eligible conduct disorder prevention studies. Restricting the study to interventions delivered in the educational setting may have limited the number of eligible university-level interventions. Conclusions There was weak evidence of the effectiveness of school-based, disorder-specific prevention interventions, although effects were modest and the evidence not robust. Cognitive–behavioural therapy-based interventions may be more effective if they include a psychoeducation component. Future work Future trials for prevention of anxiety and depression should evaluate cognitive–behavioural interventions with and without a psychoeducation component, and include mindfulness/relaxation or exercise comparators, with sufficient follow-up. Cost implications must be adequately measured. Study registration This study is registered as PROSPERO CRD42016048184. Funding This project was funded by the National Institute for Health Research (NIHR) Public Health Research programme and will be published in full in Public Health Research ; Vol. 9, No. 8. See the NIHR Journals Library website for further project information. and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2022
DA  - 2022-11-18
JO  - {'id': 'https://openalex.org/V4306400573', 'issn_l': None, 'issn': None, 'display_name': 'Cold Spring Harbor Laboratory - medRxiv', 'publisher': 'Cold Spring Harbor Laboratory', 'type': 'repository', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Takehiko Oami
AU  - Yohei Okada
AU  - Tatsuma Fukuda
AU  - Masaaki Sakuraya
AU  - Taka-aki Nakada
AU  - Nobuaki Shime
ER  - 

561.
TY  - journal-article
ID  - https://openalex.org/W4309702579
DO  - https://doi.org/10.1186/s12889-022-14422-z
TI  - Priorities for successful use of artificial intelligence by public health organizations: a literature review
AB  - Artificial intelligence (AI) has the potential to improve public health's ability to promote the health of all people in all communities. To successfully realize this potential and use AI for public health functions it is important for public health organizations to thoughtfully develop strategies for AI implementation. Six key priorities for successful use of AI technologies by public health organizations are discussed: 1) Contemporary data governance; 2) Investment in modernized data and analytic infrastructure and procedures; 3) Addressing the skills gap in the workforce; 4) Development of strategic collaborative partnerships; 5) Use of good AI practices for transparency and reproducibility, and; 6) Explicit consideration of equity and bias. semi-automatic procedures. Also, we will compare the accumulated time between the two methods. Trial registration This research is submitted with the University hospital medical information network clinical trial registry (UMIN-CTR) [UMIN000049366]. Conflicts of interest All authors declare no conflicts of interest to have. Funding None For each dataset, ∼10,000 scientific articles were initially collected, manually reviewed, and their relevance to the review task were labeled. To ensure high data quality, each paper was labeled by a consensus among multiple experienced reviewers. The overall relevance rate was 27.21% (2,663 of 9,788) for CHE and 7.50% (761 of 10,153) for CHS, respectively. Furthermore, the relevant articles were categorized into five subgroups based on the focus of their content. Next, we developed an attention-based classification language model using these two datasets. The proposed classification model yielded 0.857 and 0.908 of Area Under the Curve (AUC) for CHE and CHS dataset, respectively. This performance was significantly better than permutation test (p < 10E-9), demonstrating that the labeling processes were valid. To conclude, our datasets can be used as benchmark to develop AI systems, which can further facilitate the literature review process in regulatory science. most important. The cingulate cortex and thalamus are strongly associated with disorders of consciousness, likely due to the roles they play in maintaining awareness and involvement in the Default Mode Network respectively. Other areas of the brain like the cuneus, amygdala and hippocampus should be further investigated. Conclusions We observe gaps of rigorous evidence in certain regions (notably MENA and Latin America) and in interventions specifically targeting women as actors of peacebuilding. Gender norms and practices are important elements to consider in programme design and implementation to maximise potential benefits: focusing on empowerment only might not be enough in the absence of targeting the restrictive gender norms and practices that may undermine intervention effectiveness. Lastly, programme designers and implementation should consider explicitly targeting specific empowerment outcomes, promoting social capital and exchange, and tailoring the intervention components to the desired empowerment-related outcomes. post intervention. The results for university settings were unreliable because of inconsistency in the network meta-analysis. A narrative summary was reported for five conduct disorder prevention studies, all in primary school settings. None reported the primary outcome at the primary post-intervention time point. The economic evidence review reported heterogeneous findings from six studies. Taking the perspective of a single school budget and based on cognitive–behavioural therapy intervention costs in universal secondary school settings, the cost–consequence analysis estimated an intervention cost of £43 per student. Limitations The emphasis on disorder-specific prevention excluded broader mental health interventions and restricted the number of eligible conduct disorder prevention studies. Restricting the study to interventions delivered in the educational setting may have limited the number of eligible university-level interventions. Conclusions There was weak evidence of the effectiveness of school-based, disorder-specific prevention interventions, although effects were modest and the evidence not robust. Cognitive–behavioural therapy-based interventions may be more effective if they include a psychoeducation component. Future work Future trials for prevention of anxiety and depression should evaluate cognitive–behavioural interventions with and without a psychoeducation component, and include mindfulness/relaxation or exercise comparators, with sufficient follow-up. Cost implications must be adequately measured. Study registration This study is registered as PROSPERO CRD42016048184. Funding This project was funded by the National Institute for Health Research (NIHR) Public Health Research programme and will be published in full in Public Health Research ; Vol. 9, No. 8. See the NIHR Journals Library website for further project information. and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2022
DA  - 2022-11-22
JO  - {'id': 'https://openalex.org/S200437886', 'issn_l': '1471-2458', 'issn': ['1471-2458'], 'display_name': 'BMC Public Health', 'publisher': 'BioMed Central', 'type': 'journal', 'url': 'https://bmcpublichealth.biomedcentral.com/counter/pdf/10.1186/s12889-022-14422-z', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Stacey Fisher
AU  - Laura C. Rosella
ER  - 

562.
TY  - journal-article
ID  - https://openalex.org/W4309811661
DO  - https://doi.org/10.1016/j.mex.2022.101935
TI  - An automated method for developing search strategies for systematic review using Natural Language Processing (NLP)
AB  - The design and implementation of systematic reviews and meta-analyses are often hampered by high financial costs, significant time commitment, and biases due to researchers' familiarity with studies. We proposed and implemented a fast and standardized method for search term selection using Natural Language Processing (NLP) and co-occurrence networks to identify relevant search terms to reduce biases in conducting systematic reviews and meta-analyses.•The method was implemented using Python packaged dubbed Ananse, which is benchmarked on the search terms strategy for naïve search proposed by Grames et al. (2019) written in "R". Ananse was applied to a case example towards finding search terms to implement a systematic literature review on cumulative effect studies on forest ecosystems.•The software automatically corrected and classified 100% of the duplicate articles identified by manual deduplication. Ananse was applied to the cumulative effects assessment case study, but it can serve as a general-purpose, open-source software system that can support extensive systematic reviews within a relatively short period with reduced biases.•Besides generating keywords, Ananse can act as middleware or a data converter for integrating multiple datasets into a database. was labeled by a consensus among multiple experienced reviewers. The overall relevance rate was 27.21% (2,663 of 9,788) for CHE and 7.50% (761 of 10,153) for CHS, respectively. Furthermore, the relevant articles were categorized into five subgroups based on the focus of their content. Next, we developed an attention-based classification language model using these two datasets. The proposed classification model yielded 0.857 and 0.908 of Area Under the Curve (AUC) for CHE and CHS dataset, respectively. This performance was significantly better than permutation test (p < 10E-9), demonstrating that the labeling processes were valid. To conclude, our datasets can be used as benchmark to develop AI systems, which can further facilitate the literature review process in regulatory science. most important. The cingulate cortex and thalamus are strongly associated with disorders of consciousness, likely due to the roles they play in maintaining awareness and involvement in the Default Mode Network respectively. Other areas of the brain like the cuneus, amygdala and hippocampus should be further investigated. Conclusions We observe gaps of rigorous evidence in certain regions (notably MENA and Latin America) and in interventions specifically targeting women as actors of peacebuilding. Gender norms and practices are important elements to consider in programme design and implementation to maximise potential benefits: focusing on empowerment only might not be enough in the absence of targeting the restrictive gender norms and practices that may undermine intervention effectiveness. Lastly, programme designers and implementation should consider explicitly targeting specific empowerment outcomes, promoting social capital and exchange, and tailoring the intervention components to the desired empowerment-related outcomes. post intervention. The results for university settings were unreliable because of inconsistency in the network meta-analysis. A narrative summary was reported for five conduct disorder prevention studies, all in primary school settings. None reported the primary outcome at the primary post-intervention time point. The economic evidence review reported heterogeneous findings from six studies. Taking the perspective of a single school budget and based on cognitive–behavioural therapy intervention costs in universal secondary school settings, the cost–consequence analysis estimated an intervention cost of £43 per student. Limitations The emphasis on disorder-specific prevention excluded broader mental health interventions and restricted the number of eligible conduct disorder prevention studies. Restricting the study to interventions delivered in the educational setting may have limited the number of eligible university-level interventions. Conclusions There was weak evidence of the effectiveness of school-based, disorder-specific prevention interventions, although effects were modest and the evidence not robust. Cognitive–behavioural therapy-based interventions may be more effective if they include a psychoeducation component. Future work Future trials for prevention of anxiety and depression should evaluate cognitive–behavioural interventions with and without a psychoeducation component, and include mindfulness/relaxation or exercise comparators, with sufficient follow-up. Cost implications must be adequately measured. Study registration This study is registered as PROSPERO CRD42016048184. Funding This project was funded by the National Institute for Health Research (NIHR) Public Health Research programme and will be published in full in Public Health Research ; Vol. 9, No. 8. See the NIHR Journals Library website for further project information. and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2022
DA  - 2022-11-01
JO  - {'id': 'https://openalex.org/S2898269294', 'issn_l': '2215-0161', 'issn': ['2215-0161'], 'display_name': 'MethodsX', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'http://methods-x.com/article/S2215016122003120/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Antwi Effah Kwabena
AU  - Owusu-Banahene Wiafe
AU  - Boakye-Danquah John
AU  - Asare Bernard
AU  - Frimpong A.F Boateng
ER  - 

563.
TY  - journal-article
ID  - https://openalex.org/W4310439492
DO  - https://doi.org/10.3310/udir6682
TI  - Increasing comprehensiveness and reducing workload in a systematic review of complex interventions using automated machine learning
AB  - As part of our ongoing systematic review of complex interventions for the primary prevention of cardiovascular diseases, we have developed and evaluated automated machine-learning classifiers for title and abstract screening. The aim was to develop a high-performing algorithm comparable to human screening.We followed a three-phase process to develop and test an automated machine learning-based classifier for screening potential studies on interventions for primary prevention of cardiovascular disease. We labelled a total of 16,611 articles during the first phase of the project. In the second phase, we used the labelled articles to develop a machine learning-based classifier. After that, we examined the performance of the classifiers in correctly labelling the papers. We evaluated the performance of the five deep-learning models [i.e. parallel convolutional neural network ( CNN ), stacked CNN , parallel-stacked CNN , recurrent neural network ( RNN ) and CNN-RNN]. The models were evaluated using recall, precision and work saved over sampling at no less than 95% recall.We labelled a total of 16,611 articles, of which 676 (4.0%) were tagged as 'relevant' and 15,935 (96%) were tagged as 'irrelevant'. The recall ranged from 51.9% to 96.6%. The precision ranged from 64.6% to 99.1%. The work saved over sampling ranged from 8.9% to as high as 92.1%. The best-performing model was parallel CNN , yielding a 96.4% recall, as well as 99.1% precision, and a potential workload reduction of 89.9%.We used words from the title and the abstract only. More work needs to be done to look into possible changes in performance, such as adding features such as full document text. The approach might also not be able to be used for other complex systematic reviews on different topics.Our study shows that machine learning has the potential to significantly aid the labour-intensive screening of abstracts in systematic reviews of complex interventions. Future research should concentrate on enhancing the classifier system and determining how it can be integrated into the systematic review workflow.This project was funded by the National Institute for Health and Care Research (NIHR) Health Technology Assessment programme and will be published in Health Technology Assessment. See the NIHR Journals Library website for further project information. and Latin America) and in interventions specifically targeting women as actors of peacebuilding. Gender norms and practices are important elements to consider in programme design and implementation to maximise potential benefits: focusing on empowerment only might not be enough in the absence of targeting the restrictive gender norms and practices that may undermine intervention effectiveness. Lastly, programme designers and implementation should consider explicitly targeting specific empowerment outcomes, promoting social capital and exchange, and tailoring the intervention components to the desired empowerment-related outcomes. post intervention. The results for university settings were unreliable because of inconsistency in the network meta-analysis. A narrative summary was reported for five conduct disorder prevention studies, all in primary school settings. None reported the primary outcome at the primary post-intervention time point. The economic evidence review reported heterogeneous findings from six studies. Taking the perspective of a single school budget and based on cognitive–behavioural therapy intervention costs in universal secondary school settings, the cost–consequence analysis estimated an intervention cost of £43 per student. Limitations The emphasis on disorder-specific prevention excluded broader mental health interventions and restricted the number of eligible conduct disorder prevention studies. Restricting the study to interventions delivered in the educational setting may have limited the number of eligible university-level interventions. Conclusions There was weak evidence of the effectiveness of school-based, disorder-specific prevention interventions, although effects were modest and the evidence not robust. Cognitive–behavioural therapy-based interventions may be more effective if they include a psychoeducation component. Future work Future trials for prevention of anxiety and depression should evaluate cognitive–behavioural interventions with and without a psychoeducation component, and include mindfulness/relaxation or exercise comparators, with sufficient follow-up. Cost implications must be adequately measured. Study registration This study is registered as PROSPERO CRD42016048184. Funding This project was funded by the National Institute for Health Research (NIHR) Public Health Research programme and will be published in full in Public Health Research ; Vol. 9, No. 8. See the NIHR Journals Library website for further project information. and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2022
DA  - 2022-11-01
JO  - {'id': 'https://openalex.org/V191206091', 'issn_l': '1366-5278', 'issn': ['1366-5278', '2046-4924', '2046-4932'], 'display_name': 'Health Technology Assessment', 'publisher': 'NIHR Journals Library', 'type': 'journal', 'url': 'https://doi.org/10.3310/udir6682', 'is_oa': True, 'version': 'publishedVersion', 'license': 'publisher-specific license'}
DP  - OpenAlex
AU  - Olalekan A. Uthman
AU  - Rachel Court
AU  - Jodie Enderby
AU  - Lena Al-Khudairy
AU  - Chidozie U. Nduka
AU  - Hema Mistry
AU  - G. J. Melendez-Torres
AU  - Sian Taylor-Phillips
AU  - Aileen Clarke
ER  - 

564.
TY  - journal-article
ID  - https://openalex.org/W4312018506
DO  - https://doi.org/10.1186/s12874-022-01805-4
TI  - Machine learning computational tools to assist the performance of systematic reviews: A mapping review
AB  - Abstract Background Within evidence-based practice (EBP), systematic reviews (SR) are considered the highest level of evidence in that they summarize the best available research and describe the progress in a determined field. Due its methodology, SR require significant time and resources to be performed; they also require repetitive steps that may introduce biases and human errors. Machine learning (ML) algorithms therefore present a promising alternative and a potential game changer to speed up and automate the SR process. This review aims to map the current availability of computational tools that use ML techniques to assist in the performance of SR, and to support authors in the selection of the right software for the performance of evidence synthesis. Methods The mapping review was based on comprehensive searches in electronic databases and software repositories to obtain relevant literature and records, followed by screening for eligibility based on titles, abstracts, and full text by two reviewers. The data extraction consisted of listing and extracting the name and basic characteristics of the included tools, for example a tool’s applicability to the various SR stages, pricing options, open-source availability, and type of software. These tools were classified and graphically represented to facilitate the description of our findings. Results A total of 9653 studies and 585 records were obtained from the structured searches performed on selected bibliometric databases and software repositories respectively. After screening, a total of 119 descriptions from publications and records allowed us to identify 63 tools that assist the SR process using ML techniques. Conclusions This review provides a high-quality map of currently available ML software to assist the performance of SR. ML algorithms are arguably one of the best techniques at present for the automation of SR. The most promising tools were easily accessible and included a high number of user-friendly features permitting the automation of SR and other kinds of evidence synthesis reviews. how it can be integrated into the systematic review workflow.This project was funded by the National Institute for Health and Care Research (NIHR) Health Technology Assessment programme and will be published in Health Technology Assessment. See the NIHR Journals Library website for further project information. and Latin America) and in interventions specifically targeting women as actors of peacebuilding. Gender norms and practices are important elements to consider in programme design and implementation to maximise potential benefits: focusing on empowerment only might not be enough in the absence of targeting the restrictive gender norms and practices that may undermine intervention effectiveness. Lastly, programme designers and implementation should consider explicitly targeting specific empowerment outcomes, promoting social capital and exchange, and tailoring the intervention components to the desired empowerment-related outcomes. post intervention. The results for university settings were unreliable because of inconsistency in the network meta-analysis. A narrative summary was reported for five conduct disorder prevention studies, all in primary school settings. None reported the primary outcome at the primary post-intervention time point. The economic evidence review reported heterogeneous findings from six studies. Taking the perspective of a single school budget and based on cognitive–behavioural therapy intervention costs in universal secondary school settings, the cost–consequence analysis estimated an intervention cost of £43 per student. Limitations The emphasis on disorder-specific prevention excluded broader mental health interventions and restricted the number of eligible conduct disorder prevention studies. Restricting the study to interventions delivered in the educational setting may have limited the number of eligible university-level interventions. Conclusions There was weak evidence of the effectiveness of school-based, disorder-specific prevention interventions, although effects were modest and the evidence not robust. Cognitive–behavioural therapy-based interventions may be more effective if they include a psychoeducation component. Future work Future trials for prevention of anxiety and depression should evaluate cognitive–behavioural interventions with and without a psychoeducation component, and include mindfulness/relaxation or exercise comparators, with sufficient follow-up. Cost implications must be adequately measured. Study registration This study is registered as PROSPERO CRD42016048184. Funding This project was funded by the National Institute for Health Research (NIHR) Public Health Research programme and will be published in full in Public Health Research ; Vol. 9, No. 8. See the NIHR Journals Library website for further project information. and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2022
DA  - 2022-12-16
JO  - {'id': 'https://openalex.org/S185874209', 'issn_l': '1471-2288', 'issn': ['1471-2288'], 'display_name': 'BMC Medical Research Methodology', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://bmcmedresmethodol.biomedcentral.com/counter/pdf/10.1186/s12874-022-01805-4', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Ramon Cierco Jimenez
AU  - Teresa Lee
AU  - Nicolás Rosillo
AU  - Reynalda Cordova
AU  - Ian A Cree
AU  - Angel Gonzalez
AU  - Blanca Iciar Indave Ruiz
ER  - 

565.
TY  - journal-article
ID  - https://openalex.org/W4312070000
DO  - https://doi.org/10.3390/su15010070
TI  - Scoping Review (SR) via Text Data Mining on Water Scarcity and Climate Change
AB  - Climate change is causing the risk of weather events and instable water accessibility, making water insufficiency a serious problem. According to the 2022 Intergovernmental Panel on Climate Change (IPCC), 70% of extreme weather events such as droughts and floods have been water-related in the last 15 years. Since the climate change processes are speeding up, this percentage is expected to increase. A plethora of researchers have been working on the correlation between water scarcity and climate change. The purpose of this paper is to examine the published research dealing with water scarcity and climate. Therefore, the study carries out a scoping review (SR) via text data mining and reveals the related topics. Two kinds of analysis were carried out using IRaMuTeQ software: descriptive analysis (TTR, Giraud index, Herdan index and Zipf’s curve) and cluster analysis (Reinert’s method). The results show that the topic of water scarcity refers to the direct and indirect economic impacts on its availability for irrigation, the willingness to pay more for an irrigation water supply and the role of public institutions in “achieving sustainable development goals”. The conclusion of the paper highlights the role of this analysis for developing future research and identifies implications for theory, practice and policy in order to overcome the current global challenges related to water scarcity and climate change. on selected bibliometric databases and software repositories respectively. After screening, a total of 119 descriptions from publications and records allowed us to identify 63 tools that assist the SR process using ML techniques. Conclusions This review provides a high-quality map of currently available ML software to assist the performance of SR. ML algorithms are arguably one of the best techniques at present for the automation of SR. The most promising tools were easily accessible and included a high number of user-friendly features permitting the automation of SR and other kinds of evidence synthesis reviews. how it can be integrated into the systematic review workflow.This project was funded by the National Institute for Health and Care Research (NIHR) Health Technology Assessment programme and will be published in Health Technology Assessment. See the NIHR Journals Library website for further project information. and Latin America) and in interventions specifically targeting women as actors of peacebuilding. Gender norms and practices are important elements to consider in programme design and implementation to maximise potential benefits: focusing on empowerment only might not be enough in the absence of targeting the restrictive gender norms and practices that may undermine intervention effectiveness. Lastly, programme designers and implementation should consider explicitly targeting specific empowerment outcomes, promoting social capital and exchange, and tailoring the intervention components to the desired empowerment-related outcomes. post intervention. The results for university settings were unreliable because of inconsistency in the network meta-analysis. A narrative summary was reported for five conduct disorder prevention studies, all in primary school settings. None reported the primary outcome at the primary post-intervention time point. The economic evidence review reported heterogeneous findings from six studies. Taking the perspective of a single school budget and based on cognitive–behavioural therapy intervention costs in universal secondary school settings, the cost–consequence analysis estimated an intervention cost of £43 per student. Limitations The emphasis on disorder-specific prevention excluded broader mental health interventions and restricted the number of eligible conduct disorder prevention studies. Restricting the study to interventions delivered in the educational setting may have limited the number of eligible university-level interventions. Conclusions There was weak evidence of the effectiveness of school-based, disorder-specific prevention interventions, although effects were modest and the evidence not robust. Cognitive–behavioural therapy-based interventions may be more effective if they include a psychoeducation component. Future work Future trials for prevention of anxiety and depression should evaluate cognitive–behavioural interventions with and without a psychoeducation component, and include mindfulness/relaxation or exercise comparators, with sufficient follow-up. Cost implications must be adequately measured. Study registration This study is registered as PROSPERO CRD42016048184. Funding This project was funded by the National Institute for Health Research (NIHR) Public Health Research programme and will be published in full in Public Health Research ; Vol. 9, No. 8. See the NIHR Journals Library website for further project information. and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2022
DA  - 2022-12-21
JO  - {'id': 'https://openalex.org/S10134376', 'issn_l': '2071-1050', 'issn': ['2071-1050'], 'display_name': 'Sustainability', 'publisher': 'MDPI', 'type': 'journal', 'url': 'https://www.mdpi.com/2071-1050/15/1/70/pdf?version=1672300636', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Dario Aversa
AU  - Nino Adamashvili
AU  - Mariantonietta Fiore
AU  - Alessia Spada
ER  - 

566.
TY  - journal-article
ID  - https://openalex.org/W4313329309
DO  - https://doi.org/10.26633/rpsp.2022.112
TI  - A declaração PRISMA 2020: diretriz atualizada para relatar revisões sistemáticas
AB  - The Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) statement, published in 2009, was designed to help systematic reviewers transparently report why the review was done, what the authors did, and what they found. Over the past decade, advances in systematic review methodology and terminology have necessitated an update to the guideline. The PRISMA 2020 statement replaces the 2009 statement and includes new reporting guidance that reflects advances in methods to identify, select, appraise, and synthesise studies. The structure and presentation of the items have been modified to facilitate implementation. In this article, we present the PRISMA 2020 27-item checklist, an expanded checklist that details reporting recommendations for each item, the PRISMA 2020 abstract checklist, and the revised flow diagrams for original and updated reviews.La declaración PRISMA (Preferred Reporting Items for Systematic reviews and Meta-Analyses), publicada en 2009, se diseñó para ayudar a los autores de revisiones sistemáticas a documentar de manera transparente el porqué de la revisión, qué hicieron los autores y qué encontraron. Durante la última década, ha habido muchos avances en la metodología y terminología de las revisiones sistemáticas, lo que ha requerido una actualización de esta guía. La declaración PRISMA 2020 sustituye a la declaración de 2009 e incluye una nueva guía de presentación de las publicaciones que refleja los avances en los métodos para identificar, seleccionar, evaluar y sintetizar estudios. La estructura y la presentación de los ítems ha sido modificada para facilitar su implementación. En este artículo, presentamos la lista de verificación PRISMA 2020 con 27 ítems, y una lista de verificación ampliada que detalla las recomendaciones en la publicación de cada ítem, la lista de verificación del resumen estructurado PRISMA 2020 y el diagrama de flujo revisado para revisiones sistemáticas. tools were easily accessible and included a high number of user-friendly features permitting the automation of SR and other kinds of evidence synthesis reviews. how it can be integrated into the systematic review workflow.This project was funded by the National Institute for Health and Care Research (NIHR) Health Technology Assessment programme and will be published in Health Technology Assessment. See the NIHR Journals Library website for further project information. and Latin America) and in interventions specifically targeting women as actors of peacebuilding. Gender norms and practices are important elements to consider in programme design and implementation to maximise potential benefits: focusing on empowerment only might not be enough in the absence of targeting the restrictive gender norms and practices that may undermine intervention effectiveness. Lastly, programme designers and implementation should consider explicitly targeting specific empowerment outcomes, promoting social capital and exchange, and tailoring the intervention components to the desired empowerment-related outcomes. post intervention. The results for university settings were unreliable because of inconsistency in the network meta-analysis. A narrative summary was reported for five conduct disorder prevention studies, all in primary school settings. None reported the primary outcome at the primary post-intervention time point. The economic evidence review reported heterogeneous findings from six studies. Taking the perspective of a single school budget and based on cognitive–behavioural therapy intervention costs in universal secondary school settings, the cost–consequence analysis estimated an intervention cost of £43 per student. Limitations The emphasis on disorder-specific prevention excluded broader mental health interventions and restricted the number of eligible conduct disorder prevention studies. Restricting the study to interventions delivered in the educational setting may have limited the number of eligible university-level interventions. Conclusions There was weak evidence of the effectiveness of school-based, disorder-specific prevention interventions, although effects were modest and the evidence not robust. Cognitive–behavioural therapy-based interventions may be more effective if they include a psychoeducation component. Future work Future trials for prevention of anxiety and depression should evaluate cognitive–behavioural interventions with and without a psychoeducation component, and include mindfulness/relaxation or exercise comparators, with sufficient follow-up. Cost implications must be adequately measured. Study registration This study is registered as PROSPERO CRD42016048184. Funding This project was funded by the National Institute for Health Research (NIHR) Public Health Research programme and will be published in full in Public Health Research ; Vol. 9, No. 8. See the NIHR Journals Library website for further project information. and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2022
DA  - 2022-12-30
JO  - {'id': 'https://openalex.org/S4210196923', 'issn_l': '1020-4989', 'issn': ['1020-4989', '1680-5348'], 'display_name': 'Revista panamericana de salud pública (Impresa)', 'publisher': 'Pan American Health Organization', 'type': 'journal', 'url': 'https://iris.paho.org/bitstream/10665.2/56882/5/v46e1122022.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc-nd'}
DP  - OpenAlex
AU  - Matthew J Page
AU  - Joanne E McKenzie
AU  - Patrick M Bossuyt
AU  - Isabelle Boutron
AU  - Tammy C Hoffmann
AU  - Cynthia D Mulrow
AU  - Larissa Shamseer
AU  - Jennifer Tetzlaff
AU  - Elie A Akl
AU  - Sue E Brennan
AU  - Roger Chou
AU  - Julie Glanville
AU  - Jeremy M Grimshaw
AU  - Asbjørn Hróbjartsson
AU  - Manoj M Lalu
AU  - Tianjing Li
AU  - Elizabeth W Loder
AU  - Evan Mayo-Wilson
AU  - Steve McDonald
AU  - Luke A McGuinness
AU  - Lesley A Stewart
AU  - James Thomas
AU  - Andrea C Tricco
AU  - Vivian A Welch
AU  - Penny Whiting
AU  - David Moher
ER  - 

567.
TY  - journal-article
ID  - https://openalex.org/W4313446661
DO  - https://doi.org/10.1186/s13643-022-02163-4
TI  - Unsupervised title and abstract screening for systematic review: a retrospective case-study using topic modelling methodology
AB  - Abstract Background The importance of systematic reviews in collating and summarising available research output on a particular topic cannot be over-emphasized. However, initial screening of retrieved literature is significantly time and labour intensive. Attempts at automating parts of the systematic review process have been made with varying degree of success partly due to being domain-specific, requiring vendor-specific software or manually labelled training data. Our primary objective was to develop statistical methodology for performing automated title and abstract screening for systematic reviews. Secondary objectives included (1) to retrospectively apply the automated screening methodology to previously manually screened systematic reviews and (2) to characterize the performance of the automated screening methodology scoring algorithm in a simulation study. Methods We implemented a Latent Dirichlet Allocation-based topic model to derive representative topics from the retrieved documents’ title and abstract. The second step involves defining a score threshold for classifying the documents as relevant for full-text review or not. The score is derived based on a set of search keywords (often the database retrieval search terms). Two systematic review studies were retrospectively used to illustrate the methodology. Results In one case study (helminth dataset), $$69.83\%$$ <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"> <mml:mrow> <mml:mn>69.83</mml:mn> <mml:mo>%</mml:mo> </mml:mrow> </mml:math> sensitivity compared to manual title and abstract screening was achieved. This is against a false positive rate of $$22.63\%$$ <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"> <mml:mrow> <mml:mn>22.63</mml:mn> <mml:mo>%</mml:mo> </mml:mrow> </mml:math> . For the second case study (Wilson disease dataset), a sensitivity of $$54.02\%$$ <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"> <mml:mrow> <mml:mn>54.02</mml:mn> <mml:mo>%</mml:mo> </mml:mrow> </mml:math> and specificity of $$67.03\%$$ <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"> <mml:mrow> <mml:mn>67.03</mml:mn> <mml:mo>%</mml:mo> </mml:mrow> </mml:math> were achieved. Conclusions Unsupervised title and abstract screening has the potential to reduce the workload involved in conducting systematic review. While sensitivity of the methodology on the tested data is low, approximately $$70\%$$ <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"> <mml:mrow> <mml:mn>70</mml:mn> <mml:mo>%</mml:mo> </mml:mrow> </mml:math> specificity was achieved. Users ought to keep in mind that potentially low sensitivity might occur. One approach to mitigate this might be to incorporate additional targeted search keywords such as the indexing databases terms into the search term copora. Moreover, automated screening can be used as an additional screener to the manual screeners. See the NIHR Journals Library website for further project information. and Latin America) and in interventions specifically targeting women as actors of peacebuilding. Gender norms and practices are important elements to consider in programme design and implementation to maximise potential benefits: focusing on empowerment only might not be enough in the absence of targeting the restrictive gender norms and practices that may undermine intervention effectiveness. Lastly, programme designers and implementation should consider explicitly targeting specific empowerment outcomes, promoting social capital and exchange, and tailoring the intervention components to the desired empowerment-related outcomes. post intervention. The results for university settings were unreliable because of inconsistency in the network meta-analysis. A narrative summary was reported for five conduct disorder prevention studies, all in primary school settings. None reported the primary outcome at the primary post-intervention time point. The economic evidence review reported heterogeneous findings from six studies. Taking the perspective of a single school budget and based on cognitive–behavioural therapy intervention costs in universal secondary school settings, the cost–consequence analysis estimated an intervention cost of £43 per student. Limitations The emphasis on disorder-specific prevention excluded broader mental health interventions and restricted the number of eligible conduct disorder prevention studies. Restricting the study to interventions delivered in the educational setting may have limited the number of eligible university-level interventions. Conclusions There was weak evidence of the effectiveness of school-based, disorder-specific prevention interventions, although effects were modest and the evidence not robust. Cognitive–behavioural therapy-based interventions may be more effective if they include a psychoeducation component. Future work Future trials for prevention of anxiety and depression should evaluate cognitive–behavioural interventions with and without a psychoeducation component, and include mindfulness/relaxation or exercise comparators, with sufficient follow-up. Cost implications must be adequately measured. Study registration This study is registered as PROSPERO CRD42016048184. Funding This project was funded by the National Institute for Health Research (NIHR) Public Health Research programme and will be published in full in Public Health Research ; Vol. 9, No. 8. See the NIHR Journals Library website for further project information. and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2023
DA  - 2023-01-03
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://systematicreviewsjournal.biomedcentral.com/counter/pdf/10.1186/s13643-022-02163-4', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Leacky Muchene
AU  - Leacky K Muchene
ER  - 

568.
TY  - journal-article
ID  - https://openalex.org/W4316810661
DO  - https://doi.org/10.1186/s13643-023-02171-y
TI  - The effect of machine learning tools for evidence synthesis on resource use and time-to-completion: protocol for a retrospective pilot study
AB  - Abstract Background Machine learning (ML) tools exist that can reduce or replace human activities in repetitive or complex tasks. Yet, ML is underutilized within evidence synthesis, despite the steadily growing rate of primary study publication and the need to periodically update reviews to reflect new evidence. Underutilization may be partially explained by a paucity of evidence on how ML tools can reduce resource use and time-to-completion of reviews. Methods This protocol describes how we will answer two research questions using a retrospective study design: Is there a difference in resources used to produce reviews using recommended ML versus not using ML, and is there a difference in time-to-completion? We will also compare recommended ML use to non-recommended ML use that merely adds ML use to existing procedures. We will retrospectively include all reviews conducted at our institute from 1 August 2020, corresponding to the commission of the first review in our institute that used ML. Conclusion The results of this study will allow us to quantitatively estimate the effect of ML adoption on resource use and time-to-completion, providing our organization and others with better information to make high-level organizational decisions about ML. <mml:mrow> <mml:mn>69.83</mml:mn> <mml:mo>%</mml:mo> </mml:mrow> </mml:math> sensitivity compared to manual title and abstract screening was achieved. This is against a false positive rate of $$22.63\%$$ <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"> <mml:mrow> <mml:mn>22.63</mml:mn> <mml:mo>%</mml:mo> </mml:mrow> </mml:math> . For the second case study (Wilson disease dataset), a sensitivity of $$54.02\%$$ <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"> <mml:mrow> <mml:mn>54.02</mml:mn> <mml:mo>%</mml:mo> </mml:mrow> </mml:math> and specificity of $$67.03\%$$ <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"> <mml:mrow> <mml:mn>67.03</mml:mn> <mml:mo>%</mml:mo> </mml:mrow> </mml:math> were achieved. Conclusions Unsupervised title and abstract screening has the potential to reduce the workload involved in conducting systematic review. While sensitivity of the methodology on the tested data is low, approximately $$70\%$$ <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"> <mml:mrow> <mml:mn>70</mml:mn> <mml:mo>%</mml:mo> </mml:mrow> </mml:math> specificity was achieved. Users ought to keep in mind that potentially low sensitivity might occur. One approach to mitigate this might be to incorporate additional targeted search keywords such as the indexing databases terms into the search term copora. Moreover, automated screening can be used as an additional screener to the manual screeners. See the NIHR Journals Library website for further project information. and Latin America) and in interventions specifically targeting women as actors of peacebuilding. Gender norms and practices are important elements to consider in programme design and implementation to maximise potential benefits: focusing on empowerment only might not be enough in the absence of targeting the restrictive gender norms and practices that may undermine intervention effectiveness. Lastly, programme designers and implementation should consider explicitly targeting specific empowerment outcomes, promoting social capital and exchange, and tailoring the intervention components to the desired empowerment-related outcomes. post intervention. The results for university settings were unreliable because of inconsistency in the network meta-analysis. A narrative summary was reported for five conduct disorder prevention studies, all in primary school settings. None reported the primary outcome at the primary post-intervention time point. The economic evidence review reported heterogeneous findings from six studies. Taking the perspective of a single school budget and based on cognitive–behavioural therapy intervention costs in universal secondary school settings, the cost–consequence analysis estimated an intervention cost of £43 per student. Limitations The emphasis on disorder-specific prevention excluded broader mental health interventions and restricted the number of eligible conduct disorder prevention studies. Restricting the study to interventions delivered in the educational setting may have limited the number of eligible university-level interventions. Conclusions There was weak evidence of the effectiveness of school-based, disorder-specific prevention interventions, although effects were modest and the evidence not robust. Cognitive–behavioural therapy-based interventions may be more effective if they include a psychoeducation component. Future work Future trials for prevention of anxiety and depression should evaluate cognitive–behavioural interventions with and without a psychoeducation component, and include mindfulness/relaxation or exercise comparators, with sufficient follow-up. Cost implications must be adequately measured. Study registration This study is registered as PROSPERO CRD42016048184. Funding This project was funded by the National Institute for Health Research (NIHR) Public Health Research programme and will be published in full in Public Health Research ; Vol. 9, No. 8. See the NIHR Journals Library website for further project information. and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2023
DA  - 2023-01-17
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://systematicreviewsjournal.biomedcentral.com/counter/pdf/10.1186/s13643-023-02171-y', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Ashley Elizabeth Muller
AU  - Rigmor C. Berg
AU  - Jose Francisco Meneses-Echavez
AU  - Heather Melanie Ames
AU  - Tiril C. Borge
AU  - Patricia Sofia Jacobsen Jardim
AU  - Chris Cooper
AU  - Christopher James Rose
ER  - 

569.
TY  - posted-content
ID  - https://openalex.org/W4317467432
DO  - https://doi.org/10.1101/2023.01.18.524571
TI  - Ensemble of deep learning language models to support the creation of living systematic reviews for the COVID-19 literature: a retrospective study
AB  - Abstract Background The COVID-19 pandemic has led to an unprecedented amount of scientific publications, growing at a pace never seen before. Multiple living systematic reviews have been developed to assist professionals with up-to-date and trustworthy health information, but it is increasingly challenging for systematic reviewers to keep up with the evidence in electronic databases. We aimed to investigate deep learning-based machine learning algorithms to classify COVID-19 related publications to help scale-up the epidemiological curation process. Methods In this retrospective study, five different pre-trained deep learning-based language models were fine-tuned on a dataset of 6,365 publications manually classified into two classes, three subclasses and 22 sub-subclasses relevant for epidemiological triage purposes. In a k -fold cross-validation setting, each standalone model was assessed on a classification task and compared against an ensemble, which takes the standalone model predictions as input and uses different strategies to infer the optimal article class. A ranking task was also considered, in which the model outputs a ranked list of sub-subclasses associated with the article. Results The ensemble model significantly outperformed the standalone classifiers, achieving a F1-score of 89.2 at the class level of the classification task. The difference between the standalone and ensemble models increases at the sub-subclass level, where the ensemble reaches a micro F1-score of 70% against 67% for the best performing standalone model. For the ranking task, the ensemble obtained the highest recall@3, with a performance of 89%. Using an unanimity voting rule, the ensemble can provide predictions with higher confidence on a subset of the data, achieving detection of original papers with a F1-score up to 97% on a subset of 80% of the collection instead of 93% on the whole dataset. Conclusion This study shows the potential of using deep learning language models to perform triage of COVID-19 references efficiently and support epidemiological curation and review. The ensemble consistently and significantly outperforms any standalone model. Fine-tuning the voting strategy thresholds is an interesting alternative to annotate a subset with higher predictive confidence. term copora. Moreover, automated screening can be used as an additional screener to the manual screeners. See the NIHR Journals Library website for further project information. and Latin America) and in interventions specifically targeting women as actors of peacebuilding. Gender norms and practices are important elements to consider in programme design and implementation to maximise potential benefits: focusing on empowerment only might not be enough in the absence of targeting the restrictive gender norms and practices that may undermine intervention effectiveness. Lastly, programme designers and implementation should consider explicitly targeting specific empowerment outcomes, promoting social capital and exchange, and tailoring the intervention components to the desired empowerment-related outcomes. post intervention. The results for university settings were unreliable because of inconsistency in the network meta-analysis. A narrative summary was reported for five conduct disorder prevention studies, all in primary school settings. None reported the primary outcome at the primary post-intervention time point. The economic evidence review reported heterogeneous findings from six studies. Taking the perspective of a single school budget and based on cognitive–behavioural therapy intervention costs in universal secondary school settings, the cost–consequence analysis estimated an intervention cost of £43 per student. Limitations The emphasis on disorder-specific prevention excluded broader mental health interventions and restricted the number of eligible conduct disorder prevention studies. Restricting the study to interventions delivered in the educational setting may have limited the number of eligible university-level interventions. Conclusions There was weak evidence of the effectiveness of school-based, disorder-specific prevention interventions, although effects were modest and the evidence not robust. Cognitive–behavioural therapy-based interventions may be more effective if they include a psychoeducation component. Future work Future trials for prevention of anxiety and depression should evaluate cognitive–behavioural interventions with and without a psychoeducation component, and include mindfulness/relaxation or exercise comparators, with sufficient follow-up. Cost implications must be adequately measured. Study registration This study is registered as PROSPERO CRD42016048184. Funding This project was funded by the National Institute for Health Research (NIHR) Public Health Research programme and will be published in full in Public Health Research ; Vol. 9, No. 8. See the NIHR Journals Library website for further project information. and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2023
DA  - 2023-01-19
JO  - {'id': 'https://openalex.org/S4306402567', 'issn_l': None, 'issn': None, 'display_name': 'bioRxiv (Cold Spring Harbor Laboratory)', 'publisher': 'Cold Spring Harbor Laboratory', 'type': 'repository', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Julien Knafou
AU  - Quentin Haas
AU  - Nikolay Borissov
AU  - Michel Jacques Counotte
AU  - Nicola Low
AU  - Hira Imeri
AU  - Aziz Mert Ipekci
AU  - Diana Buitrago-Garcia
AU  - Leonie Heron
AU  - Poorya Amini
AU  - Douglas Teodoro
ER  - 

570.
TY  - journal-article
ID  - https://openalex.org/W4318026171
DO  - https://doi.org/10.1136/bmjgh-2022-010850
TI  - Systematic mapping of gender equality and social inclusion in WASH interventions: knowledge clusters and gaps
AB  - Poor access to water, sanitation and hygiene (WASH) services threatens population health and contributes to gender and social inequalities, especially in low-resource settings. Despite awareness in the WASH sector of the importance of promoting gender equality and social inclusion (GESI) to address these inequalities, evaluations of interventions focus largely on health outcomes, while gender equality and other social outcomes are rarely included. This review aimed to collate and describe available research evidence of GESI outcomes evaluated in WASH intervention studies.We applied a systematic mapping methodology and searched for both academic and grey literature published between 2010 and 2020 in 16 bibliographic databases and 53 specialist websites. Eligibility screening (with consistency checking) was conducted according to predetermined criteria, followed by metadata coding and narrative synthesis.Our evidence base comprises 463 intervention studies. Only 42% of studies measured transformative GESI outcomes of WASH interventions, referring to those that seek to transform gender relations and power imbalances to promote equality. A majority of studies disaggregated outcome data by sex, but other forms of data disaggregation were limited. Most included studies (78%) lacked a specific GESI mainstreaming component in their intervention design. Of the interventions with GESI mainstreaming, the majority targeted women and girls, with very few focused on other social groups or intersectional considerations.The review points to various areas for future primary and secondary research. Given the potential contribution of WASH to GESI, GESI considerations should be incorporated into the evaluation of WASH interventions. Regular collection of data and monitoring of GESI outcomes is needed as well as developing new and testing existing methods for monitoring and evaluation of such data. subset of 80% of the collection instead of 93% on the whole dataset. Conclusion This study shows the potential of using deep learning language models to perform triage of COVID-19 references efficiently and support epidemiological curation and review. The ensemble consistently and significantly outperforms any standalone model. Fine-tuning the voting strategy thresholds is an interesting alternative to annotate a subset with higher predictive confidence. term copora. Moreover, automated screening can be used as an additional screener to the manual screeners. See the NIHR Journals Library website for further project information. and Latin America) and in interventions specifically targeting women as actors of peacebuilding. Gender norms and practices are important elements to consider in programme design and implementation to maximise potential benefits: focusing on empowerment only might not be enough in the absence of targeting the restrictive gender norms and practices that may undermine intervention effectiveness. Lastly, programme designers and implementation should consider explicitly targeting specific empowerment outcomes, promoting social capital and exchange, and tailoring the intervention components to the desired empowerment-related outcomes. post intervention. The results for university settings were unreliable because of inconsistency in the network meta-analysis. A narrative summary was reported for five conduct disorder prevention studies, all in primary school settings. None reported the primary outcome at the primary post-intervention time point. The economic evidence review reported heterogeneous findings from six studies. Taking the perspective of a single school budget and based on cognitive–behavioural therapy intervention costs in universal secondary school settings, the cost–consequence analysis estimated an intervention cost of £43 per student. Limitations The emphasis on disorder-specific prevention excluded broader mental health interventions and restricted the number of eligible conduct disorder prevention studies. Restricting the study to interventions delivered in the educational setting may have limited the number of eligible university-level interventions. Conclusions There was weak evidence of the effectiveness of school-based, disorder-specific prevention interventions, although effects were modest and the evidence not robust. Cognitive–behavioural therapy-based interventions may be more effective if they include a psychoeducation component. Future work Future trials for prevention of anxiety and depression should evaluate cognitive–behavioural interventions with and without a psychoeducation component, and include mindfulness/relaxation or exercise comparators, with sufficient follow-up. Cost implications must be adequately measured. Study registration This study is registered as PROSPERO CRD42016048184. Funding This project was funded by the National Institute for Health Research (NIHR) Public Health Research programme and will be published in full in Public Health Research ; Vol. 9, No. 8. See the NIHR Journals Library website for further project information. and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2023
DA  - 2023-01-01
JO  - {'id': 'https://openalex.org/S2764928273', 'issn_l': '2059-7908', 'issn': ['2059-7908'], 'display_name': 'BMJ Global Health', 'publisher': 'BMJ', 'type': 'journal', 'url': 'https://gh.bmj.com/content/bmjgh/8/1/e010850.full.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc'}
DP  - OpenAlex
AU  - Biljana Macura
AU  - Ella Foggitt
AU  - Carla Liera
AU  - Adriana Soto
AU  - Arianna Orlando
AU  - Laura Del Duca
AU  - Naomi Carrard
AU  - Karin Hannes
AU  - Marni Sommer
AU  - Sarah Dickin
ER  - 

571.
TY  - journal-article
ID  - https://openalex.org/W4318225126
DO  - https://doi.org/10.12688/f1000research.125198.2
TI  - (Semi)automated approaches to data extraction for systematic reviews and meta-analyses in social sciences: A living review protocol
AB  - <ns3:p><ns3:bold>Background</ns3:bold>: An abundance of rapidly accumulating scientific evidence presents novel opportunities for researchers and practitioners alike, yet such advantages are often overshadowed by resource demands associated with finding and aggregating a continually expanding body of scientific information. Across social science disciplines, the use of automation technologies for timely and accurate knowledge synthesis can enhance research translation value, better inform key policy development, and expand the current understanding of human interactions, organizations, and systems. Ongoing developments surrounding automation are highly concentrated in research for evidence-based medicine with limited evidence surrounding tools and techniques applied outside of the clinical research community. Our objective is to conduct a living systematic review of automated data extraction techniques supporting systematic reviews and meta-analyses in the social sciences. The aim of this study is to extend the automation knowledge base by synthesizing current trends in the application of extraction technologies of key data elements of interest for social scientists.</ns3:p><ns3:p> <ns3:bold>Methods</ns3:bold>: The proposed study is a living systematic review employing a partial replication framework based on extant literature surrounding automation of data extraction for systematic reviews and meta-analyses. Protocol development, base review, and updates follow PRISMA standards for reporting systematic reviews. This protocol is preregistered in OSF: <ns3:ext-link xmlns:ns4="http://www.w3.org/1999/xlink" ext-link-type="uri" ns4:href="https://doi.org/10.17605/OSF.IO/YWTF9">(Semi)Automated Approaches to Data Extraction for Systematic Reviews and Meta-Analyses in Social Sciences: A Living Review Protocol</ns3:ext-link> on August 14, 2022.</ns3:p><ns3:p> <ns3:bold>Conclusions</ns3:bold>: Anticipated outcomes of this study include: (a) generate insights supporting advancement in transferring existing reliable methods to social science research; (b) provide a foundation for protocol development leading to enhancement of comparability and benchmarking standards across disciplines; and (c) uncover exigencies that spur continued value-adding innovation and interdisciplinary collaboration for the benefit of the collective systematic review community.</ns3:p> shows the potential of using deep learning language models to perform triage of COVID-19 references efficiently and support epidemiological curation and review. The ensemble consistently and significantly outperforms any standalone model. Fine-tuning the voting strategy thresholds is an interesting alternative to annotate a subset with higher predictive confidence. term copora. Moreover, automated screening can be used as an additional screener to the manual screeners. See the NIHR Journals Library website for further project information. and Latin America) and in interventions specifically targeting women as actors of peacebuilding. Gender norms and practices are important elements to consider in programme design and implementation to maximise potential benefits: focusing on empowerment only might not be enough in the absence of targeting the restrictive gender norms and practices that may undermine intervention effectiveness. Lastly, programme designers and implementation should consider explicitly targeting specific empowerment outcomes, promoting social capital and exchange, and tailoring the intervention components to the desired empowerment-related outcomes. post intervention. The results for university settings were unreliable because of inconsistency in the network meta-analysis. A narrative summary was reported for five conduct disorder prevention studies, all in primary school settings. None reported the primary outcome at the primary post-intervention time point. The economic evidence review reported heterogeneous findings from six studies. Taking the perspective of a single school budget and based on cognitive–behavioural therapy intervention costs in universal secondary school settings, the cost–consequence analysis estimated an intervention cost of £43 per student. Limitations The emphasis on disorder-specific prevention excluded broader mental health interventions and restricted the number of eligible conduct disorder prevention studies. Restricting the study to interventions delivered in the educational setting may have limited the number of eligible university-level interventions. Conclusions There was weak evidence of the effectiveness of school-based, disorder-specific prevention interventions, although effects were modest and the evidence not robust. Cognitive–behavioural therapy-based interventions may be more effective if they include a psychoeducation component. Future work Future trials for prevention of anxiety and depression should evaluate cognitive–behavioural interventions with and without a psychoeducation component, and include mindfulness/relaxation or exercise comparators, with sufficient follow-up. Cost implications must be adequately measured. Study registration This study is registered as PROSPERO CRD42016048184. Funding This project was funded by the National Institute for Health Research (NIHR) Public Health Research programme and will be published in full in Public Health Research ; Vol. 9, No. 8. See the NIHR Journals Library website for further project information. and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2023
DA  - 2023-01-27
JO  - {'id': 'https://openalex.org/S4210239046', 'issn_l': '2046-1402', 'issn': ['2046-1402'], 'display_name': 'F1000Research', 'publisher': 'Faculty of 1000', 'type': 'journal', 'url': 'https://f1000research.com/articles/11-1036/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Amanda Legate
AU  - Kim Nimon
ER  - 

572.
TY  - journal-article
ID  - https://openalex.org/W4318822498
DO  - https://doi.org/10.14324/lre.21.1.11
TI  - Ann Oakley: new learning and global influence from working across conventional boundaries
AB  - Ann Oakley, pioneering social researcher for nearly 60 years, is Professor of Sociology and Social Policy at IOE (Institute of Education), UCL’s Faculty of Education and Society (University College London, UK). This article explores the innovation and influence of her work and the work of her close colleagues at the Social Science Research Unit (SSRU) and its Evidence for Policy and Practice Information and Coordinating Centre (EPPI-Centre). It describes advances in research and knowledge that have their roots in listening to what women have to say about their lives. The resulting novel research methods have straddled academic boundaries – between qualitative and quantitative methodologies, between disciplines, and between academia and wider society – to enhance understanding of complex social issues and approaches to addressing them within the public sector. The impact of this work is seen in terms of influencing science, knowledge management, policy decisions, professional practice and the general public. These achievements come from approaches that are outward looking and straddle academic disciplines to produce evidence that is relevant to policymaking and to practice, with the ultimate aim being to improve day-to-day life. review, and updates follow PRISMA standards for reporting systematic reviews. This protocol is preregistered in OSF: <ns3:ext-link xmlns:ns4="http://www.w3.org/1999/xlink" ext-link-type="uri" ns4:href="https://doi.org/10.17605/OSF.IO/YWTF9">(Semi)Automated Approaches to Data Extraction for Systematic Reviews and Meta-Analyses in Social Sciences: A Living Review Protocol</ns3:ext-link> on August 14, 2022.</ns3:p><ns3:p> <ns3:bold>Conclusions</ns3:bold>: Anticipated outcomes of this study include: (a) generate insights supporting advancement in transferring existing reliable methods to social science research; (b) provide a foundation for protocol development leading to enhancement of comparability and benchmarking standards across disciplines; and (c) uncover exigencies that spur continued value-adding innovation and interdisciplinary collaboration for the benefit of the collective systematic review community.</ns3:p> shows the potential of using deep learning language models to perform triage of COVID-19 references efficiently and support epidemiological curation and review. The ensemble consistently and significantly outperforms any standalone model. Fine-tuning the voting strategy thresholds is an interesting alternative to annotate a subset with higher predictive confidence. term copora. Moreover, automated screening can be used as an additional screener to the manual screeners. See the NIHR Journals Library website for further project information. and Latin America) and in interventions specifically targeting women as actors of peacebuilding. Gender norms and practices are important elements to consider in programme design and implementation to maximise potential benefits: focusing on empowerment only might not be enough in the absence of targeting the restrictive gender norms and practices that may undermine intervention effectiveness. Lastly, programme designers and implementation should consider explicitly targeting specific empowerment outcomes, promoting social capital and exchange, and tailoring the intervention components to the desired empowerment-related outcomes. post intervention. The results for university settings were unreliable because of inconsistency in the network meta-analysis. A narrative summary was reported for five conduct disorder prevention studies, all in primary school settings. None reported the primary outcome at the primary post-intervention time point. The economic evidence review reported heterogeneous findings from six studies. Taking the perspective of a single school budget and based on cognitive–behavioural therapy intervention costs in universal secondary school settings, the cost–consequence analysis estimated an intervention cost of £43 per student. Limitations The emphasis on disorder-specific prevention excluded broader mental health interventions and restricted the number of eligible conduct disorder prevention studies. Restricting the study to interventions delivered in the educational setting may have limited the number of eligible university-level interventions. Conclusions There was weak evidence of the effectiveness of school-based, disorder-specific prevention interventions, although effects were modest and the evidence not robust. Cognitive–behavioural therapy-based interventions may be more effective if they include a psychoeducation component. Future work Future trials for prevention of anxiety and depression should evaluate cognitive–behavioural interventions with and without a psychoeducation component, and include mindfulness/relaxation or exercise comparators, with sufficient follow-up. Cost implications must be adequately measured. Study registration This study is registered as PROSPERO CRD42016048184. Funding This project was funded by the National Institute for Health Research (NIHR) Public Health Research programme and will be published in full in Public Health Research ; Vol. 9, No. 8. See the NIHR Journals Library website for further project information. and tobacco products - and over sustained time periods. intervening across a wider range of foods - as well as alcohol and tobacco products - and over sustained time periods.
PY  - 2023
DA  - 2023-01-24
JO  - {'id': 'https://openalex.org/S162811609', 'issn_l': '1474-8460', 'issn': ['1474-8479', '1474-8460'], 'display_name': 'London Review of Education', 'publisher': 'UCL Press', 'type': 'journal', 'url': 'https://uclpress.scienceopen.com/document_file/4aa4e71a-3dd7-4d34-8f01-a0837b941a25/ScienceOpen/Lond_Rev_Educ-21-11.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Sandy Oliver
ER  - 

573.
TY  - journal-article
ID  - https://openalex.org/W4319962920
DO  - https://doi.org/10.1016/j.iswa.2023.200193
TI  - An Analysis of Work Saved over Sampling in the Evaluation of Automated Citation Screening in Systematic Literature Reviews
AB  - No Abstract Found
PY  - 2023
DA  - 2023-02-01
JO  - {'id': 'https://openalex.org/S4210234522', 'issn_l': '2667-3053', 'issn': ['2667-3053'], 'display_name': 'Intelligent systems with applications', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'https://doi.org/10.1016/j.iswa.2023.200193', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Wojciech Kusa
AU  - Aldo Lipani
AU  - Petr Knoth
AU  - Allan Hanbury
ER  - 

574.
TY  - journal-article
ID  - https://openalex.org/W3123893780
DO  - https://doi.org/10.1136/bmj.n160
TI  - PRISMA 2020 explanation and elaboration: updated guidance and exemplars for reporting systematic reviews
AB  - The methods and results of systematic reviews should be reported in sufficient detail to allow users to assess the trustworthiness and applicability of the review findings. The Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) statement was developed to facilitate transparent and complete reporting of systematic reviews and has been updated (to PRISMA 2020) to reflect recent advances in systematic review methodology and terminology. Here, we present the explanation and elaboration paper for PRISMA 2020, where we explain why reporting of each item is recommended, present bullet points that detail the reporting recommendations, and present examples from published reviews. We hope that changes to the content and structure of PRISMA 2020 will facilitate uptake of the guideline and lead to more transparent, complete, and accurate reporting of systematic reviews.
PY  - 2021
DA  - 2021-03-29
JO  - {'id': 'https://openalex.org/S4210185579', 'issn_l': '1756-1833', 'issn': ['1756-1833'], 'display_name': 'BMJ', 'publisher': 'BMJ', 'type': 'journal', 'url': 'https://www.bmj.com/content/bmj/372/bmj.n160.full.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Matthew J. Page
AU  - David Moher
AU  - Patrick M.M. Bossuyt
AU  - Isabelle Boutron
AU  - Tammy Hoffmann
AU  - Cynthia D. Mulrow
AU  - Larissa Shamseer
AU  - Jennifer Tetzlaff
AU  - Elie A. Akl
AU  - Sue E. Brennan
AU  - Roger Chou
AU  - Julie Glanville
AU  - Jeremy M. Grimshaw
AU  - Asbjørn Hróbjartsson
AU  - Manoj M. Lalu
AU  - Tianjing Li
AU  - Elizabeth Loder
AU  - Evan Mayo-Wilson
AU  - Steve McDonald
AU  - Adrian M. Price-Whelan
AU  - Lesley A. Stewart
AU  - James D. Thomas
AU  - Andrea C. Tricco
AU  - Vivian Welch
AU  - Penny Whiting
AU  - Joanne E. McKenzie
ER  - 

575.
TY  - journal-article
ID  - https://openalex.org/W2593758073
DO  - https://doi.org/10.1136/bmjopen-2016-012545
TI  - Analysis of the time and workers needed to conduct systematic reviews of medical interventions using data from the PROSPERO registry
AB  - To summarise logistical aspects of recently completed systematic reviews that were registered in the International Prospective Register of Systematic Reviews (PROSPERO) registry to quantify the time and resources required to complete such projects.Meta-analysis.All of the 195 registered and completed reviews (status from the PROSPERO registry) with associated publications at the time of our search (1 July 2014).All authors extracted data using registry entries and publication information related to the data sources used, the number of initially retrieved citations, the final number of included studies, the time between registration date to publication date and number of authors involved for completion of each publication. Information related to funding and geographical location was also recorded when reported.The mean estimated time to complete the project and publish the review was 67.3 weeks (IQR=42). The number of studies found in the literature searches ranged from 27 to 92 020; the mean yield rate of included studies was 2.94% (IQR=2.5); and the mean number of authors per review was 5, SD=3. Funded reviews took significantly longer to complete and publish (mean=42 vs 26 weeks) and involved more authors and team members (mean=6.8 vs 4.8 people) than those that did not report funding (both p<0.001).Systematic reviews presently take much time and require large amounts of human resources. In the light of the ever-increasing volume of published studies, application of existing computing and informatics technology should be applied to decrease this time and resource burden. We discuss recently published guidelines that provide a framework to make finding and accessing relevant literature less burdensome.
PY  - 2017
DA  - 2017-02-01
JO  - {'id': 'https://openalex.org/S79054089', 'issn_l': '2044-6055', 'issn': ['2044-6055'], 'display_name': 'BMJ Open', 'publisher': 'BMJ', 'type': 'journal', 'url': 'https://bmjopen.bmj.com/content/bmjopen/7/2/e012545.full.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc'}
DP  - OpenAlex
AU  - Rohit Borah
AU  - Andrew J. Brown
AU  - Patrice L. Capers
AU  - Kathryn A. Kaiser
ER  - 

576.
TY  - journal-article
ID  - https://openalex.org/W2961191798
DO  - https://doi.org/10.1186/s13643-019-1074-9
TI  - Toward systematic review automation: a practical guide to using machine learning tools in research synthesis
AB  - Technologies and methods to speed up the production of systematic reviews by reducing the manual labour involved have recently emerged. Automation has been proposed or used to expedite most steps of the systematic review process, including search, screening, and data extraction. However, how these technologies work in practice and when (and when not) to use them is often not clear to practitioners. In this practical guide, we provide an overview of current machine learning methods that have been proposed to expedite evidence synthesis. We also offer guidance on which of these are ready for use, their strengths and weaknesses, and how a systematic review team might go about using them in practice. when reported.The mean estimated time to complete the project and publish the review was 67.3 weeks (IQR=42). The number of studies found in the literature searches ranged from 27 to 92 020; the mean yield rate of included studies was 2.94% (IQR=2.5); and the mean number of authors per review was 5, SD=3. Funded reviews took significantly longer to complete and publish (mean=42 vs 26 weeks) and involved more authors and team members (mean=6.8 vs 4.8 people) than those that did not report funding (both p<0.001).Systematic reviews presently take much time and require large amounts of human resources. In the light of the ever-increasing volume of published studies, application of existing computing and informatics technology should be applied to decrease this time and resource burden. We discuss recently published guidelines that provide a framework to make finding and accessing relevant literature less burdensome.
PY  - 2019
DA  - 2019-07-11
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://systematicreviewsjournal.biomedcentral.com/track/pdf/10.1186/s13643-019-1074-9', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Iain J. Marshall
AU  - Byron C. Wallace
ER  - 

577.
TY  - proceedings-article
ID  - https://openalex.org/W2964179635
DO  - https://doi.org/10.18653/v1/p18-1019
TI  - A Corpus with Multi-Level Annotations of Patients, Interventions and Outcomes to Support Language Processing for Medical Literature
AB  - We present a corpus of 5,000 richly annotated abstracts of medical articles describing clinical randomized controlled trials. Annotations include demarcations of text spans that describe the Patient population enrolled, the Interventions studied and to what they were Compared, and the Outcomes measured (the ‘PICO’ elements). These spans are further annotated at a more granular level, e.g., individual interventions within them are marked and mapped onto a structured medical vocabulary. We acquired annotations from a diverse set of workers with varying levels of expertise and cost. We describe our data collection process and the corpus itself in detail. We then outline a set of challenging NLP tasks that would aid searching of the medical literature and the practice of evidence-based medicine. project and publish the review was 67.3 weeks (IQR=42). The number of studies found in the literature searches ranged from 27 to 92 020; the mean yield rate of included studies was 2.94% (IQR=2.5); and the mean number of authors per review was 5, SD=3. Funded reviews took significantly longer to complete and publish (mean=42 vs 26 weeks) and involved more authors and team members (mean=6.8 vs 4.8 people) than those that did not report funding (both p<0.001).Systematic reviews presently take much time and require large amounts of human resources. In the light of the ever-increasing volume of published studies, application of existing computing and informatics technology should be applied to decrease this time and resource burden. We discuss recently published guidelines that provide a framework to make finding and accessing relevant literature less burdensome.
PY  - 2018
DA  - 2018-07-01
JO  - {'id': 'https://openalex.org/S4306420508', 'issn_l': None, 'issn': None, 'display_name': 'Meeting of the Association for Computational Linguistics', 'publisher': None, 'type': 'conference', 'url': 'https://www.aclweb.org/anthology/P18-1019.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Benjamin D. Nye
AU  - Junyi Jessy Li
AU  - Roma Patel
AU  - Yinfei Yang
AU  - Iain J. Marshall
AU  - Ani Nenkova
AU  - Byron C. Wallace
ER  - 

578.
TY  - journal-article
ID  - https://openalex.org/W2397182203
DO  - https://doi.org/10.1186/s13643-016-0263-z
TI  - SWIFT-Review: a text-mining workbench for systematic review
AB  - There is growing interest in using machine learning approaches to priority rank studies and reduce human burden in screening literature when conducting systematic reviews. In addition, identifying addressable questions during the problem formulation phase of systematic review can be challenging, especially for topics having a large literature base. Here, we assess the performance of the SWIFT-Review priority ranking algorithm for identifying studies relevant to a given research question. We also explore the use of SWIFT-Review during problem formulation to identify, categorize, and visualize research areas that are data rich/data poor within a large literature corpus.Twenty case studies, including 15 public data sets, representing a range of complexity and size, were used to assess the priority ranking performance of SWIFT-Review. For each study, seed sets of manually annotated included and excluded titles and abstracts were used for machine training. The remaining references were then ranked for relevance using an algorithm that considers term frequency and latent Dirichlet allocation (LDA) topic modeling. This ranking was evaluated with respect to (1) the number of studies screened in order to identify 95 % of known relevant studies and (2) the "Work Saved over Sampling" (WSS) performance metric. To assess SWIFT-Review for use in problem formulation, PubMed literature search results for 171 chemicals implicated as EDCs were uploaded into SWIFT-Review (264,588 studies) and categorized based on evidence stream and health outcome. Patterns of search results were surveyed and visualized using a variety of interactive graphics.Compared with the reported performance of other tools using the same datasets, the SWIFT-Review ranking procedure obtained the highest scores on 11 out of 15 of the public datasets. Overall, these results suggest that using machine learning to triage documents for screening has the potential to save, on average, more than 50 % of the screening effort ordinarily required when using un-ordered document lists. In addition, the tagging and annotation capabilities of SWIFT-Review can be useful during the activities of scoping and problem formulation.Text-mining and machine learning software such as SWIFT-Review can be valuable tools to reduce the human screening burden and assist in problem formulation.
PY  - 2016
DA  - 2016-05-23
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://doi.org/10.1186/s13643-016-0263-z', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Brian M. Howard
AU  - Jason J. Phillips
AU  - Kyle M. Miller
AU  - Arpit Tandon
AU  - Deepak Mav
AU  - Mihir M. Shah
AU  - Stephanie Holmgren
AU  - Katherine E. Pelch
AU  - Vickie R. Walker
AU  - Andrew A. Rooney
AU  - Malcolm R. Macleod
AU  - Ruchir R. Shah
AU  - Kristina A. Thayer
ER  - 

579.
TY  - journal-article
ID  - https://openalex.org/W2285413972
DO  - https://doi.org/10.1186/s12916-016-0555-0
TI  - Wasted research when systematic reviews fail to provide a complete and up-to-date evidence synthesis: the example of lung cancer
AB  - Multiple treatments are frequently available for a given condition, and clinicians and patients need a comprehensive, up-to-date synthesis of evidence for all competing treatments. We aimed to quantify the waste of research related to the failure of systematic reviews to provide a complete and up-to-date evidence synthesis over time.We performed a series of systematic overviews and networks of randomized trials assessing the gap between evidence covered by systematic reviews and available trials of second-line treatments for advanced non-small cell lung cancer. We searched the Cochrane Database of Systematic Reviews, Database of Abstracts of Reviews of Effects, MEDLINE, EMBASE, and other resources sequentially by year from 2009 to March 2, 2015. We sequentially compared the amount of evidence missing from systematic reviews to the randomized evidence available for inclusion each year. We constructed cumulative networks of randomized evidence over time and evaluated the proportion of trials, patients, treatments, and treatment comparisons not covered by systematic reviews on December 31 each year from 2009 to 2015.We identified 77 trials (28,636 patients) assessing 47 treatments with 54 comparisons and 29 systematic reviews (13 published after 2013). From 2009 to 2015, the evidence covered by existing systematic reviews was consistently incomplete: 45 % to 70 % of trials; 30 % to 58 % of patients; 40 % to 66 % of treatments; and 38 % to 71 % of comparisons were missing. In the cumulative networks of randomized evidence, 10 % to 17 % of treatment comparisons were partially covered by systematic reviews and 55 % to 85 % were partially or not covered.We illustrate how systematic reviews of a given condition provide a fragmented, out-of-date panorama of the evidence for all treatments. This waste of research might be reduced by the development of live cumulative network meta-analyses. screening effort ordinarily required when using un-ordered document lists. In addition, the tagging and annotation capabilities of SWIFT-Review can be useful during the activities of scoping and problem formulation.Text-mining and machine learning software such as SWIFT-Review can be valuable tools to reduce the human screening burden and assist in problem formulation.
PY  - 2016
DA  - 2016-01-20
JO  - {'id': 'https://openalex.org/S135560524', 'issn_l': '1741-7015', 'issn': ['1741-7015'], 'display_name': 'BMC Medicine', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://bmcmedicine.biomedcentral.com/track/pdf/10.1186/s12916-016-0555-0', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Perrine Créquit
AU  - Ludovic Trinquart
AU  - Amélie Yavchitz
AU  - Philippe Ravaud
ER  - 

580.
TY  - journal-article
ID  - https://openalex.org/W2770117783
DO  - https://doi.org/10.1186/s12874-017-0431-4
TI  - Frequency of data extraction errors and methods to increase data extraction quality: a methodological review
AB  - Our objective was to assess the frequency of data extraction errors and its potential impact on results in systematic reviews. Furthermore, we evaluated the effect of different extraction methods, reviewer characteristics and reviewer training on error rates and results.We performed a systematic review of methodological literature in PubMed, Cochrane methodological registry, and by manual searches (12/2016). Studies were selected by two reviewers independently. Data were extracted in standardized tables by one reviewer and verified by a second.The analysis included six studies; four studies on extraction error frequency, one study comparing different reviewer extraction methods and two studies comparing different reviewer characteristics. We did not find a study on reviewer training. There was a high rate of extraction errors (up to 50%). Errors often had an influence on effect estimates. Different data extraction methods and reviewer characteristics had moderate effect on extraction error rates and effect estimates.The evidence base for established standards of data extraction seems weak despite the high prevalence of extraction errors. More comparative studies are needed to get deeper insights into the influence of different extraction methods. (13 published after 2013). From 2009 to 2015, the evidence covered by existing systematic reviews was consistently incomplete: 45 % to 70 % of trials; 30 % to 58 % of patients; 40 % to 66 % of treatments; and 38 % to 71 % of comparisons were missing. In the cumulative networks of randomized evidence, 10 % to 17 % of treatment comparisons were partially covered by systematic reviews and 55 % to 85 % were partially or not covered.We illustrate how systematic reviews of a given condition provide a fragmented, out-of-date panorama of the evidence for all treatments. This waste of research might be reduced by the development of live cumulative network meta-analyses. screening effort ordinarily required when using un-ordered document lists. In addition, the tagging and annotation capabilities of SWIFT-Review can be useful during the activities of scoping and problem formulation.Text-mining and machine learning software such as SWIFT-Review can be valuable tools to reduce the human screening burden and assist in problem formulation.
PY  - 2017
DA  - 2017-11-28
JO  - {'id': 'https://openalex.org/S185874209', 'issn_l': '1471-2288', 'issn': ['1471-2288'], 'display_name': 'BMC Medical Research Methodology', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://doi.org/10.1186/s12874-017-0431-4', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Tim Mathes
AU  - Pauline Klaßen
AU  - Dawid Pieper
ER  - 

581.
TY  - journal-article
ID  - https://openalex.org/W2963483681
DO  - https://doi.org/10.1111/2041-210x.13268
TI  - An automated approach to identifying search terms for systematic reviews using keyword co‐occurrence networks
AB  - No Abstract Found
PY  - 2019
DA  - 2019-10-01
JO  - {'id': 'https://openalex.org/V1131227', 'issn_l': '2041-210X', 'issn': ['2041-210X'], 'display_name': 'Methods in Ecology and Evolution', 'publisher': 'Wiley-Blackwell', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Eliza M. Grames
AU  - Andrew N. Stillman
AU  - Morgan W. Tingley
AU  - Chris S. Elphick
ER  - 

582.
TY  - journal-article
ID  - https://openalex.org/W2769625657
DO  - https://doi.org/10.1186/s13012-017-0660-2
TI  - Optimising the value of the evidence generated in implementation science: the use of ontologies to address the challenges
AB  - Implementing research findings into healthcare practice and policy is a complex process occurring in diverse contexts; it invariably depends on changing human behaviour in many parts of an intricate implementation system. Questions asked with the aim of improving implementation are multifarious variants of 'What works, compared with what, how well, with what exposure, with what behaviours (for how long), for whom, in what setting and why?'. Relevant evidence is being published at a high rate, but its quantity, complexity and lack of shared terminologies present challenges. The achievement of efficient, effective and timely synthesis of evidence is facilitated by using 'ontologies' to systematically structure and organise the evidence about constructs and their relationships, using a controlled, well-defined vocabulary. (up to 50%). Errors often had an influence on effect estimates. Different data extraction methods and reviewer characteristics had moderate effect on extraction error rates and effect estimates.The evidence base for established standards of data extraction seems weak despite the high prevalence of extraction errors. More comparative studies are needed to get deeper insights into the influence of different extraction methods. (13 published after 2013). From 2009 to 2015, the evidence covered by existing systematic reviews was consistently incomplete: 45 % to 70 % of trials; 30 % to 58 % of patients; 40 % to 66 % of treatments; and 38 % to 71 % of comparisons were missing. In the cumulative networks of randomized evidence, 10 % to 17 % of treatment comparisons were partially covered by systematic reviews and 55 % to 85 % were partially or not covered.We illustrate how systematic reviews of a given condition provide a fragmented, out-of-date panorama of the evidence for all treatments. This waste of research might be reduced by the development of live cumulative network meta-analyses. screening effort ordinarily required when using un-ordered document lists. In addition, the tagging and annotation capabilities of SWIFT-Review can be useful during the activities of scoping and problem formulation.Text-mining and machine learning software such as SWIFT-Review can be valuable tools to reduce the human screening burden and assist in problem formulation.
PY  - 2017
DA  - 2017-11-14
JO  - {'id': 'https://openalex.org/S76880069', 'issn_l': '1748-5908', 'issn': ['1748-5908'], 'display_name': 'Implementation Science', 'publisher': 'BioMed Central', 'type': 'journal', 'url': 'https://implementationscience.biomedcentral.com/track/pdf/10.1186/s13012-017-0660-2', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Susan Michie
AU  - Marie Johnston
ER  - 

583.
TY  - journal-article
ID  - https://openalex.org/W2180291732
DO  - https://doi.org/10.1186/s13643-015-0147-7
TI  - How to conduct systematic reviews more expeditiously?
AB  - Healthcare consumers, researchers, patients and policy makers increasingly use systematic reviews (SRs) to aid their decision-making process. However, the conduct of SRs can be a time-consuming and resource-intensive task. Often, clinical practice guideline developers or other decision-makers need to make informed decisions in a timely fashion (e.g. outbreaks of infection, hospital-based health technology assessments). Possible approaches to address the issue of timeliness in the production of SRs are to (a) implement process parallelisation, (b) adapt and apply innovative technologies, and/or (c) modify SR processes (e.g. study eligibility criteria, search sources, data extraction or quality assessment). Highly parallelised systematic reviewing requires substantial resources to support a team of experienced information specialists, reviewers and methodologists working alongside with clinical content experts to minimise the time for completing individual review steps while maximising the parallel progression of multiple steps. Effective coordination and management within the team and across external stakeholders are essential elements of this process. Emerging innovative technologies have a great potential for reducing workload and improving efficiency of SR production. The most promising areas of application would be to allow automation of specific SR tasks, in particular if these tasks are time consuming and resource intensive (e.g. language translation, study selection, data extraction). Modification of SR processes involves restricting, truncating and/or bypassing one or more SR steps, which may risk introducing bias to the review findings. Although the growing experiences in producing various types of rapid reviews (RR) and the accumulation of empirical studies exploring potential bias associated with specific SR tasks have contributed to the methodological development for expediting SR production, there is still a dearth of research examining the actual impact of methodological modifications and comparing the findings between RRs and SRs. This evidence would help to inform as to which SR tasks can be accelerated or truncated and to what degree, while maintaining the validity of review findings. Timely delivered SRs can be of value in informing healthcare decisions and recommendations, especially when there is practical urgency and there is no other relevant synthesised evidence. human screening burden and assist in problem formulation.
PY  - 2015
DA  - 2015-11-12
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://doi.org/10.1186/s13643-015-0147-7', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Alexander Tsertsvadze
AU  - Yen-Fu Chen
AU  - David Moher
AU  - Paul Sutcliffe
AU  - Noel D. McCarthy
ER  - 

584.
TY  - journal-article
ID  - https://openalex.org/W2508652664
DO  - https://doi.org/10.1186/s12874-016-0183-6
TI  - Resuming the discussion of AMSTAR: What can (should) be made better?
AB  - Evidence syntheses, and in particular systematic reviews (SRs), have become one of the cornerstones of evidence-based health care. The Assessment of Multiple Systematic Reviews (AMSTAR) tool has become the most widely used tool for investigating the methodological quality of SRs and is currently undergoing revision. The objective of this paper is to present insights, challenges and potential solutions from the point of view of a group of assessors, while referring to earlier methodological discussions and debates with respect to AMSTAR.One major drawback of AMSTAR is that it relies heavily on reporting quality rather than on methodological quality. This can be found in several items. Furthermore, it should be acknowledged that there are now new methods and procedures that did not exist when AMSTAR was developed. For example, the note to item 1 should now refer to the International Prospective Register of Ongoing Systematic Reviews (PROSPERO). Furthermore, item 3 should consider the definition of hand-searching, as the process of reviewing conference proceedings using the search function (e.g. in Microsoft Word or in a PDF file) does not meet the definition set out by the Cochrane Collaboration. Moreover, methods for assessing the quality of the body of evidence have evolved since AMSTAR was developed and should be incorporated into a revised AMSTAR tool. Potential solutions are presented for each AMSTAR item with the aim of allowing a more thorough assessment of SRs. As the AMSTAR tool is currently undergoing further development, our paper hopes to add to preceding discussions and papers regarding this tool and stimulate further discussion. development for expediting SR production, there is still a dearth of research examining the actual impact of methodological modifications and comparing the findings between RRs and SRs. This evidence would help to inform as to which SR tasks can be accelerated or truncated and to what degree, while maintaining the validity of review findings. Timely delivered SRs can be of value in informing healthcare decisions and recommendations, especially when there is practical urgency and there is no other relevant synthesised evidence. human screening burden and assist in problem formulation.
PY  - 2016
DA  - 2016-08-26
JO  - {'id': 'https://openalex.org/V185874209', 'issn_l': '1471-2288', 'issn': ['1471-2288'], 'display_name': 'BMC Medical Research Methodology', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://doi.org/10.1186/s12874-016-0183-6', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Uta Wegewitz
AU  - Beate Weikert
AU  - Alba Fishta
AU  - Anja Jacobs
AU  - Dawid Pieper
ER  - 

585.
TY  - journal-article
ID  - https://openalex.org/W2790635258
DO  - https://doi.org/10.3390/toxins10020083
TI  - Occurrence of β-N-methylamino-l-alanine (BMAA) and Isomers in Aquatic Environments and Aquatic Food Sources for Humans
AB  - The neurotoxin β-N-methylamino-l-alanine (BMAA), a non-protein amino acid produced by terrestrial and aquatic cyanobacteria and by micro-algae, has been suggested to play a role as an environmental factor in the neurodegenerative disease Amyotrophic Lateral Sclerosis-Parkinsonism-Dementia complex (ALS-PDC). The ubiquitous presence of BMAA in aquatic environments and organisms along the food chain potentially makes it public health concerns. However, the BMAA-associated human health risk remains difficult to rigorously assess due to analytical challenges associated with the detection and quantification of BMAA and its natural isomers, 2,4-diamino butyric acid (DAB), β-amino-N-methyl-alanine (BAMA) and N-(2-aminoethyl) glycine (AEG). This systematic review, reporting the current knowledge on the presence of BMAA and isomers in aquatic environments and human food sources, was based on a selection and a score numbering of the scientific literature according to various qualitative and quantitative criteria concerning the chemical analytical methods used. Results from the best-graded studies show that marine bivalves are to date the matrix containing the higher amount of BMAA, far more than most fish muscles, but with an exception for shark cartilage. This review discusses the available data in terms of their use for human health risk assessment and identifies knowledge gaps requiring further investigations. evolved since AMSTAR was developed and should be incorporated into a revised AMSTAR tool. Potential solutions are presented for each AMSTAR item with the aim of allowing a more thorough assessment of SRs. As the AMSTAR tool is currently undergoing further development, our paper hopes to add to preceding discussions and papers regarding this tool and stimulate further discussion. development for expediting SR production, there is still a dearth of research examining the actual impact of methodological modifications and comparing the findings between RRs and SRs. This evidence would help to inform as to which SR tasks can be accelerated or truncated and to what degree, while maintaining the validity of review findings. Timely delivered SRs can be of value in informing healthcare decisions and recommendations, especially when there is practical urgency and there is no other relevant synthesised evidence. human screening burden and assist in problem formulation.
PY  - 2018
DA  - 2018-02-14
JO  - {'id': 'https://openalex.org/S128990672', 'issn_l': '2072-6651', 'issn': ['2072-6651'], 'display_name': 'Toxins', 'publisher': 'MDPI', 'type': 'journal', 'url': 'https://www.mdpi.com/2072-6651/10/2/83/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Emilie Lance
AU  - Nathalie Arnich
AU  - Thomas Maignien
AU  - Ronel Biré
ER  - 

586.
TY  - journal-article
ID  - https://openalex.org/W2411035889
DO  - https://doi.org/10.1515/jdis-2017-0019
TI  - Rediscovering Don Swanson:The Past, Present and Future of Literature-based Discovery
AB  - Abstract Purpose The late Don R. Swanson was well appreciated during his lifetime as Dean of the Graduate Library School at University of Chicago, as winner of the American Society for Information Science Award of Merit for 2000, and as author of many seminal articles. In this informal essay, I will give my personal perspective on Don’s contributions to science, and outline some current and future directions in literature-based discovery that are rooted in concepts that he developed. Design/methodology/approach Personal recollections and literature review. Findings The Swanson A-B-C model of literature-based discovery has been successfully used by laboratory investigators analyzing their findings and hypotheses. It continues to be a fertile area of research in a wide range of application areas including text mining, drug repurposing, studies of scientific innovation, knowledge discovery in databases, and bioinformatics. Recently, additional modes of discovery that do not follow the A-B-C model have also been proposed and explored (e.g. so-called storytelling, gaps, analogies, link prediction, negative consensus, outliers, and revival of neglected or discarded research questions). Research limitations This paper reflects the opinions of the author and is not a comprehensive nor technically based review of literature-based discovery. Practical implications The general scientific public is still not aware of the availability of tools for literature-based discovery. Our Arrowsmith project site maintains a suite of discovery tools that are free and open to the public ( http://arrowsmith.psych.uic.edu) , as does BITOLA which is maintained by Dmitar Hristovski ( http://http://ibmi.mf.uni-lj.si/bitola) , and Epiphanet which is maintained by Trevor Cohen ( http://epiphanet.uth.tmc.edu/) . Bringing user-friendly tools to the public should be a high priority, since even more than advancing basic research in informatics, it is vital that we ensure that scientists actually use discovery tools and that these are actually able to help them make experimental discoveries in the lab and in the clinic. Originality/value This paper discusses problems and issues which were inherent in Don’s thoughts during his life, including those which have not yet been fully taken up and studied systematically. synthesised evidence. human screening burden and assist in problem formulation.
PY  - 2017
DA  - 2017-12-29
JO  - {'id': 'https://openalex.org/S2764801193', 'issn_l': '2096-157X', 'issn': ['2096-157X', '2543-683X'], 'display_name': 'Journal of Data and Information Science', 'publisher': 'Chinese Academy of Sciences', 'type': 'journal', 'url': 'https://content.sciendo.com/downloadpdf/journals/jdis/2/4/article-p43.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc-nd'}
DP  - OpenAlex
AU  - Neil R. Smalheiser
ER  - 

587.
TY  - journal-article
ID  - https://openalex.org/W3149778443
DO  - https://doi.org/10.1016/j.infsof.2021.106589
TI  - Automation of systematic literature reviews: A systematic literature review
AB  - Systematic Literature Review (SLR) studies aim to identify relevant primary papers, extract the required data, analyze, and synthesize results to gain further and broader insight into the investigated domain. Multiple SLR studies have been conducted in several domains, such as software engineering, medicine, and pharmacy. Conducting an SLR is a time-consuming, laborious, and costly effort. As such, several researchers developed different techniques to automate the SLR process. However, a systematic overview of the current state-of-the-art in SLR automation seems to be lacking. This study aims to collect and synthesize the studies that focus on the automation of SLR to pave the way for further research. A systematic literature review is conducted on published primary studies on the automation of SLR studies, in which 41 primary studies have been analyzed. This SLR identifies the objectives of automation studies, application domains, automated steps of the SLR, automation techniques, and challenges and solution directions. According to our study, the leading automated step is the Selection of Primary Studies . Although many studies have provided automation approaches for systematic literature reviews, no study has been found to apply automation techniques in the planning and reporting phase. Further research is needed to support the automation of the other activities of the SLR process. for literature-based discovery. Our Arrowsmith project site maintains a suite of discovery tools that are free and open to the public ( http://arrowsmith.psych.uic.edu) , as does BITOLA which is maintained by Dmitar Hristovski ( http://http://ibmi.mf.uni-lj.si/bitola) , and Epiphanet which is maintained by Trevor Cohen ( http://epiphanet.uth.tmc.edu/) . Bringing user-friendly tools to the public should be a high priority, since even more than advancing basic research in informatics, it is vital that we ensure that scientists actually use discovery tools and that these are actually able to help them make experimental discoveries in the lab and in the clinic. Originality/value This paper discusses problems and issues which were inherent in Don’s thoughts during his life, including those which have not yet been fully taken up and studied systematically. synthesised evidence. human screening burden and assist in problem formulation.
PY  - 2021
DA  - 2021-08-01
JO  - {'id': 'https://openalex.org/S205010575', 'issn_l': '0950-5849', 'issn': ['0950-5849', '1873-6025'], 'display_name': 'Information & Software Technology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Raymon van Dinter
AU  - Bedir Tekinerdogan
AU  - Daniel Rodriguez
ER  - 

588.
TY  - journal-article
ID  - https://openalex.org/W2947064635
DO  - https://doi.org/10.1186/s13643-019-1035-3
TI  - Study-based registers reduce waste in systematic reviewing: discussion and case report
AB  - Maintained study-based registers (SBRs) have, at their core, study records linked to, potentially, multiple other records such as references, data sets, standard texts and full-text reports. Such registers can minimise and refine searching, de-duplicating, screening and acquisition of full texts. SBRs can facilitate new review titles/updates and, within seconds, inform the team about the potential workload of each task. We discuss the advantages/disadvantages of SBRs and report a case of how such a register was used to develop a successful grant application and deliver results—reducing considerable redundancy of effort. SBRs saved time in question-setting and scoping and made rapid production of nine Cochrane systematic reviews possible. Whilst helping prioritise and conduct systematic reviews, SBRs improve quality. Those funding information specialists for literature reviewing could reasonably stipulate the resulting SBR to be delivered for dissemination and use beyond the life of the project. the SLR, automation techniques, and challenges and solution directions. According to our study, the leading automated step is the Selection of Primary Studies . Although many studies have provided automation approaches for systematic literature reviews, no study has been found to apply automation techniques in the planning and reporting phase. Further research is needed to support the automation of the other activities of the SLR process. for literature-based discovery. Our Arrowsmith project site maintains a suite of discovery tools that are free and open to the public ( http://arrowsmith.psych.uic.edu) , as does BITOLA which is maintained by Dmitar Hristovski ( http://http://ibmi.mf.uni-lj.si/bitola) , and Epiphanet which is maintained by Trevor Cohen ( http://epiphanet.uth.tmc.edu/) . Bringing user-friendly tools to the public should be a high priority, since even more than advancing basic research in informatics, it is vital that we ensure that scientists actually use discovery tools and that these are actually able to help them make experimental discoveries in the lab and in the clinic. Originality/value This paper discusses problems and issues which were inherent in Don’s thoughts during his life, including those which have not yet been fully taken up and studied systematically. synthesised evidence. human screening burden and assist in problem formulation.
PY  - 2019
DA  - 2019-05-30
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://doi.org/10.1186/s13643-019-1035-3', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Farhad Shokraneh
AU  - Clive E Adams
ER  - 

589.
TY  - journal-article
ID  - https://openalex.org/W3080144472
DO  - https://doi.org/10.1111/iwj.13474
TI  - Hyperspectral imaging in wound care: A systematic review
AB  - Multispectral and hyperspectral imaging (HSI) are emerging imaging techniques with the potential to transform the way patients with wounds are cared for, but it is not clear whether current systems are capable of delivering real-time tissue characterisation and treatment guidance. We conducted a systematic review of HSI systems that have been assessed in patients, published over the past 32 years. We analysed 140 studies, including 10 different HSI systems. Current in vivo HSI systems generate a tissue oxygenation map. Tissue oxygenation measurements may help to predict those patients at risk of wound formation or delayed healing. No safety concerns were reported in any studies. A small number of studies have demonstrated the capabilities of in vivo label-free HSI, but further work is needed to fully integrate it into the current clinical workflow for different wound aetiologies. As an emerging imaging modality for medical applications, HSI offers great potential for non-invasive disease diagnosis and guidance when treating patients with both acute and chronic wounds. Primary Studies . Although many studies have provided automation approaches for systematic literature reviews, no study has been found to apply automation techniques in the planning and reporting phase. Further research is needed to support the automation of the other activities of the SLR process. for literature-based discovery. Our Arrowsmith project site maintains a suite of discovery tools that are free and open to the public ( http://arrowsmith.psych.uic.edu) , as does BITOLA which is maintained by Dmitar Hristovski ( http://http://ibmi.mf.uni-lj.si/bitola) , and Epiphanet which is maintained by Trevor Cohen ( http://epiphanet.uth.tmc.edu/) . Bringing user-friendly tools to the public should be a high priority, since even more than advancing basic research in informatics, it is vital that we ensure that scientists actually use discovery tools and that these are actually able to help them make experimental discoveries in the lab and in the clinic. Originality/value This paper discusses problems and issues which were inherent in Don’s thoughts during his life, including those which have not yet been fully taken up and studied systematically. synthesised evidence. human screening burden and assist in problem formulation.
PY  - 2020
DA  - 2020-08-23
JO  - {'id': 'https://openalex.org/S118780703', 'issn_l': '1742-4801', 'issn': ['1742-4801', '1742-481X'], 'display_name': 'International Wound Journal', 'publisher': 'Wiley-Blackwell', 'type': 'journal', 'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/iwj.13474', 'is_oa': True, 'version': 'publishedVersion', 'license': 'implied-oa'}
DP  - OpenAlex
AU  - Gennadi Saiko
AU  - Phoebe Lombardi
AU  - Yunghan Au
AU  - Douglas Queen
AU  - David G. Armstrong
AU  - Keith G Harding
ER  - 

590.
TY  - journal-article
ID  - https://openalex.org/W2604351697
DO  - https://doi.org/10.1002/jrsm.1237
TI  - Can abstract screening workload be reduced using text mining? User experiences of the tool Rayyan
AB  - One time-consuming aspect of conducting systematic reviews is the task of sifting through abstracts to identify relevant studies. One promising approach for reducing this burden uses text mining technology to identify those abstracts that are potentially most relevant for a project, allowing those abstracts to be screened first.To examine the effectiveness of the text mining functionality of the abstract screening tool Rayyan. User experiences were collected.Rayyan was used to screen abstracts for 6 reviews in 2015. After screening 25%, 50%, and 75% of the abstracts, the screeners logged the relevant references identified. A survey was sent to users.After screening half of the search result with Rayyan, 86% to 99% of the references deemed relevant to the study were identified. Of those studies included in the final reports, 96% to 100% were already identified in the first half of the screening process. Users rated Rayyan 4.5 out of 5.The text mining function in Rayyan successfully helped reviewers identify relevant studies early in the screening process. Studies . Although many studies have provided automation approaches for systematic literature reviews, no study has been found to apply automation techniques in the planning and reporting phase. Further research is needed to support the automation of the other activities of the SLR process. for literature-based discovery. Our Arrowsmith project site maintains a suite of discovery tools that are free and open to the public ( http://arrowsmith.psych.uic.edu) , as does BITOLA which is maintained by Dmitar Hristovski ( http://http://ibmi.mf.uni-lj.si/bitola) , and Epiphanet which is maintained by Trevor Cohen ( http://epiphanet.uth.tmc.edu/) . Bringing user-friendly tools to the public should be a high priority, since even more than advancing basic research in informatics, it is vital that we ensure that scientists actually use discovery tools and that these are actually able to help them make experimental discoveries in the lab and in the clinic. Originality/value This paper discusses problems and issues which were inherent in Don’s thoughts during his life, including those which have not yet been fully taken up and studied systematically. synthesised evidence. human screening burden and assist in problem formulation.
PY  - 2017
DA  - 2017-09-01
JO  - {'id': 'https://openalex.org/S205768342', 'issn_l': '1759-2879', 'issn': ['1759-2879', '1759-2887'], 'display_name': 'Research Synthesis Methods', 'publisher': 'Wiley-Blackwell', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Hanna Olofsson
AU  - Agneta Brolund
AU  - Christel Hellberg
AU  - Rebecca A. Silverstein
AU  - Karin Stenström
AU  - Marie Österberg
AU  - Jessica Dagerhamn
ER  - 

591.
TY  - other
ID  - https://openalex.org/W4240003251
DO  - https://doi.org/10.1002/9781119536604.ch5
TI  - Collecting data
AB  - No Abstract Found
PY  - 2019
DA  - 2019-09-20
JO  - {'id': None, 'issn_l': None, 'issn': None, 'display_name': 'Cochrane Handbook for Systematic Reviews of Interventions', 'publisher': None, 'type': None, 'url': 'https://doi.org/10.1002/9781119536604.ch5', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Tianjing Li
AU  - Julian P T Higgins
AU  - Jonathan J Deeks
ER  - 

592.
TY  - journal-article
ID  - https://openalex.org/W2887617069
DO  - https://doi.org/10.1016/j.acra.2018.04.025
TI  - Systematic Review of the Literature: Best Practices
AB  - Reviews of published scientific literature are a valuable resource that can underline best practices in medicine and clarify clinical controversies. Among the various types of reviews, the systematic review of the literature is ranked as the most rigorous since it is a high-level summary of existing evidence focused on answering a precise question. Systematic reviews employ a pre-defined protocol to identify relevant and trustworthy literature. Such reviews can accomplish several critical goals that are not easily achievable with typical empirical studies by allowing identification and discussion of best evidence, contradictory findings, and gaps in the literature. The Association of University Radiologists Radiology Research Alliance Systematic Review Task Force convened to explore the methodology and practical considerations involved in performing a systematic review. This article provides a detailed and practical guide for performing a systematic review and discusses its applications in radiology. Users rated Rayyan 4.5 out of 5.The text mining function in Rayyan successfully helped reviewers identify relevant studies early in the screening process. Studies . Although many studies have provided automation approaches for systematic literature reviews, no study has been found to apply automation techniques in the planning and reporting phase. Further research is needed to support the automation of the other activities of the SLR process. for literature-based discovery. Our Arrowsmith project site maintains a suite of discovery tools that are free and open to the public ( http://arrowsmith.psych.uic.edu) , as does BITOLA which is maintained by Dmitar Hristovski ( http://http://ibmi.mf.uni-lj.si/bitola) , and Epiphanet which is maintained by Trevor Cohen ( http://epiphanet.uth.tmc.edu/) . Bringing user-friendly tools to the public should be a high priority, since even more than advancing basic research in informatics, it is vital that we ensure that scientists actually use discovery tools and that these are actually able to help them make experimental discoveries in the lab and in the clinic. Originality/value This paper discusses problems and issues which were inherent in Don’s thoughts during his life, including those which have not yet been fully taken up and studied systematically. synthesised evidence. human screening burden and assist in problem formulation.
PY  - 2018
DA  - 2018-11-01
JO  - {'id': 'https://openalex.org/S182038535', 'issn_l': '1076-6332', 'issn': ['1076-6332', '1878-4046'], 'display_name': 'Academic Radiology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Supriya Gupta
AU  - Prabhakar Rajiah
AU  - Erik H. Middlebrooks
AU  - Dhiraj Baruah
AU  - Brett W. Carter
AU  - Kirsteen R. Burton
AU  - Arindam R. Chatterjee
AU  - Matthew J. Miller
ER  - 

593.
TY  - journal-article
ID  - https://openalex.org/W3176607169
DO  - https://doi.org/10.3390/su13137182
TI  - Implications for Sustainability of the Joint Application of Bioeconomy and Circular Economy: A Worldwide Trend Study
AB  - The joint application of bioeconomy (BE) and circular economy (CE) promotes the sustainable use of natural resources, since by applying a systemic approach, it improves the efficiency of these resources and reduces the impact on the environment. Both strategies, which belong to the area of green economy, provide a global and integrated approach towards environmental sustainability, as regards the extraction of biological materials, the protection of biodiversity and even the primary function of food production in agriculture. The objective was to analyze the implications for sustainability of BE and CE joint application. A systematic and bibliometric review has been applied to a sample of 1961 articles, selected from the period 2004–May 2021. A quantitative and qualitative advance is observed in this field of study. The expansion of scientific production is due to its multidisciplinary nature, since it implies technical, environmental and economic knowledge. The main contribution of this study is to understand the state of research on the implications for sustainability that BE and CE have when combined, in relation to their evolution, the scientific collaboration between the main driving agents, and the identification of the main lines of research developed. phase. Further research is needed to support the automation of the other activities of the SLR process. for literature-based discovery. Our Arrowsmith project site maintains a suite of discovery tools that are free and open to the public ( http://arrowsmith.psych.uic.edu) , as does BITOLA which is maintained by Dmitar Hristovski ( http://http://ibmi.mf.uni-lj.si/bitola) , and Epiphanet which is maintained by Trevor Cohen ( http://epiphanet.uth.tmc.edu/) . Bringing user-friendly tools to the public should be a high priority, since even more than advancing basic research in informatics, it is vital that we ensure that scientists actually use discovery tools and that these are actually able to help them make experimental discoveries in the lab and in the clinic. Originality/value This paper discusses problems and issues which were inherent in Don’s thoughts during his life, including those which have not yet been fully taken up and studied systematically. synthesised evidence. human screening burden and assist in problem formulation.
PY  - 2021
DA  - 2021-06-26
JO  - {'id': 'https://openalex.org/S10134376', 'issn_l': '2071-1050', 'issn': ['2071-1050'], 'display_name': 'Sustainability', 'publisher': 'MDPI', 'type': 'journal', 'url': 'https://www.mdpi.com/2071-1050/13/13/7182/pdf?version=1624698403', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Emilio Abad-Segura
AU  - Ana Batlles-delaFuente
AU  - Mariana-Daniela González-Zamar
AU  - Luis J. Belmonte-Ureña
ER  - 

594.
TY  - journal-article
ID  - https://openalex.org/W2606513243
DO  - https://doi.org/10.1007/s13755-017-0020-2
TI  - Patient healthcare trajectory. An essential monitoring tool: a systematic review
AB  - Abstract Background Patient healthcare trajectory is a recent emergent topic in the literature, encompassing broad concepts. However, the rationale for studying patients’ trajectories, and how this trajectory concept is defined remains a public health challenge. Our research was focused on patients’ trajectories based on disease management and care, while also considering medico-economic aspects of the associated management. We illustrated this concept with an example: a myocardial infarction (MI) occurring in a patient’s hospital trajectory of care. The patient follow-up was traced via the prospective payment system. We applied a semi-automatic text mining process to conduct a comprehensive review of patient healthcare trajectory studies. This review investigated how the concept of trajectory is defined, studied and what it achieves. Methods We performed a PubMed search to identify reports that had been published in peer-reviewed journals between January 1, 2000 and October 31, 2015. Fourteen search questions were formulated to guide our review. A semi-automatic text mining process based on a semantic approach was performed to conduct a comprehensive review of patient healthcare trajectory studies. Text mining techniques were used to explore the corpus in a semantic perspective in order to answer non-a priori questions. Complementary review methods on a selected subset were used to answer a priori questions. Results Among the 33,514 publications initially selected for analysis, only 70 relevant articles were semi-automatically extracted and thoroughly analysed. Oncology is particularly prevalent due to its already well-established processes of care. For the trajectory thema, 80% of articles were distributed in 11 clusters. These clusters contain distinct semantic information, for example health outcomes (29%), care process (26%) and administrative and financial aspects (16%). Conclusion This literature review highlights the recent interest in the trajectory concept. The approach is also gradually being used to monitor trajectories of care for chronic diseases such as diabetes, organ failure or coronary artery and MI trajectory of care, to improve care and reduce costs. Patient trajectory is undoubtedly an essential approach to be further explored in order to improve healthcare monitoring. studied systematically. synthesised evidence. human screening burden and assist in problem formulation.
PY  - 2017
DA  - 2017-04-12
JO  - {'id': 'https://openalex.org/V4210178793', 'issn_l': '2047-2501', 'issn': ['2047-2501'], 'display_name': 'Health information science and systems', 'publisher': 'Springer Nature', 'type': 'journal', 'url': 'https://link.springer.com/content/pdf/10.1007/s13755-017-0020-2.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Jessica Pinaire
AU  - Jérôme Azé
AU  - Sandra Bringay
AU  - Paul Landais
ER  - 

595.
TY  - journal-article
ID  - https://openalex.org/W3120355807
DO  - https://doi.org/10.1136/bmjebm-2020-111651
TI  - Summarising good practice guidelines for data extraction for systematic reviews and meta-analysis
AB  - Data extraction is the process of a systematic review that occurs between identifying eligible studies and analysing the data, whether it can be a qualitative synthesis or a quantitative synthesis involving the pooling of data in a meta-analysis. The aims of data extraction are to obtain information about the included studies in terms of the characteristics of each study and its population and, for quantitative synthesis, to collect the necessary data to carry out meta-analysis. In systematic reviews, information about the included studies will also be required to conduct risk of bias assessments, but these data are not the focus of this article.

Following good practice when extracting data will help make the process efficient and reduce the risk of errors and bias. Failure to follow good practice risks basing the analysis on poor quality data, and therefore providing poor quality inputs, which will result in poor quality outputs, with unreliable conclusions and invalid study findings. In computer science, this is known as ‘garbage in, garbage out’ or ‘rubbish in, rubbish out’. Furthermore, providing insufficient information about the included studies for readers to be able to assess the generalisability of the findings from a systematic review will undermine the value of the pooled analysis. Such failures will cause your systematic review and meta-analysis to be less useful than it ought to be.

Some guidelines for data extraction are formal, including those described in the Cochrane Handbook for Systematic Reviews of Interventions,1 the Cochrane Handbook for Diagnostic Test Accuracy Reviews,2 3 the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) reporting guidelines for systematic reviews and their protocols4–7 and other sources,8 9, formal guidelines are complemented with informal advice in the form of examples and videos on how to avoid possible pitfalls and guidance on … for chronic diseases such as diabetes, organ failure or coronary artery and MI trajectory of care, to improve care and reduce costs. Patient trajectory is undoubtedly an essential approach to be further explored in order to improve healthcare monitoring. studied systematically. synthesised evidence. human screening burden and assist in problem formulation.
PY  - 2021
DA  - 2021-02-25
JO  - {'id': 'https://openalex.org/S4210227606', 'issn_l': '2515-446X', 'issn': ['2515-446X', '2515-4478'], 'display_name': 'BMJ evidence-based medicine', 'publisher': 'BMJ', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Kathryn L. Taylor
AU  - Kamal R Mahtani
AU  - Jeffrey K Aronson
ER  - 

596.
TY  - proceedings-article
ID  - https://openalex.org/W2406978180
DO  - https://doi.org/10.1145/2915970.2915982
TI  - A critical analysis of studies that address the use of text mining for citation screening in systematic reviews
AB  - Background: Since the introduction of the systematic review process to Software Engineering in 2004, researchers have investigated a number of ways to mitigate the amount of effort and time taken to filter through large volumes of literature.Aim: This study aims to provide a critical analysis of text mining techniques used to support the citation screening stage of the systematic review process.Method: We critically re-reviewed papers included in a previous systematic review which addressed the use of text mining methods to support the screening of papers for inclusion in a review. The previous review did not provide a detailed analysis of the text mining methods used. We focus on the availability in the papers of information about the text mining methods employed, including the description and explanation of the methods, parameter settings, assessment of the appropriateness of their application given the size and dimensionality of the data used, performance on training, testing and validation data sets, and further information that may support the reproducibility of the included studies.Results: Support Vector Machines (SVM), Naive Bayes (NB) and Committee of classifiers (Ensemble) are the most used classification algorithms. In all of the studies, features were represented with Bag-of-Words (BOW) using both binary features (28%) and term frequency (66%). Five studies experimented with n-grams with n between 2 and 4, but mostly the unigram was used. χ2, information gain and tf-idf were the most commonly used feature selection techniques. Feature extraction was rarely used although LDA and topic modelling were used. Recall, precision, F and AUC were the most used metrics and cross validation was also well used. More than half of the studies used a corpus size of below 1,000 documents for their experiments while corpus size for around 80% of the studies was 3,000 or fewer documents. The major common ground we found for comparing performance assessment based on independent replication of studies was the use of the same dataset but a sound performance comparison could not be established because the studies had little else in common. In most of the studies, insufficient information was reported to enable independent replication. The studies analysed generally did not include any discussion of the statistical appropriateness of the text mining method that they applied. In the case of applications of SVM, none of the studies report the number of support vectors that they found to indicate the complexity of the prediction engine that they use, making it impossible to judge the extent to which over-fitting might account for the good performance results.Conclusions: There is yet to be concrete evidence about the effectiveness of text mining algorithms regarding their use in the automation of citation screening in systematic reviews. The studies indicate that options are still being explored, but there is a need for better reporting as well as more explicit process details and access to datasets to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2016
DA  - 2016-06-01
JO  - {'id': 'https://openalex.org/S4306418396', 'issn_l': None, 'issn': None, 'display_name': 'Evaluation and Assessment in Software Engineering', 'publisher': None, 'type': 'conference', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Babatunde K. Olorisade
AU  - Ed de Quincey
AU  - Pearl Brereton
AU  - Peter Andras
ER  - 

597.
TY  - journal-article
ID  - https://openalex.org/W2893752993
DO  - https://doi.org/10.1016/j.jclinepi.2018.08.023
TI  - Automatic extraction of quantitative data from ClinicalTrials.gov to conduct meta-analyses
AB  - Systematic reviews and meta-analyses are labor-intensive and time-consuming. Automated extraction of quantitative data from primary studies can accelerate this process. ClinicalTrials.gov, launched in 2000, is the world's largest trial repository of results data from clinical trials; it has been used as a source instead of journal articles. We have developed a Web application called EXACT (EXtracting Accurate efficacy and safety information from ClinicalTrials.gov) that allows users without advanced programming skills to automatically extract data from ClinicalTrials.gov in analysis-ready format. We have also used the automatically extracted data to examine the reproducibility of meta-analyses in three published systematic reviews.We developed a Python-based software application (EXACT) that automatically extracts data required for meta-analysis from the ClinicalTrials.gov database in a spreadsheet format. We confirmed the accuracy of the extracted data and then used those data to repeat meta-analyses in three published systematic reviews. To ensure that we used the same statistical methods and outcomes as the published systematic reviews, we repeated the meta-analyses using data manually extracted from the relevant journal articles. For the outcomes whose results we were able to reproduce using those journal article data, we examined the usability of ClinicalTrials.gov data.EXACT extracted data at ClincalTrials.gov with 100% accuracy, and it required 60% less time than the usual practice of manually extracting data from journal articles. We found that 87% of the data elements extracted using EXACT matched those extracted manually from the journal articles. We were able to reproduce 24 of 28 outcomes using the journal article data. Of these 24 outcomes, we were able to reproduce 83.3% of the published estimates using data at ClinicalTrials.gov.EXACT (http://bio-nlp.org/EXACT) automatically and accurately extracted data elements from ClinicalTrials.gov and thus reduced time in data extraction. The ClinicalTrials.gov data reproduced most meta-analysis results in our study, but this conclusion needs further validation. ground we found for comparing performance assessment based on independent replication of studies was the use of the same dataset but a sound performance comparison could not be established because the studies had little else in common. In most of the studies, insufficient information was reported to enable independent replication. The studies analysed generally did not include any discussion of the statistical appropriateness of the text mining method that they applied. In the case of applications of SVM, none of the studies report the number of support vectors that they found to indicate the complexity of the prediction engine that they use, making it impossible to judge the extent to which over-fitting might account for the good performance results.Conclusions: There is yet to be concrete evidence about the effectiveness of text mining algorithms regarding their use in the automation of citation screening in systematic reviews. The studies indicate that options are still being explored, but there is a need for better reporting as well as more explicit process details and access to datasets to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2019
DA  - 2019-01-01
JO  - {'id': 'https://openalex.org/S64418186', 'issn_l': '0895-4356', 'issn': ['1878-5921', '0895-4356'], 'display_name': 'Journal of Clinical Epidemiology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Richeek Pradhan
AU  - David C. Hoaglin
AU  - Matthew Cornell
AU  - Weisong Liu
AU  - Victoria Wang
AU  - Hong Yu
ER  - 

598.
TY  - journal-article
ID  - https://openalex.org/W2902105843
DO  - https://doi.org/10.1186/s12911-019-0814-z
TI  - Machine learning to help researchers evaluate biases in clinical trials: a prospective, randomized user study
AB  - Assessing risks of bias in randomized controlled trials (RCTs) is an important but laborious task when conducting systematic reviews. RobotReviewer (RR), an open-source machine learning (ML) system, semi-automates bias assessments. We conducted a user study of RobotReviewer, evaluating time saved and usability of the tool.Systematic reviewers applied the Cochrane Risk of Bias tool to four randomly selected RCT articles. Reviewers judged: whether an RCT was at low, or high/unclear risk of bias for each bias domain in the Cochrane tool (Version 1); and highlighted article text justifying their decision. For a random two of the four articles, the process was semi-automated: users were provided with ML-suggested bias judgments and text highlights. Participants could amend the suggestions if necessary. We measured time taken for the task, ML suggestions, usability via the System Usability Scale (SUS) and collected qualitative feedback.For 41 volunteers, semi-automation was quicker than manual assessment (mean 755 vs. 824 s; relative time 0.75, 95% CI 0.62-0.92). Reviewers accepted 301/328 (91%) of the ML Risk of Bias (RoB) judgments, and 202/328 (62%) of text highlights without change. Overall, ML suggested text highlights had a recall of 0.90 (SD 0.14) and precision of 0.87 (SD 0.21) with respect to the users' final versions. Reviewers assigned the system a mean 77.7 SUS score, corresponding to a rating between "good" and "excellent".Semi-automation (where humans validate machine learning suggestions) can improve the efficiency of evidence synthesis. Our system was rated highly usable, and expedited bias assessment of RCTs. the journal article data. Of these 24 outcomes, we were able to reproduce 83.3% of the published estimates using data at ClinicalTrials.gov.EXACT (http://bio-nlp.org/EXACT) automatically and accurately extracted data elements from ClinicalTrials.gov and thus reduced time in data extraction. The ClinicalTrials.gov data reproduced most meta-analysis results in our study, but this conclusion needs further validation. ground we found for comparing performance assessment based on independent replication of studies was the use of the same dataset but a sound performance comparison could not be established because the studies had little else in common. In most of the studies, insufficient information was reported to enable independent replication. The studies analysed generally did not include any discussion of the statistical appropriateness of the text mining method that they applied. In the case of applications of SVM, none of the studies report the number of support vectors that they found to indicate the complexity of the prediction engine that they use, making it impossible to judge the extent to which over-fitting might account for the good performance results.Conclusions: There is yet to be concrete evidence about the effectiveness of text mining algorithms regarding their use in the automation of citation screening in systematic reviews. The studies indicate that options are still being explored, but there is a need for better reporting as well as more explicit process details and access to datasets to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2019
DA  - 2019-05-08
JO  - {'id': 'https://openalex.org/V107516304', 'issn_l': '1472-6947', 'issn': ['1472-6947'], 'display_name': 'BMC Medical Informatics and Decision Making', 'publisher': 'BioMed Central', 'type': 'journal', 'url': 'https://doi.org/10.1186/s12911-019-0814-z', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Frank Soboczenski
AU  - Thomas A Trikalinos
AU  - Joël Kuiper
AU  - Randolph G. Bias
AU  - Byron C. Wallace
AU  - Iain J. Marshall
ER  - 

599.
TY  - journal-article
ID  - https://openalex.org/W2992824360
DO  - https://doi.org/10.1186/s12911-019-0992-8
TI  - Improving reference prioritisation with PICO recognition
AB  - Machine learning can assist with multiple tasks during systematic reviews to facilitate the rapid retrieval of relevant references during screening and to identify and extract information relevant to the study characteristics, which include the PICO elements of patient/population, intervention, comparator, and outcomes. The latter requires techniques for identifying and categorising fragments of text, known as named entity recognition.A publicly available corpus of PICO annotations on biomedical abstracts is used to train a named entity recognition model, which is implemented as a recurrent neural network. This model is then applied to a separate collection of abstracts for references from systematic reviews within biomedical and health domains. The occurrences of words tagged in the context of specific PICO contexts are used as additional features for a relevancy classification model. Simulations of the machine learning-assisted screening are used to evaluate the work saved by the relevancy model with and without the PICO features. Chi-squared and statistical significance of positive predicted values are used to identify words that are more indicative of relevancy within PICO contexts.Inclusion of PICO features improves the performance metric on 15 of the 20 collections, with substantial gains on certain systematic reviews. Examples of words whose PICO context are more precise can explain this increase.Words within PICO tagged segments in abstracts are predictive features for determining inclusion. Combining PICO annotation model into the relevancy classification pipeline is a promising approach. The annotations may be useful on their own to aid users in pinpointing necessary information for data extraction, or to facilitate semantic search. were able to reproduce 83.3% of the published estimates using data at ClinicalTrials.gov.EXACT (http://bio-nlp.org/EXACT) automatically and accurately extracted data elements from ClinicalTrials.gov and thus reduced time in data extraction. The ClinicalTrials.gov data reproduced most meta-analysis results in our study, but this conclusion needs further validation. ground we found for comparing performance assessment based on independent replication of studies was the use of the same dataset but a sound performance comparison could not be established because the studies had little else in common. In most of the studies, insufficient information was reported to enable independent replication. The studies analysed generally did not include any discussion of the statistical appropriateness of the text mining method that they applied. In the case of applications of SVM, none of the studies report the number of support vectors that they found to indicate the complexity of the prediction engine that they use, making it impossible to judge the extent to which over-fitting might account for the good performance results.Conclusions: There is yet to be concrete evidence about the effectiveness of text mining algorithms regarding their use in the automation of citation screening in systematic reviews. The studies indicate that options are still being explored, but there is a need for better reporting as well as more explicit process details and access to datasets to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2019
DA  - 2019-12-05
JO  - {'id': 'https://openalex.org/V107516304', 'issn_l': '1472-6947', 'issn': ['1472-6947'], 'display_name': 'BMC Medical Informatics and Decision Making', 'publisher': 'BioMed Central', 'type': 'journal', 'url': 'https://bmcmedinformdecismak.biomedcentral.com/track/pdf/10.1186/s12911-019-0992-8', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - John McNaught
AU  - Meizhi Ju
AU  - Piotr Przybyła
AU  - Sophia Ananiadou
ER  - 

600.
TY  - journal-article
ID  - https://openalex.org/W2810434445
DO  - https://doi.org/10.1016/j.jclinepi.2018.06.011
TI  - Improving the conduct of systematic reviews: a process mining perspective
AB  - To illustrate the use of process mining concepts, techniques, and tools to improve the systematic review process.We simulated review activities and step-specific methods in the process for systematic reviews conducted by one research team over 1 year to generate an event log of activities, with start/end dates, reviewer assignment by expertise, and person-hours worked. Process mining techniques were applied to the event log to "discover" process models, which allowed visual display, animation, or replay of the simulated review activities. Summary statistics were calculated for person-time and timelines. We also analyzed the social networks of team interactions.The 12 simulated reviews included an average of 3,831 titles/abstracts (range: 1,565-6,368) and 20 studies (6-42). The average review completion time was 463 days (range: 289-629) (881 person-hours [range: 243-1,752]). The average person-hours per activity were study selection 26%, data collection 24%, report preparation 23%, and meta-analysis 17%. Social network analyses showed the organizational interaction of team members, including how they worked together to complete review tasks and to hand over tasks upon completion.Event log and process mining can be valuable tools for research teams interested in improving and modernizing the systematic review process. certain systematic reviews. Examples of words whose PICO context are more precise can explain this increase.Words within PICO tagged segments in abstracts are predictive features for determining inclusion. Combining PICO annotation model into the relevancy classification pipeline is a promising approach. The annotations may be useful on their own to aid users in pinpointing necessary information for data extraction, or to facilitate semantic search. were able to reproduce 83.3% of the published estimates using data at ClinicalTrials.gov.EXACT (http://bio-nlp.org/EXACT) automatically and accurately extracted data elements from ClinicalTrials.gov and thus reduced time in data extraction. The ClinicalTrials.gov data reproduced most meta-analysis results in our study, but this conclusion needs further validation. ground we found for comparing performance assessment based on independent replication of studies was the use of the same dataset but a sound performance comparison could not be established because the studies had little else in common. In most of the studies, insufficient information was reported to enable independent replication. The studies analysed generally did not include any discussion of the statistical appropriateness of the text mining method that they applied. In the case of applications of SVM, none of the studies report the number of support vectors that they found to indicate the complexity of the prediction engine that they use, making it impossible to judge the extent to which over-fitting might account for the good performance results.Conclusions: There is yet to be concrete evidence about the effectiveness of text mining algorithms regarding their use in the automation of citation screening in systematic reviews. The studies indicate that options are still being explored, but there is a need for better reporting as well as more explicit process details and access to datasets to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2018
DA  - 2018-11-01
JO  - {'id': 'https://openalex.org/S64418186', 'issn_l': '0895-4356', 'issn': ['1878-5921', '0895-4356'], 'display_name': 'Journal of Clinical Epidemiology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Ba' Pham
AU  - Ebrahim Bagheri
AU  - Patricia Rios
AU  - Asef Pourmasoumi
AU  - Reid Robson
AU  - Jeremiah Hwee
AU  - Wanrudee Isaranuwatchai
AU  - Nazia Darvesh
AU  - Matthew J. Page
AU  - Andrea C. Tricco
ER  - 

601.
TY  - journal-article
ID  - https://openalex.org/W2961552777
DO  - https://doi.org/10.1016/j.jclinepi.2019.07.005
TI  - A randomized trial provided new evidence on the accuracy and efficiency of traditional vs. electronically annotated abstraction approaches in systematic reviews
AB  - Data Abstraction Assistant (DAA) is a software for linking items abstracted into a data collection form for a systematic review to their locations in a study report. We conducted a randomized cross-over trial that compared DAA-facilitated single-data abstraction plus verification ("DAA verification"), single data abstraction plus verification ("regular verification"), and independent dual data abstraction plus adjudication ("independent abstraction").This study is an online randomized cross-over trial with 26 pairs of data abstractors. Each pair abstracted data from six articles, two per approach. Outcomes were the proportion of errors and time taken.Overall proportion of errors was 17% for DAA verification, 16% for regular verification, and 15% for independent abstraction. DAA verification was associated with higher odds of errors when compared with regular verification (adjusted odds ratio [OR] = 1.08; 95% confidence interval [CI]: 0.99-1.17) or independent abstraction (adjusted OR = 1.12; 95% CI: 1.03-1.22). For each article, DAA verification took 20 minutes (95% CI: 1-40) longer than regular verification, but 46 minutes (95% CI: 26 to 66) shorter than independent abstraction.Independent abstraction may only be necessary for complex data items. DAA provides an audit trail that is crucial for reproducible research. certain systematic reviews. Examples of words whose PICO context are more precise can explain this increase.Words within PICO tagged segments in abstracts are predictive features for determining inclusion. Combining PICO annotation model into the relevancy classification pipeline is a promising approach. The annotations may be useful on their own to aid users in pinpointing necessary information for data extraction, or to facilitate semantic search. were able to reproduce 83.3% of the published estimates using data at ClinicalTrials.gov.EXACT (http://bio-nlp.org/EXACT) automatically and accurately extracted data elements from ClinicalTrials.gov and thus reduced time in data extraction. The ClinicalTrials.gov data reproduced most meta-analysis results in our study, but this conclusion needs further validation. ground we found for comparing performance assessment based on independent replication of studies was the use of the same dataset but a sound performance comparison could not be established because the studies had little else in common. In most of the studies, insufficient information was reported to enable independent replication. The studies analysed generally did not include any discussion of the statistical appropriateness of the text mining method that they applied. In the case of applications of SVM, none of the studies report the number of support vectors that they found to indicate the complexity of the prediction engine that they use, making it impossible to judge the extent to which over-fitting might account for the good performance results.Conclusions: There is yet to be concrete evidence about the effectiveness of text mining algorithms regarding their use in the automation of citation screening in systematic reviews. The studies indicate that options are still being explored, but there is a need for better reporting as well as more explicit process details and access to datasets to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2019
DA  - 2019-07-11
JO  - {'id': 'https://openalex.org/V64418186', 'issn_l': '0895-4356', 'issn': ['1878-5921', '0895-4356'], 'display_name': 'Journal of Clinical Epidemiology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'http://www.jclinepi.com/article/S0895435619302665/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc-nd'}
DP  - OpenAlex
AU  - Tianjing Li
AU  - Ian J. Saldanha
AU  - Jens Jap
AU  - Bryant Walker Smith
AU  - Joseph K. Canner
AU  - Susan Hutfless
AU  - Vernal Branch
AU  - Simona Carini
AU  - Wiley Chan
AU  - Berry de Bruijn
AU  - Byron C. Wallace
AU  - Sandra Walsh
AU  - Elizabeth J. Whamond
AU  - Mohammad Hassan Murad
AU  - Ida Sim
AU  - Jesse A. Berlin
AU  - Joseph Lau
AU  - Kay Dickersin
AU  - Christopher H. Schmid
ER  - 

602.
TY  - journal-article
ID  - https://openalex.org/W2970557058
DO  - https://doi.org/10.1136/injuryprev-2019-043247
TI  - Evaluation of text mining to reduce screening workload for injury-focused systematic reviews
AB  - Introduction Text mining to support screening in large-scale systematic reviews has been recommended; however, their suitability for reviews in injury research is not known. We examined the performance of text mining in supporting the second reviewer in a systematic review examining associations between fault attribution and health and work-related outcomes after transport injury. Methods Citations were independently screened in Abstrackr in full (reviewer 1; 10 559 citations), and until no more citations were predicted to be relevant (reviewer 2; 1809 citations, 17.1%). All potentially relevant full-text articles were assessed by reviewer 1 (555 articles). Reviewer 2 used text mining (Wordstat, QDA Miner) to reduce assessment to full-text articles containing ≥1 fault-related exposure term (367 articles, 66.1%). Results Abstrackr offered excellent workload savings: 82.7% of citations did not require screening by reviewer 2, and total screening time was reduced by 36.6% compared with traditional dual screening of all citations. Abstrackr predictions had high specificity (83.7%), and low false negatives (0.3%), but overestimated citation relevance, probably due to the complexity of the review with multiple outcomes and high imbalance of relevant to irrelevant records, giving low sensitivity (29.7%) and precision (14.5%). Text mining of full-text articles reduced the number needing to be screened by 33.9%, and reduced total full-text screening time by 38.7% compared with traditional dual screening. Conclusions Overall, text mining offered important benefits to systematic review workflow, but should not replace full screening by one reviewer, especially for complex reviews examining multiple health or injury outcomes. Trial registration number CRD42018084123. facilitate semantic search. were able to reproduce 83.3% of the published estimates using data at ClinicalTrials.gov.EXACT (http://bio-nlp.org/EXACT) automatically and accurately extracted data elements from ClinicalTrials.gov and thus reduced time in data extraction. The ClinicalTrials.gov data reproduced most meta-analysis results in our study, but this conclusion needs further validation. ground we found for comparing performance assessment based on independent replication of studies was the use of the same dataset but a sound performance comparison could not be established because the studies had little else in common. In most of the studies, insufficient information was reported to enable independent replication. The studies analysed generally did not include any discussion of the statistical appropriateness of the text mining method that they applied. In the case of applications of SVM, none of the studies report the number of support vectors that they found to indicate the complexity of the prediction engine that they use, making it impossible to judge the extent to which over-fitting might account for the good performance results.Conclusions: There is yet to be concrete evidence about the effectiveness of text mining algorithms regarding their use in the automation of citation screening in systematic reviews. The studies indicate that options are still being explored, but there is a need for better reporting as well as more explicit process details and access to datasets to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2020
DA  - 2020-02-01
JO  - {'id': 'https://openalex.org/S81674035', 'issn_l': '1353-8047', 'issn': ['1475-5785', '1353-8047'], 'display_name': 'Injury Prevention', 'publisher': 'BMJ', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Melita J. Giummarra
AU  - Georgina Lau
AU  - Belinda J. Gabbe
ER  - 

603.
TY  - journal-article
ID  - https://openalex.org/W2970074717
DO  - https://doi.org/10.1016/j.jbi.2019.103275
TI  - Towards a characterization of apparent contradictions in the biomedical literature using context analysis
AB  - • Semantic predications to identify candidate contradictions in biomedical literature. • Automatic and manual filtering steps identify apparent contradictions from candidates. • Contextual characteristics can explain apparent contradictions or indicate true ones. With the substantial growth in the biomedical research literature, a larger number of claims are published daily, some of which seemingly disagree with or contradict prior claims on the same topics. Resolving such contradictions is critical to advancing our understanding of human disease and developing effective treatments. Automated text analysis techniques can facilitate such analysis by extracting claims from the literature, flagging those that are potentially contradictory, and identifying any study characteristics that may explain such contradictions. Using SemMedDB, our own PubMed-scale repository of semantic predications (subject-relation-object triples), we identified apparent contradictions in the biomedical research literature and developed a categorization of contextual characteristics that explain such contradictions. Clinically relevant semantic predications relating to 20 diseases and involving opposing predicate pairs (e.g., an intervention treats or causes a disease) were retrieved from SemMedDB. After addressing inference, uncertainty, generic concepts, and NLP errors through automatic and manual filtering steps, a set of apparent contradictions were identified and characterized. We retrieved 117,676 predication instances from 62,360 PubMed abstracts (Jan 1980-Dec 2016). From these instances, automatic filtering steps generated 2236 candidate contradictory pairs. Through manual analysis, we determined that 58 of these pairs (2.6%) were apparent contradictions. We identified five main categories of contextual characteristics that explain these contradictions: (a) internal to the patient, (b) external to the patient, (c) endogenous/exogenous, (d) known controversy, and (e) contradictions in literature. Categories (a) and (b) were subcategorized further (e.g., species, dosage) and accounted for the bulk of the contradictory information. Semantic predications, by accounting for lexical variability, and SemMedDB, owing to its literature scale, can support identification and elucidation of potentially contradictory claims across the biomedical domain. Further filtering and classification steps are needed to distinguish among them the true contradictory claims. The ability to detect contradictions automatically can facilitate important biomedical knowledge management tasks, such as tracking and verifying scientific claims, summarizing research on a given topic, identifying knowledge gaps, and assessing evidence for systematic reviews, with potential benefits to the scientific community. Future work will focus on automating these steps for fully automatic recognition of contradictions from the biomedical research literature. report the number of support vectors that they found to indicate the complexity of the prediction engine that they use, making it impossible to judge the extent to which over-fitting might account for the good performance results.Conclusions: There is yet to be concrete evidence about the effectiveness of text mining algorithms regarding their use in the automation of citation screening in systematic reviews. The studies indicate that options are still being explored, but there is a need for better reporting as well as more explicit process details and access to datasets to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2019
DA  - 2019-08-29
JO  - {'id': 'https://openalex.org/S11622463', 'issn_l': '1532-0464', 'issn': ['1532-0480', '1532-0464'], 'display_name': 'Journal of Biomedical Informatics', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'https://doi.org/10.1016/j.jbi.2019.103275', 'is_oa': True, 'version': 'publishedVersion', 'license': 'elsevier-specific'}
DP  - OpenAlex
AU  - Graciela Rosemblat
AU  - Marcelo Fiszman
AU  - Dongwook Shin
AU  - Halil Kilicoglu
ER  - 

604.
TY  - journal-article
ID  - https://openalex.org/W2999105954
DO  - https://doi.org/10.1080/17437199.2020.1716198
TI  - Semi-Automated evidence synthesis in health psychology: current methods and future prospects
AB  - The evidence base in health psychology is vast and growing rapidly. These factors make it difficult (and sometimes practically impossible) to consider all available evidence when making decisions about the state of knowledge on a given phenomenon (e.g., associations of variables, effects of interventions on particular outcomes). Systematic reviews, meta-analyses, and other rigorous syntheses of the research mitigate this problem by providing concise, actionable summaries of knowledge in a given area of study. Yet, conducting these syntheses has grown increasingly laborious owing to the fast accumulation of new evidence; existing, manual methods for synthesis do not scale well. In this article, we discuss how semi-automation via machine learning and natural language processing methods may help researchers and practitioners to review evidence more efficiently. We outline concrete examples in health psychology, highlighting practical, open-source technologies available now. We indicate the potential of more advanced methods and discuss how to avoid the pitfalls of automated reviews. an intervention treats or causes a disease) were retrieved from SemMedDB. After addressing inference, uncertainty, generic concepts, and NLP errors through automatic and manual filtering steps, a set of apparent contradictions were identified and characterized. We retrieved 117,676 predication instances from 62,360 PubMed abstracts (Jan 1980-Dec 2016). From these instances, automatic filtering steps generated 2236 candidate contradictory pairs. Through manual analysis, we determined that 58 of these pairs (2.6%) were apparent contradictions. We identified five main categories of contextual characteristics that explain these contradictions: (a) internal to the patient, (b) external to the patient, (c) endogenous/exogenous, (d) known controversy, and (e) contradictions in literature. Categories (a) and (b) were subcategorized further (e.g., species, dosage) and accounted for the bulk of the contradictory information. Semantic predications, by accounting for lexical variability, and SemMedDB, owing to its literature scale, can support identification and elucidation of potentially contradictory claims across the biomedical domain. Further filtering and classification steps are needed to distinguish among them the true contradictory claims. The ability to detect contradictions automatically can facilitate important biomedical knowledge management tasks, such as tracking and verifying scientific claims, summarizing research on a given topic, identifying knowledge gaps, and assessing evidence for systematic reviews, with potential benefits to the scientific community. Future work will focus on automating these steps for fully automatic recognition of contradictions from the biomedical research literature. report the number of support vectors that they found to indicate the complexity of the prediction engine that they use, making it impossible to judge the extent to which over-fitting might account for the good performance results.Conclusions: There is yet to be concrete evidence about the effectiveness of text mining algorithms regarding their use in the automation of citation screening in systematic reviews. The studies indicate that options are still being explored, but there is a need for better reporting as well as more explicit process details and access to datasets to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2020
DA  - 2020-01-29
JO  - {'id': 'https://openalex.org/S111502347', 'issn_l': '1743-7199', 'issn': ['1743-7199', '1743-7202'], 'display_name': 'Health Psychology Review', 'publisher': 'Taylor & Francis', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Iain J. Marshall
AU  - Blair T. Johnson
AU  - Zigeng Wang
AU  - Sanguthevar Rajasekaran
AU  - Byron C. Wallace
ER  - 

605.
TY  - journal-article
ID  - https://openalex.org/W2777333262
DO  - https://doi.org/10.1016/j.jphys.2017.11.009
TI  - Updating systematic reviews
AB  - No Abstract Found
PY  - 2018
DA  - 2018-01-01
JO  - {'id': 'https://openalex.org/S99546260', 'issn_l': '1836-9561', 'issn': ['1836-9553', '1836-9561'], 'display_name': 'Journal of Physiotherapy', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'https://doi.org/10.1016/j.jphys.2017.11.009', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc-nd'}
DP  - OpenAlex
AU  - Mark R. Elkins
ER  - 

606.
TY  - journal-article
ID  - https://openalex.org/W2956721904
DO  - https://doi.org/10.1016/j.ijmedinf.2019.06.020
TI  - Text preprocessing for improving hypoglycemia detection from clinical notes – A case study of patients with diabetes
AB  - Hypoglycemia is a common safety event when attempting to optimize glycemic control in diabetes (DM). While electronic medical records provide a natural ground for detecting and analyzing hypoglycemia, ICD codes used in the databases may be invalid, insensitive or non-specific in detecting new hypoglycemic events. We developed text preprocessing methods to improve automatic detection of hypoglycemia from analysis of clinical encounter text notes.We set out to improve hypoglycemia detection from clinical notes by introducing three preprocessing methods: stop word filtering, medication signaling, and ICD narrative enrichment. To test the proposed methods, we selected clinical notes from VA Maryland Healthcare System, based on various combinations of three criteria that are suggestive of hypoglycemia, including ICD-9 code of diabetes and hypoglycemia, laboratory glucose values < 70 md/dL, and text reference to a proximate hypoglycemia event. In addition, we constructed one dataset of 395 clinical notes from year 2009 and another of 460 notes from year 2014 to test the generality of the proposed methods. For each of the datasets, two physician judges manually reviewed individual clinical notes to determine whether hypoglycemia was present or absent. A third physician judge served as a final adjudicator for disagreements.Each of the proposed preprocessing methods contributed to the performance of hypoglycemia detection by significantly increasing the F1 score in the range of 5.3∼7.4% on one dataset (p < .01). Among the methods, stop word filtering contributed most to the performance improvement (7.4%). Combining all the preprocessing methods led to greater performance gain (p < .001) compared with using each method individually. Similar patterns were observed for the other dataset with the F1 score being increased in the range of 7.7%∼9.4% by individual methods (p < .001). Nevertheless, combining the three methods did not yield additional performance gain.The proposed text preprocessing methods improved the performance of hypoglycemia detection from clinical text notes. Stop word filtering achieved the most performance improvement. ICD narrative enrichment boosted the recall of detection. Combining the three preprocessing methods led to additional performance gains. tasks, such as tracking and verifying scientific claims, summarizing research on a given topic, identifying knowledge gaps, and assessing evidence for systematic reviews, with potential benefits to the scientific community. Future work will focus on automating these steps for fully automatic recognition of contradictions from the biomedical research literature. report the number of support vectors that they found to indicate the complexity of the prediction engine that they use, making it impossible to judge the extent to which over-fitting might account for the good performance results.Conclusions: There is yet to be concrete evidence about the effectiveness of text mining algorithms regarding their use in the automation of citation screening in systematic reviews. The studies indicate that options are still being explored, but there is a need for better reporting as well as more explicit process details and access to datasets to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2019
DA  - 2019-09-01
JO  - {'id': 'https://openalex.org/S53142634', 'issn_l': '1386-5056', 'issn': ['1386-5056', '1872-8243'], 'display_name': 'International Journal of Medical Informatics', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Lina Zhou
AU  - Tariq Siddiqui
AU  - Stephen L. Seliger
AU  - Jacob B. Blumenthal
AU  - Yin Kang
AU  - Rebecca M. Doerfler
AU  - Jeffrey C. Fink
ER  - 

607.
TY  - journal-article
ID  - https://openalex.org/W2994661761
DO  - https://doi.org/10.1016/j.aap.2019.105333
TI  - A systematic review of the association between fault or blame-related attributions and procedures after transport injury and health and work-related outcomes
AB  - Attributions of fault are often associated with worse injury outcomes; however, the consistency and magnitude of these impacts is not known. This review examined the prognostic role of fault on health, mental health, pain and work outcomes after transport injury. A systematic search of five electronic databases (Medline, Embase, CINAHL, PsycINFO, Cochrane Library) yielded 16,324 records published between 2000 and January 2018. Eligibility criteria were: adult transport injury survivors; prospective design; multivariable analysis; fault-related factor analysed; pain, mental health, general health or work-related outcome. Citations (n = 10,558, excluding duplicates) and full text articles (n = 555) were screened manually (Reviewer 1), and using concurrent machine learning and text mining (Reviewer 2; using Abstrackr, WordStat and QDA miner). Data from 55 papers that met all inclusion criteria were extracted, papers were evaluated for risk of bias using the QUIPS tool, and overall level of evidence was assessed using the GRADE tool. There were six main fault-related factors classified as: fault or responsibility, fault-based compensation, lawyer involvement or litigation, blame or guilt, road user or position in vehicle, and impact direction. Overall there were inconsistent associations between fault and transport injury outcomes, and 60% of papers had high risk of bias. There was moderate evidence that fault-based compensation claims were associated with poorer health-related outcomes, and that lawyer involvement was associated with poorer work outcomes beyond 12 months post-injury. However, the evidence of negative associations between fault-based compensation claims and work-related outcomes was limited. Lawyer involvement and fault-based compensation claims were associated with adverse mental health outcomes six months post-injury, but not beyond 12 months. The most consistent associations between fault and negative outcomes were not for fault attributions, per se, but were related to fault-related procedures (e.g., lawyer engagement, fault-based compensation claims). text preprocessing methods improved the performance of hypoglycemia detection from clinical text notes. Stop word filtering achieved the most performance improvement. ICD narrative enrichment boosted the recall of detection. Combining the three preprocessing methods led to additional performance gains. tasks, such as tracking and verifying scientific claims, summarizing research on a given topic, identifying knowledge gaps, and assessing evidence for systematic reviews, with potential benefits to the scientific community. Future work will focus on automating these steps for fully automatic recognition of contradictions from the biomedical research literature. report the number of support vectors that they found to indicate the complexity of the prediction engine that they use, making it impossible to judge the extent to which over-fitting might account for the good performance results.Conclusions: There is yet to be concrete evidence about the effectiveness of text mining algorithms regarding their use in the automation of citation screening in systematic reviews. The studies indicate that options are still being explored, but there is a need for better reporting as well as more explicit process details and access to datasets to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2020
DA  - 2020-02-01
JO  - {'id': 'https://openalex.org/S188336720', 'issn_l': '0001-4575', 'issn': ['1879-2057', '0001-4575'], 'display_name': 'Accident Analysis & Prevention', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Melita J. Giummarra
AU  - Georgina Lau
AU  - Genevieve Grant
AU  - Belinda J. Gabbe
ER  - 

608.
TY  - journal-article
ID  - https://openalex.org/W3013835212
DO  - https://doi.org/10.12688/f1000research.22781.2
TI  - Data extraction methods for systematic review (semi)automation: A living review protocol
AB  - <ns4:p><ns4:bold>Background:</ns4:bold> Researchers in evidence-based medicine cannot keep up with the amounts of both old and newly published primary research articles. Support for the early stages of the systematic review process – searching and screening studies for eligibility – is necessary because it is currently impossible to search for relevant research with precision. Better automated data extraction may not only facilitate the stage of review traditionally labelled ‘data extraction’, but also change earlier phases of the review process by making it possible to identify relevant research. Exponential improvements in computational processing speed and data storage are fostering the development of data mining models and algorithms. This, in combination with quicker pathways to publication, led to a large landscape of tools and methods for data mining and extraction.</ns4:p><ns4:p> <ns4:bold>Objective:</ns4:bold> To review published methods and tools for data extraction to (semi)automate the systematic reviewing process.</ns4:p><ns4:p> <ns4:bold>Methods:</ns4:bold> We propose to conduct a living review. With this methodology we aim to do constant evidence surveillance, bi-monthly search updates, as well as review updates every 6 months if new evidence permits it. In a cross-sectional analysis we will extract methodological characteristics and assess the quality of reporting in our included papers.</ns4:p><ns4:p> <ns4:bold>Conclusions:</ns4:bold> We aim to increase transparency in the reporting and assessment of automation technologies to the benefit of data scientists, systematic reviewers and funders of health research. This living review will help to reduce duplicate efforts by data scientists who develop data mining methods. It will also serve to inform systematic reviewers about possibilities to support their data extraction.</ns4:p> health outcomes six months post-injury, but not beyond 12 months. The most consistent associations between fault and negative outcomes were not for fault attributions, per se, but were related to fault-related procedures (e.g., lawyer engagement, fault-based compensation claims). text preprocessing methods improved the performance of hypoglycemia detection from clinical text notes. Stop word filtering achieved the most performance improvement. ICD narrative enrichment boosted the recall of detection. Combining the three preprocessing methods led to additional performance gains. tasks, such as tracking and verifying scientific claims, summarizing research on a given topic, identifying knowledge gaps, and assessing evidence for systematic reviews, with potential benefits to the scientific community. Future work will focus on automating these steps for fully automatic recognition of contradictions from the biomedical research literature. report the number of support vectors that they found to indicate the complexity of the prediction engine that they use, making it impossible to judge the extent to which over-fitting might account for the good performance results.Conclusions: There is yet to be concrete evidence about the effectiveness of text mining algorithms regarding their use in the automation of citation screening in systematic reviews. The studies indicate that options are still being explored, but there is a need for better reporting as well as more explicit process details and access to datasets to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2020
DA  - 2020-03-25
JO  - {'id': 'https://openalex.org/S4210239046', 'issn_l': '2046-1402', 'issn': ['2046-1402'], 'display_name': 'F1000Research', 'publisher': 'Faculty of 1000', 'type': 'journal', 'url': 'https://f1000research.com/articles/9-210/v2/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Lena Schmidt
AU  - Babatunde K. Olorisade
AU  - Adrian M. Price-Whelan
AU  - James D. Thomas
AU  - Julian P T Higgins
ER  - 

609.
TY  - journal-article
ID  - https://openalex.org/W4223614283
DO  - https://doi.org/10.1016/j.scitotenv.2022.155159
TI  - Assay of renewable energy transition: A systematic literature review
AB  - Issues of environmental degradation, finite quantity and uneven spatial distribution of fuels in nature, and growing demand accentuated by volatility of oil prices have led to the global clean renewable energy transition (RET). With an objective of examining the current knowledge-stock on RET, we reviewed 248 journal publications pooled from three databases (ScienceDirect, Web of Science and Scopus) using a Systematic Literature Review method. This study does not focus on the specifications of a particular energy technology or regress relations among a limited set of variables. Rather, the key contribution is the critical assessment of the factors that encourage and those that hinder the transition process to provide a wider perspective through seven broad lenses: technological, investment, market, environmental, government and institutional, policy and social. Research, development and implementation of technology is a direct outcome of policy investment. Developed countries are leading the RET research while the global south is far behind. Most of the studies were found to be donor-driven which faced a serious risk of being counter-welcomed in different settings of the world without compromising the objectives of the transition. A strong international collaboration among the rich and poor countries is urgently felt necessary to foster mutual benefits. Research, planning and implementation of the RET would be highly effective and sustainable through a participatory bottom-up approach promoting local technology instead of imposed expensive imported ones. The need for "demand-pull" and "technology-push" policy instruments is stringent for successful transition. We conclude that there is a unanimous agreement among all the studies on the future prospects of renewable energy in the electricity sector; however, some skepticism still exists regarding other high energy demanding areas. Our review recommends updating existing and designing new robust policy mixes to guide the modality and pace of the RET, adhering to local specificities. of hypoglycemia detection from clinical text notes. Stop word filtering achieved the most performance improvement. ICD narrative enrichment boosted the recall of detection. Combining the three preprocessing methods led to additional performance gains. tasks, such as tracking and verifying scientific claims, summarizing research on a given topic, identifying knowledge gaps, and assessing evidence for systematic reviews, with potential benefits to the scientific community. Future work will focus on automating these steps for fully automatic recognition of contradictions from the biomedical research literature. report the number of support vectors that they found to indicate the complexity of the prediction engine that they use, making it impossible to judge the extent to which over-fitting might account for the good performance results.Conclusions: There is yet to be concrete evidence about the effectiveness of text mining algorithms regarding their use in the automation of citation screening in systematic reviews. The studies indicate that options are still being explored, but there is a need for better reporting as well as more explicit process details and access to datasets to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2022
DA  - 2022-04-01
JO  - {'id': 'https://openalex.org/S86852077', 'issn_l': '0048-9697', 'issn': ['0048-9697', '1879-1026'], 'display_name': 'Science of The Total Environment', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Utsav Bhattarai
AU  - Tek Narayan Maraseni
AU  - Armando Apan
ER  - 

610.
TY  - journal-article
ID  - https://openalex.org/W2609740230
DO  - https://doi.org/10.1016/j.jbi.2017.04.004
TI  - Evaluation of a rule-based method for epidemiological document classification towards the automation of systematic reviews
AB  - Most data extraction efforts in epidemiology are focused on obtaining targeted information from clinical trials. In contrast, limited research has been conducted on the identification of information from observational studies, a major source for human evidence in many fields, including environmental health. The recognition of key epidemiological information (e.g., exposures) through text mining techniques can assist in the automation of systematic reviews and other evidence summaries.We designed and applied a knowledge-driven, rule-based approach to identify targeted information (study design, participant population, exposure, outcome, confounding factors, and the country where the study was conducted) from abstracts of epidemiological studies included in several systematic reviews of environmental health exposures. The rules were based on common syntactical patterns observed in text and are thus not specific to any systematic review. To validate the general applicability of our approach, we compared the data extracted using our approach versus hand curation for 35 epidemiological study abstracts manually selected for inclusion in two systematic reviews.The returned F-score, precision, and recall ranged from 70% to 98%, 81% to 100%, and 54% to 97%, respectively. The highest precision was observed for exposure, outcome and population (100%) while recall was best for exposure and study design with 97% and 89%, respectively. The lowest recall was observed for the population (54%), which also had the lowest F-score (70%).The generated performance of our text-mining approach demonstrated encouraging results for the identification of targeted information from observational epidemiological study abstracts related to environmental exposures. We have demonstrated that rules based on generic syntactic patterns in one corpus can be applied to other observational study design by simple interchanging the dictionaries aiming to identify certain characteristics (i.e., outcomes, exposures). At the document level, the recognised information can assist in the selection and categorization of studies included in a systematic review. specificities. of hypoglycemia detection from clinical text notes. Stop word filtering achieved the most performance improvement. ICD narrative enrichment boosted the recall of detection. Combining the three preprocessing methods led to additional performance gains. tasks, such as tracking and verifying scientific claims, summarizing research on a given topic, identifying knowledge gaps, and assessing evidence for systematic reviews, with potential benefits to the scientific community. Future work will focus on automating these steps for fully automatic recognition of contradictions from the biomedical research literature. report the number of support vectors that they found to indicate the complexity of the prediction engine that they use, making it impossible to judge the extent to which over-fitting might account for the good performance results.Conclusions: There is yet to be concrete evidence about the effectiveness of text mining algorithms regarding their use in the automation of citation screening in systematic reviews. The studies indicate that options are still being explored, but there is a need for better reporting as well as more explicit process details and access to datasets to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2017
DA  - 2017-06-01
JO  - {'id': 'https://openalex.org/S11622463', 'issn_l': '1532-0464', 'issn': ['1532-0480', '1532-0464'], 'display_name': 'Journal of Biomedical Informatics', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'https://doi.org/10.1016/j.jbi.2017.04.004', 'is_oa': True, 'version': 'publishedVersion', 'license': 'elsevier-specific'}
DP  - OpenAlex
AU  - George Karystianis
AU  - Kristina A. Thayer
AU  - Mary Leigh Wolfe
AU  - Guy Tsafnat
ER  - 

611.
TY  - journal-article
ID  - https://openalex.org/W2808716231
DO  - https://doi.org/10.2903/sp.efsa.2018.en-1427
TI  - Machine learning techniques for the automation of literature reviews and systematic reviews in EFSA
AB  - No Abstract Found
PY  - 2018
DA  - 2018-06-01
JO  - {'id': 'https://openalex.org/S4210168838', 'issn_l': '2397-8325', 'issn': ['2397-8325'], 'display_name': 'EFSA supporting publications', 'publisher': 'European Food Safety Authority', 'type': 'journal', 'url': 'https://efsa.onlinelibrary.wiley.com/doi/pdfdirect/10.2903/sp.efsa.2018.EN-1427', 'is_oa': True, 'version': 'publishedVersion', 'license': 'implied-oa'}
DP  - OpenAlex
AU  - Stijn Jaspers
AU  - Ewoud De Troyer
AU  - Marc Aerts
ER  - 

612.
TY  - journal-article
ID  - https://openalex.org/W2990795924
DO  - https://doi.org/10.1177/2515245919882693
TI  - Advancing Meta-Analysis With Knowledge-Management Platforms: Using metaBUS in Psychology
AB  - In this article, we provide a review of research-curation and knowledge-management efforts that may be leveraged to advance research and education in psychological science. After reviewing the approaches and content of other efforts, we focus on the metaBUS project’s platform, the most comprehensive effort to date. The metaBUS platform uses standards-based protocols in combination with human judgment to organize and make readily accessible a database of research findings, currently numbering more than 1 million. It allows users to conduct rudimentary, instant meta-analyses, and capacities for visualization and communication of meta-analytic findings have recently been added. We conclude by discussing challenges, opportunities, and recommendations for expanding the project beyond applied psychology. based on common syntactical patterns observed in text and are thus not specific to any systematic review. To validate the general applicability of our approach, we compared the data extracted using our approach versus hand curation for 35 epidemiological study abstracts manually selected for inclusion in two systematic reviews.The returned F-score, precision, and recall ranged from 70% to 98%, 81% to 100%, and 54% to 97%, respectively. The highest precision was observed for exposure, outcome and population (100%) while recall was best for exposure and study design with 97% and 89%, respectively. The lowest recall was observed for the population (54%), which also had the lowest F-score (70%).The generated performance of our text-mining approach demonstrated encouraging results for the identification of targeted information from observational epidemiological study abstracts related to environmental exposures. We have demonstrated that rules based on generic syntactic patterns in one corpus can be applied to other observational study design by simple interchanging the dictionaries aiming to identify certain characteristics (i.e., outcomes, exposures). At the document level, the recognised information can assist in the selection and categorization of studies included in a systematic review. specificities. of hypoglycemia detection from clinical text notes. Stop word filtering achieved the most performance improvement. ICD narrative enrichment boosted the recall of detection. Combining the three preprocessing methods led to additional performance gains. tasks, such as tracking and verifying scientific claims, summarizing research on a given topic, identifying knowledge gaps, and assessing evidence for systematic reviews, with potential benefits to the scientific community. Future work will focus on automating these steps for fully automatic recognition of contradictions from the biomedical research literature. report the number of support vectors that they found to indicate the complexity of the prediction engine that they use, making it impossible to judge the extent to which over-fitting might account for the good performance results.Conclusions: There is yet to be concrete evidence about the effectiveness of text mining algorithms regarding their use in the automation of citation screening in systematic reviews. The studies indicate that options are still being explored, but there is a need for better reporting as well as more explicit process details and access to datasets to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2020
DA  - 2020-03-01
JO  - {'id': 'https://openalex.org/V4210173062', 'issn_l': '2515-2459', 'issn': ['2515-2459', '2515-2467'], 'display_name': 'Advances in methods and practices in psychological science', 'publisher': 'SAGE Publishing', 'type': 'journal', 'url': 'https://journals.sagepub.com/doi/pdf/10.1177/2515245919882693', 'is_oa': True, 'version': 'publishedVersion', 'license': None}
DP  - OpenAlex
AU  - Frank A. Bosco
AU  - James B. Field
AU  - Kai Larsen
AU  - Yingyi Chang
AU  - Krista L. Uggerslev
ER  - 

613.
TY  - journal-article
ID  - https://openalex.org/W2995299295
DO  - https://doi.org/10.1186/s13643-019-1250-y
TI  - The Systematic Review Data Repository (SRDR): descriptive characteristics of publicly available data and opportunities for research
AB  - Abstract Background Conducting systematic reviews (“reviews”) requires a great deal of effort and resources. Making data extracted during reviews available publicly could offer many benefits, including reducing unnecessary duplication of effort, standardizing data, supporting analyses to address secondary research questions, and facilitating methodologic research. Funded by the US Agency for Healthcare Research and Quality (AHRQ), the Systematic Review Data Repository (SRDR) is a free, web-based, open-source, data management and archival platform for reviews. Our specific objectives in this paper are to describe (1) the current extent of usage of SRDR and (2) the characteristics of all projects with publicly available data on the SRDR website. Methods We examined all projects with data made publicly available through SRDR as of November 12, 2019. We extracted information about the characteristics of these projects. Two investigators extracted and verified the data. Results SRDR has had 2552 individual user accounts belonging to users from 80 countries. Since SRDR’s launch in 2012, data have been made available publicly for 152 of the 735 projects in SRDR (21%), at a rate of 24.5 projects per year, on average. Most projects are in clinical fields (144/152 projects; 95%); most have evaluated interventions (therapeutic or preventive) (109/152; 72%). The most frequent health areas addressed are mental and behavioral disorders (31/152; 20%) and diseases of the eye and ocular adnexa (23/152; 15%). Two-thirds of the projects (104/152; 67%) were funded by AHRQ, and one-sixth (23/152; 15%) are Cochrane reviews. The 152 projects each address a median of 3 research questions (IQR 1–5) and include a median of 70 studies (IQR 20–130). Conclusions Until we arrive at a future in which the systematic review and broader research communities are comfortable with the accuracy of automated data extraction, re-use of data extracted by humans has the potential to help reduce redundancy and costs. The 152 projects with publicly available data through SRDR, and the more than 15,000 studies therein, are freely available to researchers and the general public who might be working on similar reviews or updates of reviews or who want access to the data for decision-making, meta-research, or other purposes. for systematic reviews, with potential benefits to the scientific community. Future work will focus on automating these steps for fully automatic recognition of contradictions from the biomedical research literature. report the number of support vectors that they found to indicate the complexity of the prediction engine that they use, making it impossible to judge the extent to which over-fitting might account for the good performance results.Conclusions: There is yet to be concrete evidence about the effectiveness of text mining algorithms regarding their use in the automation of citation screening in systematic reviews. The studies indicate that options are still being explored, but there is a need for better reporting as well as more explicit process details and access to datasets to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2019
DA  - 2019-12-20
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://systematicreviewsjournal.biomedcentral.com/track/pdf/10.1186/s13643-019-1250-y', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Ian J. Saldanha
AU  - Bryant Walker Smith
AU  - Evangelia E. Ntzani
AU  - Jens Jap
AU  - Ethan M Balk
AU  - Joseph Lau
ER  - 

614.
TY  - journal-article
ID  - https://openalex.org/W3163124033
DO  - https://doi.org/10.12688/f1000research.51117.1
TI  - Data extraction methods for systematic review (semi)automation: A living systematic review
AB  - <ns3:p><ns3:bold>Background:</ns3:bold> The reliable and usable (semi)automation of data extraction can support the field of systematic review by reducing the workload required to gather information about the conduct and results of the included studies. This living systematic review examines published approaches for data extraction from reports of clinical studies.</ns3:p><ns3:p> <ns3:bold>Methods:</ns3:bold> We systematically and continually search MEDLINE, Institute of Electrical and Electronics Engineers (IEEE), arXiv, and the <ns3:italic>dblp computer science bibliography</ns3:italic> databases. Full text screening and data extraction are conducted within an open-source living systematic review application created for the purpose of this review. This iteration of the living review includes publications up to a cut-off date of 22 April 2020.</ns3:p><ns3:p> <ns3:bold>Results: </ns3:bold>In total, 53 publications are included in this version of our review. Of these, 41 (77%) of the publications addressed extraction of data from abstracts, while 14 (26%) used full texts. A total of 48 (90%) publications developed and evaluated classifiers that used randomised controlled trials as the main target texts. Over 30 entities were extracted, with PICOs (population, intervention, comparator, outcome) being the most frequently extracted. A description of their datasets was provided by 49 publications (94%), but only seven (13%) made the data publicly available. Code was made available by 10 (19%) publications, and five (9%) implemented publicly available tools.</ns3:p><ns3:p> <ns3:bold>Conclusions:</ns3:bold> This living systematic review presents an overview of (semi)automated data-extraction literature of interest to different types of systematic review. We identified a broad evidence base of publications describing data extraction for interventional reviews and a small number of publications extracting epidemiological or diagnostic accuracy data. The lack of publicly available gold-standard data for evaluation, and lack of application thereof, makes it difficult to draw conclusions on which is the best-performing system for each data extraction target. With this living review we aim to review the literature continually.</ns3:p> and costs. The 152 projects with publicly available data through SRDR, and the more than 15,000 studies therein, are freely available to researchers and the general public who might be working on similar reviews or updates of reviews or who want access to the data for decision-making, meta-research, or other purposes. for systematic reviews, with potential benefits to the scientific community. Future work will focus on automating these steps for fully automatic recognition of contradictions from the biomedical research literature. report the number of support vectors that they found to indicate the complexity of the prediction engine that they use, making it impossible to judge the extent to which over-fitting might account for the good performance results.Conclusions: There is yet to be concrete evidence about the effectiveness of text mining algorithms regarding their use in the automation of citation screening in systematic reviews. The studies indicate that options are still being explored, but there is a need for better reporting as well as more explicit process details and access to datasets to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2021
DA  - 2021-05-19
JO  - {'id': 'https://openalex.org/S4210239046', 'issn_l': '2046-1402', 'issn': ['2046-1402'], 'display_name': 'F1000Research', 'publisher': 'Faculty of 1000', 'type': 'journal', 'url': 'https://f1000research.com/articles/10-401/v1/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Lena Schmidt
AU  - Babatunde K. Olorisade
AU  - Adrian M. Price-Whelan
AU  - James D. Thomas
AU  - Julian P T Higgins
ER  - 

615.
TY  - journal-article
ID  - https://openalex.org/W2573112476
DO  - https://doi.org/10.1016/j.jclinepi.2016.11.019
TI  - Commentary on EPC methods: an exploration of the use of text-mining software in systematic reviews
AB  - • The reliable The Agency for Healthcare Research and Quality Evidence-based Practice Center program recently published a methods white paper on the gather information effectivehealthcare.ahrq.gov the conduct web site which focused on a preliminary exploration of the use of text-mining in evidence synthesis. from reports of clinical studies.</ns3:p><ns3:p> <ns3:bold>Methods:</ns3:bold> We systematically and continually search MEDLINE, Institute of Electrical and Electronics Engineers (IEEE), arXiv, and the <ns3:italic>dblp computer science bibliography</ns3:italic> databases. Full text screening and data extraction are conducted within an open-source living systematic review application created for the purpose of this review. This iteration of the living review includes publications up to a cut-off date of 22 April 2020.</ns3:p><ns3:p> <ns3:bold>Results: </ns3:bold>In total, 53 publications are included in this version of our review. Of these, 41 (77%) of the publications addressed extraction of data from abstracts, while 14 (26%) used full texts. A total of 48 (90%) publications developed and evaluated classifiers that used randomised controlled trials as the main target texts. Over 30 entities were extracted, with PICOs (population, intervention, comparator, outcome) being the most frequently extracted. A description of their datasets was provided by 49 publications (94%), but only seven (13%) made the data publicly available. Code was made available by 10 (19%) publications, and five (9%) implemented publicly available tools.</ns3:p><ns3:p> <ns3:bold>Conclusions:</ns3:bold> This living systematic review presents an overview of (semi)automated data-extraction literature of interest to different types of systematic review. We identified a broad evidence base of publications describing data extraction for interventional reviews and a small number of publications extracting epidemiological or diagnostic accuracy data. The lack of publicly available gold-standard data for evaluation, and lack of application thereof, makes it difficult to draw conclusions on which is the best-performing system for each data extraction target. With this living review we aim to review the literature continually.</ns3:p> and costs. The 152 projects with publicly available data through SRDR, and the more than 15,000 studies therein, are freely available to researchers and the general public who might be working on similar reviews or updates of reviews or who want access to the data for decision-making, meta-research, or other purposes. for systematic reviews, with potential benefits to the scientific community. Future work will focus on automating these steps for fully automatic recognition of contradictions from the biomedical research literature. report the number of support vectors that they found to indicate the complexity of the prediction engine that they use, making it impossible to judge the extent to which over-fitting might account for the good performance results.Conclusions: There is yet to be concrete evidence about the effectiveness of text mining algorithms regarding their use in the automation of citation screening in systematic reviews. The studies indicate that options are still being explored, but there is a need for better reporting as well as more explicit process details and access to datasets to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2017
DA  - 2017-01-18
JO  - {'id': 'https://openalex.org/S64418186', 'issn_l': '0895-4356', 'issn': ['1878-5921', '0895-4356'], 'display_name': 'Journal of Clinical Epidemiology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Robin Paynter
AU  - Lionel L. Bañez
AU  - Eileen Erinoff
AU  - Jennifer Lege-Matsuura
AU  - Shannon A Potter
ER  - 

616.
TY  - journal-article
ID  - https://openalex.org/W3127501124
DO  - https://doi.org/10.1111/jep.13542
TI  - Artificial intelligence methods for a Bayesian epistemology‐powered evidence evaluation
AB  - Rationale, aims and objectives The diversity of types of evidence (eg, case reports, animal studies and observational studies) makes the assessment of a drug's safety profile into a formidable challenge. While frequentist uncertain inference struggles in aggregating these signals, the more flexible Bayesian approaches seem better suited for this quest. Artificial Intelligence (AI) offers great promise to these approaches for information retrieval, decision support, and learning probabilities from data. Methods E-Synthesis is a Bayesian framework for drug safety assessments built on philosophical principles and considerations. It aims to aggregate all the available information, in order to provide a Bayesian probability of a drug causing an adverse reaction. AI systems are being developed for evidence aggregation in medicine, which increasingly are automated. Results We find that AI can help E-Synthesis with information retrieval, usability (graphical decision-making aids), learning Bayes factors from historical data, assessing quality of information and determining conditional probabilities for the so-called ‘indicators’ of causation for E-Synthesis. Vice versa, E-Synthesis offers a solid methodological basis for (semi-)automated evidence aggregation with AI systems. Conclusions Properly applied, AI can help the transition of philosophical principles and considerations concerning evidence aggregation for drug safety to a tool that can be used in practice. by 10 (19%) publications, and five (9%) implemented publicly available tools.</ns3:p><ns3:p> <ns3:bold>Conclusions:</ns3:bold> This living systematic review presents an overview of (semi)automated data-extraction literature of interest to different types of systematic review. We identified a broad evidence base of publications describing data extraction for interventional reviews and a small number of publications extracting epidemiological or diagnostic accuracy data. The lack of publicly available gold-standard data for evaluation, and lack of application thereof, makes it difficult to draw conclusions on which is the best-performing system for each data extraction target. With this living review we aim to review the literature continually.</ns3:p> and costs. The 152 projects with publicly available data through SRDR, and the more than 15,000 studies therein, are freely available to researchers and the general public who might be working on similar reviews or updates of reviews or who want access to the data for decision-making, meta-research, or other purposes. for systematic reviews, with potential benefits to the scientific community. Future work will focus on automating these steps for fully automatic recognition of contradictions from the biomedical research literature. report the number of support vectors that they found to indicate the complexity of the prediction engine that they use, making it impossible to judge the extent to which over-fitting might account for the good performance results.Conclusions: There is yet to be concrete evidence about the effectiveness of text mining algorithms regarding their use in the automation of citation screening in systematic reviews. The studies indicate that options are still being explored, but there is a need for better reporting as well as more explicit process details and access to datasets to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2021
DA  - 2021-02-11
JO  - {'id': 'https://openalex.org/S2713501', 'issn_l': '1356-1294', 'issn': ['1356-1294', '1365-2753'], 'display_name': 'Journal of Evaluation in Clinical Practice', 'publisher': 'Wiley-Blackwell', 'type': 'journal', 'url': 'https://doi.org/10.1111/jep.13542', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Francesco De Pretis
AU  - Jürgen Landes
AU  - William Peden
ER  - 

617.
TY  - journal-article
ID  - https://openalex.org/W3207456925
DO  - https://doi.org/10.1177/02683962211048201
TI  - Artificial intelligence and the conduct of literature reviews
AB  - Artificial intelligence (AI) is beginning to transform traditional research practices in many areas. In this context, literature reviews stand out because they operate on large and rapidly growing volumes of documents, that is, partially structured (meta)data, and pervade almost every type of paper published in information systems research or related social science disciplines. To familiarize researchers with some of the recent trends in this area, we outline how AI can expedite individual steps of the literature review process. Considering that the use of AI in this context is in an early stage of development, we propose a comprehensive research agenda for AI-based literature reviews (AILRs) in our field. With this agenda, we would like to encourage design science research and a broader constructive discourse on shaping the future of AILRs in research. usability (graphical decision-making aids), learning Bayes factors from historical data, assessing quality of information and determining conditional probabilities for the so-called ‘indicators’ of causation for E-Synthesis. Vice versa, E-Synthesis offers a solid methodological basis for (semi-)automated evidence aggregation with AI systems. Conclusions Properly applied, AI can help the transition of philosophical principles and considerations concerning evidence aggregation for drug safety to a tool that can be used in practice. by 10 (19%) publications, and five (9%) implemented publicly available tools.</ns3:p><ns3:p> <ns3:bold>Conclusions:</ns3:bold> This living systematic review presents an overview of (semi)automated data-extraction literature of interest to different types of systematic review. We identified a broad evidence base of publications describing data extraction for interventional reviews and a small number of publications extracting epidemiological or diagnostic accuracy data. The lack of publicly available gold-standard data for evaluation, and lack of application thereof, makes it difficult to draw conclusions on which is the best-performing system for each data extraction target. With this living review we aim to review the literature continually.</ns3:p> and costs. The 152 projects with publicly available data through SRDR, and the more than 15,000 studies therein, are freely available to researchers and the general public who might be working on similar reviews or updates of reviews or who want access to the data for decision-making, meta-research, or other purposes. for systematic reviews, with potential benefits to the scientific community. Future work will focus on automating these steps for fully automatic recognition of contradictions from the biomedical research literature. report the number of support vectors that they found to indicate the complexity of the prediction engine that they use, making it impossible to judge the extent to which over-fitting might account for the good performance results.Conclusions: There is yet to be concrete evidence about the effectiveness of text mining algorithms regarding their use in the automation of citation screening in systematic reviews. The studies indicate that options are still being explored, but there is a need for better reporting as well as more explicit process details and access to datasets to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2021
DA  - 2021-10-08
JO  - {'id': 'https://openalex.org/S135086714', 'issn_l': '0268-3962', 'issn': ['0268-3962', '1466-4437'], 'display_name': 'Journal of Information Technology', 'publisher': 'Macmillan Publishers', 'type': 'journal', 'url': 'https://journals.sagepub.com/doi/pdf/10.1177/02683962211048201', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Gerit Wagner
AU  - Roman Lukyanenko
AU  - Guy Paré
ER  - 

618.
TY  - book-chapter
ID  - https://openalex.org/W3082069439
DO  - https://doi.org/10.1007/978-3-030-32489-6_12
TI  - Automating Systematic Literature Review
AB  - No Abstract Found
PY  - 2020
DA  - 2020-01-01
JO  - {'id': 'https://openalex.org/V4306463941', 'issn_l': None, 'issn': None, 'display_name': 'Springer International Publishing eBooks', 'publisher': 'Springer Nature', 'type': 'ebook platform', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Katia Romero Felizardo
AU  - Jeffrey C. Carver
ER  - 

619.
TY  - journal-article
ID  - https://openalex.org/W2897310814
DO  - https://doi.org/10.1002/jrsm.1326
TI  - Features and functioning of D ata A bstraction A ssistant, a software application for data abstraction during systematic reviews
AB  - During systematic reviews, data abstraction is labor- and time-intensive and error-prone. Existing data abstraction systems do not track specific locations and contexts of abstracted information. To address this limitation, we developed a software application, the Data Abstraction Assistant (DAA) and surveyed early users about their experience using DAA.We designed DAA to encompass three essential features: (1) a platform for indicating the source of abstracted information, (2) compatibility with a variety of data abstraction systems, and (3) user-friendliness.DAA (1) converts source documents from PDF to HTML format (to enable tracking of source of abstracted information), (2) transmits the HTML to the data abstraction system, and (3) displays the HTML in an area adjacent to the data abstraction form in the data abstraction system. The data abstractor can mark locations on the HTML that DAA associates with items on the data abstraction form.When we surveyed 52 early users of DAA, 83% reported that using DAA was either very or somewhat easy; 71% are very or somewhat likely to use DAA in the future; and 87% are very or somewhat likely to recommend that others use DAA in the future.DAA, a user-friendly software for linking abstracted data with their exact source, is likely to be a very useful tool in the toolbox of systematic reviewers. DAA facilitates verification of abstracted data and provides an audit trail that is crucial for reproducible research. of systematic review. We identified a broad evidence base of publications describing data extraction for interventional reviews and a small number of publications extracting epidemiological or diagnostic accuracy data. The lack of publicly available gold-standard data for evaluation, and lack of application thereof, makes it difficult to draw conclusions on which is the best-performing system for each data extraction target. With this living review we aim to review the literature continually.</ns3:p> and costs. The 152 projects with publicly available data through SRDR, and the more than 15,000 studies therein, are freely available to researchers and the general public who might be working on similar reviews or updates of reviews or who want access to the data for decision-making, meta-research, or other purposes. for systematic reviews, with potential benefits to the scientific community. Future work will focus on automating these steps for fully automatic recognition of contradictions from the biomedical research literature. report the number of support vectors that they found to indicate the complexity of the prediction engine that they use, making it impossible to judge the extent to which over-fitting might account for the good performance results.Conclusions: There is yet to be concrete evidence about the effectiveness of text mining algorithms regarding their use in the automation of citation screening in systematic reviews. The studies indicate that options are still being explored, but there is a need for better reporting as well as more explicit process details and access to datasets to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2019
DA  - 2019-03-01
JO  - {'id': 'https://openalex.org/V205768342', 'issn_l': '1759-2879', 'issn': ['1759-2879', '1759-2887'], 'display_name': 'Research Synthesis Methods', 'publisher': 'Wiley-Blackwell', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Jens Jap
AU  - Ian J. Saldanha
AU  - Bryant Walker Smith
AU  - Joseph Lau
AU  - Christopher H. Schmid
AU  - Tianjing Li
ER  - 

620.
TY  - journal-article
ID  - https://openalex.org/W2982597005
DO  - https://doi.org/10.1016/j.jbi.2019.103321
TI  - Quantifying semantic similarity of clinical evidence in the biomedical literature to facilitate related evidence synthesis
AB  - • A publicly available expert-annotated data set of 1000 pairs of clinical evidence. • A generalisable approach for quantification of clinical evidence. • Unsupervised neural network representation of medical concepts for semantic similarity quantification. • Analysis of measures for quantifying semantic similarity of clinical evidence. Published clinical trials and high quality peer reviewed medical publications are considered as the main sources of evidence used for synthesizing systematic reviews or practicing Evidence Based Medicine (EBM). Finding all relevant published evidence for a particular medical case is a time and labour intensive task, given the breadth of the biomedical literature. Automatic quantification of conceptual relationships between key clinical evidence within and across publications, despite variations in the expression of clinically-relevant concepts, can help to facilitate synthesis of evidence. In this study, we aim to provide an approach towards expediting evidence synthesis by quantifying semantic similarity of key evidence as expressed in the form of individual sentences. Such semantic textual similarity can be applied as a key approach for supporting selection of related studies. We propose a generalisable approach for quantifying semantic similarity of clinical evidence in the biomedical literature, specifically considering the similarity of sentences corresponding to a given type of evidence, such as clinical interventions, population information, clinical findings, etc. We develop three sets of generic, ontology-based, and vector-space models of similarity measures that make use of a variety of lexical, conceptual, and contextual information to quantify the similarity of full sentences containing clinical evidence. To understand the impact of different similarity measures on the overall evidence semantic similarity quantification, we provide a comparative analysis of these measures when used as input to an unsupervised linear interpolation and a supervised regression ensemble. In order to provide a reliable test-bed for this experiment, we generate a dataset of 1000 pairs of sentences from biomedical publications that are annotated by ten human experts. We also extend the experiments on an external dataset for further generalisability testing. The combination of all diverse similarity measures showed stronger correlations with the gold standard similarity scores in the dataset than any individual kind of measure. Our approach reached near 0.80 average Pearson correlation across different clinical evidence types using the devised similarity measures. Although they were more effective when combined together, individual generic and vector-space measures also resulted in strong similarity quantification when used in both unsupervised and supervised models. On the external dataset, our similarity measures were highly competitive with the state-of-the-art approaches developed and trained specifically on that dataset for predicting semantic similarity. Experimental results showed that the proposed semantic similarity quantification approach can effectively identify related clinical evidence that is reported in the literature. The comparison with a state-of-the-art method demonstrated the effectiveness of the approach, and experiments with an external dataset support its generalisability. well as more explicit process details and access to datasets to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2019
DA  - 2019-12-01
JO  - {'id': 'https://openalex.org/S11622463', 'issn_l': '1532-0464', 'issn': ['1532-0480', '1532-0464'], 'display_name': 'Journal of Biomedical Informatics', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'https://doi.org/10.1016/j.jbi.2019.103321', 'is_oa': True, 'version': 'publishedVersion', 'license': 'elsevier-specific'}
DP  - OpenAlex
AU  - Hamed Hassanzadeh
AU  - Anthony Nguyen
AU  - Karin Verspoor
ER  - 

621.
TY  - journal-article
ID  - https://openalex.org/W3007303748
DO  - https://doi.org/10.1007/s10669-020-09763-2
TI  - Deep learning in automated text classification: a case study using toxicological abstracts
AB  - No Abstract Found
PY  - 2020
DA  - 2020-12-01
JO  - {'id': 'https://openalex.org/V2764812402', 'issn_l': '2194-5411', 'issn': ['2194-5403', '2194-5411'], 'display_name': 'Environment Systems and Decisions', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Arun Varghese
AU  - George Agyeman-Badu
AU  - Michelle Cawley
ER  - 

622.
TY  - journal-article
ID  - https://openalex.org/W3133622905
DO  - https://doi.org/10.1016/j.jbi.2021.103717
TI  - Toward assessing clinical trial publications for reporting transparency
AB  - To annotate a corpus of randomized controlled trial (RCT) publications with the checklist items of CONSORT reporting guidelines and using the corpus to develop text mining methods for RCT appraisal.We annotated a corpus of 50 RCT articles at the sentence level using 37 fine-grained CONSORT checklist items. A subset (31 articles) was double-annotated and adjudicated, while 19 were annotated by a single annotator and reconciled by another. We calculated inter-annotator agreement at the article and section level using MASI (Measuring Agreement on Set-Valued Items) and at the CONSORT item level using Krippendorff's α. We experimented with two rule-based methods (phrase-based and section header-based) and two supervised learning approaches (support vector machine and BioBERT-based neural network classifiers), for recognizing 17 methodology-related items in the RCT Methods sections.We created CONSORT-TM consisting of 10,709 sentences, 4,845 (45%) of which were annotated with 5,246 labels. A median of 28 CONSORT items (out of possible 37) were annotated per article. Agreement was moderate at the article and section levels (average MASI: 0.60 and 0.64, respectively). Agreement varied considerably among individual checklist items (Krippendorff's α= 0.06-0.96). The model based on BioBERT performed best overall for recognizing methodology-related items (micro-precision: 0.82, micro-recall: 0.63, micro-F1: 0.71). Combining models using majority vote and label aggregation further improved precision and recall, respectively.Our annotated corpus, CONSORT-TM, contains more fine-grained information than earlier RCT corpora. Low frequency of some CONSORT items made it difficult to train effective text mining models to recognize them. For the items commonly reported, CONSORT-TM can serve as a testbed for text mining methods that assess RCT transparency, rigor, and reliability, and support methods for peer review and authoring assistance. Minor modifications to the annotation scheme and a larger corpus could facilitate improved text mining models. CONSORT-TM is publicly available at https://github.com/kilicogluh/CONSORT-TM. dataset of 1000 pairs of sentences from biomedical publications that are annotated by ten human experts. We also extend the experiments on an external dataset for further generalisability testing. The combination of all diverse similarity measures showed stronger correlations with the gold standard similarity scores in the dataset than any individual kind of measure. Our approach reached near 0.80 average Pearson correlation across different clinical evidence types using the devised similarity measures. Although they were more effective when combined together, individual generic and vector-space measures also resulted in strong similarity quantification when used in both unsupervised and supervised models. On the external dataset, our similarity measures were highly competitive with the state-of-the-art approaches developed and trained specifically on that dataset for predicting semantic similarity. Experimental results showed that the proposed semantic similarity quantification approach can effectively identify related clinical evidence that is reported in the literature. The comparison with a state-of-the-art method demonstrated the effectiveness of the approach, and experiments with an external dataset support its generalisability. well as more explicit process details and access to datasets to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2021
DA  - 2021-04-01
JO  - {'id': 'https://openalex.org/S11622463', 'issn_l': '1532-0464', 'issn': ['1532-0480', '1532-0464'], 'display_name': 'Journal of Biomedical Informatics', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'https://doi.org/10.1016/j.jbi.2021.103717', 'is_oa': True, 'version': 'publishedVersion', 'license': 'elsevier-specific'}
DP  - OpenAlex
AU  - Halil Kilicoglu
AU  - Graciela Rosemblat
AU  - Linh Cao Hoang
AU  - Sahil Wadhwa
AU  - Zeshan Peng
AU  - Mario Malički
AU  - Jodi Schneider
AU  - Gerben ter Riet
ER  - 

623.
TY  - journal-article
ID  - https://openalex.org/W2910177331
DO  - https://doi.org/10.1007/s10669-019-09717-3
TI  - Active learning in automated text classification: a case study exploring bias in predicted model performance metrics
AB  - Machine learning has emerged as a cost-effective innovation to support systematic literature reviews in human health risk assessments and other contexts. Supervised machine learning approaches rely on a training dataset, a relatively small set of documents with human-annotated labels indicating their topic, to build models that automatically classify a larger set of unclassified documents. “Active” machine learning has been proposed as an approach that limits the cost of creating a training dataset by interactively and sequentially focussing on training only the most informative documents. We simulate active learning using a dataset of approximately 7000 abstracts from the scientific literature related to the chemical arsenic. The dataset was previously annotated by subject matter experts with regard to relevance to two topics relating to toxicology and risk assessment. We examine the performance of alternative sampling approaches to sequentially expanding the training dataset, specifically looking at uncertainty-based sampling and probability-based sampling. We discover that while such active learning methods can potentially reduce training dataset size compared to random sampling, predictions of model performance in active learning are likely to suffer from statistical bias that negates the method’s potential benefits. We discuss approaches and the extent to which the bias resulting from skewed sampling can be compensated. We propose a useful role for active learning in contexts in which the accuracy of model performance metrics is not critical and/or where it is beneficial to rapidly create a class-balanced training dataset. mining models to recognize them. For the items commonly reported, CONSORT-TM can serve as a testbed for text mining methods that assess RCT transparency, rigor, and reliability, and support methods for peer review and authoring assistance. Minor modifications to the annotation scheme and a larger corpus could facilitate improved text mining models. CONSORT-TM is publicly available at https://github.com/kilicogluh/CONSORT-TM. dataset of 1000 pairs of sentences from biomedical publications that are annotated by ten human experts. We also extend the experiments on an external dataset for further generalisability testing. The combination of all diverse similarity measures showed stronger correlations with the gold standard similarity scores in the dataset than any individual kind of measure. Our approach reached near 0.80 average Pearson correlation across different clinical evidence types using the devised similarity measures. Although they were more effective when combined together, individual generic and vector-space measures also resulted in strong similarity quantification when used in both unsupervised and supervised models. On the external dataset, our similarity measures were highly competitive with the state-of-the-art approaches developed and trained specifically on that dataset for predicting semantic similarity. Experimental results showed that the proposed semantic similarity quantification approach can effectively identify related clinical evidence that is reported in the literature. The comparison with a state-of-the-art method demonstrated the effectiveness of the approach, and experiments with an external dataset support its generalisability. well as more explicit process details and access to datasets to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2019
DA  - 2019-09-01
JO  - {'id': 'https://openalex.org/S2764812402', 'issn_l': '2194-5411', 'issn': ['2194-5403', '2194-5411'], 'display_name': 'Environment Systems and Decisions', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Arun Varghese
AU  - Tao Hong
AU  - C. R. Hunter
AU  - George Agyeman-Badu
AU  - Michelle Cawley
ER  - 

624.
TY  - journal-article
ID  - https://openalex.org/W3097876348
DO  - https://doi.org/10.1136/bmjopen-2020-038893
TI  - Impact of transition programmes for students and new graduate nurses on workplace bullying, violence, stress and resilience: a scoping review protocol
AB  - Introduction The shortage of nurses is projected to grow, and the number of new graduate nurses (NGNs) who are predicted to replace expert nurses has increased. Meanwhile, those NGNs leaving their job within the first year, give various reasons for leaving, including workplace bullying and violence. In response, some hospitals and universities have developed nurse transition programmes such as nurse residency programmes and nurse internship programmes to attract NGNs and to assist in their changing status from education to practice. Although these programmes have been successful in decreasing the turnover rate for new nurses and are cost-effective, their impact on workplace bullying and violence has not been systematically reviewed and is yet to be determined. A scoping review will be conducted to address this gap. The aim is to identify current knowledge regarding the content of transition programmes and their impact in supporting NGNs dealing with workplace violence, bullying and stress. Methods and analysis Arksey and O’Malley’s scoping framework and the Joanna Briggs Institute scoping review guidance will guide the methodology process of the review. Published studies, with no date limit, will be identified through the electronic databases (CINAHL, Scopus, MEDLINE, Web of Science, ASSIA, PsycINFO, Embase, PROSPERO and ProQuest Dissertation) and reference lists. Primary key terms will be ‘novice nurse’, ‘new graduate nurses’ and ‘transition programmes’. Two reviewers, guided by standardised procedures, will perform the study selection process independently. Data from the selected studies will be extracted using a data extraction form. Thematic analysis (for qualitative papers) and descriptive summary of the results (for quantitative papers) will be performed. Ethics and dissemination Ethical approval is not required for this review. Findings will be used to inform future study designs to evaluate the transition programmes and disseminated via peer-reviewed journals and conferences. at https://github.com/kilicogluh/CONSORT-TM. dataset of 1000 pairs of sentences from biomedical publications that are annotated by ten human experts. We also extend the experiments on an external dataset for further generalisability testing. The combination of all diverse similarity measures showed stronger correlations with the gold standard similarity scores in the dataset than any individual kind of measure. Our approach reached near 0.80 average Pearson correlation across different clinical evidence types using the devised similarity measures. Although they were more effective when combined together, individual generic and vector-space measures also resulted in strong similarity quantification when used in both unsupervised and supervised models. On the external dataset, our similarity measures were highly competitive with the state-of-the-art approaches developed and trained specifically on that dataset for predicting semantic similarity. Experimental results showed that the proposed semantic similarity quantification approach can effectively identify related clinical evidence that is reported in the literature. The comparison with a state-of-the-art method demonstrated the effectiveness of the approach, and experiments with an external dataset support its generalisability. well as more explicit process details and access to datasets to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2020
DA  - 2020-10-30
JO  - {'id': 'https://openalex.org/S79054089', 'issn_l': '2044-6055', 'issn': ['2044-6055'], 'display_name': 'BMJ Open', 'publisher': 'BMJ', 'type': 'journal', 'url': 'https://bmjopen.bmj.com/content/bmjopen/10/10/e038893.full.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc'}
DP  - OpenAlex
AU  - Khadijah Ali Alshawush
AU  - Nutmeg Hallett
AU  - Caroline Bradbury-Jones
ER  - 

625.
TY  - journal-article
ID  - https://openalex.org/W3104156511
DO  - https://doi.org/10.1186/s13643-020-01528-x
TI  - Decoding semi-automated title-abstract screening: findings from a convenience sample of reviews
AB  - Abstract Background We evaluated the benefits and risks of using the Abstrackr machine learning (ML) tool to semi-automate title-abstract screening and explored whether Abstrackr’s predictions varied by review or study-level characteristics. Methods For a convenience sample of 16 reviews for which adequate data were available to address our objectives (11 systematic reviews and 5 rapid reviews), we screened a 200-record training set in Abstrackr and downloaded the relevance (relevant or irrelevant) of the remaining records, as predicted by the tool. We retrospectively simulated the liberal-accelerated screening approach. We estimated the time savings and proportion missed compared with dual independent screening. For reviews with pairwise meta-analyses, we evaluated changes to the pooled effects after removing the missed studies. We explored whether the tool’s predictions varied by review and study-level characteristics. Results Using the ML-assisted liberal-accelerated approach, we wrongly excluded 0 to 3 (0 to 14%) records that were included in the final reports, but saved a median (IQR) 26 (9, 42) h of screening time. One missed study was included in eight pairwise meta-analyses in one systematic review. The pooled effect for just one of those meta-analyses changed considerably (from MD (95% CI) − 1.53 (− 2.92, − 0.15) to − 1.17 (− 2.70, 0.36)). Of 802 records in the final reports, 87% were correctly predicted as relevant. The correctness of the predictions did not differ by review (systematic or rapid, P = 0.37) or intervention type (simple or complex, P = 0.47). The predictions were more often correct in reviews with multiple (89%) vs. single (83%) research questions ( P = 0.01), or that included only trials (95%) vs. multiple designs (86%) ( P = 0.003). At the study level, trials (91%), mixed methods (100%), and qualitative (93%) studies were more often correctly predicted as relevant compared with observational studies (79%) or reviews (83%) ( P = 0.0006). Studies at high or unclear (88%) vs. low risk of bias (80%) ( P = 0.039), and those published more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews. to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2020
DA  - 2020-11-27
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://systematicreviewsjournal.biomedcentral.com/track/pdf/10.1186/s13643-020-01528-x', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Allison Gates
AU  - Michelle Gates
AU  - D. DaRosa
AU  - Sarah A. Elliott
AU  - Jennifer Pillay
AU  - Sholeh Rahman
AU  - Ben Vandermeer
AU  - Lisa Hartling
ER  - 

626.
TY  - journal-article
ID  - https://openalex.org/W4225269224
DO  - https://doi.org/10.1016/j.jclinepi.2022.04.027
TI  - Artificial intelligence in COVID-19 evidence syntheses was underutilized, but impactful: a methodological study
AB  - A rapidly developing scenario like a pandemic requires the prompt production of high-quality systematic reviews, which can be automated using artificial intelligence (AI) techniques. We evaluated the application of AI tools in COVID-19 evidence syntheses.After prospective registration of the review protocol, we automated the download of all open-access COVID-19 systematic reviews in the COVID-19 Living Overview of Evidence database, indexed them for AI-related keywords, and located those that used AI tools. We compared their journals' JCR Impact Factor, citations per month, screening workloads, completion times (from pre-registration to preprint or submission to a journal) and AMSTAR-2 methodology assessments (maximum score 13 points) with a set of publication date matched control reviews without AI.Of the 3,999 COVID-19 reviews, 28 (0.7%, 95% CI 0.47-1.03%) made use of AI. On average, compared to controls (n = 64), AI reviews were published in journals with higher Impact Factors (median 8.9 vs. 3.5, P < 0.001), and screened more abstracts per author (302.2 vs. 140.3, P = 0.009) and per included study (189.0 vs. 365.8, P < 0.001) while inspecting less full texts per author (5.3 vs. 14.0, P = 0.005). No differences were found in citation counts (0.5 vs. 0.6, P = 0.600), inspected full texts per included study (3.8 vs. 3.4, P = 0.481), completion times (74.0 vs. 123.0, P = 0.205) or AMSTAR-2 (7.5 vs. 6.3, P = 0.119).AI was an underutilized tool in COVID-19 systematic reviews. Its usage, compared to reviews without AI, was associated with more efficient screening of literature and higher publication impact. There is scope for the application of AI in automating systematic reviews. trials (95%) vs. multiple designs (86%) ( P = 0.003). At the study level, trials (91%), mixed methods (100%), and qualitative (93%) studies were more often correctly predicted as relevant compared with observational studies (79%) or reviews (83%) ( P = 0.0006). Studies at high or unclear (88%) vs. low risk of bias (80%) ( P = 0.039), and those published more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews. to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2022
DA  - 2022-05-01
JO  - {'id': 'https://openalex.org/S64418186', 'issn_l': '0895-4356', 'issn': ['1878-5921', '0895-4356'], 'display_name': 'Journal of Clinical Epidemiology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'http://www.jclinepi.com/article/S0895435622001160/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc-nd'}
DP  - OpenAlex
AU  - Juan R. Tercero-Hidalgo
AU  - Khalid Mohammed Khan
AU  - Aurora Bueno-Cavanillas
AU  - Rodrigo Fernández-López
AU  - Juan F. Huete
AU  - Carmen Amezcua-Prieto
AU  - Javier Zamora
AU  - Juan M. Fernández-Luna
ER  - 

627.
TY  - journal-article
ID  - https://openalex.org/W4280542232
DO  - https://doi.org/10.1177/17456916211053319
TI  - The Cooperation Databank: Machine-Readable Science Accelerates Research Synthesis
AB  - Publishing studies using standardized, machine-readable formats will enable machines to perform meta-analyses on demand. To build a semantically enhanced technology that embodies these functions, we developed the Cooperation Databank (CoDa)-a databank that contains 2,636 studies on human cooperation (1958-2017) conducted in 78 societies involving 356,283 participants. Experts annotated these studies along 312 variables, including the quantitative results (13,959 effects). We designed an ontology that defines and relates concepts in cooperation research and that can represent the relationships between results of correlational and experimental studies. We have created a research platform that, given the data set, enables users to retrieve studies that test the relation of variables with cooperation, visualize these study results, and perform (a) meta-analyses, (b) metaregressions, (c) estimates of publication bias, and (d) statistical power analyses for future studies. We leveraged the data set with visualization tools that allow users to explore the ontology of concepts in cooperation research and to plot a citation network of the history of studies. CoDa offers a vision of how publishing studies in a machine-readable format can establish institutions and tools that improve scientific practices and knowledge. 0.005). No differences were found in citation counts (0.5 vs. 0.6, P = 0.600), inspected full texts per included study (3.8 vs. 3.4, P = 0.481), completion times (74.0 vs. 123.0, P = 0.205) or AMSTAR-2 (7.5 vs. 6.3, P = 0.119).AI was an underutilized tool in COVID-19 systematic reviews. Its usage, compared to reviews without AI, was associated with more efficient screening of literature and higher publication impact. There is scope for the application of AI in automating systematic reviews. trials (95%) vs. multiple designs (86%) ( P = 0.003). At the study level, trials (91%), mixed methods (100%), and qualitative (93%) studies were more often correctly predicted as relevant compared with observational studies (79%) or reviews (83%) ( P = 0.0006). Studies at high or unclear (88%) vs. low risk of bias (80%) ( P = 0.039), and those published more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews. to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2022
DA  - 2022-05-17
JO  - {'id': 'https://openalex.org/S27228949', 'issn_l': '1745-6916', 'issn': ['1745-6916', '1745-6924'], 'display_name': 'Perspectives on Psychological Science', 'publisher': 'SAGE Publishing', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Giuliana Spadaro
AU  - Ilaria Tiddi
AU  - Simon Columbus
AU  - Shu-Xian Jin
AU  - Annette ten Teije
AU  - Daniel Balliet
ER  - 

628.
TY  - proceedings-article
ID  - https://openalex.org/W2902188296
DO  - https://doi.org/10.1109/snams.2018.8554896
TI  - The Canonical Model of Structure for Data Extraction in Systematic Reviews of Scientific Research Articles
AB  - The systematic review activity is time-consuming, error prone and labour intensive activity due to the manual processes involved; with data extraction being an extremely difficult and cognitively demanding process. Automation can save a significant amount of time and reduces the workload. However, there is no unified approach for automatic data extraction in systematic reviews. This paper presents a canonical model of structure of the papers that serves as a unified approach and a foundation for subsequent extraction of information from scientific research articles automatically. The model was developed using text mining and natural language processing techniques on one thousand (1000) published research papers. A novel approach was used to identify the various section headings from the papers. This approach achieved an accuracy of 82%. A statistical analysis of the most frequent words/phrases in the section headings was used to build the canonical model of structure of the papers. in cooperation research and to plot a citation network of the history of studies. CoDa offers a vision of how publishing studies in a machine-readable format can establish institutions and tools that improve scientific practices and knowledge. 0.005). No differences were found in citation counts (0.5 vs. 0.6, P = 0.600), inspected full texts per included study (3.8 vs. 3.4, P = 0.481), completion times (74.0 vs. 123.0, P = 0.205) or AMSTAR-2 (7.5 vs. 6.3, P = 0.119).AI was an underutilized tool in COVID-19 systematic reviews. Its usage, compared to reviews without AI, was associated with more efficient screening of literature and higher publication impact. There is scope for the application of AI in automating systematic reviews. trials (95%) vs. multiple designs (86%) ( P = 0.003). At the study level, trials (91%), mixed methods (100%), and qualitative (93%) studies were more often correctly predicted as relevant compared with observational studies (79%) or reviews (83%) ( P = 0.0006). Studies at high or unclear (88%) vs. low risk of bias (80%) ( P = 0.039), and those published more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews. to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2018
DA  - 2018-12-03
JO  - {'id': None, 'issn_l': None, 'issn': None, 'display_name': None, 'publisher': None, 'type': None, 'url': 'https://doi.org/10.1109/snams.2018.8554896', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Muhammad Mukhtar Aliyu
AU  - Rahat Iqbal
AU  - Anne James
ER  - 

629.
TY  - journal-article
ID  - https://openalex.org/W3006673017
DO  - https://doi.org/10.1002/jrsm.1398
TI  - Comparing machine and human reviewers to evaluate the risk of bias in randomized controlled trials
AB  - Background Evidence from new health technologies is growing, along with demands for evidence to inform policy decisions, creating challenges in completing health technology assessments (HTAs)/systematic reviews (SRs) in a timely manner. Software can decrease the time and burden by automating the process, but evidence validating such software is limited. We tested the accuracy of RobotReviewer, a semi-autonomous risk of bias (RoB) assessment tool, and its agreement with human reviewers. Methods Two reviewers independently conducted RoB assessments on a sample of randomized controlled trials (RCTs), and their consensus ratings were compared with those generated by RobotReviewer. Agreement with the human reviewers was assessed using percent agreement and weighted kappa (κ). The accuracy of RobotReviewer was also assessed by calculating the sensitivity, specificity, and area under the curve in comparison to the consensus agreement of the human reviewers. Results The study included 372 RCTs. Inter-rater reliability ranged from κ = −0.06 (no agreement) for blinding of participants and personnel to κ = 0.62 (good agreement) for random sequence generation (excluding overall RoB). RobotReviewer was found to use a high percentage of “irrelevant supporting quotations” to complement RoB assessments for blinding of participants and personnel (72.6%), blinding of outcome assessment (70.4%), and allocation concealment (54.3%). Conclusion RobotReviewer can help with risk of bias assessment of RCTs but cannot replace human evaluations. Thus, reviewers should check and validate RoB assessments from RobotReviewer by consulting the original article when not relevant supporting quotations are provided by RobotReviewer. This consultation is in line with the recommendation provided by the developers. There is scope for the application of AI in automating systematic reviews. trials (95%) vs. multiple designs (86%) ( P = 0.003). At the study level, trials (91%), mixed methods (100%), and qualitative (93%) studies were more often correctly predicted as relevant compared with observational studies (79%) or reviews (83%) ( P = 0.0006). Studies at high or unclear (88%) vs. low risk of bias (80%) ( P = 0.039), and those published more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews. to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2020
DA  - 2020-03-03
JO  - {'id': 'https://openalex.org/S205768342', 'issn_l': '1759-2879', 'issn': ['1759-2879', '1759-2887'], 'display_name': 'Research Synthesis Methods', 'publisher': 'Wiley-Blackwell', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Susan Armijo-Olivo
AU  - Rodger Craig
AU  - Sandy Campbell
ER  - 

630.
TY  - journal-article
ID  - https://openalex.org/W3033427052
DO  - https://doi.org/10.1097/gco.0000000000000643
TI  - Artificial intelligence and automation of systematic reviews in women's health
AB  - Purpose of review new Evidence-based women's healthcare is underpinned by systematic reviews and guidelines. Generating an evidence synthesis to support guidance for clinical practice is a time-consuming and labour-intensive activity that delays transfer of research into practice. Artificial intelligence has the potential to rapidly collate, combine, and update high-quality medical evidence with accuracy and precision, and without bias. of Recent findings assessment This article describes the main fields of artificial intelligence with examples of its application to systematic reviews. These include the capabilities of processing natural language texts, retrieving information, reasoning, and learning. The complementarity and interconnection of the various artificial intelligence techniques can be harnessed to solve difficult problems in automation of reviews. Computer science can advance evidence-based medicine through development, testing, and refinement of artificial intelligence tools to deploy automation, creating 'living' evidence syntheses. Results Summary study Groundbreaking, high-quality, and impactful artificial intelligence will accelerate the transfer of individual research studies seamlessly into evidence syntheses for contemporaneously improving the quality of healthcare. random sequence generation (excluding overall RoB). RobotReviewer was found to use a high percentage of “irrelevant supporting quotations” to complement RoB assessments for blinding of participants and personnel (72.6%), blinding of outcome assessment (70.4%), and allocation concealment (54.3%). Conclusion RobotReviewer can help with risk of bias assessment of RCTs but cannot replace human evaluations. Thus, reviewers should check and validate RoB assessments from RobotReviewer by consulting the original article when not relevant supporting quotations are provided by RobotReviewer. This consultation is in line with the recommendation provided by the developers. There is scope for the application of AI in automating systematic reviews. trials (95%) vs. multiple designs (86%) ( P = 0.003). At the study level, trials (91%), mixed methods (100%), and qualitative (93%) studies were more often correctly predicted as relevant compared with observational studies (79%) or reviews (83%) ( P = 0.0006). Studies at high or unclear (88%) vs. low risk of bias (80%) ( P = 0.039), and those published more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews. to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2020
DA  - 2020-10-01
JO  - {'id': 'https://openalex.org/S203280300', 'issn_l': '1040-872X', 'issn': ['1080-8256', '1040-872X', '1473-656X'], 'display_name': 'Current Opinion in Obstetrics & Gynecology', 'publisher': 'Lippincott Williams & Wilkins', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Carmen Amezcua-Prieto
AU  - Juan M. Fernández-Luna
AU  - Juan F Huete-Guadix
AU  - Aurora Bueno-Cavanillas
AU  - Khalid Mohammed Khan
ER  - 

631.
TY  - journal-article
ID  - https://openalex.org/W3144391370
DO  - https://doi.org/10.1186/s13643-021-01632-6
TI  - Successful incorporation of single reviewer assessments during systematic review screening: development and validation of sensitivity and work-saved of an algorithm that considers exclusion criteria and count.
AB  - Accepted systematic review (SR) methodology requires citation screening by two reviewers to maximise retrieval of eligible studies. We hypothesized that records could be excluded by a single reviewer without loss of sensitivity in two conditions; the record was ineligible for multiple reasons, or the record was ineligible for one or more specific reasons that could be reliably assessed.Twenty-four SRs performed at CHEO, a pediatric health care and research centre in Ottawa, Canada, were divided into derivation and validation sets. Exclusion criteria during abstract screening were sorted into 11 specific categories, with loss in sensitivity determined by individual category and by number of exclusion criteria endorsed. Five single reviewer algorithms that combined individual categories and multiple exclusion criteria were then tested on the derivation and validation sets, with success defined a priori as less than 5% loss of sensitivity.The 24 SRs included 930 eligible and 27390 ineligible citations. The reviews were mostly focused on pediatrics (70.8%, N=17/24), but covered various specialties. Using a single reviewer to exclude any citation led to an average loss of sensitivity of 8.6% (95%CI, 6.0-12.1%). Excluding citations with ≥2 exclusion criteria led to 1.2% average loss of sensitivity (95%CI, 0.5-3.1%). Five specific exclusion criteria performed with perfect sensitivity: conference abstract, ineligible age group, case report/series, not human research, and review article. In the derivation set, the five algorithms achieved a loss of sensitivity ranging from 0.0 to 1.9% and work-saved ranging from 14.8 to 39.1%. In the validation set, the loss of sensitivity for all 5 algorithms remained below 2.6%, with work-saved between 10.5% and 48.2%.Findings suggest that targeted application of single-reviewer screening, considering both type and number of exclusion criteria, could retain sensitivity and significantly decrease workload. Further research is required to investigate the potential for combining this approach with crowdsourcing or machine learning methodologies. (79%) or reviews (83%) ( P = 0.0006). Studies at high or unclear (88%) vs. low risk of bias (80%) ( P = 0.039), and those published more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews. to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2021
DA  - 2021-04-05
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Nassr Nama
AU  - Mirna Hennawy
AU  - Nick Barrowman
AU  - Katie O’Hearn
AU  - Margaret Sampson
AU  - James G. McNally
ER  - 

632.
TY  - journal-article
ID  - https://openalex.org/W2620639629
DO  - nan
TI  - Feasibility of Extracting Key Elements from ClinicalTrials.gov to Support Clinicians' Patient Care Decisions.
AB  - Motivation: Clinicians need up-to-date evidence from high quality clinical trials to support clinical decisions. However, applying evidence from the primary literature requires significant effort. Objective: To examine the feasibility of automatically extracting key clinical trial information from ClinicalTrials.gov. Methods: We assessed the coverage of ClinicalTrials.gov for high quality clinical studies that are indexed in PubMed. Using 140 random ClinicalTrials.gov records, we developed and tested rules for the automatic extraction of key information. Results: The rate of high quality clinical trial registration in ClinicalTrials.gov increased from 0.2% in 2005 to 17% in 2015. Trials reporting results increased from 3% in 2005 to 19% in 2015. The accuracy of the automatic extraction algorithm for 10 trial attributes was 90% on average. Future research is needed to improve the algorithm accuracy and to design information displays to optimally present trial information to clinicians. included 930 eligible and 27390 ineligible citations. The reviews were mostly focused on pediatrics (70.8%, N=17/24), but covered various specialties. Using a single reviewer to exclude any citation led to an average loss of sensitivity of 8.6% (95%CI, 6.0-12.1%). Excluding citations with ≥2 exclusion criteria led to 1.2% average loss of sensitivity (95%CI, 0.5-3.1%). Five specific exclusion criteria performed with perfect sensitivity: conference abstract, ineligible age group, case report/series, not human research, and review article. In the derivation set, the five algorithms achieved a loss of sensitivity ranging from 0.0 to 1.9% and work-saved ranging from 14.8 to 39.1%. In the validation set, the loss of sensitivity for all 5 algorithms remained below 2.6%, with work-saved between 10.5% and 48.2%.Findings suggest that targeted application of single-reviewer screening, considering both type and number of exclusion criteria, could retain sensitivity and significantly decrease workload. Further research is required to investigate the potential for combining this approach with crowdsourcing or machine learning methodologies. (79%) or reviews (83%) ( P = 0.0006). Studies at high or unclear (88%) vs. low risk of bias (80%) ( P = 0.039), and those published more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews. to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2016
DA  - 2016-01-01
JO  - {'id': 'https://openalex.org/S4306417663', 'issn_l': None, 'issn': None, 'display_name': 'American Medical Informatics Association Annual Symposium', 'publisher': None, 'type': 'conference', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Hee-Jun Kim
AU  - Jiantao Bian
AU  - Javed Mostafa
AU  - Siddhartha Jonnalagadda
AU  - Guilherme Del Fiol
ER  - 

633.
TY  - journal-article
ID  - https://openalex.org/W2906214584
DO  - https://doi.org/10.1016/j.jclinepi.2018.12.014
TI  - Software engineering principles address current problems in the systematic review ecosystem.
AB  - Systematic reviewers are simultaneously unable to produce systematic reviews fast enough to keep up with the availability of new trial evidence while overproducing systematic reviews that are unlikely to change practice because they are redundant or biased. Although the transparency and completeness of trial reporting has improved with changes in policy and new technologies, systematic reviews have not yet benefited from the same level of effort. We found that new methods and tools used to automate aspects of systematic review processes have focused on improving the efficiency of individual systematic reviews rather than the efficiency of the entire ecosystem of systematic review production. We use software engineering principles to review challenges and opportunities for improving the interoperability, integrity, efficiency, and maintainability. We conclude by recommending ways to improve access to structured systematic review results. Major opportunities for improving systematic reviews will come from new tools and changes in policy focused on doing the right systematic reviews rather than just doing more of them faster. to exclude any citation led to an average loss of sensitivity of 8.6% (95%CI, 6.0-12.1%). Excluding citations with ≥2 exclusion criteria led to 1.2% average loss of sensitivity (95%CI, 0.5-3.1%). Five specific exclusion criteria performed with perfect sensitivity: conference abstract, ineligible age group, case report/series, not human research, and review article. In the derivation set, the five algorithms achieved a loss of sensitivity ranging from 0.0 to 1.9% and work-saved ranging from 14.8 to 39.1%. In the validation set, the loss of sensitivity for all 5 algorithms remained below 2.6%, with work-saved between 10.5% and 48.2%.Findings suggest that targeted application of single-reviewer screening, considering both type and number of exclusion criteria, could retain sensitivity and significantly decrease workload. Further research is required to investigate the potential for combining this approach with crowdsourcing or machine learning methodologies. (79%) or reviews (83%) ( P = 0.0006). Studies at high or unclear (88%) vs. low risk of bias (80%) ( P = 0.039), and those published more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews. to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2019
DA  - 2019-05-01
JO  - {'id': 'https://openalex.org/S64418186', 'issn_l': '0895-4356', 'issn': ['1878-5921', '0895-4356'], 'display_name': 'Journal of Clinical Epidemiology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Rabia Bashir
AU  - Adam G. Dunn
ER  - 

634.
TY  - book-chapter
ID  - https://openalex.org/W2952966142
DO  - https://doi.org/10.1007/978-3-030-20485-3_19
TI  - An Effective Machine Learning Framework for Data Elements Extraction from the Literature of Anxiety Outcome Measures to Build Systematic Review
AB  - The process of developing systematic reviews is a well established method of collecting evidence from publications, where it follows a predefined and explicit protocol design to promote rigour, transparency and repeatability. The process is manual and involves lot of time and needs expertise. The aim of this work is to build an effective framework using machine learning techniques to partially automate the process of systematic literature review by extracting required data elements of anxiety outcome measures. A framework is thus proposed that initially builds a training corpus by extracting different data elements related to anxiety outcome measures from relevant publications. The publications are retrieved from Medline, EMBASE, CINAHL, AHMED and Pyscinfo following a given set of rules defined by a research group in the United Kingdom reviewing comfort interventions in health care. Subsequently, the method trains a machine learning classifier using this training corpus to extract the desired data elements from new publications. The experiments are conducted on 48 publications containing anxiety outcome measures with an aim to automatically extract the sentences stating the mean and standard deviation of the measures of outcomes of different types of interventions to lessen anxiety. The experimental results show that the recall and precision of the proposed method using random forest classifier are respectively 100% and 83%, which indicates that the method is able to extract all required data elements. sensitivity ranging from 0.0 to 1.9% and work-saved ranging from 14.8 to 39.1%. In the validation set, the loss of sensitivity for all 5 algorithms remained below 2.6%, with work-saved between 10.5% and 48.2%.Findings suggest that targeted application of single-reviewer screening, considering both type and number of exclusion criteria, could retain sensitivity and significantly decrease workload. Further research is required to investigate the potential for combining this approach with crowdsourcing or machine learning methodologies. (79%) or reviews (83%) ( P = 0.0006). Studies at high or unclear (88%) vs. low risk of bias (80%) ( P = 0.039), and those published more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews. to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2019
DA  - 2019-06-26
JO  - {'id': 'https://openalex.org/V4210177767', 'issn_l': '1865-1348', 'issn': ['1865-1348', '1865-1356'], 'display_name': 'Lecture notes in business information processing', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Shubhaditya Goswami
AU  - Sukanya Pal
AU  - Simon D. Goldsworthy
AU  - Tanmay Basu
ER  - 

635.
TY  - proceedings-article
ID  - https://openalex.org/W2970008788
DO  - https://doi.org/10.18653/v1/w19-5012
TI  - A distantly supervised dataset for automated data extraction from diagnostic studies
AB  - Systematic reviews are important in evidence based medicine, but are expensive to produce. Automating or semi-automating the data extraction of index test, target condition, and reference standard from articles has the potential to decrease the cost of conducting systematic reviews of diagnostic test accuracy, but relevant training data is not available. We create a distantly supervised dataset of approximately 90,000 sentences, and let two experts manually annotate a small subset of around 1,000 sentences for evaluation. We evaluate the performance of BioBERT and logistic regression for ranking the sentences, and compare the performance for distant and direct supervision. Our results suggest that distant supervision can work as well as, or better than direct supervision on this problem, and that distantly trained models can perform as well as, or better than human annotators. Subsequently, the method trains a machine learning classifier using this training corpus to extract the desired data elements from new publications. The experiments are conducted on 48 publications containing anxiety outcome measures with an aim to automatically extract the sentences stating the mean and standard deviation of the measures of outcomes of different types of interventions to lessen anxiety. The experimental results show that the recall and precision of the proposed method using random forest classifier are respectively 100% and 83%, which indicates that the method is able to extract all required data elements. sensitivity ranging from 0.0 to 1.9% and work-saved ranging from 14.8 to 39.1%. In the validation set, the loss of sensitivity for all 5 algorithms remained below 2.6%, with work-saved between 10.5% and 48.2%.Findings suggest that targeted application of single-reviewer screening, considering both type and number of exclusion criteria, could retain sensitivity and significantly decrease workload. Further research is required to investigate the potential for combining this approach with crowdsourcing or machine learning methodologies. (79%) or reviews (83%) ( P = 0.0006). Studies at high or unclear (88%) vs. low risk of bias (80%) ( P = 0.039), and those published more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews. to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2019
DA  - 2019-08-01
JO  - {'id': 'https://openalex.org/V4306402512', 'issn_l': None, 'issn': None, 'display_name': 'Le Centre pour la Communication Scientifique Directe - HAL - Diderot', 'publisher': 'Le Centre pour la Communication Scientifique Directe', 'type': 'repository', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Christopher R. Norman
AU  - Mariska M.G. Leeflang
AU  - René Spijker
AU  - Evangelos Kanoulas
AU  - Aurélie Névéol
ER  - 

636.
TY  - journal-article
ID  - https://openalex.org/W3203297670
DO  - https://doi.org/10.2196/33124
TI  - Toward Automated Data Extraction According to Tabular Data Structure: Cross-sectional Pilot Survey of the Comparative Clinical Literature
AB  - Systematic reviews depend on time-consuming extraction of data from the PDFs of underlying studies. To date, automation efforts have focused on extracting data from the text, and no approach has yet succeeded in fully automating ingestion of quantitative evidence. However, the majority of relevant data is generally presented in tables, and the tabular structure is more amenable to automated extraction than free text.The purpose of this study was to classify the structure and format of descriptive statistics reported in tables in the comparative medical literature.We sampled 100 published randomized controlled trials from 2019 based on a search in PubMed; these results were imported to the AutoLit platform. Studies were excluded if they were nonclinical, noncomparative, not in English, protocols, or not available in full text. In AutoLit, tables reporting baseline or outcome data in all studies were characterized based on reporting practices. Measurement context, meaning the structure in which the interventions of interest, patient arm breakdown, measurement time points, and data element descriptions were presented, was classified based on the number of contextual pieces and metadata reported. The statistic formats for reported metrics (specific instances of reporting of data elements) were then classified by location and broken down into reporting strategies for continuous, dichotomous, and categorical metrics.We included 78 of 100 sampled studies, one of which (1.3%) did not report data elements in tables. The remaining 77 studies reported baseline and outcome data in 174 tables, and 96% (69/72) of these tables broke down reporting by patient arms. Fifteen structures were found for the reporting of measurement context, which were broadly grouped into: 1×1 contexts, where two pieces of context are reported in total (eg, arms in columns, data elements in rows); 2×1 contexts, where two pieces of context are given on row headers (eg, time points in columns, arms nested in data elements on rows); and 1×2 contexts, where two pieces of context are given on column headers. The 1×1 contexts were present in 57% of tables (99/174), compared to 20% (34/174) for 2×1 contexts and 15% (26/174) for 1×2 contexts; the remaining 8% (15/174) used unique/other stratification methods. Statistic formats were reported in the headers or descriptions of 84% (65/74) of studies.In this cross-sectional pilot review, we found a high density of information in tables, but with major heterogeneity in presentation of measurement context. The highest-density studies reported both baseline and outcome measures in tables, with arm-level breakout, intervention labels, and arm sizes present, and reported both the statistic formats and units. The measurement context formats presented here, broadly classified into three classes that cover 92% (71/78) of studies, form a basis for understanding the frequency of different reporting styles, supporting automated detection of the data format for extraction of metrics. meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews. to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2021
DA  - 2021-11-24
JO  - {'id': 'https://openalex.org/V4210234749', 'issn_l': '2561-326X', 'issn': ['2561-326X'], 'display_name': 'JMIR formative research', 'publisher': 'JMIR Publications Inc.', 'type': 'journal', 'url': 'https://formative.jmir.org/2021/11/e33124/PDF', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Kevin M. Kallmes
AU  - Nicole Hardy
AU  - Kevin M. Kallmes
ER  - 

637.
TY  - journal-article
ID  - https://openalex.org/W4206902451
DO  - https://doi.org/10.1186/s13643-021-01881-5
TI  - Automation of literature screening using machine learning in medical evidence synthesis: a diagnostic test accuracy systematic review protocol
AB  - Systematic review is an indispensable tool for optimal evidence collection and evaluation in evidence-based medicine. However, the explosive increase of the original literatures makes it difficult to accomplish critical appraisal and regular update. Artificial intelligence (AI) algorithms have been applied to automate the literature screening procedure in medical systematic reviews. In these studies, different algorithms were used and results with great variance were reported. It is therefore imperative to systematically review and analyse the developed automatic methods for literature screening and their effectiveness reported in current studies.An electronic search will be conducted using PubMed, Embase, ACM Digital Library, and IEEE Xplore Digital Library databases, as well as literatures found through supplementary search in Google scholar, on automatic methods for literature screening in systematic reviews. Two reviewers will independently conduct the primary screening of the articles and data extraction, in which nonconformities will be solved by discussion with a methodologist. Data will be extracted from eligible studies, including the basic characteristics of study, the information of training set and validation set, and the function and performance of AI algorithms, and summarised in a table. The risk of bias and applicability of the eligible studies will be assessed by the two reviewers independently based on Quality Assessment of Diagnostic Accuracy Studies (QUADAS-2). Quantitative analyses, if appropriate, will also be performed.Automating systematic review process is of great help in reducing workload in evidence-based practice. Results from this systematic review will provide essential summary of the current development of AI algorithms for automatic literature screening in medical evidence synthesis and help to inspire further studies in this field.PROSPERO CRD42020170815 (28 April 2020). of context are reported in total (eg, arms in columns, data elements in rows); 2×1 contexts, where two pieces of context are given on row headers (eg, time points in columns, arms nested in data elements on rows); and 1×2 contexts, where two pieces of context are given on column headers. The 1×1 contexts were present in 57% of tables (99/174), compared to 20% (34/174) for 2×1 contexts and 15% (26/174) for 1×2 contexts; the remaining 8% (15/174) used unique/other stratification methods. Statistic formats were reported in the headers or descriptions of 84% (65/74) of studies.In this cross-sectional pilot review, we found a high density of information in tables, but with major heterogeneity in presentation of measurement context. The highest-density studies reported both baseline and outcome measures in tables, with arm-level breakout, intervention labels, and arm sizes present, and reported both the statistic formats and units. The measurement context formats presented here, broadly classified into three classes that cover 92% (71/78) of studies, form a basis for understanding the frequency of different reporting styles, supporting automated detection of the data format for extraction of metrics. meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews. to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2022
DA  - 2022-01-15
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://systematicreviewsjournal.biomedcentral.com/track/pdf/10.1186/s13643-021-01881-5', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Yuelun Zhang
AU  - Siyu Liang
AU  - Yunying Feng
AU  - Qing Wang
AU  - Feng Sun
AU  - Shi Chen
AU  - Yiying Yang
AU  - Xin He
AU  - Huijuan Zhu
AU  - Hui Pan
ER  - 

638.
TY  - journal-article
ID  - https://openalex.org/W2970877041
DO  - nan
TI  - Overview of the TAC 2018 Systematic Review Information Extraction Track.
AB  - No Abstract Found
PY  - 2018
DA  - 2018-01-01
JO  - {'id': 'https://openalex.org/S2501765825', 'issn_l': '1201-561X', 'issn': ['1201-561X'], 'display_name': 'Theory and Applications of Categories', 'publisher': 'Masaryk University', 'type': 'journal', 'url': 'https://tac.nist.gov/publications/2018/additional.papers/TAC2018.SRIE.overview.proceedings.pdf', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Charles B. Schmitt
AU  - Vickie R. Walker
AU  - Ashley J. Williams
AU  - Arun Varghese
AU  - Yousuf Ahmad
AU  - Andrew A. Rooney
AU  - Mary Leigh Wolfe
ER  - 

639.
TY  - journal-article
ID  - https://openalex.org/W2971957790
DO  - https://doi.org/10.30699/ijp.2019.95692.1942
TI  - Secondary Use of Laboratory data: Potentialities and Limitations
AB  - Clinical databases have been developed in recent years especially during the course of all medical concerns including laboratory results. The information produced by the diagnostic laboratories have great impact on health care system with various secondary uses. These uses are sometimes as publishing new extracted information of laboratory reports which have been widely applied in the scientific journals. Nowadays, some large scale or national databases are also formed from the integration of these data from smaller centers in the field of human health in many countries. These databases are beneficial for different stakeholders who may need this information. Unfortunately, reviewing some of these uses has indicated lots of errors in quality control, test validity, uniformity and so on. More importantly, some of the diagnostic procedures have been applied in the clinical diagnostic laboratories without even preliminary clinical evaluation studies. Therefore, any taken conclusion from these analyzed data may not be reliable. This use requires checking the several specifications that have been notified in this study. Current review also intends to show how the correct information should be to extract for the scientific reports, or integrated in large scale databases. of the eligible studies will be assessed by the two reviewers independently based on Quality Assessment of Diagnostic Accuracy Studies (QUADAS-2). Quantitative analyses, if appropriate, will also be performed.Automating systematic review process is of great help in reducing workload in evidence-based practice. Results from this systematic review will provide essential summary of the current development of AI algorithms for automatic literature screening in medical evidence synthesis and help to inspire further studies in this field.PROSPERO CRD42020170815 (28 April 2020). of context are reported in total (eg, arms in columns, data elements in rows); 2×1 contexts, where two pieces of context are given on row headers (eg, time points in columns, arms nested in data elements on rows); and 1×2 contexts, where two pieces of context are given on column headers. The 1×1 contexts were present in 57% of tables (99/174), compared to 20% (34/174) for 2×1 contexts and 15% (26/174) for 1×2 contexts; the remaining 8% (15/174) used unique/other stratification methods. Statistic formats were reported in the headers or descriptions of 84% (65/74) of studies.In this cross-sectional pilot review, we found a high density of information in tables, but with major heterogeneity in presentation of measurement context. The highest-density studies reported both baseline and outcome measures in tables, with arm-level breakout, intervention labels, and arm sizes present, and reported both the statistic formats and units. The measurement context formats presented here, broadly classified into three classes that cover 92% (71/78) of studies, form a basis for understanding the frequency of different reporting styles, supporting automated detection of the data format for extraction of metrics. meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews. to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2019
DA  - 2019-08-01
JO  - {'id': 'https://openalex.org/S2765036875', 'issn_l': '1735-5303', 'issn': ['1735-5303', '2345-3656'], 'display_name': 'iranian journal of pathology', 'publisher': None, 'type': 'journal', 'url': 'http://ijp.iranpath.org/article_36263_eb06af3323d9bcdbd9844d4c9773d44f.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Massoud Hajia
ER  - 

640.
TY  - book-chapter
ID  - https://openalex.org/W2982810819
DO  - https://doi.org/10.1007/978-3-030-33607-3_29
TI  - Convolutional Neural Network for Core Sections Identification in Scientific Research Publications
AB  - The overwhelming volume of data generated online continuous to grow at an exponential and unprecedented rate. Over 80% of such data is unstructured. Scientific research publications constitute a significant portion of such unstructured data. Systematic literature review (SLR) activity is a rigorous and challenging process. The key challenge in SLR is the automatic extraction of the relevant data from the sheer volume of research publications. Lack of a unified framework has been identified as the key problem. A canonical model, based on the structure of the papers was proposed as the framework for data extraction purposes in SLR. Implemented as a classification problem, traditional machine learning models were used to realise the canonical model. A good accuracy was reported in these traditional models. However, there is room for improvement. This paper presents the result of the work on the same problem using convolutional neural network (CNN), which is more sophisticated (deeper). The results show an improvement over the traditional machine learning models with an accuracy of 85%. Unlike the previous CNN NLP works, this work also demonstrates the application of CNN on a bigger NLP dataset such as the data from the scientific research publications. The result also shows that the CNN performs even better in NLP tasks with bigger datasets. analyses, if appropriate, will also be performed.Automating systematic review process is of great help in reducing workload in evidence-based practice. Results from this systematic review will provide essential summary of the current development of AI algorithms for automatic literature screening in medical evidence synthesis and help to inspire further studies in this field.PROSPERO CRD42020170815 (28 April 2020). of context are reported in total (eg, arms in columns, data elements in rows); 2×1 contexts, where two pieces of context are given on row headers (eg, time points in columns, arms nested in data elements on rows); and 1×2 contexts, where two pieces of context are given on column headers. The 1×1 contexts were present in 57% of tables (99/174), compared to 20% (34/174) for 2×1 contexts and 15% (26/174) for 1×2 contexts; the remaining 8% (15/174) used unique/other stratification methods. Statistic formats were reported in the headers or descriptions of 84% (65/74) of studies.In this cross-sectional pilot review, we found a high density of information in tables, but with major heterogeneity in presentation of measurement context. The highest-density studies reported both baseline and outcome measures in tables, with arm-level breakout, intervention labels, and arm sizes present, and reported both the statistic formats and units. The measurement context formats presented here, broadly classified into three classes that cover 92% (71/78) of studies, form a basis for understanding the frequency of different reporting styles, supporting automated detection of the data format for extraction of metrics. meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews. to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2019
DA  - 2019-11-14
JO  - {'id': 'https://openalex.org/S106296714', 'issn_l': '0302-9743', 'issn': ['1611-3349', '0302-9743'], 'display_name': 'Lecture Notes in Computer Science', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Bello Ahmad Muhammad
AU  - Rahat Iqbal
AU  - Anne James
AU  - Dianabasi Nkantah
ER  - 

641.
TY  - journal-article
ID  - https://openalex.org/W3164471952
DO  - https://doi.org/10.1002/jat.4204
TI  - Toxic effects of nanomaterials for health applications: How automation can support a systematic review of the literature?
AB  - Systematic reviews of the scientific literature can be an important source of information supporting the daily work of the regulators in their decision making, particularly in areas of innovative technologies where the regulatory experience is still limited. Significant research activities in the field of nanotechnology resulted in a huge number of publications in the last decades. However, even if the published data can provide relevant information, scientific articles are often of diverse quality, and it is nearly impossible to manually process and evaluate such amount of data in a systematic manner. In this feasibility study, we investigated to what extent open-access automation tools can support a systematic review of toxic effects of nanomaterials for health applications reported in the scientific literature. In this study, we used a battery of available tools to perform the initial steps of a systematic review such as targeted searches, data curation and abstract screening. This work was complemented with an in-house developed tool that allowed us to extract specific sections of the articles such as the materials and methods part or the results section where we could perform subsequent text analysis. We ranked the articles according to quality criteria based on the reported nanomaterial characterisation and extracted most frequently described toxic effects induced by different types of nanomaterials. Even if further demonstration of the reliability and applicability of automation tools is necessary, this study demonstrated the potential to leverage information from the scientific literature by using automation systems in a tiered strategy. for automatic literature screening in medical evidence synthesis and help to inspire further studies in this field.PROSPERO CRD42020170815 (28 April 2020). of context are reported in total (eg, arms in columns, data elements in rows); 2×1 contexts, where two pieces of context are given on row headers (eg, time points in columns, arms nested in data elements on rows); and 1×2 contexts, where two pieces of context are given on column headers. The 1×1 contexts were present in 57% of tables (99/174), compared to 20% (34/174) for 2×1 contexts and 15% (26/174) for 1×2 contexts; the remaining 8% (15/174) used unique/other stratification methods. Statistic formats were reported in the headers or descriptions of 84% (65/74) of studies.In this cross-sectional pilot review, we found a high density of information in tables, but with major heterogeneity in presentation of measurement context. The highest-density studies reported both baseline and outcome measures in tables, with arm-level breakout, intervention labels, and arm sizes present, and reported both the statistic formats and units. The measurement context formats presented here, broadly classified into three classes that cover 92% (71/78) of studies, form a basis for understanding the frequency of different reporting styles, supporting automated detection of the data format for extraction of metrics. meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews. to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2022
DA  - 2022-01-01
JO  - {'id': 'https://openalex.org/S81851855', 'issn_l': '0260-437X', 'issn': ['1099-1263', '0260-437X'], 'display_name': 'Journal of Applied Toxicology', 'publisher': 'Wiley', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Blanka Halamoda-Kenzaoui
AU  - Etienne Rolland
AU  - Jacopo Piovesan
AU  - Antonio Gallardo
AU  - Susanne Bremer-Hoffmann
ER  - 

642.
TY  - journal-article
ID  - https://openalex.org/W4200392107
DO  - https://doi.org/10.1016/j.envint.2021.107025
TI  - Evaluation of a semi-automated data extraction tool for public health literature-based reviews: Dextr
AB  - There has been limited development and uptake of machine-learning methods to automate data extraction for literature-based assessments. Although advanced extraction approaches have been applied to some clinical research reviews, existing methods are not well suited for addressing toxicology or environmental health questions due to unique data needs to support reviews in these fields.To develop and evaluate a flexible, web-based tool for semi-automated data extraction that: 1) makes data extraction predictions with user verification, 2) integrates token-level annotations, and 3) connects extracted entities to support hierarchical data extraction.Dextr was developed with Agile software methodology using a two-team approach. The development team outlined proposed features and coded the software. The advisory team guided developers and evaluated Dextr's performance on precision, recall, and extraction time by comparing a manual extraction workflow to a semi-automated extraction workflow using a dataset of 51 environmental health animal studies.The semi-automated workflow did not appear to affect precision rate (96.0% vs. 95.4% manual, p = 0.38), resulted in a small reduction in recall rate (91.8% vs. 97.0% manual, p < 0.01), and substantially reduced the median extraction time (436 s vs. 933 s per study manual, p < 0.01) compared to a manual workflow.Dextr provides similar performance to manual extraction in terms of recall and precision and greatly reduces data extraction time. Unlike other tools, Dextr provides the ability to extract complex concepts (e.g., multiple experiments with various exposures and doses within a single study), properly connect the extracted elements within a study, and effectively limit the work required by researchers to generate machine-readable, annotated exports. The Dextr tool addresses data-extraction challenges associated with environmental health sciences literature with a simple user interface, incorporates the key capabilities of user verification and entity connecting, provides a platform for further automation developments, and has the potential to improve data extraction for literature reviews in this and other fields. contexts, where two pieces of context are given on column headers. The 1×1 contexts were present in 57% of tables (99/174), compared to 20% (34/174) for 2×1 contexts and 15% (26/174) for 1×2 contexts; the remaining 8% (15/174) used unique/other stratification methods. Statistic formats were reported in the headers or descriptions of 84% (65/74) of studies.In this cross-sectional pilot review, we found a high density of information in tables, but with major heterogeneity in presentation of measurement context. The highest-density studies reported both baseline and outcome measures in tables, with arm-level breakout, intervention labels, and arm sizes present, and reported both the statistic formats and units. The measurement context formats presented here, broadly classified into three classes that cover 92% (71/78) of studies, form a basis for understanding the frequency of different reporting styles, supporting automated detection of the data format for extraction of metrics. meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews. to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2022
DA  - 2022-01-01
JO  - {'id': 'https://openalex.org/S143381477', 'issn_l': '0160-4120', 'issn': ['0160-4120', '1873-6750'], 'display_name': 'Environment International', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'https://doi.org/10.1016/j.envint.2021.107025', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc-nd'}
DP  - OpenAlex
AU  - Vickie R. Walker
AU  - Charles B. Schmitt
AU  - Mary Leigh Wolfe
AU  - Artur Nowak
AU  - Kuba Kulesza
AU  - Ashley J. Williams
AU  - Rob Shin
AU  - Jonathan D. Cohen
AU  - Dave Burch
AU  - Matthew D. Stout
AU  - Kelly A. Shipkowski
AU  - Andrew A. Rooney
ER  - 

643.
TY  - journal-article
ID  - https://openalex.org/W4293168746
DO  - https://doi.org/10.1021/acs.jcim.1c01079
TI  - Prior Knowledge for Predictive Modeling: The Case of Acute Aquatic Toxicity
AB  - Early assessment of the potential impact of chemicals on health and the environment requires toxicological properties of the molecules. Predictive modeling is often used to estimate the property values in silico from pre-existing experimental data, which is often scarce and uncertain. One of the ways to advance the predictive modeling procedure might be the use of knowledge existing in the field. Scientific publications contain a vast amount of knowledge. However, the amount of manual work required to process the enormous volumes of information gathered in scientific articles might hinder its utilization. This work explores the opportunity of semiautomated knowledge extraction from scientific papers and investigates a few potential ways of its use for predictive modeling. The knowledge extraction and predictive modeling are applied to the field of acute aquatic toxicity. Acute aquatic toxicity is an important parameter of the safety assessment of chemicals. The extensive amount of diverse information existing in the field makes acute aquatic toxicity an attractive area for investigation of knowledge use for predictive modeling. The work demonstrates that the knowledge collection and classification procedure could be useful in hybrid modeling studies concerning the model and predictor selection, addressing data gaps, and evaluation of models' performance. to manual extraction in terms of recall and precision and greatly reduces data extraction time. Unlike other tools, Dextr provides the ability to extract complex concepts (e.g., multiple experiments with various exposures and doses within a single study), properly connect the extracted elements within a study, and effectively limit the work required by researchers to generate machine-readable, annotated exports. The Dextr tool addresses data-extraction challenges associated with environmental health sciences literature with a simple user interface, incorporates the key capabilities of user verification and entity connecting, provides a platform for further automation developments, and has the potential to improve data extraction for literature reviews in this and other fields. contexts, where two pieces of context are given on column headers. The 1×1 contexts were present in 57% of tables (99/174), compared to 20% (34/174) for 2×1 contexts and 15% (26/174) for 1×2 contexts; the remaining 8% (15/174) used unique/other stratification methods. Statistic formats were reported in the headers or descriptions of 84% (65/74) of studies.In this cross-sectional pilot review, we found a high density of information in tables, but with major heterogeneity in presentation of measurement context. The highest-density studies reported both baseline and outcome measures in tables, with arm-level breakout, intervention labels, and arm sizes present, and reported both the statistic formats and units. The measurement context formats presented here, broadly classified into three classes that cover 92% (71/78) of studies, form a basis for understanding the frequency of different reporting styles, supporting automated detection of the data format for extraction of metrics. meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews. to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2022
DA  - 2022-09-12
JO  - {'id': 'https://openalex.org/S167262187', 'issn_l': '1549-9596', 'issn': ['1549-960X', '1549-9596'], 'display_name': 'Journal of Chemical Information and Modeling', 'publisher': 'American Chemical Society', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Gulnara Shavalieva
AU  - Stavros Papadokonstantakis
AU  - Gregory Peters
ER  - 

644.
TY  - posted-content
ID  - https://openalex.org/W2466116446
DO  - nan
TI  - A Novel Framework to Expedite Systematic Reviews by Automatically Building Information Extraction Training Corpora.
AB  - A systematic review identifies and collates various clinical studies and compares data elements and results in order to provide an evidence based answer for a particular clinical question. The process is manual and involves lot of time. A tool to automate this process is lacking. The aim of this work is to develop a framework using natural language processing and machine learning to build information extraction algorithms to identify data elements in a new primary publication, without having to go through the expensive task of manual annotation to build gold standards for each data element type. The system is developed in two stages. Initially, it uses information contained in existing systematic reviews to identify the sentences from the PDF files of the included references that contain specific data elements of interest using a modified Jaccard similarity measure. These sentences have been treated as labeled data.A Support Vector Machine (SVM) classifier is trained on this labeled data to extract data elements of interests from a new article. We conducted experiments on Cochrane Database systematic reviews related to congestive heart failure using inclusion criteria as an example data element. The empirical results show that the proposed system automatically identifies sentences containing the data element of interest with a high recall (93.75%) and reasonable precision (27.05% - which means the reviewers have to read only 3.7 sentences on average). The empirical results suggest that the tool is retrieving valuable information from the reference articles, even when it is time-consuming to identify them manually. Thus we hope that the tool will be useful for automatic data extraction from biomedical research publications. The future scope of this work is to generalize this information framework for all types of systematic reviews. provides a platform for further automation developments, and has the potential to improve data extraction for literature reviews in this and other fields. contexts, where two pieces of context are given on column headers. The 1×1 contexts were present in 57% of tables (99/174), compared to 20% (34/174) for 2×1 contexts and 15% (26/174) for 1×2 contexts; the remaining 8% (15/174) used unique/other stratification methods. Statistic formats were reported in the headers or descriptions of 84% (65/74) of studies.In this cross-sectional pilot review, we found a high density of information in tables, but with major heterogeneity in presentation of measurement context. The highest-density studies reported both baseline and outcome measures in tables, with arm-level breakout, intervention labels, and arm sizes present, and reported both the statistic formats and units. The measurement context formats presented here, broadly classified into three classes that cover 92% (71/78) of studies, form a basis for understanding the frequency of different reporting styles, supporting automated detection of the data format for extraction of metrics. meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews. to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2016
DA  - 2016-06-21
JO  - {'id': 'https://openalex.org/S2597136632', 'issn_l': None, 'issn': None, 'display_name': 'arXiv: Information Retrieval', 'publisher': None, 'type': 'journal', 'url': 'https://arxiv.org/pdf/1606.06424.pdf', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Tanmay Basu
AU  - Shraman Kumar
AU  - Abhishek Kalyan
AU  - Pawan Kumar Jayaswal
AU  - Pawan Goyal
AU  - Stephen Pettifer
AU  - Siddhartha Jonnalagadda
ER  - 

645.
TY  - book-chapter
ID  - https://openalex.org/W2804869627
DO  - https://doi.org/10.1007/978-3-319-91800-6_7
TI  - Designing “Living” Evidence Networks for Health Optimisation: Knowledge Extraction of Patient-Relevant Outcomes in Mental Disorders
AB  - No Abstract Found
PY  - 2018
DA  - 2018-06-03
JO  - {'id': 'https://openalex.org/S4306463941', 'issn_l': None, 'issn': None, 'display_name': 'Springer International Publishing eBooks', 'publisher': 'Springer Nature', 'type': 'ebook platform', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Hoang Nguyen
AU  - Øystein Eiring
AU  - Danny C. C. Poo
ER  - 

646.
TY  - journal-article
ID  - https://openalex.org/W2902240663
DO  - nan
TI  - Comparison of Changes in the Number of Included Patients Between Interventional Trials and Observational Studies Published from 1995 to 2014 in Three Leading Journals.
AB  - Since the late 1990s, research and administrative institutions have been developing health data warehouses and increasingly reusing claims data. The impact of these changes is not yet completely quantified. Our objective was to compare the change in the number of patients included per study between observational and interventional studies over a 20-year period starting in 1995.We extracted all abstracts from studies published in three leading medical journals over the period 1995-2014 (18,107 studies). Then, we divided our study into two steps. First, we constructed an SVM-based predictive model to categorize each abstract into "observational", "interventional" or "other" studies. In a second step, we built an algorithm based on regular expressions to automatically extract the number of included patients.During the investigated period, the median number of enrolled patients per study increased for interventional studies, from 282 in 1995-1999 to 629 in 2010-2014. In the same time, the median number of patients increased more for observational studies, from 368 in 1995-1999 to 2078 in 2010-2014.The routine storage of an increasing amount of data (from data warehouses or claims data) has had an impact in recent years on the number of patients included in observational studies. The recent development of "randomized registry trials" combining, on the one hand, an intervention and, on the other hand, the identification of the outcome through data reuse, may also have an impact, over the next decade, on the number of patients included in randomized clinical trials. reference articles, even when it is time-consuming to identify them manually. Thus we hope that the tool will be useful for automatic data extraction from biomedical research publications. The future scope of this work is to generalize this information framework for all types of systematic reviews. provides a platform for further automation developments, and has the potential to improve data extraction for literature reviews in this and other fields. contexts, where two pieces of context are given on column headers. The 1×1 contexts were present in 57% of tables (99/174), compared to 20% (34/174) for 2×1 contexts and 15% (26/174) for 1×2 contexts; the remaining 8% (15/174) used unique/other stratification methods. Statistic formats were reported in the headers or descriptions of 84% (65/74) of studies.In this cross-sectional pilot review, we found a high density of information in tables, but with major heterogeneity in presentation of measurement context. The highest-density studies reported both baseline and outcome measures in tables, with arm-level breakout, intervention labels, and arm sizes present, and reported both the statistic formats and units. The measurement context formats presented here, broadly classified into three classes that cover 92% (71/78) of studies, form a basis for understanding the frequency of different reporting styles, supporting automated detection of the data format for extraction of metrics. meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews. to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2018
DA  - 2018-01-01
JO  - {'id': 'https://openalex.org/S4210179765', 'issn_l': '0926-9630', 'issn': ['1879-8365', '0926-9630'], 'display_name': 'Studies in health technology and informatics', 'publisher': 'IOS Press', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Arnaud Dezetree
AU  - Emmanuel Chazard
AU  - Daniel R. Schlegel
AU  - Sylvester Sakilay
AU  - Peter L. Elkin
AU  - Grégoire Ficheur
ER  - 

647.
TY  - proceedings-article
ID  - https://openalex.org/W2962722156
DO  - https://doi.org/10.18653/v1/w18-5609
TI  - Unsupervised Identification of Study Descriptors in Toxicology Research: An Experimental Study
AB  - Identifying and extracting data elements such as study descriptors in publication full texts is a critical yet manual and labor-intensive step required in a number of tasks. In this paper we address the question of identifying data elements in an unsupervised manner. Specifically, provided a set of criteria describing specific study parameters, such as species, route of administration, and dosing regimen, we develop an unsupervised approach to identify text segments (sentences) relevant to the criteria. A binary classifier trained to identify publications that met the criteria performs better when trained on the candidate sentences than when trained on sentences randomly picked from the text, supporting the intuition that our method is able to accurately identify study descriptors. patients.During the investigated period, the median number of enrolled patients per study increased for interventional studies, from 282 in 1995-1999 to 629 in 2010-2014. In the same time, the median number of patients increased more for observational studies, from 368 in 1995-1999 to 2078 in 2010-2014.The routine storage of an increasing amount of data (from data warehouses or claims data) has had an impact in recent years on the number of patients included in observational studies. The recent development of "randomized registry trials" combining, on the one hand, an intervention and, on the other hand, the identification of the outcome through data reuse, may also have an impact, over the next decade, on the number of patients included in randomized clinical trials. reference articles, even when it is time-consuming to identify them manually. Thus we hope that the tool will be useful for automatic data extraction from biomedical research publications. The future scope of this work is to generalize this information framework for all types of systematic reviews. provides a platform for further automation developments, and has the potential to improve data extraction for literature reviews in this and other fields. contexts, where two pieces of context are given on column headers. The 1×1 contexts were present in 57% of tables (99/174), compared to 20% (34/174) for 2×1 contexts and 15% (26/174) for 1×2 contexts; the remaining 8% (15/174) used unique/other stratification methods. Statistic formats were reported in the headers or descriptions of 84% (65/74) of studies.In this cross-sectional pilot review, we found a high density of information in tables, but with major heterogeneity in presentation of measurement context. The highest-density studies reported both baseline and outcome measures in tables, with arm-level breakout, intervention labels, and arm sizes present, and reported both the statistic formats and units. The measurement context formats presented here, broadly classified into three classes that cover 92% (71/78) of studies, form a basis for understanding the frequency of different reporting styles, supporting automated detection of the data format for extraction of metrics. meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews. to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2018
DA  - 2018-10-01
JO  - {'id': 'https://openalex.org/S4306418267', 'issn_l': None, 'issn': None, 'display_name': 'Empirical Methods in Natural Language Processing', 'publisher': None, 'type': 'conference', 'url': 'https://www.aclweb.org/anthology/W18-5609.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Drahomira Herrmannova
AU  - Steven L. Young
AU  - Robert M. Patton
AU  - Christopher C. Stahl
AU  - Nicole Kleinstreuer
AU  - Mary Leigh Wolfe
ER  - 

648.
TY  - journal-article
ID  - https://openalex.org/W3136759842
DO  - https://doi.org/10.3390/info12040139
TI  - A Sentence Classification Framework to Identify Geometric Errors in Radiation Therapy from Relevant Literature
AB  - The objective of systematic reviews is to address a research question by summarizing relevant studies following a detailed, comprehensive, and transparent plan and search protocol to reduce bias. Systematic reviews are very useful in the biomedical and healthcare domain; however, the data extraction phase of the systematic review process necessitates substantive expertise and is labour-intensive and time-consuming. The aim of this work is to partially automate the process of building systematic radiotherapy treatment literature reviews by summarizing the required data elements of geometric errors of radiotherapy from relevant literature using machine learning and natural language processing (NLP) approaches. A framework is developed in this study that initially builds a training corpus by extracting sentences containing different types of geometric errors of radiotherapy from relevant publications. The publications are retrieved from PubMed following a given set of rules defined by a domain expert. Subsequently, the method develops a training corpus by extracting relevant sentences using a sentence similarity measure. A support vector machine (SVM) classifier is then trained on this training corpus to extract the sentences from new publications which contain relevant geometric errors. To demonstrate the proposed approach, we have used 60 publications containing geometric errors in radiotherapy to automatically extract the sentences stating the mean and standard deviation of different types of errors between planned and executed radiotherapy. The experimental results show that the recall and precision of the proposed framework are, respectively, 97% and 72%. The results clearly show that the framework is able to extract almost all sentences containing required data of geometric errors. be useful for automatic data extraction from biomedical research publications. The future scope of this work is to generalize this information framework for all types of systematic reviews. provides a platform for further automation developments, and has the potential to improve data extraction for literature reviews in this and other fields. contexts, where two pieces of context are given on column headers. The 1×1 contexts were present in 57% of tables (99/174), compared to 20% (34/174) for 2×1 contexts and 15% (26/174) for 1×2 contexts; the remaining 8% (15/174) used unique/other stratification methods. Statistic formats were reported in the headers or descriptions of 84% (65/74) of studies.In this cross-sectional pilot review, we found a high density of information in tables, but with major heterogeneity in presentation of measurement context. The highest-density studies reported both baseline and outcome measures in tables, with arm-level breakout, intervention labels, and arm sizes present, and reported both the statistic formats and units. The measurement context formats presented here, broadly classified into three classes that cover 92% (71/78) of studies, form a basis for understanding the frequency of different reporting styles, supporting automated detection of the data format for extraction of metrics. meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews. to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2021
DA  - 2021-03-24
JO  - {'id': 'https://openalex.org/S4210219776', 'issn_l': '2078-2489', 'issn': ['2078-2489'], 'display_name': 'Information', 'publisher': 'MDPI', 'type': 'journal', 'url': 'https://www.mdpi.com/2078-2489/12/4/139/pdf?version=1616590571', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Tanmay Basu
AU  - Simon D. Goldsworthy
AU  - Georgios V. Gkoutos
ER  - 

649.
TY  - journal-article
ID  - https://openalex.org/W3164676482
DO  - https://doi.org/10.1186/s12874-021-01354-2
TI  - Creating efficiencies in the extraction of data from randomized trials: a prospective evaluation of a machine learning and text mining tool
AB  - Abstract Background Machine learning tools that semi-automate data extraction may create efficiencies in systematic review production. We evaluated a machine learning and text mining tool’s ability to (a) automatically extract data elements from randomized trials, and (b) save time compared with manual extraction and verification. Methods For 75 randomized trials, we manually extracted and verified data for 21 data elements. We uploaded the randomized trials to an online machine learning and text mining tool, and quantified performance by evaluating its ability to identify the reporting of data elements (reported or not reported), and the relevance of the extracted sentences, fragments, and overall solutions. For each randomized trial, we measured the time to complete manual extraction and verification, and to review and amend the data extracted by the tool. We calculated the median (interquartile range [IQR]) time for manual and semi-automated data extraction, and overall time savings. Results The tool identified the reporting (reported or not reported) of data elements with median (IQR) 91% (75% to 99%) accuracy. Among the top five sentences for each data element at least one sentence was relevant in a median (IQR) 88% (83% to 99%) of cases. Among a median (IQR) 90% (86% to 97%) of relevant sentences, pertinent fragments had been highlighted by the tool; exact matches were unreliable (median (IQR) 52% [33% to 73%]). A median 48% of solutions were fully correct, but performance varied greatly across data elements (IQR 21% to 71%). Using ExaCT to assist the first reviewer resulted in a modest time savings compared with manual extraction by a single reviewer (17.9 vs. 21.6 h total extraction time across 75 randomized trials). Conclusions Using ExaCT to assist with data extraction resulted in modest gains in efficiency compared with manual extraction. The tool was reliable for identifying the reporting of most data elements. The tool’s ability to identify at least one relevant sentence and highlight pertinent fragments was generally good, but changes to sentence selection and/or highlighting were often required. Protocol https://doi.org/10.7939/DVN/RQPJKS 20% (34/174) for 2×1 contexts and 15% (26/174) for 1×2 contexts; the remaining 8% (15/174) used unique/other stratification methods. Statistic formats were reported in the headers or descriptions of 84% (65/74) of studies.In this cross-sectional pilot review, we found a high density of information in tables, but with major heterogeneity in presentation of measurement context. The highest-density studies reported both baseline and outcome measures in tables, with arm-level breakout, intervention labels, and arm sizes present, and reported both the statistic formats and units. The measurement context formats presented here, broadly classified into three classes that cover 92% (71/78) of studies, form a basis for understanding the frequency of different reporting styles, supporting automated detection of the data format for extraction of metrics. meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews. to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2021
DA  - 2021-08-16
JO  - {'id': 'https://openalex.org/S185874209', 'issn_l': '1471-2288', 'issn': ['1471-2288'], 'display_name': 'BMC Medical Research Methodology', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://bmcmedresmethodol.biomedcentral.com/track/pdf/10.1186/s12874-021-01354-2', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Allison Gates
AU  - Michelle Gates
AU  - Shannon Sim
AU  - Sarah A. Elliott
AU  - Jennifer Pillay
AU  - Lisa Hartling
ER  - 

650.
TY  - book-chapter
ID  - https://openalex.org/W3170008619
DO  - https://doi.org/10.1007/978-3-030-77417-2_17
TI  - A Roadmap for Composing Automatic Literature Reviews: A Text Mining Approach
AB  - Due to accelerated growth in the number of scientific papers, writing literature reviews has become an increasingly costly activity. Therefore, the search for computational tools to assist in this process has been gaining ground in recent years. This work presents an overview of the current scenario of development of artificial intelligence tools aimed to assist in the production of systematic literature reviews. The process of creating a literature review is both creative and technical. The technical part of this process is liable to automation. For the purpose of organization, we divide this technical part into four steps: searching, screening, extraction, and synthesis. For each of these steps, we present artificial intelligence techniques that can be useful to its realization. In addition, we also present the obstacles encountered for the application of each technique. Finally, we propose a pipeline for the automatic creation of systematic literature reviews, by combining and placing existing techniques in stages where they possess the greatest potential to be useful.KeywordsSystematic reviewText miningAutomation 99%) accuracy. Among the top five sentences for each data element at least one sentence was relevant in a median (IQR) 88% (83% to 99%) of cases. Among a median (IQR) 90% (86% to 97%) of relevant sentences, pertinent fragments had been highlighted by the tool; exact matches were unreliable (median (IQR) 52% [33% to 73%]). A median 48% of solutions were fully correct, but performance varied greatly across data elements (IQR 21% to 71%). Using ExaCT to assist the first reviewer resulted in a modest time savings compared with manual extraction by a single reviewer (17.9 vs. 21.6 h total extraction time across 75 randomized trials). Conclusions Using ExaCT to assist with data extraction resulted in modest gains in efficiency compared with manual extraction. The tool was reliable for identifying the reporting of most data elements. The tool’s ability to identify at least one relevant sentence and highlight pertinent fragments was generally good, but changes to sentence selection and/or highlighting were often required. Protocol https://doi.org/10.7939/DVN/RQPJKS 20% (34/174) for 2×1 contexts and 15% (26/174) for 1×2 contexts; the remaining 8% (15/174) used unique/other stratification methods. Statistic formats were reported in the headers or descriptions of 84% (65/74) of studies.In this cross-sectional pilot review, we found a high density of information in tables, but with major heterogeneity in presentation of measurement context. The highest-density studies reported both baseline and outcome measures in tables, with arm-level breakout, intervention labels, and arm sizes present, and reported both the statistic formats and units. The measurement context formats presented here, broadly classified into three classes that cover 92% (71/78) of studies, form a basis for understanding the frequency of different reporting styles, supporting automated detection of the data format for extraction of metrics. meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews. to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2021
DA  - 2021-03-10
JO  - {'id': 'https://openalex.org/V4210216221', 'issn_l': '1867-8211', 'issn': ['1867-8211', '1867-822X'], 'display_name': 'Lecture notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Eugênio Monteiro da Silva Júnior
AU  - Moisés Lima Dutra
ER  - 

651.
TY  - posted-content
ID  - https://openalex.org/W3176001288
DO  - nan
TI  - Machine Reading of Hypotheses for Organizational Research Reviews and Pre-trained Models via R Shiny App for Non-Programmers.
AB  - The volume of scientific publications in organizational research becomes exceedingly overwhelming for human researchers who seek to timely extract and review knowledge. This paper introduces natural language processing (NLP) models to accelerate the discovery, extraction, and organization of theoretical developments (i.e., hypotheses) from social science publications. We illustrate and evaluate NLP models in the context of a systematic review of stakeholder value constructs and hypotheses. Specifically, we develop NLP models to automatically 1) detect sentences in scholarly documents as hypotheses or not (Hypothesis Detection), 2) deconstruct the hypotheses into nodes (constructs) and links (causal/associative relationships) (Relationship Deconstruction ), and 3) classify the features of links in terms causality (versus association) and direction (positive, negative, versus nonlinear) (Feature Classification). Our models have reported high performance metrics for all three tasks. While our models are built in Python, we have made the pre-trained models fully accessible for non-programmers. We have provided instructions on installing and using our pre-trained models via an R Shiny app graphic user interface (GUI). Finally, we suggest the next paths to extend our methodology for computer-assisted knowledge synthesis. was relevant in a median (IQR) 88% (83% to 99%) of cases. Among a median (IQR) 90% (86% to 97%) of relevant sentences, pertinent fragments had been highlighted by the tool; exact matches were unreliable (median (IQR) 52% [33% to 73%]). A median 48% of solutions were fully correct, but performance varied greatly across data elements (IQR 21% to 71%). Using ExaCT to assist the first reviewer resulted in a modest time savings compared with manual extraction by a single reviewer (17.9 vs. 21.6 h total extraction time across 75 randomized trials). Conclusions Using ExaCT to assist with data extraction resulted in modest gains in efficiency compared with manual extraction. The tool was reliable for identifying the reporting of most data elements. The tool’s ability to identify at least one relevant sentence and highlight pertinent fragments was generally good, but changes to sentence selection and/or highlighting were often required. Protocol https://doi.org/10.7939/DVN/RQPJKS 20% (34/174) for 2×1 contexts and 15% (26/174) for 1×2 contexts; the remaining 8% (15/174) used unique/other stratification methods. Statistic formats were reported in the headers or descriptions of 84% (65/74) of studies.In this cross-sectional pilot review, we found a high density of information in tables, but with major heterogeneity in presentation of measurement context. The highest-density studies reported both baseline and outcome measures in tables, with arm-level breakout, intervention labels, and arm sizes present, and reported both the statistic formats and units. The measurement context formats presented here, broadly classified into three classes that cover 92% (71/78) of studies, form a basis for understanding the frequency of different reporting styles, supporting automated detection of the data format for extraction of metrics. meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews. to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2021
DA  - 2021-06-30
JO  - {'id': 'https://openalex.org/S2597136632', 'issn_l': None, 'issn': None, 'display_name': 'arXiv: Information Retrieval', 'publisher': None, 'type': 'journal', 'url': 'https://arxiv.org/pdf/2106.16102', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Victor Zitian Chen
AU  - Felipe Montano-Campos
AU  - Wlodek Zadrozny
AU  - E. Canfield
ER  - 

652.
TY  - journal-article
ID  - https://openalex.org/W3184058630
DO  - https://doi.org/10.47909/ijsmc.52
TI  - A roadmap toward the automatic composition of systematic literature reviews
AB  - Objective. This paper presents an overview of existing artificial intelligence tools to produce systematic literature reviews. Furthermore, we propose a general framework resulting from combining these techniques to highlight the challenges and possibilities currently existing in this research area. Design/Methodology/Approach. We undertook a scoping review on the systematic literature review steps to automate them via computational techniques. Results/Discussion. The process of creating a literature review is both creative and technical. The technical part of this process is liable to automation. Based on the literature, we chose to divide this technical part into four steps: searching, screening, extraction, and synthesis. For each one of these steps, we presented practical artificial intelligence techniques to carry them out. In addition, we presented the obstacles encountered in the application of each technique. Conclusion. We proposed a framework for automatically creating systematic literature reviews by combining and placing existing techniques in stages where they possess the greatest potential to be useful. Despite still lacking practical assessment in different areas of knowledge, this proposal indicates ways with the potential to reduce the time-consuming and repetitive work embedded in the systematic literature review process. Originality/Value. The paper presents the current possibilities for automating systematic literature reviews and how they can work together to reduce researchers’ operational workload. tool; exact matches were unreliable (median (IQR) 52% [33% to 73%]). A median 48% of solutions were fully correct, but performance varied greatly across data elements (IQR 21% to 71%). Using ExaCT to assist the first reviewer resulted in a modest time savings compared with manual extraction by a single reviewer (17.9 vs. 21.6 h total extraction time across 75 randomized trials). Conclusions Using ExaCT to assist with data extraction resulted in modest gains in efficiency compared with manual extraction. The tool was reliable for identifying the reporting of most data elements. The tool’s ability to identify at least one relevant sentence and highlight pertinent fragments was generally good, but changes to sentence selection and/or highlighting were often required. Protocol https://doi.org/10.7939/DVN/RQPJKS 20% (34/174) for 2×1 contexts and 15% (26/174) for 1×2 contexts; the remaining 8% (15/174) used unique/other stratification methods. Statistic formats were reported in the headers or descriptions of 84% (65/74) of studies.In this cross-sectional pilot review, we found a high density of information in tables, but with major heterogeneity in presentation of measurement context. The highest-density studies reported both baseline and outcome measures in tables, with arm-level breakout, intervention labels, and arm sizes present, and reported both the statistic formats and units. The measurement context formats presented here, broadly classified into three classes that cover 92% (71/78) of studies, form a basis for understanding the frequency of different reporting styles, supporting automated detection of the data format for extraction of metrics. meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews. to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2021
DA  - 2021-07-27
JO  - {'id': 'https://openalex.org/V4210199169', 'issn_l': '2709-3158', 'issn': ['2709-7595', '2709-3158'], 'display_name': 'Iberoamerican journal of science measurement and communication', 'publisher': 'ColNes', 'type': 'journal', 'url': 'https://pub.colnes.org/index.php/ijsmc/article/download/52/88', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc'}
DP  - OpenAlex
AU  - Eugênio Monteiro da Silva Júnior
AU  - Moisés Lima Dutra
ER  - 

653.
TY  - journal-article
ID  - https://openalex.org/W4225297356
DO  - https://doi.org/10.2196/33219
TI  - Web-Based Software Tools for Systematic Literature Review in Medicine: Systematic Search and Feature Analysis
AB  - Background Systematic reviews (SRs) are central to evaluating therapies but have high costs in terms of both time and money. Many software tools exist to assist with SRs, but most tools do not support the full process, and transparency and replicability of SR depend on performing and presenting evidence according to established best practices. Objective This study aims to provide a basis for comparing and selecting between web-based software tools that support SR, by conducting a feature-by-feature comparison of SR tools. Methods We searched for SR tools by reviewing any such tool listed in the SR Toolbox, previous reviews of SR tools, and qualitative Google searching. We included all SR tools that were currently functional and required no coding, and excluded reference managers, desktop applications, and statistical software. The list of features to assess was populated by combining all features assessed in 4 previous reviews of SR tools; we also added 5 features (manual addition, screening automation, dual extraction, living review, and public outputs) that were independently noted as best practices or enhancements of transparency and replicability. Then, 2 reviewers assigned binary present or absent assessments to all SR tools with respect to all features, and a third reviewer adjudicated all disagreements. Results Of the 53 SR tools found, 55% (29/53) were excluded, leaving 45% (24/53) for assessment. In total, 30 features were assessed across 6 classes, and the interobserver agreement was 86.46%. Giotto Compliance (27/30, 90%), DistillerSR (26/30, 87%), and Nested Knowledge (26/30, 87%) support the most features, followed by EPPI-Reviewer Web (25/30, 83%), LitStream (23/30, 77%), JBI SUMARI (21/30, 70%), and SRDB.PRO (VTS Software) (21/30, 70%). Fewer than half of all the features assessed are supported by 7 tools: RobotAnalyst (National Centre for Text Mining), SRDR (Agency for Healthcare Research and Quality), SyRF (Systematic Review Facility), Data Abstraction Assistant (Center for Evidence Synthesis in Health), SR Accelerator (Institute for Evidence-Based Healthcare), RobotReviewer (RobotReviewer), and COVID-NMA (COVID-NMA). Notably, of the 24 tools, only 10 (42%) support direct search, only 7 (29%) offer dual extraction, and only 13 (54%) offer living/updatable reviews. Conclusions DistillerSR, Nested Knowledge, and EPPI-Reviewer Web each offer a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. and outcome measures in tables, with arm-level breakout, intervention labels, and arm sizes present, and reported both the statistic formats and units. The measurement context formats presented here, broadly classified into three classes that cover 92% (71/78) of studies, form a basis for understanding the frequency of different reporting styles, supporting automated detection of the data format for extraction of metrics. meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews. to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2022
DA  - 2022-05-02
JO  - {'id': 'https://openalex.org/S2764650051', 'issn_l': '2291-9694', 'issn': ['2291-9694'], 'display_name': 'JMIR medical informatics', 'publisher': 'JMIR Publications', 'type': 'journal', 'url': 'https://medinform.jmir.org/2022/5/e33219/PDF', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Kathryn Cowie
AU  - Asad Rahmatullah
AU  - Nicole Hardy
AU  - Kevin M. Kallmes
AU  - Kevin M. Kallmes
ER  - 

654.
TY  - journal-article
ID  - https://openalex.org/W4251645445
DO  - https://doi.org/10.12688/f1000research.22781.1
TI  - Data extraction methods for systematic review (semi)automation: A living review protocol
AB  - <ns4:p><ns4:bold>Background:</ns4:bold> Researchers in evidence-based medicine cannot keep up with the amounts of both old and newly published primary research articles. Conducting and updating of systematic reviews is time-consuming. In practice, data extraction is one of the most complex tasks in this process. Exponential improvements in computational processing speed and data storage are fostering the development of data extraction models and algorithms. This, in combination with quicker pathways to publication, led to a large landscape of tools and methods for data extraction tasks.</ns4:p><ns4:p> <ns4:bold>Objective</ns4:bold>: To review published methods and tools for data extraction to (semi)automate the systematic reviewing process.</ns4:p><ns4:p> <ns4:bold>Methods</ns4:bold>: We propose to conduct a living review. With this methodology we aim to do monthly search updates, as well as bi-annual review updates if new evidence permits it. In a cross-sectional analysis we will extract methodological characteristics and assess the quality of reporting in our included papers.</ns4:p><ns4:p> <ns4:bold>Conclusions</ns4:bold>: We aim to increase transparency in the reporting and assessment of machine learning technologies to the benefit of data scientists, systematic reviewers and funders of health research. This living review will help to reduce duplicate efforts by data scientists who develop data extraction methods. It will also serve to inform systematic reviewers about possibilities to support their data extraction.</ns4:p> SR tools found, 55% (29/53) were excluded, leaving 45% (24/53) for assessment. In total, 30 features were assessed across 6 classes, and the interobserver agreement was 86.46%. Giotto Compliance (27/30, 90%), DistillerSR (26/30, 87%), and Nested Knowledge (26/30, 87%) support the most features, followed by EPPI-Reviewer Web (25/30, 83%), LitStream (23/30, 77%), JBI SUMARI (21/30, 70%), and SRDB.PRO (VTS Software) (21/30, 70%). Fewer than half of all the features assessed are supported by 7 tools: RobotAnalyst (National Centre for Text Mining), SRDR (Agency for Healthcare Research and Quality), SyRF (Systematic Review Facility), Data Abstraction Assistant (Center for Evidence Synthesis in Health), SR Accelerator (Institute for Evidence-Based Healthcare), RobotReviewer (RobotReviewer), and COVID-NMA (COVID-NMA). Notably, of the 24 tools, only 10 (42%) support direct search, only 7 (29%) offer dual extraction, and only 13 (54%) offer living/updatable reviews. Conclusions DistillerSR, Nested Knowledge, and EPPI-Reviewer Web each offer a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. and outcome measures in tables, with arm-level breakout, intervention labels, and arm sizes present, and reported both the statistic formats and units. The measurement context formats presented here, broadly classified into three classes that cover 92% (71/78) of studies, form a basis for understanding the frequency of different reporting styles, supporting automated detection of the data format for extraction of metrics. meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews. to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2020
DA  - 2020-03-25
JO  - {'id': 'https://openalex.org/S4210239046', 'issn_l': '2046-1402', 'issn': ['2046-1402'], 'display_name': 'F1000Research', 'publisher': 'Faculty of 1000', 'type': 'journal', 'url': 'https://f1000research.com/articles/9-210/v1/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Lena Schmidt
AU  - Babatunde K. Olorisade
AU  - Adrian M. Price-Whelan
AU  - Julian P T Higgins
ER  - 

655.
TY  - journal-article
ID  - https://openalex.org/W4282937925
DO  - https://doi.org/10.1093/jamia/ocac066
TI  - Automated medical literature screening using artificial intelligence: a systematic review and meta-analysis
AB  - Abstract Objective We aim to investigate the application and accuracy of artificial intelligence (AI) methods for automated medical literature screening for systematic reviews. Materials and Methods We systematically searched PubMed, Embase, and IEEE Xplore Digital Library to identify potentially relevant studies. We included studies in automated literature screening that reported study question, source of dataset, and developed algorithm models for literature screening. The literature screening results by human investigators were considered to be the reference standard. Quantitative synthesis of the accuracy was conducted using a bivariate model. Results Eighty-six studies were included in our systematic review and 17 studies were further included for meta-analysis. The combined recall, specificity, and precision were 0.928 [95% confidence interval (CI), 0.878–0.958], 0.647 (95% CI, 0.442–0.809), and 0.200 (95% CI, 0.135–0.287) when achieving maximized recall, but were 0.708 (95% CI, 0.570–0.816), 0.921 (95% CI, 0.824–0.967), and 0.461 (95% CI, 0.375–0.549) when achieving maximized precision in the AI models. No significant difference was found in recall among subgroup analyses including the algorithms, the number of screened literatures, and the fraction of included literatures. Discussion and Conclusion This systematic review and meta-analysis study showed that the recall is more important than the specificity or precision in literature screening, and a recall over 0.95 should be prioritized. We recommend to report the effectiveness indices of automatic algorithms separately. At the current stage manual literature screening is still indispensable for medical systematic reviews. Compliance (27/30, 90%), DistillerSR (26/30, 87%), and Nested Knowledge (26/30, 87%) support the most features, followed by EPPI-Reviewer Web (25/30, 83%), LitStream (23/30, 77%), JBI SUMARI (21/30, 70%), and SRDB.PRO (VTS Software) (21/30, 70%). Fewer than half of all the features assessed are supported by 7 tools: RobotAnalyst (National Centre for Text Mining), SRDR (Agency for Healthcare Research and Quality), SyRF (Systematic Review Facility), Data Abstraction Assistant (Center for Evidence Synthesis in Health), SR Accelerator (Institute for Evidence-Based Healthcare), RobotReviewer (RobotReviewer), and COVID-NMA (COVID-NMA). Notably, of the 24 tools, only 10 (42%) support direct search, only 7 (29%) offer dual extraction, and only 13 (54%) offer living/updatable reviews. Conclusions DistillerSR, Nested Knowledge, and EPPI-Reviewer Web each offer a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. and outcome measures in tables, with arm-level breakout, intervention labels, and arm sizes present, and reported both the statistic formats and units. The measurement context formats presented here, broadly classified into three classes that cover 92% (71/78) of studies, form a basis for understanding the frequency of different reporting styles, supporting automated detection of the data format for extraction of metrics. meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews. to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2022
DA  - 2022-05-31
JO  - {'id': 'https://openalex.org/V129839026', 'issn_l': '1067-5027', 'issn': ['1067-5027', '1527-974X'], 'display_name': 'Journal of the American Medical Informatics Association', 'publisher': 'Oxford University Press', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Yunying Feng
AU  - Siyu Liang
AU  - Yuelun Zhang
AU  - Shi Chen
AU  - Qing Wang
AU  - Tianze Huang
AU  - Feng Sun
AU  - Xiaoqing Liu
AU  - Huijuan Zhu
AU  - Hui Pan
ER  - 

656.
TY  - journal-article
ID  - https://openalex.org/W4283079132
DO  - https://doi.org/10.1186/s12911-022-01897-4
TI  - Automatic data extraction to support meta-analysis statistical analysis: a case study on breast cancer
AB  - Meta-analyses aggregate results of different clinical studies to assess the effectiveness of a treatment. Despite their importance, meta-analyses are time-consuming and labor-intensive as they involve reading hundreds of research articles and extracting data. The number of research articles is increasing rapidly and most meta-analyses are outdated shortly after publication as new evidence has not been included. Automatic extraction of data from research articles can expedite the meta-analysis process and allow for automatic updates when new results become available. In this study, we propose a system for automatically extracting data from research abstracts and performing statistical analysis.Our corpus consists of 1011 PubMed abstracts of breast cancer randomized controlled trials annotated with the core elements of clinical trials: Participants, Intervention, Control, and Outcomes (PICO). We proposed a BERT-based named entity recognition (NER) model to identify PICO information from research abstracts. After extracting the PICO information, we parse numeric outcomes to identify the number of patients having certain outcomes for statistical analysis.The NER model extracted PICO elements with relatively high accuracy, achieving F1-scores greater than 0.80 in most entities. We assessed the performance of the proposed system by reproducing the results of an existing meta-analysis. The data extraction step achieved high accuracy, however the statistical analysis step achieved low performance because abstracts sometimes lack all the required information.We proposed a system for automatically extracting data from research abstracts and performing statistical analysis. We evaluated the performance of the system by reproducing an existing meta-analysis and the system achieved a relatively good performance, though more substantiation is required. 83%), LitStream (23/30, 77%), JBI SUMARI (21/30, 70%), and SRDB.PRO (VTS Software) (21/30, 70%). Fewer than half of all the features assessed are supported by 7 tools: RobotAnalyst (National Centre for Text Mining), SRDR (Agency for Healthcare Research and Quality), SyRF (Systematic Review Facility), Data Abstraction Assistant (Center for Evidence Synthesis in Health), SR Accelerator (Institute for Evidence-Based Healthcare), RobotReviewer (RobotReviewer), and COVID-NMA (COVID-NMA). Notably, of the 24 tools, only 10 (42%) support direct search, only 7 (29%) offer dual extraction, and only 13 (54%) offer living/updatable reviews. Conclusions DistillerSR, Nested Knowledge, and EPPI-Reviewer Web each offer a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. and outcome measures in tables, with arm-level breakout, intervention labels, and arm sizes present, and reported both the statistic formats and units. The measurement context formats presented here, broadly classified into three classes that cover 92% (71/78) of studies, form a basis for understanding the frequency of different reporting styles, supporting automated detection of the data format for extraction of metrics. meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews. to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2022
DA  - 2022-06-18
JO  - {'id': 'https://openalex.org/S107516304', 'issn_l': '1472-6947', 'issn': ['1472-6947'], 'display_name': 'BMC Medical Informatics and Decision Making', 'publisher': 'BioMed Central', 'type': 'journal', 'url': 'https://bmcmedinformdecismak.biomedcentral.com/counter/pdf/10.1186/s12911-022-01897-4', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Faith W. Mutinda
AU  - Kongmeng Liew
AU  - Shuntaro Yada
AU  - Shoko Wakamiya
AU  - Eiji Aramaki
ER  - 

657.
TY  - journal-article
ID  - https://openalex.org/W4296930504
DO  - https://doi.org/10.3390/biomedinformatics2030032
TI  - Machine Learning Tools and Platforms in Clinical Trial Outputs to Support Evidence-Based Health Informatics: A Rapid Review of the Literature
AB  - Background: The application of machine learning (ML) tools (MLTs) to support clinical trials outputs in evidence-based health informatics can be an effective, useful, feasible, and acceptable way to advance medical research and provide precision medicine. Methods: In this study, the author used the rapid review approach and snowballing methods. The review was conducted in the following databases: PubMed, Scopus, COCHRANE LIBRARY, clinicaltrials.gov, Semantic Scholar, and the first six pages of Google Scholar from the 10 July–15 August 2022 period. Results: Here, 49 articles met the required criteria and were included in this review. Accordingly, 32 MLTs and platforms were identified in this study that applied the automatic extraction of knowledge from clinical trial outputs. Specifically, the initial use of automated tools resulted in modest to satisfactory time savings compared with the manual management. In addition, the evaluation of performance, functionality, usability, user interface, and system requirements also yielded positive results. Moreover, the evaluation of some tools in terms of acceptance, feasibility, precision, accuracy, efficiency, efficacy, and reliability was also positive. Conclusions: In summary, design based on the application of clinical trial results in ML is a promising approach to apply more reliable solutions. Future studies are needed to propose common standards for the assessment of MLTs and to clinically validate the performance in specific healthcare and technical domains. for automatically extracting data from research abstracts and performing statistical analysis. We evaluated the performance of the system by reproducing an existing meta-analysis and the system achieved a relatively good performance, though more substantiation is required. 83%), LitStream (23/30, 77%), JBI SUMARI (21/30, 70%), and SRDB.PRO (VTS Software) (21/30, 70%). Fewer than half of all the features assessed are supported by 7 tools: RobotAnalyst (National Centre for Text Mining), SRDR (Agency for Healthcare Research and Quality), SyRF (Systematic Review Facility), Data Abstraction Assistant (Center for Evidence Synthesis in Health), SR Accelerator (Institute for Evidence-Based Healthcare), RobotReviewer (RobotReviewer), and COVID-NMA (COVID-NMA). Notably, of the 24 tools, only 10 (42%) support direct search, only 7 (29%) offer dual extraction, and only 13 (54%) offer living/updatable reviews. Conclusions DistillerSR, Nested Knowledge, and EPPI-Reviewer Web each offer a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. and outcome measures in tables, with arm-level breakout, intervention labels, and arm sizes present, and reported both the statistic formats and units. The measurement context formats presented here, broadly classified into three classes that cover 92% (71/78) of studies, form a basis for understanding the frequency of different reporting styles, supporting automated detection of the data format for extraction of metrics. meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews. to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2022
DA  - 2022-09-14
JO  - {'id': 'https://openalex.org/S4210213753', 'issn_l': '2673-7426', 'issn': ['2673-7426'], 'display_name': 'BioMedInformatics', 'publisher': 'MDPI AG', 'type': 'journal', 'url': 'https://www.mdpi.com/2673-7426/2/3/32/pdf?version=1663163045', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Stella C. Christopoulou
ER  - 

658.
TY  - posted-content
ID  - https://openalex.org/W2515474772
DO  - nan
TI  - CRTS: A type system for representing clinical recommendations
AB  - Background: Clinical guidelines and recommendations are the driving wheels of the evidence-based medicine (EBM) paradigm, but these are available primarily as unstructured text and are generally highly heterogeneous in nature. This significantly reduces the dissemination and automatic application of these recommendations at the point of care. A comprehensive structured representation of these recommendations is highly beneficial in this regard. Objective: The objective of this paper to present Clinical Recommendation Type System (CRTS), a common type system that can effectively represent a clinical recommendation in a structured form. Methods: CRTS is built by analyzing 125 recommendations and 195 research articles corresponding to 6 different diseases available from UpToDate, a publicly available clinical knowledge system, and from the National Guideline Clearinghouse, a public resource for evidence-based clinical practice guidelines. Results: We show that CRTS not only covers the recommendations but also is flexible to be extended to represent information from primary literature. We also describe how our developed type system can be applied for clinical decision support, medical knowledge summarization, and citation retrieval. Conclusion: We showed that our proposed type system is precise and comprehensive in representing a large sample of recommendations available for various disorders. CRTS can now be used to build interoperable information extraction systems that automatically extract clinical recommendations and related data elements from clinical evidence resources, guidelines, systematic reviews and primary publications. 
Keywords: guidelines and recommendations, type system, clinical decision support, evidence-based medicine, information storage and retrieval existing meta-analysis and the system achieved a relatively good performance, though more substantiation is required. 83%), LitStream (23/30, 77%), JBI SUMARI (21/30, 70%), and SRDB.PRO (VTS Software) (21/30, 70%). Fewer than half of all the features assessed are supported by 7 tools: RobotAnalyst (National Centre for Text Mining), SRDR (Agency for Healthcare Research and Quality), SyRF (Systematic Review Facility), Data Abstraction Assistant (Center for Evidence Synthesis in Health), SR Accelerator (Institute for Evidence-Based Healthcare), RobotReviewer (RobotReviewer), and COVID-NMA (COVID-NMA). Notably, of the 24 tools, only 10 (42%) support direct search, only 7 (29%) offer dual extraction, and only 13 (54%) offer living/updatable reviews. Conclusions DistillerSR, Nested Knowledge, and EPPI-Reviewer Web each offer a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. and outcome measures in tables, with arm-level breakout, intervention labels, and arm sizes present, and reported both the statistic formats and units. The measurement context formats presented here, broadly classified into three classes that cover 92% (71/78) of studies, form a basis for understanding the frequency of different reporting styles, supporting automated detection of the data format for extraction of metrics. meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews. to facilitate study replication for evidence strengthening. In general, the reader often gets the impression that text mining algorithms were applied as magic tools in the reviewed papers, relying on default settings or default optimization of available machine learning toolboxes without an in-depth understanding of the statistical validity and appropriateness of such tools for text mining purposes.
PY  - 2016
DA  - 2016-09-06
JO  - {'id': 'https://openalex.org/V2596401190', 'issn_l': None, 'issn': None, 'display_name': 'arXiv: Computation and Language', 'publisher': None, 'type': 'journal', 'url': 'https://arxiv.org/pdf/1609.01592.pdf', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Ravi Garg
AU  - Kalpana Raja
AU  - Siddhartha Jonnalagadda
ER  - 

659.
TY  - dissertation
ID  - https://openalex.org/W2603784858
DO  - https://doi.org/10.14264/uql.2017.167
TI  - A framework for developing knowledge bases of scientific artefacts in the biomedical domain
AB  - The volume of scientific papers published annually in the biomedical domain is continuously increasing. Streamlining the process of identifying the most critical and significant nuggets of information (such as hypotheses, observations, interventions, findings) in a given research publication is a challenging but worthwhile task. This essential information, known as scientific artefacts, underpins the knowledge used by many health professionals in the decision-making process or researchers in creating systematic reviews; however most of today’s search engines are unable to identify these artefacts. Evidence Based Medicine (EBM) represents a framework that encompasses decision-making in the healthcare domain, based on providing medical practitioners with the best available evidence so they can choose the optimum treatment for individual patients. In order to provide patients with the best treatment, health professionals need access to current, timely and reliable evidence retrieved from relevant published medical research or previously synthesised evidence. Hence, devising mechanisms that can automatically identify, retrieve, consolidate and present scientific artefacts, based on a given query, has the potential to greatly facilitate collating related evidence and ultimately streamline medical decision-making. This thesis represents an attempt to define a comprehensive framework for acquiring and managing scientific artefacts in the EBM domain – by transforming unstructured publications into structured, consolidated, pertinent knowledge. There have been previous attempts to model such information (e.g., supporting and contradicting statements), however these approaches have primarily focused on providing users with conceptual high-level frameworks and associated manual annotation services. The approach proposed in this thesis employs novel, sets of low-level features to uniquely identify key scientific information in EBM, and enable knowledge extraction and retrieval. This will also lead to automatic creation of networks of scientific artefacts, and eventually the detection of effects across diverse artefacts (i.e., new potential drug treatments). This goal will be attained by firstly modelling and extracting scientific artefacts from publications (more specifically, abstracts) and then consolidating and linking them using Linked Data approaches. The first step for pinpointing the best evidence in the published research is to formulate clinical queries and their answers. Hence, a comprehensive and fine-grained model is essential to formulate key factors of evidence-based decision making according to various medical cases. The Problem/Population, Intervention, Comparison, and Outcome (PICO) framework is a specialised model to frame and answer a clinical or health care related question. An extension of PICO formalises this fundamental information by classifying it into six classes: Population, Intervention, Background, Outcome, Study Design, and Other (called the PIBOSO model). The PIBOSO model has been used as the underlying model throughout this thesis for defining the scientific artefacts in publications. Once modelled, the challenge then shifts towards automatically recognising such scientific artefacts within a published abstract and detecting similar occurrences across multiple abstracts. Machine Learning techniques have been widely applied in this context, especially since the recognition task can be formulated as a sentence classification task, and therefore can be addressed using classification techniques. This thesis presents a scientific artefact classifier that is trained on a novel set of discriminative features. The results indicate that this approach represents a marked improvement compared to the state of the art. In order to be able to find those related scientific artefacts (or evidence) extracted from a large number of published abstracts and then consolidate those that are conceptually similar, this thesis proposes an improved semantic similarity quantification approach. A unique set of similarity measures, which examines similarity of sentences from different syntactic, structural, and semantic features, is presented and then used to train an ensemble regressor. This ensemble can accurately predict the semantic similarity of both generic and domain-specific English sentences. The quantified similarities of scientific artefacts are then employed to consolidate and link those that are highly similar. The resulting Knowledge Base comprises a network of semantically related scientific artefacts, abstracts and publications. The holistic framework described in this thesis, has the potential to transform large corpuses of unstructured text into an enriched, consolidated and linked network of scientific artefacts. The resulting Knowledge Base (which will evolve, improve and expand over time) enables one to quickly gain a broad and deep understanding of the current state of evidence (PIBOSO scientific artefacts) related to a medical topic.
PY  - 2017
DA  - 2017-01-30
JO  - {'id': None, 'issn_l': None, 'issn': None, 'display_name': None, 'publisher': None, 'type': None, 'url': 'https://doi.org/10.14264/uql.2017.167', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Hamed Hassanzadeh
ER  - 

660.
TY  - journal-article
ID  - https://openalex.org/W2787252755
DO  - nan
TI  - A Knowledge-based System for Intelligent Support in Pharmacogenomics Evidence Assessment: Ontology-driven Evidence Representation and Retrieval.
AB  - Pharmacogenomics holds promise as a critical component of precision medicine. Yet, the use of pharmacogenomics in routine clinical care is minimal, partly due to the lack of efficient and effective use of existing evidence. This paper describes the design, development, implementation and evaluation of a knowledge-based system that fulfills three critical features: a) providing clinically relevant evidence, b) applying an evidence-based approach, and c) using semantically computable formalism, to facilitate efficient evidence assessment to support timely decisions on adoption of pharmacogenomics in clinical care. To illustrate functionality, the system was piloted in the context of clopidogrel and warfarin pharmacogenomics. In contrast to existing pharmacogenomics knowledge bases, the developed system is the first to exploit the expressivity and reasoning power of logic-based representation formalism to enable unambiguous expression and automatic retrieval of pharmacogenomics evidence to support systematic review with meta-analysis. research or previously synthesised evidence. Hence, devising mechanisms that can automatically identify, retrieve, consolidate and present scientific artefacts, based on a given query, has the potential to greatly facilitate collating related evidence and ultimately streamline medical decision-making. This thesis represents an attempt to define a comprehensive framework for acquiring and managing scientific artefacts in the EBM domain – by transforming unstructured publications into structured, consolidated, pertinent knowledge. There have been previous attempts to model such information (e.g., supporting and contradicting statements), however these approaches have primarily focused on providing users with conceptual high-level frameworks and associated manual annotation services. The approach proposed in this thesis employs novel, sets of low-level features to uniquely identify key scientific information in EBM, and enable knowledge extraction and retrieval. This will also lead to automatic creation of networks of scientific artefacts, and eventually the detection of effects across diverse artefacts (i.e., new potential drug treatments). This goal will be attained by firstly modelling and extracting scientific artefacts from publications (more specifically, abstracts) and then consolidating and linking them using Linked Data approaches. The first step for pinpointing the best evidence in the published research is to formulate clinical queries and their answers. Hence, a comprehensive and fine-grained model is essential to formulate key factors of evidence-based decision making according to various medical cases. The Problem/Population, Intervention, Comparison, and Outcome (PICO) framework is a specialised model to frame and answer a clinical or health care related question. An extension of PICO formalises this fundamental information by classifying it into six classes: Population, Intervention, Background, Outcome, Study Design, and Other (called the PIBOSO model). The PIBOSO model has been used as the underlying model throughout this thesis for defining the scientific artefacts in publications. Once modelled, the challenge then shifts towards automatically recognising such scientific artefacts within a published abstract and detecting similar occurrences across multiple abstracts. Machine Learning techniques have been widely applied in this context, especially since the recognition task can be formulated as a sentence classification task, and therefore can be addressed using classification techniques. This thesis presents a scientific artefact classifier that is trained on a novel set of discriminative features. The results indicate that this approach represents a marked improvement compared to the state of the art. In order to be able to find those related scientific artefacts (or evidence) extracted from a large number of published abstracts and then consolidate those that are conceptually similar, this thesis proposes an improved semantic similarity quantification approach. A unique set of similarity measures, which examines similarity of sentences from different syntactic, structural, and semantic features, is presented and then used to train an ensemble regressor. This ensemble can accurately predict the semantic similarity of both generic and domain-specific English sentences. The quantified similarities of scientific artefacts are then employed to consolidate and link those that are highly similar. The resulting Knowledge Base comprises a network of semantically related scientific artefacts, abstracts and publications. The holistic framework described in this thesis, has the potential to transform large corpuses of unstructured text into an enriched, consolidated and linked network of scientific artefacts. The resulting Knowledge Base (which will evolve, improve and expand over time) enables one to quickly gain a broad and deep understanding of the current state of evidence (PIBOSO scientific artefacts) related to a medical topic.
PY  - 2017
DA  - 2017-01-01
JO  - {'id': 'https://openalex.org/S4306501627', 'issn_l': '2153-4063', 'issn': ['2153-4063'], 'display_name': 'AMIA Joint Summits on Translational Science proceedings. AMIA Joint Summits on Translational Science', 'publisher': None, 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Chia-Ju Lee
AU  - Beth Devine
AU  - Peter Tarczy-Hornoch
ER  - 

661.
TY  - posted-content
ID  - https://openalex.org/W2899270352
DO  - nan
TI  - Unsupervised Identification of Study Descriptors in Toxicology Research: An Experimental Study
AB  - Identifying and extracting data elements such as study descriptors in publication full texts is a critical yet manual and labor-intensive step required in a number of tasks. In this paper we address the question of identifying data elements in an unsupervised manner. Specifically, provided a set of criteria describing specific study parameters, such as species, route of administration, and dosing regimen, we develop an unsupervised approach to identify text segments (sentences) relevant to the criteria. A binary classifier trained to identify publications that met the criteria performs better when trained on the candidate sentences than when trained on sentences randomly picked from the text, supporting the intuition that our method is able to accurately identify study descriptors. reasoning power of logic-based representation formalism to enable unambiguous expression and automatic retrieval of pharmacogenomics evidence to support systematic review with meta-analysis. research or previously synthesised evidence. Hence, devising mechanisms that can automatically identify, retrieve, consolidate and present scientific artefacts, based on a given query, has the potential to greatly facilitate collating related evidence and ultimately streamline medical decision-making. This thesis represents an attempt to define a comprehensive framework for acquiring and managing scientific artefacts in the EBM domain – by transforming unstructured publications into structured, consolidated, pertinent knowledge. There have been previous attempts to model such information (e.g., supporting and contradicting statements), however these approaches have primarily focused on providing users with conceptual high-level frameworks and associated manual annotation services. The approach proposed in this thesis employs novel, sets of low-level features to uniquely identify key scientific information in EBM, and enable knowledge extraction and retrieval. This will also lead to automatic creation of networks of scientific artefacts, and eventually the detection of effects across diverse artefacts (i.e., new potential drug treatments). This goal will be attained by firstly modelling and extracting scientific artefacts from publications (more specifically, abstracts) and then consolidating and linking them using Linked Data approaches. The first step for pinpointing the best evidence in the published research is to formulate clinical queries and their answers. Hence, a comprehensive and fine-grained model is essential to formulate key factors of evidence-based decision making according to various medical cases. The Problem/Population, Intervention, Comparison, and Outcome (PICO) framework is a specialised model to frame and answer a clinical or health care related question. An extension of PICO formalises this fundamental information by classifying it into six classes: Population, Intervention, Background, Outcome, Study Design, and Other (called the PIBOSO model). The PIBOSO model has been used as the underlying model throughout this thesis for defining the scientific artefacts in publications. Once modelled, the challenge then shifts towards automatically recognising such scientific artefacts within a published abstract and detecting similar occurrences across multiple abstracts. Machine Learning techniques have been widely applied in this context, especially since the recognition task can be formulated as a sentence classification task, and therefore can be addressed using classification techniques. This thesis presents a scientific artefact classifier that is trained on a novel set of discriminative features. The results indicate that this approach represents a marked improvement compared to the state of the art. In order to be able to find those related scientific artefacts (or evidence) extracted from a large number of published abstracts and then consolidate those that are conceptually similar, this thesis proposes an improved semantic similarity quantification approach. A unique set of similarity measures, which examines similarity of sentences from different syntactic, structural, and semantic features, is presented and then used to train an ensemble regressor. This ensemble can accurately predict the semantic similarity of both generic and domain-specific English sentences. The quantified similarities of scientific artefacts are then employed to consolidate and link those that are highly similar. The resulting Knowledge Base comprises a network of semantically related scientific artefacts, abstracts and publications. The holistic framework described in this thesis, has the potential to transform large corpuses of unstructured text into an enriched, consolidated and linked network of scientific artefacts. The resulting Knowledge Base (which will evolve, improve and expand over time) enables one to quickly gain a broad and deep understanding of the current state of evidence (PIBOSO scientific artefacts) related to a medical topic.
PY  - 2018
DA  - 2018-11-03
JO  - {'id': 'https://openalex.org/S2596401190', 'issn_l': None, 'issn': None, 'display_name': 'arXiv: Computation and Language', 'publisher': None, 'type': 'journal', 'url': 'https://arxiv.org/pdf/1811.01183.pdf', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Drahomira Herrmannova
AU  - Steven L. Young
AU  - Robert M. Patton
AU  - Christopher C. Stahl
AU  - Nicole Kleinstreuer
AU  - Mary Leigh Wolfe
ER  - 

662.
TY  - journal-article
ID  - https://openalex.org/W2919984680
DO  - https://doi.org/10.1016/j.yjbinx.2019.100005
TI  - Comparing breast cancer treatments using automatically detected surrogate and clinically relevant outcomes entities from text
AB  - Abstract and extracting Population, intervention, comparison and outcome (PICO) facets of clinical studies are required both for physicians in a clinical setting and for reviewers as they compare the effectiveness of different treatment strategies. Automated methods developed for the first three of these facets identify entities, but outcome detection has been limited to identifying the entire sentence. We frame outcome detection as a noun phrase prediction task and use semi-supervised learning to detect new outcomes (aka endpoints) from the method section of 88 K MEDLINE abstracts. A manual analysis showed that 96.7% of all outcomes can be captured using a noun phrase representation. With respect to the machine learning classifiers, the Support Vector Machine produced higher precision, F1-score, and accuracy than the General Linear Model when evaluated with respect to the initial gold standard of survivorship seed terms and a manual gold standard that considered all outcomes. However, the best model does not employ machine learning, but rather leverages list structure and resulted in 90.14 precision, 60.69 recall, 75.41 F1-score, and 92.60 accuracy with respect to the manual gold standard of all outcomes. Finally we developed a silver standard with a precision of 89.28 and recall of 86.77 compared to the manual gold standard and used the silver standard to identify all outcomes reported for five breast cancer treatments. The increased precision afforded by this approach reveals that in contrast to chemotherapy and targeted therapy, the surrogate outcome disease free survival (DFS) is reported more frequently than the clinically relevant outcome overall survival (OS) for hormone therapies, which is consistent with findings that DFS translates into firm OS improvements in a hormone therapy setting. of scientific artefacts, and eventually the detection of effects across diverse artefacts (i.e., new potential drug treatments). This goal will be attained by firstly modelling and extracting scientific artefacts from publications (more specifically, abstracts) and then consolidating and linking them using Linked Data approaches. The first step for pinpointing the best evidence in the published research is to formulate clinical queries and their answers. Hence, a comprehensive and fine-grained model is essential to formulate key factors of evidence-based decision making according to various medical cases. The Problem/Population, Intervention, Comparison, and Outcome (PICO) framework is a specialised model to frame and answer a clinical or health care related question. An extension of PICO formalises this fundamental information by classifying it into six classes: Population, Intervention, Background, Outcome, Study Design, and Other (called the PIBOSO model). The PIBOSO model has been used as the underlying model throughout this thesis for defining the scientific artefacts in publications. Once modelled, the challenge then shifts towards automatically recognising such scientific artefacts within a published abstract and detecting similar occurrences across multiple abstracts. Machine Learning techniques have been widely applied in this context, especially since the recognition task can be formulated as a sentence classification task, and therefore can be addressed using classification techniques. This thesis presents a scientific artefact classifier that is trained on a novel set of discriminative features. The results indicate that this approach represents a marked improvement compared to the state of the art. In order to be able to find those related scientific artefacts (or evidence) extracted from a large number of published abstracts and then consolidate those that are conceptually similar, this thesis proposes an improved semantic similarity quantification approach. A unique set of similarity measures, which examines similarity of sentences from different syntactic, structural, and semantic features, is presented and then used to train an ensemble regressor. This ensemble can accurately predict the semantic similarity of both generic and domain-specific English sentences. The quantified similarities of scientific artefacts are then employed to consolidate and link those that are highly similar. The resulting Knowledge Base comprises a network of semantically related scientific artefacts, abstracts and publications. The holistic framework described in this thesis, has the potential to transform large corpuses of unstructured text into an enriched, consolidated and linked network of scientific artefacts. The resulting Knowledge Base (which will evolve, improve and expand over time) enables one to quickly gain a broad and deep understanding of the current state of evidence (PIBOSO scientific artefacts) related to a medical topic.
PY  - 2019
DA  - 2019-01-01
JO  - {'id': 'https://openalex.org/S11622463', 'issn_l': '1532-0464', 'issn': ['1532-0480', '1532-0464'], 'display_name': 'Journal of Biomedical Informatics', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'https://doi.org/10.1016/j.yjbinx.2019.100005', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Catherine Blake
AU  - Rebecca D. Kehm
ER  - 

663.
TY  - journal-article
ID  - https://openalex.org/W2964036488
DO  - https://doi.org/10.1136/bmjebm-2019-111206
TI  - Automatic extraction of quantitative data from ClinicalTrials.gov to conduct meta-analyses
AB  - Increasing the speed for completing a systematic review is needed to keep up to date with the literature. Could automatic data extraction from ClinicalTrials.gov provide an important step in speeding up the process of evidence synthesis? 

How can we conduct systematic reviews more quickly? An assessment of information in the PROSPERO registry (International prospective register of systematic reviews) to 2014, Borah et al 1 estimated the average time to carry out a systematic review to be over a year. This time frame has remained broadly unchanged in comparison with an estimate published 18 years earlier.2 Because of the speed with which some clinical disciplines generate new evidence, there is a danger that new systematic reviews become out of date within the time taken for them to be completed and published, and as a consequence their findings appear too slowly to influence practice.

Lifting data from electronic articles or data repositories automatically using computer software, rather than extracting it painstakingly by hand, has been gradually growing in popularity among systematic reviewers.3 The move to automation seems appealing and … manual gold standard of all outcomes. Finally we developed a silver standard with a precision of 89.28 and recall of 86.77 compared to the manual gold standard and used the silver standard to identify all outcomes reported for five breast cancer treatments. The increased precision afforded by this approach reveals that in contrast to chemotherapy and targeted therapy, the surrogate outcome disease free survival (DFS) is reported more frequently than the clinically relevant outcome overall survival (OS) for hormone therapies, which is consistent with findings that DFS translates into firm OS improvements in a hormone therapy setting. of scientific artefacts, and eventually the detection of effects across diverse artefacts (i.e., new potential drug treatments). This goal will be attained by firstly modelling and extracting scientific artefacts from publications (more specifically, abstracts) and then consolidating and linking them using Linked Data approaches. The first step for pinpointing the best evidence in the published research is to formulate clinical queries and their answers. Hence, a comprehensive and fine-grained model is essential to formulate key factors of evidence-based decision making according to various medical cases. The Problem/Population, Intervention, Comparison, and Outcome (PICO) framework is a specialised model to frame and answer a clinical or health care related question. An extension of PICO formalises this fundamental information by classifying it into six classes: Population, Intervention, Background, Outcome, Study Design, and Other (called the PIBOSO model). The PIBOSO model has been used as the underlying model throughout this thesis for defining the scientific artefacts in publications. Once modelled, the challenge then shifts towards automatically recognising such scientific artefacts within a published abstract and detecting similar occurrences across multiple abstracts. Machine Learning techniques have been widely applied in this context, especially since the recognition task can be formulated as a sentence classification task, and therefore can be addressed using classification techniques. This thesis presents a scientific artefact classifier that is trained on a novel set of discriminative features. The results indicate that this approach represents a marked improvement compared to the state of the art. In order to be able to find those related scientific artefacts (or evidence) extracted from a large number of published abstracts and then consolidate those that are conceptually similar, this thesis proposes an improved semantic similarity quantification approach. A unique set of similarity measures, which examines similarity of sentences from different syntactic, structural, and semantic features, is presented and then used to train an ensemble regressor. This ensemble can accurately predict the semantic similarity of both generic and domain-specific English sentences. The quantified similarities of scientific artefacts are then employed to consolidate and link those that are highly similar. The resulting Knowledge Base comprises a network of semantically related scientific artefacts, abstracts and publications. The holistic framework described in this thesis, has the potential to transform large corpuses of unstructured text into an enriched, consolidated and linked network of scientific artefacts. The resulting Knowledge Base (which will evolve, improve and expand over time) enables one to quickly gain a broad and deep understanding of the current state of evidence (PIBOSO scientific artefacts) related to a medical topic.
PY  - 2020
DA  - 2020-06-01
JO  - {'id': 'https://openalex.org/S4210227606', 'issn_l': '2515-446X', 'issn': ['2515-446X', '2515-4478'], 'display_name': 'BMJ evidence-based medicine', 'publisher': 'BMJ', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Thomas R. Fanshawe
AU  - Rafael Perera
ER  - 

664.
TY  - dissertation
ID  - https://openalex.org/W2981319994
DO  - nan
TI  - Understanding in vivo modelling of depression
AB  - No Abstract Found
PY  - 2019
DA  - 2019-11-25
JO  - {'id': None, 'issn_l': None, 'issn': None, 'display_name': None, 'publisher': None, 'type': None, 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Alexandra Bannach-Brown
ER  - 

665.
TY  - posted-content
ID  - https://openalex.org/W3119795531
DO  - https://doi.org/10.1101/2021.01.12.21249695
TI  - Toward Assessing Clinical Trial Publications for Reporting Transparency
AB  - Abstract Objective To annotate a corpus of randomized controlled trial (RCT) publications with the checklist items of CONSORT reporting guidelines and using the corpus to develop text mining methods for RCT appraisal. Methods We annotated a corpus of 50 RCT articles at the sentence level using 37 fine-grained CONSORT checklist items. A subset (31 articles) was double-annotated and adjudicated, while 19 were annotated by a single annotator and reconciled by another. We calculated inter-annotator agreement at the article and section level using MASI (Measuring Agreement on Set-Valued Items) and at the CONSORT item level using Krippendorff’s α . We experimented with two rule-based methods (phrase-based and section header-based) and two supervised learning approaches (support vector machine and BioBERT-based neural network classifiers), for recognizing 17 methodology-related items in the RCT Methods sections. Results We created CONSORT-TM consisting of 10,709 sentences, 4,845 (45%) of which were annotated with 5,246 labels. A median of 28 CONSORT items (out of possible 37) were annotated per article. Agreement was moderate at the article and section levels (average MASI: 0.60 and 0.64, respectively). Agreement varied considerably among individual checklist items (Krippendorff’s α = 0.06-0.96). The model based on BioBERT performed best overall for recognizing methodology-related items (micro-precision: 0.82, micro-recall: 0.63, micro-F1: 0.71). Combining models using majority vote and label aggregation further improved precision and recall, respectively. Conclusion Our annotated corpus, CONSORT-TM, contains more fine-grained information than earlier RCT corpora. Low frequency of some CONSORT items made it difficult to train effective text mining models to recognize them. For the items commonly reported, CONSORT-TM can serve as a testbed for text mining methods that assess RCT transparency, rigor, and reliability, and support methods for peer review and authoring assistance. Minor modifications to the annotation scheme and a larger corpus could facilitate improved text mining models. CONSORT-TM is publicly available at https://github.com/kilicogluh/CONSORT-TM . Graphical abstract Highlights We constructed a corpus of RCT publications annotated with CONSORT checklist items. We developed text mining methods to identify methodology-related check-list items. A BioBERT-based model performs best in recognizing adequately reported items. A phrase-based method performs best in recognizing infrequently reported items. The corpus and the text mining methods can be used to address reporting transparency. (PICO) framework is a specialised model to frame and answer a clinical or health care related question. An extension of PICO formalises this fundamental information by classifying it into six classes: Population, Intervention, Background, Outcome, Study Design, and Other (called the PIBOSO model). The PIBOSO model has been used as the underlying model throughout this thesis for defining the scientific artefacts in publications. Once modelled, the challenge then shifts towards automatically recognising such scientific artefacts within a published abstract and detecting similar occurrences across multiple abstracts. Machine Learning techniques have been widely applied in this context, especially since the recognition task can be formulated as a sentence classification task, and therefore can be addressed using classification techniques. This thesis presents a scientific artefact classifier that is trained on a novel set of discriminative features. The results indicate that this approach represents a marked improvement compared to the state of the art. In order to be able to find those related scientific artefacts (or evidence) extracted from a large number of published abstracts and then consolidate those that are conceptually similar, this thesis proposes an improved semantic similarity quantification approach. A unique set of similarity measures, which examines similarity of sentences from different syntactic, structural, and semantic features, is presented and then used to train an ensemble regressor. This ensemble can accurately predict the semantic similarity of both generic and domain-specific English sentences. The quantified similarities of scientific artefacts are then employed to consolidate and link those that are highly similar. The resulting Knowledge Base comprises a network of semantically related scientific artefacts, abstracts and publications. The holistic framework described in this thesis, has the potential to transform large corpuses of unstructured text into an enriched, consolidated and linked network of scientific artefacts. The resulting Knowledge Base (which will evolve, improve and expand over time) enables one to quickly gain a broad and deep understanding of the current state of evidence (PIBOSO scientific artefacts) related to a medical topic.
PY  - 2021
DA  - 2021-01-15
JO  - {'id': 'https://openalex.org/S3005729997', 'issn_l': None, 'issn': None, 'display_name': 'medRxiv', 'publisher': 'Cold Spring Harbor Laboratory Press', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Halil Kilicoglu
AU  - Graciela Rosemblat
AU  - Linh Cao Hoang
AU  - Sahil Wadhwa
AU  - Zeshan Peng
AU  - Mario Malički
AU  - Jodi Schneider
AU  - Gerben ter Riet
ER  - 

666.
TY  - book-chapter
ID  - https://openalex.org/W3154307759
DO  - https://doi.org/10.1007/978-3-319-52677-5_194-1
TI  - Introduction to Systematic Reviews
AB  - No Abstract Found
PY  - 2021
DA  - 2021-01-01
JO  - {'id': 'https://openalex.org/S4306463941', 'issn_l': None, 'issn': None, 'display_name': 'Springer International Publishing eBooks', 'publisher': 'Springer Nature', 'type': 'ebook platform', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Tianjing Li
AU  - Ian J. Saldanha
AU  - Karen A. Robinson
ER  - 

667.
TY  - proceedings-article
ID  - https://openalex.org/W3154463678
DO  - https://doi.org/10.18653/v1/2021.emnlp-main.686
TI  - Detect and Classify – Joint Span Detection and Classification for Health Outcomes
AB  - A health outcome is a measurement or an observation used to capture and assess the effect of a treatment. Automatic detection of health outcomes from text would undoubtedly speed up access to evidence necessary in healthcare decision making. Prior work on outcome detection has modelled this task as either (a) a sequence labelling task, where the goal is to detect which text spans describe health outcomes or (b) a classification task, where the goal is to classify a text into a pre-defined set of categories depending on an outcome that is mentioned somewhere in that text. However, this decoupling of span detection and classification is problematic from a modelling perspective and ignores global structural correspondences between sentence-level and word-level information present in a given text. We propose a method that uses both word-level and sentence-level information to simultaneously perform outcome span detection and outcome type classification. In addition to injecting contextual information to hidden vectors, we use label attention to appropriately weight both word-level and sentence-level information. Experimental results on several benchmark datasets for health outcome detection show that our model consistently outperforms decoupled methods, reporting competitive results. The model based on BioBERT performed best overall for recognizing methodology-related items (micro-precision: 0.82, micro-recall: 0.63, micro-F1: 0.71). Combining models using majority vote and label aggregation further improved precision and recall, respectively. Conclusion Our annotated corpus, CONSORT-TM, contains more fine-grained information than earlier RCT corpora. Low frequency of some CONSORT items made it difficult to train effective text mining models to recognize them. For the items commonly reported, CONSORT-TM can serve as a testbed for text mining methods that assess RCT transparency, rigor, and reliability, and support methods for peer review and authoring assistance. Minor modifications to the annotation scheme and a larger corpus could facilitate improved text mining models. CONSORT-TM is publicly available at https://github.com/kilicogluh/CONSORT-TM . Graphical abstract Highlights We constructed a corpus of RCT publications annotated with CONSORT checklist items. We developed text mining methods to identify methodology-related check-list items. A BioBERT-based model performs best in recognizing adequately reported items. A phrase-based method performs best in recognizing infrequently reported items. The corpus and the text mining methods can be used to address reporting transparency. (PICO) framework is a specialised model to frame and answer a clinical or health care related question. An extension of PICO formalises this fundamental information by classifying it into six classes: Population, Intervention, Background, Outcome, Study Design, and Other (called the PIBOSO model). The PIBOSO model has been used as the underlying model throughout this thesis for defining the scientific artefacts in publications. Once modelled, the challenge then shifts towards automatically recognising such scientific artefacts within a published abstract and detecting similar occurrences across multiple abstracts. Machine Learning techniques have been widely applied in this context, especially since the recognition task can be formulated as a sentence classification task, and therefore can be addressed using classification techniques. This thesis presents a scientific artefact classifier that is trained on a novel set of discriminative features. The results indicate that this approach represents a marked improvement compared to the state of the art. In order to be able to find those related scientific artefacts (or evidence) extracted from a large number of published abstracts and then consolidate those that are conceptually similar, this thesis proposes an improved semantic similarity quantification approach. A unique set of similarity measures, which examines similarity of sentences from different syntactic, structural, and semantic features, is presented and then used to train an ensemble regressor. This ensemble can accurately predict the semantic similarity of both generic and domain-specific English sentences. The quantified similarities of scientific artefacts are then employed to consolidate and link those that are highly similar. The resulting Knowledge Base comprises a network of semantically related scientific artefacts, abstracts and publications. The holistic framework described in this thesis, has the potential to transform large corpuses of unstructured text into an enriched, consolidated and linked network of scientific artefacts. The resulting Knowledge Base (which will evolve, improve and expand over time) enables one to quickly gain a broad and deep understanding of the current state of evidence (PIBOSO scientific artefacts) related to a medical topic.
PY  - 2021
DA  - 2021-01-01
JO  - {'id': 'https://openalex.org/V2596401190', 'issn_l': None, 'issn': None, 'display_name': 'arXiv: Computation and Language', 'publisher': None, 'type': 'journal', 'url': 'https://aclanthology.org/2021.emnlp-main.686.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Michael Abaho
AU  - Danushka Bollegala
AU  - Paula R Williamson
AU  - Susanna Dodd
ER  - 

668.
TY  - book-chapter
ID  - https://openalex.org/W3157451217
DO  - https://doi.org/10.1007/978-3-030-46216-1_27
TI  - Meta-analyzing Corpus Linguistic Research
AB  - No Abstract Found
PY  - 2020
DA  - 2020-01-01
JO  - {'id': 'https://openalex.org/S4306463941', 'issn_l': None, 'issn': None, 'display_name': 'Springer International Publishing eBooks', 'publisher': 'Springer Nature', 'type': 'ebook platform', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Atsushi Mizumoto
AU  - Luke Plonsky
AU  - Jesse Egbert
ER  - 

669.
TY  - nan
ID  - https://openalex.org/W3169332062
DO  - nan
TI  - Conducting a Systematic Review: Trends in Machine Learning and Text Mining
AB  - No Abstract Found
PY  - 2020
DA  - 2020-01-01
JO  - {'id': None, 'issn_l': None, 'issn': None, 'display_name': 'XXVI Congreso Argentino de Ciencias de la Computación (CACIC) (Modalidad virtual, 5 al 9 de octubre de 2020)', 'publisher': None, 'type': None, 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Mariana Falco
AU  - Ignacio Berdiñas
ER  - 

670.
TY  - book-chapter
ID  - https://openalex.org/W3174423172
DO  - https://doi.org/10.1007/978-3-030-71921-0_6
TI  - Data Extraction from Included Studies
AB  - No Abstract Found
PY  - 2021
DA  - 2021-01-01
JO  - {'id': 'https://openalex.org/V4306463941', 'issn_l': None, 'issn': None, 'display_name': 'Springer International Publishing eBooks', 'publisher': 'Springer Nature', 'type': 'ebook platform', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Kwi Moon
AU  - Shripada Rao
ER  - 

671.
TY  - book-chapter
ID  - https://openalex.org/W3185932187
DO  - https://doi.org/10.1007/978-3-030-71881-7_12
TI  - Machine Learning in Evidence Synthesis Research
AB  - No Abstract Found
PY  - 2021
DA  - 2021-01-01
JO  - {'id': 'https://openalex.org/V4306463941', 'issn_l': None, 'issn': None, 'display_name': 'Springer International Publishing eBooks', 'publisher': 'Springer Nature', 'type': 'ebook platform', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Alonso Carrasco-Labra
AU  - Olivia Urquhart
AU  - Heiko Spallek
ER  - 

672.
TY  - book-chapter
ID  - https://openalex.org/W3190720226
DO  - https://doi.org/10.1007/978-3-030-58080-3_43-1
TI  - Artificial Intelligence in Evidence-Based Medicine
AB  - No Abstract Found
PY  - 2021
DA  - 2021-01-01
JO  - {'id': 'https://openalex.org/S4306463941', 'issn_l': None, 'issn': None, 'display_name': 'Springer International Publishing eBooks', 'publisher': 'Springer Nature', 'type': 'ebook platform', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Artur Nowak
ER  - 

673.
TY  - posted-content
ID  - https://openalex.org/W3199007285
DO  - https://doi.org/10.1101/2021.09.14.21263586
TI  - Investigating the impact of weakly supervised data on text mining models of publication transparency: a case study on randomized controlled trials
AB  - Abstract Lack of large quantities of annotated data is a major barrier in developing effective text mining models of biomedical literature. In this study, we explored weak supervision strategies to improve the accuracy of text classification models developed for assessing methodological transparency of randomized controlled trial (RCT) publications. Specifically, we used Snorkel, a framework to programmatically build training sets, and UMLS-EDA, a data augmentation method that leverages a small number of existing examples to generate new training instances, for weak supervision and assessed their effect on a BioBERT-based text classification model proposed for the task in previous work. Performance improvements due to weak supervision were limited and were surpassed by gains from hyperparameter tuning. Our analysis suggests that refinements to the weak supervision strategies to better deal with multi-label case could be beneficial. and sentence-level information to simultaneously perform outcome span detection and outcome type classification. In addition to injecting contextual information to hidden vectors, we use label attention to appropriately weight both word-level and sentence-level information. Experimental results on several benchmark datasets for health outcome detection show that our model consistently outperforms decoupled methods, reporting competitive results. The model based on BioBERT performed best overall for recognizing methodology-related items (micro-precision: 0.82, micro-recall: 0.63, micro-F1: 0.71). Combining models using majority vote and label aggregation further improved precision and recall, respectively. Conclusion Our annotated corpus, CONSORT-TM, contains more fine-grained information than earlier RCT corpora. Low frequency of some CONSORT items made it difficult to train effective text mining models to recognize them. For the items commonly reported, CONSORT-TM can serve as a testbed for text mining methods that assess RCT transparency, rigor, and reliability, and support methods for peer review and authoring assistance. Minor modifications to the annotation scheme and a larger corpus could facilitate improved text mining models. CONSORT-TM is publicly available at https://github.com/kilicogluh/CONSORT-TM . Graphical abstract Highlights We constructed a corpus of RCT publications annotated with CONSORT checklist items. We developed text mining methods to identify methodology-related check-list items. A BioBERT-based model performs best in recognizing adequately reported items. A phrase-based method performs best in recognizing infrequently reported items. The corpus and the text mining methods can be used to address reporting transparency. (PICO) framework is a specialised model to frame and answer a clinical or health care related question. An extension of PICO formalises this fundamental information by classifying it into six classes: Population, Intervention, Background, Outcome, Study Design, and Other (called the PIBOSO model). The PIBOSO model has been used as the underlying model throughout this thesis for defining the scientific artefacts in publications. Once modelled, the challenge then shifts towards automatically recognising such scientific artefacts within a published abstract and detecting similar occurrences across multiple abstracts. Machine Learning techniques have been widely applied in this context, especially since the recognition task can be formulated as a sentence classification task, and therefore can be addressed using classification techniques. This thesis presents a scientific artefact classifier that is trained on a novel set of discriminative features. The results indicate that this approach represents a marked improvement compared to the state of the art. In order to be able to find those related scientific artefacts (or evidence) extracted from a large number of published abstracts and then consolidate those that are conceptually similar, this thesis proposes an improved semantic similarity quantification approach. A unique set of similarity measures, which examines similarity of sentences from different syntactic, structural, and semantic features, is presented and then used to train an ensemble regressor. This ensemble can accurately predict the semantic similarity of both generic and domain-specific English sentences. The quantified similarities of scientific artefacts are then employed to consolidate and link those that are highly similar. The resulting Knowledge Base comprises a network of semantically related scientific artefacts, abstracts and publications. The holistic framework described in this thesis, has the potential to transform large corpuses of unstructured text into an enriched, consolidated and linked network of scientific artefacts. The resulting Knowledge Base (which will evolve, improve and expand over time) enables one to quickly gain a broad and deep understanding of the current state of evidence (PIBOSO scientific artefacts) related to a medical topic.
PY  - 2021
DA  - 2021-09-22
JO  - {'id': 'https://openalex.org/S4306400573', 'issn_l': None, 'issn': None, 'display_name': 'medRxiv (Cold Spring Harbor Laboratory)', 'publisher': 'Cold Spring Harbor Laboratory', 'type': 'repository', 'url': 'https://doi.org/10.1101/2021.09.14.21263586', 'is_oa': True, 'version': 'submittedVersion', 'license': None}
DP  - OpenAlex
AU  - Linh Cao Hoang
AU  - Lan Jiang
AU  - Halil Kilicoglu
ER  - 

674.
TY  - proceedings-article
ID  - https://openalex.org/W3211441842
DO  - nan
TI  - Detect and Classify – Joint Span Detection and Classification for Health Outcomes
AB  - A health outcome is a measurement or an observation used to capture and assess the effect of a treatment. Automatic detection of health outcomes from text would undoubtedly speed up access to evidence necessary in healthcare decision making. Prior work on outcome detection has modelled this task as either (a) a sequence labelling task, where the goal is to detect which text spans describe health outcomes, or (b) a classification task, where the goal is to classify a text into a predefined set of categories depending on an outcome that is mentioned somewhere in that text. However, this decoupling of span detection and classification is problematic from a modelling perspective and ignores global structural correspondences between sentence-level and word-level information present in a given text. To address this, we propose a method that uses both word-level and sentence-level information to simultaneously perform outcome span detection and outcome type classification. In addition to injecting contextual information to hidden vectors, we use label attention to appropriately weight both word and sentence level information. Experimental results on several benchmark datasets for health outcome detection show that our proposed method consistently outperforms decoupled methods, reporting competitive results. performed best overall for recognizing methodology-related items (micro-precision: 0.82, micro-recall: 0.63, micro-F1: 0.71). Combining models using majority vote and label aggregation further improved precision and recall, respectively. Conclusion Our annotated corpus, CONSORT-TM, contains more fine-grained information than earlier RCT corpora. Low frequency of some CONSORT items made it difficult to train effective text mining models to recognize them. For the items commonly reported, CONSORT-TM can serve as a testbed for text mining methods that assess RCT transparency, rigor, and reliability, and support methods for peer review and authoring assistance. Minor modifications to the annotation scheme and a larger corpus could facilitate improved text mining models. CONSORT-TM is publicly available at https://github.com/kilicogluh/CONSORT-TM . Graphical abstract Highlights We constructed a corpus of RCT publications annotated with CONSORT checklist items. We developed text mining methods to identify methodology-related check-list items. A BioBERT-based model performs best in recognizing adequately reported items. A phrase-based method performs best in recognizing infrequently reported items. The corpus and the text mining methods can be used to address reporting transparency. (PICO) framework is a specialised model to frame and answer a clinical or health care related question. An extension of PICO formalises this fundamental information by classifying it into six classes: Population, Intervention, Background, Outcome, Study Design, and Other (called the PIBOSO model). The PIBOSO model has been used as the underlying model throughout this thesis for defining the scientific artefacts in publications. Once modelled, the challenge then shifts towards automatically recognising such scientific artefacts within a published abstract and detecting similar occurrences across multiple abstracts. Machine Learning techniques have been widely applied in this context, especially since the recognition task can be formulated as a sentence classification task, and therefore can be addressed using classification techniques. This thesis presents a scientific artefact classifier that is trained on a novel set of discriminative features. The results indicate that this approach represents a marked improvement compared to the state of the art. In order to be able to find those related scientific artefacts (or evidence) extracted from a large number of published abstracts and then consolidate those that are conceptually similar, this thesis proposes an improved semantic similarity quantification approach. A unique set of similarity measures, which examines similarity of sentences from different syntactic, structural, and semantic features, is presented and then used to train an ensemble regressor. This ensemble can accurately predict the semantic similarity of both generic and domain-specific English sentences. The quantified similarities of scientific artefacts are then employed to consolidate and link those that are highly similar. The resulting Knowledge Base comprises a network of semantically related scientific artefacts, abstracts and publications. The holistic framework described in this thesis, has the potential to transform large corpuses of unstructured text into an enriched, consolidated and linked network of scientific artefacts. The resulting Knowledge Base (which will evolve, improve and expand over time) enables one to quickly gain a broad and deep understanding of the current state of evidence (PIBOSO scientific artefacts) related to a medical topic.
PY  - 2021
DA  - 2021-11-01
JO  - {'id': 'https://openalex.org/S4306418267', 'issn_l': None, 'issn': None, 'display_name': 'Empirical Methods in Natural Language Processing', 'publisher': None, 'type': 'conference', 'url': 'https://aclanthology.org/2021.emnlp-main.686/', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Michael Abaho
AU  - Danushka Bollegala
AU  - Paula R Williamson
AU  - Susanna Dodd
ER  - 

675.
TY  - journal-article
ID  - https://openalex.org/W3214639705
DO  - https://doi.org/10.1111/hir.12413
TI  - Using an artificial intelligence tool can be as accurate as human assessors in level one screening for a systematic review
AB  - Artificial intelligence (AI) offers a promising solution to expedite various phases of the systematic review process such as screening.We aimed to assess the accuracy of an AI tool in identifying eligible references for a systematic review compared to identification by human assessors.For the case study (a systematic review of knowledge translation interventions), we used a diagnostic accuracy design and independently assessed for eligibility a set of articles (n = 300) using human raters and the AI system DistillerAI (Evidence Partners, Ottawa, Canada). We analysed a series of 64 possible confidence levels for the AI's decisions and calculated several standard parameters of diagnostic accuracy for each.When set to a lower AI confidence threshold of 0.1 or greater and an upper threshold of 0.9 or lower, DistillerAI made article selection decisions very similarly to human assessors. Within this range, DistillerAI made a decision on the majority of articles (93-100%), with a sensitivity of 1.0 and specificity ranging from 0.9 to 1.0.DistillerAI appears to be accurate in its assessment of articles in a case study of 300 articles. Further experimentation with DistillerAI will establish its performance among other subject areas. outperforms decoupled methods, reporting competitive results. performed best overall for recognizing methodology-related items (micro-precision: 0.82, micro-recall: 0.63, micro-F1: 0.71). Combining models using majority vote and label aggregation further improved precision and recall, respectively. Conclusion Our annotated corpus, CONSORT-TM, contains more fine-grained information than earlier RCT corpora. Low frequency of some CONSORT items made it difficult to train effective text mining models to recognize them. For the items commonly reported, CONSORT-TM can serve as a testbed for text mining methods that assess RCT transparency, rigor, and reliability, and support methods for peer review and authoring assistance. Minor modifications to the annotation scheme and a larger corpus could facilitate improved text mining models. CONSORT-TM is publicly available at https://github.com/kilicogluh/CONSORT-TM . Graphical abstract Highlights We constructed a corpus of RCT publications annotated with CONSORT checklist items. We developed text mining methods to identify methodology-related check-list items. A BioBERT-based model performs best in recognizing adequately reported items. A phrase-based method performs best in recognizing infrequently reported items. The corpus and the text mining methods can be used to address reporting transparency. (PICO) framework is a specialised model to frame and answer a clinical or health care related question. An extension of PICO formalises this fundamental information by classifying it into six classes: Population, Intervention, Background, Outcome, Study Design, and Other (called the PIBOSO model). The PIBOSO model has been used as the underlying model throughout this thesis for defining the scientific artefacts in publications. Once modelled, the challenge then shifts towards automatically recognising such scientific artefacts within a published abstract and detecting similar occurrences across multiple abstracts. Machine Learning techniques have been widely applied in this context, especially since the recognition task can be formulated as a sentence classification task, and therefore can be addressed using classification techniques. This thesis presents a scientific artefact classifier that is trained on a novel set of discriminative features. The results indicate that this approach represents a marked improvement compared to the state of the art. In order to be able to find those related scientific artefacts (or evidence) extracted from a large number of published abstracts and then consolidate those that are conceptually similar, this thesis proposes an improved semantic similarity quantification approach. A unique set of similarity measures, which examines similarity of sentences from different syntactic, structural, and semantic features, is presented and then used to train an ensemble regressor. This ensemble can accurately predict the semantic similarity of both generic and domain-specific English sentences. The quantified similarities of scientific artefacts are then employed to consolidate and link those that are highly similar. The resulting Knowledge Base comprises a network of semantically related scientific artefacts, abstracts and publications. The holistic framework described in this thesis, has the potential to transform large corpuses of unstructured text into an enriched, consolidated and linked network of scientific artefacts. The resulting Knowledge Base (which will evolve, improve and expand over time) enables one to quickly gain a broad and deep understanding of the current state of evidence (PIBOSO scientific artefacts) related to a medical topic.
PY  - 2021
DA  - 2021-11-18
JO  - {'id': 'https://openalex.org/S66051165', 'issn_l': '1471-1834', 'issn': ['1365-2532', '1471-1842', '0265-6647', '1471-1834'], 'display_name': 'Health Information and Libraries Journal', 'publisher': 'Wiley-Blackwell', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Joseph A. Burns
AU  - Nicole Etherington
AU  - Olivia Cheng-Boivin
AU  - Sylvain Boet
ER  - 

676.
TY  - journal-article
ID  - https://openalex.org/W4200056480
DO  - https://doi.org/10.1016/j.jbi.2021.103970
TI  - Extracting experimental parameter entities from scientific articles
AB  - Systematic reviews are labor-intensive processes to combine all knowledge about a given topic into a coherent summary. Despite the high labor investment, they are necessary to create an exhaustive overview of current evidence relevant to a research question. In this work, we evaluate three state-of-the-art supervised multi-label sequence classification systems to automatically identify 24 different experimental design factors for the categories of Animal, Dose, Exposure, and Endpoint from journal articles describing the experiments related to toxicity and health effects of environmental agents. We then present an in depth analysis of the results evaluating the lexical diversity of the design parameters with respect to model performance, evaluating the impact of tokenization and non-contiguous mentions, and finally evaluating the dependencies between entities within the category entities. We demonstrate that in general, algorithms that use embedded representations of the sequences out-perform statistical algorithms, but that even these algorithms struggle with lexically diverse entities. of 1.0 and specificity ranging from 0.9 to 1.0.DistillerAI appears to be accurate in its assessment of articles in a case study of 300 articles. Further experimentation with DistillerAI will establish its performance among other subject areas. outperforms decoupled methods, reporting competitive results. performed best overall for recognizing methodology-related items (micro-precision: 0.82, micro-recall: 0.63, micro-F1: 0.71). Combining models using majority vote and label aggregation further improved precision and recall, respectively. Conclusion Our annotated corpus, CONSORT-TM, contains more fine-grained information than earlier RCT corpora. Low frequency of some CONSORT items made it difficult to train effective text mining models to recognize them. For the items commonly reported, CONSORT-TM can serve as a testbed for text mining methods that assess RCT transparency, rigor, and reliability, and support methods for peer review and authoring assistance. Minor modifications to the annotation scheme and a larger corpus could facilitate improved text mining models. CONSORT-TM is publicly available at https://github.com/kilicogluh/CONSORT-TM . Graphical abstract Highlights We constructed a corpus of RCT publications annotated with CONSORT checklist items. We developed text mining methods to identify methodology-related check-list items. A BioBERT-based model performs best in recognizing adequately reported items. A phrase-based method performs best in recognizing infrequently reported items. The corpus and the text mining methods can be used to address reporting transparency. (PICO) framework is a specialised model to frame and answer a clinical or health care related question. An extension of PICO formalises this fundamental information by classifying it into six classes: Population, Intervention, Background, Outcome, Study Design, and Other (called the PIBOSO model). The PIBOSO model has been used as the underlying model throughout this thesis for defining the scientific artefacts in publications. Once modelled, the challenge then shifts towards automatically recognising such scientific artefacts within a published abstract and detecting similar occurrences across multiple abstracts. Machine Learning techniques have been widely applied in this context, especially since the recognition task can be formulated as a sentence classification task, and therefore can be addressed using classification techniques. This thesis presents a scientific artefact classifier that is trained on a novel set of discriminative features. The results indicate that this approach represents a marked improvement compared to the state of the art. In order to be able to find those related scientific artefacts (or evidence) extracted from a large number of published abstracts and then consolidate those that are conceptually similar, this thesis proposes an improved semantic similarity quantification approach. A unique set of similarity measures, which examines similarity of sentences from different syntactic, structural, and semantic features, is presented and then used to train an ensemble regressor. This ensemble can accurately predict the semantic similarity of both generic and domain-specific English sentences. The quantified similarities of scientific artefacts are then employed to consolidate and link those that are highly similar. The resulting Knowledge Base comprises a network of semantically related scientific artefacts, abstracts and publications. The holistic framework described in this thesis, has the potential to transform large corpuses of unstructured text into an enriched, consolidated and linked network of scientific artefacts. The resulting Knowledge Base (which will evolve, improve and expand over time) enables one to quickly gain a broad and deep understanding of the current state of evidence (PIBOSO scientific artefacts) related to a medical topic.
PY  - 2021
DA  - 2021-12-01
JO  - {'id': 'https://openalex.org/S11622463', 'issn_l': '1532-0464', 'issn': ['1532-0480', '1532-0464'], 'display_name': 'Journal of Biomedical Informatics', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Steele Farnsworth
AU  - Gabrielle Gurdin
AU  - Jorge A Vargas
AU  - Andriy Mulyar
AU  - Nastassja Lewinski
AU  - Bridget T. McInnes
ER  - 

677.
TY  - posted-content
ID  - https://openalex.org/W4213285645
DO  - https://doi.org/10.2196/preprints.33124
TI  - Toward Automated Data Extraction: A Pilot Survey of the Structure of Tabular Data in Clinical Comparative Literature (Preprint)
AB  - <sec> <title>BACKGROUND</title> Systematic reviews depend on time-consuming extraction of data from PDFs of underlying studies. To date, automation efforts have focused on extracting from the text, and no approach has yet succeeded in fully automating ingestion of quantitative evidence. However, the majority of relevant data is generally presented in tables, and tabular structure is more amenable to automated extraction than free-text. </sec> <sec> <title>OBJECTIVE</title> The purpose of this survey is to classify the structure and format of descriptive statistics reported in tables in the comparative medical literature. </sec> <sec> <title>METHODS</title> We sampled 100 published randomized controlled trials (RCTs) from the year 2019 from PubMed; these results were imported to the AutoLit platform. Studies were excluded if they were non-clinical, non-comparative, not in English, protocol-only, or not available in full text. In AutoLit, tables reporting baseline or outcome data in all studies were characterized based on reporting practices. Measurement context, meaning the structure in which the interventions of interest, patient arm breakdown, measurement timepoints, and data element descriptions were presented, was classified based on the number of contextual pieces and metadata reported. Then, the statistic formats for reported metrics (specific instances of reporting of data elements) were classified by location and broken down into reporting strategies for continuous, dichotomous, and categorical metrics. </sec> <sec> <title>RESULTS</title> We included 78 of 100 studies, one of which (1.3%) did not report data elements in tables. The remaining 77 studies reported baseline and outcome data in 174 tables, and 97% of these tables broke down reporting by patient arms. Fifteen structures were found for the reporting of measurement context, which were broadly grouped into: 1x1 Contexts, where two pieces of context are reported total (e.g. “arms in columns, data elements in rows); 2x1 Contexts, where two pieces of context are given on row headers (e.g. timepoints in columns, arms nested in data elements on rows); 1x2 Contexts, where two pieces of context are given on column headers. 1x1 contexts were present in 57% of tables, compared to 20% for 2x1 and 15% for 1x2 (8% used unique/other stratification). Statistic formats were reported in the headers or descriptions of 84% of studies. </sec> <sec> <title>CONCLUSIONS</title> In this pilot survey, we found a high density of information in tables, but with major heterogeneity in presentation of measurement context. The highest-density studies reported both baseline and outcome measures in tables, with arm-level breakout, intervention labels and arm sizes present, and reported both the statistic formats and units. The measurement context formats presented here, broadly classified into three classes that cover 92% of studies, form a basis for understanding the frequency of different reporting styles, supporting automated detection of data format for extraction of metrics. </sec> across multiple abstracts. Machine Learning techniques have been widely applied in this context, especially since the recognition task can be formulated as a sentence classification task, and therefore can be addressed using classification techniques. This thesis presents a scientific artefact classifier that is trained on a novel set of discriminative features. The results indicate that this approach represents a marked improvement compared to the state of the art. In order to be able to find those related scientific artefacts (or evidence) extracted from a large number of published abstracts and then consolidate those that are conceptually similar, this thesis proposes an improved semantic similarity quantification approach. A unique set of similarity measures, which examines similarity of sentences from different syntactic, structural, and semantic features, is presented and then used to train an ensemble regressor. This ensemble can accurately predict the semantic similarity of both generic and domain-specific English sentences. The quantified similarities of scientific artefacts are then employed to consolidate and link those that are highly similar. The resulting Knowledge Base comprises a network of semantically related scientific artefacts, abstracts and publications. The holistic framework described in this thesis, has the potential to transform large corpuses of unstructured text into an enriched, consolidated and linked network of scientific artefacts. The resulting Knowledge Base (which will evolve, improve and expand over time) enables one to quickly gain a broad and deep understanding of the current state of evidence (PIBOSO scientific artefacts) related to a medical topic.
PY  - 2021
DA  - 2021-08-24
JO  - {'id': None, 'issn_l': None, 'issn': None, 'display_name': None, 'publisher': None, 'type': None, 'url': 'https://doi.org/10.2196/preprints.33124', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Kevin M. Kallmes
AU  - Nicole Hardy
AU  - Kevin M. Kallmes
ER  - 

678.
TY  - book-chapter
ID  - https://openalex.org/W4213379757
DO  - https://doi.org/10.1007/978-3-030-64573-1_43
TI  - Artificial Intelligence in Evidence-Based Medicine
AB  - No Abstract Found
PY  - 2022
DA  - 2022-01-01
JO  - {'id': 'https://openalex.org/S4306463941', 'issn_l': None, 'issn': None, 'display_name': 'Springer International Publishing eBooks', 'publisher': 'Springer Nature', 'type': 'ebook platform', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Artur Nowak
ER  - 

679.
TY  - posted-content
ID  - https://openalex.org/W4214599167
DO  - https://doi.org/10.2196/preprints.34575
TI  - Digital learning tools for postgraduate family medicine training: Protocol for a scoping review using natural language processing (Preprint)
AB  - <sec> <title>BACKGROUND</title> Introduction The COVID-19 pandemic has highlighted the growing need for digital learning tools in postgraduate family medicine training. Family medicine departments must understand and recognize the use and effectiveness of digital tools in order to integrate them into curricula and develop effective learning tools that fill gaps and meet the learning needs of trainees. </sec> <sec> <title>OBJECTIVE</title> This scoping review will aim to explore and organize the breadth of knowledge regarding digital learning tools in family medicine training. </sec> <sec> <title>METHODS</title> This scoping review will follow the methodological framework outlined by Arksey and O’Malley, including a search of published academic literature in six databases (MEDLINE, ERIC, Education Source, Embase, Scopus, and Web of Science) and grey literature. Following title/abstract, and full text screening, characteristics and main findings of the included studies and resources will be tabulated and summarized. Thematic analysis and natural language processing will be conducted to identify common themes and synthesize the literature. Additionally, natural language processing (NLP) will be employed for bibliometric and scientometric analysis of the identified literature. </sec> <sec> <title>RESULTS</title> The search strategy has been developed and launched. Data extraction is currently underway. </sec> <sec> <title>CONCLUSIONS</title> In this scoping review, we will identify and consolidate information and evidence related to the use and effectiveness of existing digital learning tools in postgraduate family medicine training. Our findings will improve the understanding of the current landscape of digital learning tools, which will be of great value to educators and trainees interested in using existing tools, to innovators looking to design digital learning tools that meet current needs, and to researchers involved in the study of digital tools. </sec> pieces of context are reported total (e.g. “arms in columns, data elements in rows); 2x1 Contexts, where two pieces of context are given on row headers (e.g. timepoints in columns, arms nested in data elements on rows); 1x2 Contexts, where two pieces of context are given on column headers. 1x1 contexts were present in 57% of tables, compared to 20% for 2x1 and 15% for 1x2 (8% used unique/other stratification). Statistic formats were reported in the headers or descriptions of 84% of studies. </sec> <sec> <title>CONCLUSIONS</title> In this pilot survey, we found a high density of information in tables, but with major heterogeneity in presentation of measurement context. The highest-density studies reported both baseline and outcome measures in tables, with arm-level breakout, intervention labels and arm sizes present, and reported both the statistic formats and units. The measurement context formats presented here, broadly classified into three classes that cover 92% of studies, form a basis for understanding the frequency of different reporting styles, supporting automated detection of data format for extraction of metrics. </sec> across multiple abstracts. Machine Learning techniques have been widely applied in this context, especially since the recognition task can be formulated as a sentence classification task, and therefore can be addressed using classification techniques. This thesis presents a scientific artefact classifier that is trained on a novel set of discriminative features. The results indicate that this approach represents a marked improvement compared to the state of the art. In order to be able to find those related scientific artefacts (or evidence) extracted from a large number of published abstracts and then consolidate those that are conceptually similar, this thesis proposes an improved semantic similarity quantification approach. A unique set of similarity measures, which examines similarity of sentences from different syntactic, structural, and semantic features, is presented and then used to train an ensemble regressor. This ensemble can accurately predict the semantic similarity of both generic and domain-specific English sentences. The quantified similarities of scientific artefacts are then employed to consolidate and link those that are highly similar. The resulting Knowledge Base comprises a network of semantically related scientific artefacts, abstracts and publications. The holistic framework described in this thesis, has the potential to transform large corpuses of unstructured text into an enriched, consolidated and linked network of scientific artefacts. The resulting Knowledge Base (which will evolve, improve and expand over time) enables one to quickly gain a broad and deep understanding of the current state of evidence (PIBOSO scientific artefacts) related to a medical topic.
PY  - 2021
DA  - 2021-10-29
JO  - {'id': None, 'issn_l': None, 'issn': None, 'display_name': None, 'publisher': None, 'type': None, 'url': 'https://doi.org/10.2196/preprints.34575', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Hui Yan
AU  - Arya Rahgozar
AU  - Claire Sethuram
AU  - Sathya Karunananathan
AU  - Douglas Archibald
AU  - Lindsay Bradley
AU  - Ramtin Hakimjavadi
AU  - Mary Helmer-Smith
AU  - Kheira Jolin-Dahel
AU  - Tess McCutcheon
AU  - Jeffrey Puncher
AU  - Parisa Rezaiefar
AU  - Lina Shoppoff
AU  - Clare Liddy
ER  - 

680.
TY  - journal-article
ID  - https://openalex.org/W4220860813
DO  - https://doi.org/10.1016/j.heliyon.2022.e09095
TI  - Assessing author willingness to enter study information into structured data templates as part of the manuscript submission process: A pilot study
AB  - Environmental health and other researchers can benefit from automated or semi-automated summaries of data within published studies as summarizing study methods and results is time and resource intensive. Automated summaries can be designed to identify and extract details of interest pertaining to the study design, population, testing agent/intervention, or outcome (etc.). Much of the data reported across existing publications lack unified structure, standardization and machine-readable formats or may be presented in complex tables which serve as barriers that impede the development of automated data extraction methodologies.As full automation of data extraction seems unlikely soon, encouraging investigators to submit structured summaries of methods and results in standardized formats with meta-data tagging of content may be of value during the publication process. This would produce machine-readable content to facilitate automated data extraction, establish sharable data repositories, help make research data FAIR, and could improve reporting quality.A pilot study was conducted to assess the feasibility of asking participants to summarize study methods and results using a structured, web-based data extraction model as a potential workflow that could be implemented during the manuscript submission process.Eight participants entered study details and data into the Health Assessment Workplace Collaborative (HAWC). Participants were surveyed after the extraction exercise to ascertain 1) whether this extraction exercise will impact their conducting and reporting of future research, 2) the ease of data extraction, including which fields were easiest and relatively more problematic to extract and 3) the amount of time taken to perform data extractions and other related tasks. Investigators then presented participants the potential benefits of providing structured data in the format they were extracting. After this, participants were surveyed about 1) their willingness to provide structured data during the publication process and 2) whether they felt the potential application of structured data entry approaches and their implementation during the journal submission process should continue to be further explored.Routine provision of structured data that summarizes key information from research studies could reduce the amount of effort required for reusing that data in the future, such as in systematic reviews or agency scientific assessments. Our pilot study suggests that directly asking authors to provide that data, via structured templates, may be a viable approach to achieving this: participants were willing to do so, and the overall process was not prohibitively arduous. We also found some support for the hypothesis that use of study templates may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken. have been widely applied in this context, especially since the recognition task can be formulated as a sentence classification task, and therefore can be addressed using classification techniques. This thesis presents a scientific artefact classifier that is trained on a novel set of discriminative features. The results indicate that this approach represents a marked improvement compared to the state of the art. In order to be able to find those related scientific artefacts (or evidence) extracted from a large number of published abstracts and then consolidate those that are conceptually similar, this thesis proposes an improved semantic similarity quantification approach. A unique set of similarity measures, which examines similarity of sentences from different syntactic, structural, and semantic features, is presented and then used to train an ensemble regressor. This ensemble can accurately predict the semantic similarity of both generic and domain-specific English sentences. The quantified similarities of scientific artefacts are then employed to consolidate and link those that are highly similar. The resulting Knowledge Base comprises a network of semantically related scientific artefacts, abstracts and publications. The holistic framework described in this thesis, has the potential to transform large corpuses of unstructured text into an enriched, consolidated and linked network of scientific artefacts. The resulting Knowledge Base (which will evolve, improve and expand over time) enables one to quickly gain a broad and deep understanding of the current state of evidence (PIBOSO scientific artefacts) related to a medical topic.
PY  - 2022
DA  - 2022-03-01
JO  - {'id': 'https://openalex.org/S2898612692', 'issn_l': '2405-8440', 'issn': ['2405-8440'], 'display_name': 'Heliyon', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'http://www.cell.com/article/S2405844022003838/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc-nd'}
DP  - OpenAlex
AU  - A. Amina Wilkins
AU  - Amanda S. Persad
AU  - Ingrid L. Druwe
AU  - Janice C. Lee
AU  - Paul Whaley
AU  - M. Taylor
AU  - Andrew A. Shapiro
AU  - Natalie Blanton
AU  - Courtney Lemeris
AU  - Kristina A. Thayer
ER  - 

681.
TY  - journal-article
ID  - https://openalex.org/W4221116448
DO  - https://doi.org/10.1016/j.jclinepi.2022.03.019
TI  - Crowdsourcing trainees in a living systematic review provided valuable experiential learning opportunities: a mixed-methods study
AB  - <h2>Abstract</h2><h3>Objectives</h3> To understand trainee experiences of participating in a living systematic review (LSR) for rheumatoid arthritis and the potential benefits in terms of experiential evidence-based medicine (EBM) education. <h3>Study Design and Setting</h3> We conducted a mixed-methods study with trainees who participated in the LSR and who were recruited broadly from training programs in two countries. Trainees received task-specific training and completed one or more tasks in the review: assessing article eligibility, data extraction, and quality assessment. Trainees completed a survey followed by a one-on-one interview. Data were triangulated to produce broad themes. <h3>Results</h3> Twenty one trainees, most of whom had a little prior experience with systematic reviews, reported a positive overall experience. Key benefits included learning opportunities, task segmentation (ability to focus on a single task, as opposed to an entire review), working in a supportive environment, international collaboration, and incentives such as authorship or acknowledgment. Trainees reported improvement in their competency as a Scholar, Collaborator, Leader, and Medical Expert. Challenges included communication and technical difficulties and appropriate matching of tasks to trainee skillsets. <h3>Conclusion</h3> Participating in an LSR provided benefits to a wide range of trainees and may provide an opportunity for experiential EBM training, while helping LSR sustainability. exercise to ascertain 1) whether this extraction exercise will impact their conducting and reporting of future research, 2) the ease of data extraction, including which fields were easiest and relatively more problematic to extract and 3) the amount of time taken to perform data extractions and other related tasks. Investigators then presented participants the potential benefits of providing structured data in the format they were extracting. After this, participants were surveyed about 1) their willingness to provide structured data during the publication process and 2) whether they felt the potential application of structured data entry approaches and their implementation during the journal submission process should continue to be further explored.Routine provision of structured data that summarizes key information from research studies could reduce the amount of effort required for reusing that data in the future, such as in systematic reviews or agency scientific assessments. Our pilot study suggests that directly asking authors to provide that data, via structured templates, may be a viable approach to achieving this: participants were willing to do so, and the overall process was not prohibitively arduous. We also found some support for the hypothesis that use of study templates may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken. have been widely applied in this context, especially since the recognition task can be formulated as a sentence classification task, and therefore can be addressed using classification techniques. This thesis presents a scientific artefact classifier that is trained on a novel set of discriminative features. The results indicate that this approach represents a marked improvement compared to the state of the art. In order to be able to find those related scientific artefacts (or evidence) extracted from a large number of published abstracts and then consolidate those that are conceptually similar, this thesis proposes an improved semantic similarity quantification approach. A unique set of similarity measures, which examines similarity of sentences from different syntactic, structural, and semantic features, is presented and then used to train an ensemble regressor. This ensemble can accurately predict the semantic similarity of both generic and domain-specific English sentences. The quantified similarities of scientific artefacts are then employed to consolidate and link those that are highly similar. The resulting Knowledge Base comprises a network of semantically related scientific artefacts, abstracts and publications. The holistic framework described in this thesis, has the potential to transform large corpuses of unstructured text into an enriched, consolidated and linked network of scientific artefacts. The resulting Knowledge Base (which will evolve, improve and expand over time) enables one to quickly gain a broad and deep understanding of the current state of evidence (PIBOSO scientific artefacts) related to a medical topic.
PY  - 2022
DA  - 2022-03-01
JO  - {'id': 'https://openalex.org/S64418186', 'issn_l': '0895-4356', 'issn': ['1878-5921', '0895-4356'], 'display_name': 'Journal of Clinical Epidemiology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Chloe H. Lee
AU  - Megan C. Thomas
AU  - None Ejaredar
AU  - Aliya Kassam
AU  - Samuel L Whittle
AU  - Rachelle Buchbinder
AU  - Peter Tugwell
AU  - George A. Wells
AU  - Jordi Pardo Pardo
AU  - Glen Hazlewood
ER  - 

682.
TY  - journal-article
ID  - https://openalex.org/W4225326828
DO  - https://doi.org/10.2196/34575
TI  - Natural Language Processing to Identify Digital Learning Tools in Postgraduate Family Medicine: Protocol for a Scoping Review
AB  - Background The COVID-19 pandemic has highlighted the growing need for digital learning tools in postgraduate family medicine training. Family medicine departments must understand and recognize the use and effectiveness of digital tools in order to integrate them into curricula and develop effective learning tools that fill gaps and meet the learning needs of trainees. Objective This scoping review will aim to explore and organize the breadth of knowledge regarding digital learning tools in family medicine training. Methods This scoping review follows the 6 stages of the methodological framework outlined first by Arksey and O’Malley, then refined by Levac et al, including a search of published academic literature in 6 databases (MEDLINE, ERIC, Education Source, Embase, Scopus, and Web of Science) and gray literature. Following title and abstract and full text screening, characteristics and main findings of the included studies and resources will be tabulated and summarized. Thematic analysis and natural language processing (NLP) will be conducted in parallel using a 9-step approach to identify common themes and synthesize the literature. Additionally, NLP will be employed for bibliometric and scientometric analysis of the identified literature. Results The search strategy has been developed and launched. As of October 2021, we have completed stages 1, 2, and 3 of the scoping review. We identified 132 studies for inclusion through the academic literature search and 127 relevant studies in the gray literature search. Further refinement of the eligibility criteria and data extraction has been ongoing since September 2021. Conclusions In this scoping review, we will identify and consolidate information and evidence related to the use and effectiveness of existing digital learning tools in postgraduate family medicine training. Our findings will improve the understanding of the current landscape of digital learning tools, which will be of great value to educators and trainees interested in using existing tools, innovators looking to design digital learning tools that meet current needs, and researchers involved in the study of digital tools. Trial Registration OSF Registries osf.io/wju4k; https://osf.io/wju4k International Registered Report Identifier (IRRID) DERR1-10.2196/34575 future, such as in systematic reviews or agency scientific assessments. Our pilot study suggests that directly asking authors to provide that data, via structured templates, may be a viable approach to achieving this: participants were willing to do so, and the overall process was not prohibitively arduous. We also found some support for the hypothesis that use of study templates may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken. have been widely applied in this context, especially since the recognition task can be formulated as a sentence classification task, and therefore can be addressed using classification techniques. This thesis presents a scientific artefact classifier that is trained on a novel set of discriminative features. The results indicate that this approach represents a marked improvement compared to the state of the art. In order to be able to find those related scientific artefacts (or evidence) extracted from a large number of published abstracts and then consolidate those that are conceptually similar, this thesis proposes an improved semantic similarity quantification approach. A unique set of similarity measures, which examines similarity of sentences from different syntactic, structural, and semantic features, is presented and then used to train an ensemble regressor. This ensemble can accurately predict the semantic similarity of both generic and domain-specific English sentences. The quantified similarities of scientific artefacts are then employed to consolidate and link those that are highly similar. The resulting Knowledge Base comprises a network of semantically related scientific artefacts, abstracts and publications. The holistic framework described in this thesis, has the potential to transform large corpuses of unstructured text into an enriched, consolidated and linked network of scientific artefacts. The resulting Knowledge Base (which will evolve, improve and expand over time) enables one to quickly gain a broad and deep understanding of the current state of evidence (PIBOSO scientific artefacts) related to a medical topic.
PY  - 2022
DA  - 2022-05-02
JO  - {'id': 'https://openalex.org/S2739058702', 'issn_l': '1929-0748', 'issn': ['1929-0748'], 'display_name': 'JMIR Research Protocols', 'publisher': 'JMIR Publications', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Hui Yan
AU  - Arya Rahgozar
AU  - Claire Sethuram
AU  - Sathya Karunananthan
AU  - Douglas Archibald
AU  - Lindsay Bradley
AU  - Ramtin Hakimjavadi
AU  - Mary Helmer-Smith
AU  - Kheira Jolin-Dahel
AU  - Tess McCutcheon
AU  - Jeffrey Puncher
AU  - Parisa Rezaiefar
AU  - Lina Shoppoff
AU  - Clare Liddy
ER  - 

683.
TY  - book-chapter
ID  - https://openalex.org/W4232331499
DO  - https://doi.org/10.1007/978-3-319-78966-8_8
TI  - Abstracting Evidence
AB  - No Abstract Found
PY  - 2018
DA  - 2018-01-01
JO  - {'id': 'https://openalex.org/S4306463941', 'issn_l': None, 'issn': None, 'display_name': 'Springer International Publishing eBooks', 'publisher': 'Springer Nature', 'type': 'ebook platform', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Luca Testa
AU  - Mario Bollati
ER  - 

684.
TY  - posted-content
ID  - https://openalex.org/W4240818803
DO  - https://doi.org/10.2196/preprints.33219
TI  - Software Tools for Systematic Literature Review in Medicine: A Review and Feature Analysis (Preprint)
AB  - <sec> <title>BACKGROUND</title> Systematic reviews (SRs) are central to evaluating therapies but have high costs in terms of both time and money. Many software tools exist to assist with SRs, but most tools do not support the full process, and transparency and replicability of SR depends on performing and presenting evidence according to established best practices. </sec> <sec> <title>OBJECTIVE</title> In order to provide a basis for comparing and selecting between software tools that support SR, we performed a feature-by-feature comparison of SR tools. </sec> <sec> <title>METHODS</title> We searched for SR tools by reviewing any such tool listed the Systematic Review Toolbox, previous reviews of SR tools, and qualitative Google searching. We included all SR tools that were currently functional, and require no coding and excluded reference managers, desktop applications, and statistical software. The list of features to assess was populated by combining all features assessed in four previous reviews of SR tools; we also added five features (Manual Addition, Screening Automation, Dual Extraction, Living review, Public outputs) that were independently noted as best practices or enhancements of transparency/replicability. Then, two reviewers assigned binary “present/absent” assessments to all SR tools with respect to all features, and a third reviewer adjudicated all disagreements. </sec> <sec> <title>RESULTS</title> Of 49 SR tools found, 27 were excluded, leaving 22 for assessment. Twenty-eight features were assessed across 6 classes, and the inter-observer agreement was 86.46%. DistillerSR, EPPI-Reviewer Web, and Nested Knowledge support the most features (24/28, 86%), followed by Covidence, SRDB.PRO, SysRev (20/28, 71%). Six tools support fewer than half of all features assessed: SyRF, Data Abstraction Assistant, SWIFT-review, SR-Accelerator, RobotReviewer, and COVID-NMA. Notably, only 9 of 22 tools (41%) support direct search, only four (18%) offer dual extraction, and only 9 (41%) offer living/updatable reviews. </sec> <sec> <title>CONCLUSIONS</title> DistillerSR, EPPI-Reviewer Web, and Nested Knowledge each offer a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. </sec> scientific assessments. Our pilot study suggests that directly asking authors to provide that data, via structured templates, may be a viable approach to achieving this: participants were willing to do so, and the overall process was not prohibitively arduous. We also found some support for the hypothesis that use of study templates may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken. have been widely applied in this context, especially since the recognition task can be formulated as a sentence classification task, and therefore can be addressed using classification techniques. This thesis presents a scientific artefact classifier that is trained on a novel set of discriminative features. The results indicate that this approach represents a marked improvement compared to the state of the art. In order to be able to find those related scientific artefacts (or evidence) extracted from a large number of published abstracts and then consolidate those that are conceptually similar, this thesis proposes an improved semantic similarity quantification approach. A unique set of similarity measures, which examines similarity of sentences from different syntactic, structural, and semantic features, is presented and then used to train an ensemble regressor. This ensemble can accurately predict the semantic similarity of both generic and domain-specific English sentences. The quantified similarities of scientific artefacts are then employed to consolidate and link those that are highly similar. The resulting Knowledge Base comprises a network of semantically related scientific artefacts, abstracts and publications. The holistic framework described in this thesis, has the potential to transform large corpuses of unstructured text into an enriched, consolidated and linked network of scientific artefacts. The resulting Knowledge Base (which will evolve, improve and expand over time) enables one to quickly gain a broad and deep understanding of the current state of evidence (PIBOSO scientific artefacts) related to a medical topic.
PY  - 2021
DA  - 2021-08-28
JO  - {'id': None, 'issn_l': None, 'issn': None, 'display_name': None, 'publisher': None, 'type': None, 'url': 'https://doi.org/10.2196/preprints.33219', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Kathryn Cowie
AU  - Asad Rahmatullah
AU  - Nicole Hardy
AU  - Kevin M. Kallmes
AU  - Kevin M. Kallmes
ER  - 

685.
TY  - journal-article
ID  - https://openalex.org/W4244228094
DO  - https://doi.org/10.3917/heg.081.0013
TI  - Motrial, le premier méta-moteur de recherche des études cliniques sur les interventions non médicamenteuses (INM)
AB  - Le nombre de publications d&#8217;&#233;tudes cliniques &#233;valuant les interventions non m&#233;dicamenteuses (INM) augmente exponentiellement depuis 2000. Il encourage les chercheurs &#224; r&#233;aliser les revues syst&#233;matiques et les m&#233;ta-analyses attendues par les professionnels de sant&#233;, les patients et les d&#233;cideurs pour conna&#238;tre leur efficacit&#233; r&#233;elle et leur indication pertinente. Seulement, la diversification des supports de communication m&#233;dicale et scientifique, les strat&#233;gies opportunistes de publication, les informations manquantes dans les publications et la non exhaustivit&#233; des bases de donn&#233;es biom&#233;dicales rendent la recherche bibliographique complexe et &#224; risque de biais. Pour r&#233;pondre &#224; ce manque, la Plateforme CEPS propose un moteur de recherche, appel&#233; Motrial, qui permet de collecter, de trier et d&#8217;organiser les publications d&#8217;&#233;tudes cliniques sur les INM. and require no coding and excluded reference managers, desktop applications, and statistical software. The list of features to assess was populated by combining all features assessed in four previous reviews of SR tools; we also added five features (Manual Addition, Screening Automation, Dual Extraction, Living review, Public outputs) that were independently noted as best practices or enhancements of transparency/replicability. Then, two reviewers assigned binary “present/absent” assessments to all SR tools with respect to all features, and a third reviewer adjudicated all disagreements. </sec> <sec> <title>RESULTS</title> Of 49 SR tools found, 27 were excluded, leaving 22 for assessment. Twenty-eight features were assessed across 6 classes, and the inter-observer agreement was 86.46%. DistillerSR, EPPI-Reviewer Web, and Nested Knowledge support the most features (24/28, 86%), followed by Covidence, SRDB.PRO, SysRev (20/28, 71%). Six tools support fewer than half of all features assessed: SyRF, Data Abstraction Assistant, SWIFT-review, SR-Accelerator, RobotReviewer, and COVID-NMA. Notably, only 9 of 22 tools (41%) support direct search, only four (18%) offer dual extraction, and only 9 (41%) offer living/updatable reviews. </sec> <sec> <title>CONCLUSIONS</title> DistillerSR, EPPI-Reviewer Web, and Nested Knowledge each offer a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. </sec> scientific assessments. Our pilot study suggests that directly asking authors to provide that data, via structured templates, may be a viable approach to achieving this: participants were willing to do so, and the overall process was not prohibitively arduous. We also found some support for the hypothesis that use of study templates may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken. have been widely applied in this context, especially since the recognition task can be formulated as a sentence classification task, and therefore can be addressed using classification techniques. This thesis presents a scientific artefact classifier that is trained on a novel set of discriminative features. The results indicate that this approach represents a marked improvement compared to the state of the art. In order to be able to find those related scientific artefacts (or evidence) extracted from a large number of published abstracts and then consolidate those that are conceptually similar, this thesis proposes an improved semantic similarity quantification approach. A unique set of similarity measures, which examines similarity of sentences from different syntactic, structural, and semantic features, is presented and then used to train an ensemble regressor. This ensemble can accurately predict the semantic similarity of both generic and domain-specific English sentences. The quantified similarities of scientific artefacts are then employed to consolidate and link those that are highly similar. The resulting Knowledge Base comprises a network of semantically related scientific artefacts, abstracts and publications. The holistic framework described in this thesis, has the potential to transform large corpuses of unstructured text into an enriched, consolidated and linked network of scientific artefacts. The resulting Knowledge Base (which will evolve, improve and expand over time) enables one to quickly gain a broad and deep understanding of the current state of evidence (PIBOSO scientific artefacts) related to a medical topic.
PY  - 2018
DA  - 2018-01-01
JO  - {'id': 'https://openalex.org/S4210179309', 'issn_l': '2115-452X', 'issn': ['2115-452X', '2269-0530'], 'display_name': 'HEGEL', 'publisher': 'CAIRN', 'type': 'journal', 'url': 'https://www.cairn.info/load_pdf.php?ID_ARTICLE=HEG_081_0013&download=1', 'is_oa': True, 'version': 'publishedVersion', 'license': None}
DP  - OpenAlex
AU  - Grégory Ninot
AU  - Fabienne Amadori
AU  - Jérôme Maitre
AU  - Sylvie Rapior
AU  - Loric Rivière
AU  - Raphaël Trouillet
AU  - François Carbonnel
ER  - 

686.
TY  - book-chapter
ID  - https://openalex.org/W4245786806
DO  - https://doi.org/10.1007/978-3-319-25655-9_8
TI  - Abstracting Evidence
AB  - No Abstract Found
PY  - 2016
DA  - 2016-01-01
JO  - {'id': 'https://openalex.org/S4306463941', 'issn_l': None, 'issn': None, 'display_name': 'Springer International Publishing eBooks', 'publisher': 'Springer Nature', 'type': 'ebook platform', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Giuseppe Biondi-Zoccai
AU  - Giuseppe La Torre
AU  - Leonardo Roever
AU  - Fabrizio D'Ascenzo
ER  - 

687.
TY  - book-chapter
ID  - https://openalex.org/W4252331751
DO  - https://doi.org/10.1007/978-3-030-12263-8_7
TI  - Data Extraction
AB  - No Abstract Found
PY  - 2019
DA  - 2019-01-01
JO  - {'id': 'https://openalex.org/S4306463941', 'issn_l': None, 'issn': None, 'display_name': 'Springer International Publishing eBooks', 'publisher': 'Springer Nature', 'type': 'ebook platform', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - David Tod
ER  - 

688.
TY  - other
ID  - https://openalex.org/W4280533837
DO  - https://doi.org/10.1002/9781119099369.ch24
TI  - Future for Systematic Reviews and Meta‐Analysis
AB  - No Abstract Found
PY  - 2022
DA  - 2022-04-22
JO  - {'id': None, 'issn_l': None, 'issn': None, 'display_name': 'Systematic Reviews in Health Research', 'publisher': None, 'type': None, 'url': 'https://doi.org/10.1002/9781119099369.ch24', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Shah Ebrahim
AU  - Mark D. Huffman
ER  - 

689.
TY  - other
ID  - https://openalex.org/W4280570258
DO  - https://doi.org/10.1002/9781119099369.ch23
TI  - Innovations in Systematic Review Production
AB  - No Abstract Found
PY  - 2022
DA  - 2022-04-22
JO  - {'id': None, 'issn_l': None, 'issn': None, 'display_name': 'Systematic Reviews in Health Research', 'publisher': None, 'type': None, 'url': 'https://doi.org/10.1002/9781119099369.ch23', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Julian Elliott
AU  - Tari Turner
ER  - 

690.
TY  - journal-article
ID  - https://openalex.org/W4284963846
DO  - https://doi.org/10.1080/09669582.2022.2095392
TI  - Impacts of environmental communication on pro-environmental intentions and behaviours: a systematic review on nature-based tourism context
AB  - No Abstract Found
PY  - 2022
DA  - 2022-07-08
JO  - {'id': 'https://openalex.org/S167854760', 'issn_l': '0966-9582', 'issn': ['1747-7646', '0966-9582'], 'display_name': 'Journal of Sustainable Tourism', 'publisher': 'Taylor & Francis', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Mu He
AU  - Clara-Jane Blye
AU  - Elizabeth Halpenny
ER  - 

691.
TY  - book-chapter
ID  - https://openalex.org/W4286370353
DO  - https://doi.org/10.1007/978-3-319-52636-2_194
TI  - Introduction to Systematic Reviews
AB  - No Abstract Found
PY  - 2022
DA  - 2022-01-01
JO  - {'id': 'https://openalex.org/S4306463941', 'issn_l': None, 'issn': None, 'display_name': 'Springer International Publishing eBooks', 'publisher': 'Springer Nature', 'type': 'ebook platform', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Tianjing Li
AU  - Ian J. Saldanha
AU  - Karen A. Robinson
ER  - 

692.
TY  - journal-article
ID  - https://openalex.org/W4286376487
DO  - nan
TI  - Investigating the impact of weakly supervised data on text mining models of publication transparency: a case study on randomized controlled trials.
AB  - Lack of large quantities of annotated data is a major barrier in developing effective text mining models of biomedical literature. In this study, we explored weak supervision to improve the accuracy of text classification models for assessing methodological transparency of randomized controlled trial (RCT) publications. Specifically, we used Snorkel, a framework to programmatically build training sets, and UMLS-EDA, a data augmentation method that leverages a small number of labeled examples to generate new training instances, and assessed their effect on a BioBERT-based text classification model proposed for the task in previous work. Performance improvements due to weak supervision were limited and were surpassed by gains from hyperparameter tuning. Our analysis suggests that refinements to the weak supervision strategies to better deal with multi-label case could be beneficial. Our code and data are available at https://github.com/kilicogluh/CONSORT-TM/tree/master/weakSupervision. to assess was populated by combining all features assessed in four previous reviews of SR tools; we also added five features (Manual Addition, Screening Automation, Dual Extraction, Living review, Public outputs) that were independently noted as best practices or enhancements of transparency/replicability. Then, two reviewers assigned binary “present/absent” assessments to all SR tools with respect to all features, and a third reviewer adjudicated all disagreements. </sec> <sec> <title>RESULTS</title> Of 49 SR tools found, 27 were excluded, leaving 22 for assessment. Twenty-eight features were assessed across 6 classes, and the inter-observer agreement was 86.46%. DistillerSR, EPPI-Reviewer Web, and Nested Knowledge support the most features (24/28, 86%), followed by Covidence, SRDB.PRO, SysRev (20/28, 71%). Six tools support fewer than half of all features assessed: SyRF, Data Abstraction Assistant, SWIFT-review, SR-Accelerator, RobotReviewer, and COVID-NMA. Notably, only 9 of 22 tools (41%) support direct search, only four (18%) offer dual extraction, and only 9 (41%) offer living/updatable reviews. </sec> <sec> <title>CONCLUSIONS</title> DistillerSR, EPPI-Reviewer Web, and Nested Knowledge each offer a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. </sec> scientific assessments. Our pilot study suggests that directly asking authors to provide that data, via structured templates, may be a viable approach to achieving this: participants were willing to do so, and the overall process was not prohibitively arduous. We also found some support for the hypothesis that use of study templates may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken. have been widely applied in this context, especially since the recognition task can be formulated as a sentence classification task, and therefore can be addressed using classification techniques. This thesis presents a scientific artefact classifier that is trained on a novel set of discriminative features. The results indicate that this approach represents a marked improvement compared to the state of the art. In order to be able to find those related scientific artefacts (or evidence) extracted from a large number of published abstracts and then consolidate those that are conceptually similar, this thesis proposes an improved semantic similarity quantification approach. A unique set of similarity measures, which examines similarity of sentences from different syntactic, structural, and semantic features, is presented and then used to train an ensemble regressor. This ensemble can accurately predict the semantic similarity of both generic and domain-specific English sentences. The quantified similarities of scientific artefacts are then employed to consolidate and link those that are highly similar. The resulting Knowledge Base comprises a network of semantically related scientific artefacts, abstracts and publications. The holistic framework described in this thesis, has the potential to transform large corpuses of unstructured text into an enriched, consolidated and linked network of scientific artefacts. The resulting Knowledge Base (which will evolve, improve and expand over time) enables one to quickly gain a broad and deep understanding of the current state of evidence (PIBOSO scientific artefacts) related to a medical topic.
PY  - 2022
DA  - 2022-01-01
JO  - {'id': None, 'issn_l': None, 'issn': None, 'display_name': 'AMIA ... Annual Symposium proceedings. AMIA Symposium', 'publisher': None, 'type': None, 'url': 'https://pubmed.ncbi.nlm.nih.gov/35854729/', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Linh Hoanga
AU  - Lan Jiang
AU  - Halil Kilicoglu
ER  - 

693.
TY  - journal-article
ID  - https://openalex.org/W4292513334
DO  - https://doi.org/10.1007/s10995-022-03503-5
TI  - Optimizing Outcomes: A Systematic Review of Psychosocial Risk Factors Affecting Perinatal Black/African-American Women with Substance Use Disorder in the United States
AB  - No Abstract Found
PY  - 2022
DA  - 2022-08-10
JO  - {'id': 'https://openalex.org/S96699677', 'issn_l': '1092-7875', 'issn': ['1573-6628', '1092-7875'], 'display_name': 'Maternal and Child Health Journal', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Norma C. Rodriguez de Lisenko
AU  - Heewon L. Gray
AU  - Joseph Bohn
ER  - 

694.
TY  - journal-article
ID  - https://openalex.org/W4296239696
DO  - https://doi.org/10.12973/ijem.8.4.625
TI  - Number of Response Options, Reliability, Validity, and Potential Bias in the Use of the Likert Scale Education and Social Science Research: A Literature Review
AB  - &lt;p style="text-align: justify;"&gt;This study reviews 60 papers using a Likert scale and published between 2012 – 2021. Screening for literature review uses the PRISMA method. The data analysis technique was carried out through data extraction, then synthesized in a structured manner using the narrative method. To achieve credible research results at the stage of the data collection and data analysis process, a group discussion forum (FGD) was conducted. The findings show that only 10% of studies use a measurement scale with an even answer choice category (4, 6, 8, or 10 choices). In general, (90%) of research uses a measurement instrument that involves a Likert scale with odd response choices (5, 7, 9, or 11) and the most popular researchers use a Likert scale with a total response of 5 points. The use of a rating scale with an odd number of responses of more than five points (especially on a seven-point scale) is the most effective in terms of reliability and validity coefficients, but if the researcher wants to direct respondents to one side, then a scale with an even number of responses (six points) is possible. more suitable. The presence of response bias and central tendency bias can affect the validity and reliability of the use of the Likert scale instrument.&lt;/p&gt; for assessment. Twenty-eight features were assessed across 6 classes, and the inter-observer agreement was 86.46%. DistillerSR, EPPI-Reviewer Web, and Nested Knowledge support the most features (24/28, 86%), followed by Covidence, SRDB.PRO, SysRev (20/28, 71%). Six tools support fewer than half of all features assessed: SyRF, Data Abstraction Assistant, SWIFT-review, SR-Accelerator, RobotReviewer, and COVID-NMA. Notably, only 9 of 22 tools (41%) support direct search, only four (18%) offer dual extraction, and only 9 (41%) offer living/updatable reviews. </sec> <sec> <title>CONCLUSIONS</title> DistillerSR, EPPI-Reviewer Web, and Nested Knowledge each offer a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. </sec> scientific assessments. Our pilot study suggests that directly asking authors to provide that data, via structured templates, may be a viable approach to achieving this: participants were willing to do so, and the overall process was not prohibitively arduous. We also found some support for the hypothesis that use of study templates may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken. have been widely applied in this context, especially since the recognition task can be formulated as a sentence classification task, and therefore can be addressed using classification techniques. This thesis presents a scientific artefact classifier that is trained on a novel set of discriminative features. The results indicate that this approach represents a marked improvement compared to the state of the art. In order to be able to find those related scientific artefacts (or evidence) extracted from a large number of published abstracts and then consolidate those that are conceptually similar, this thesis proposes an improved semantic similarity quantification approach. A unique set of similarity measures, which examines similarity of sentences from different syntactic, structural, and semantic features, is presented and then used to train an ensemble regressor. This ensemble can accurately predict the semantic similarity of both generic and domain-specific English sentences. The quantified similarities of scientific artefacts are then employed to consolidate and link those that are highly similar. The resulting Knowledge Base comprises a network of semantically related scientific artefacts, abstracts and publications. The holistic framework described in this thesis, has the potential to transform large corpuses of unstructured text into an enriched, consolidated and linked network of scientific artefacts. The resulting Knowledge Base (which will evolve, improve and expand over time) enables one to quickly gain a broad and deep understanding of the current state of evidence (PIBOSO scientific artefacts) related to a medical topic.
PY  - 2022
DA  - 2022-11-15
JO  - {'id': 'https://openalex.org/S4210232051', 'issn_l': '2469-9632', 'issn': ['2469-9632'], 'display_name': 'International journal of educational methodology', 'publisher': 'Tayfun Yagar', 'type': 'journal', 'url': 'https://pdf.ijem.com/IJEM_8_4_625.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Imam Kusmaryono
AU  - Dyana Wijayanti
ER  - 

695.
TY  - journal-article
ID  - https://openalex.org/W4296546700
DO  - https://doi.org/10.12688/f1000research.125198.1
TI  - (Semi)automated approaches to data extraction for systematic reviews and meta-analyses in social sciences: A living review protocol
AB  - <ns3:p><ns3:bold>Background</ns3:bold>: An abundance of rapidly accumulating scientific evidence presents novel opportunities for researchers and practitioners alike, yet such advantages are often overshadowed by resource demands associated with finding and aggregating a continually expanding body of scientific information. Across social science disciplines, the use of automation technologies for timely and accurate knowledge synthesis can enhance research translation value, better inform key policy development, and expand the current understanding of human interactions, organizations, and systems. Ongoing developments surrounding automation are highly concentrated in research for evidence-based medicine with limited evidence surrounding tools and techniques applied outside of the clinical research community. Our objective is to conduct a living systematic review of automated data extraction techniques supporting systematic reviews and meta-analyses in the social sciences. The aim of this study is to extend the automation knowledge base by synthesizing current trends in the application of extraction technologies of key data elements of interest for social scientists.</ns3:p><ns3:p> <ns3:bold>Methods</ns3:bold>: The proposed study is a living systematic review employing a partial replication framework based on extant literature surrounding automation of data extraction for systematic reviews and meta-analyses. Protocol development, base review, and updates follow PRISMA standards for reporting systematic reviews. This protocol is preregistered in OSF: <ns3:ext-link xmlns:ns4="http://www.w3.org/1999/xlink" ext-link-type="uri" ns4:href="https://doi.org/10.17605/OSF.IO/YWTF9">(Semi)Automated Approaches to Data Extraction for Systematic Reviews and Meta-Analyses in Social Sciences: A Living Review Protocol</ns3:ext-link> on August 14, 2022.</ns3:p><ns3:p> <ns3:bold>Conclusions</ns3:bold>: Anticipated outcomes of this study include: (a) generate insights supporting advancement in transferring existing reliable methods to social science research; (b) provide a foundation for protocol development leading to enhancement of comparability and benchmarking standards across disciplines; and (c) uncover exigencies that spur continued value-adding innovation and interdisciplinary collaboration for the benefit of the collective systematic review community.</ns3:p> only 9 (41%) offer living/updatable reviews. </sec> <sec> <title>CONCLUSIONS</title> DistillerSR, EPPI-Reviewer Web, and Nested Knowledge each offer a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. </sec> scientific assessments. Our pilot study suggests that directly asking authors to provide that data, via structured templates, may be a viable approach to achieving this: participants were willing to do so, and the overall process was not prohibitively arduous. We also found some support for the hypothesis that use of study templates may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken. have been widely applied in this context, especially since the recognition task can be formulated as a sentence classification task, and therefore can be addressed using classification techniques. This thesis presents a scientific artefact classifier that is trained on a novel set of discriminative features. The results indicate that this approach represents a marked improvement compared to the state of the art. In order to be able to find those related scientific artefacts (or evidence) extracted from a large number of published abstracts and then consolidate those that are conceptually similar, this thesis proposes an improved semantic similarity quantification approach. A unique set of similarity measures, which examines similarity of sentences from different syntactic, structural, and semantic features, is presented and then used to train an ensemble regressor. This ensemble can accurately predict the semantic similarity of both generic and domain-specific English sentences. The quantified similarities of scientific artefacts are then employed to consolidate and link those that are highly similar. The resulting Knowledge Base comprises a network of semantically related scientific artefacts, abstracts and publications. The holistic framework described in this thesis, has the potential to transform large corpuses of unstructured text into an enriched, consolidated and linked network of scientific artefacts. The resulting Knowledge Base (which will evolve, improve and expand over time) enables one to quickly gain a broad and deep understanding of the current state of evidence (PIBOSO scientific artefacts) related to a medical topic.
PY  - 2022
DA  - 2022-09-12
JO  - {'id': 'https://openalex.org/S4210239046', 'issn_l': '2046-1402', 'issn': ['2046-1402'], 'display_name': 'F1000Research', 'publisher': 'Faculty of 1000', 'type': 'journal', 'url': 'https://f1000research.com/articles/11-1036/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Amanda Legate
AU  - Kim Nimon
ER  - 

696.
TY  - posted-content
ID  - https://openalex.org/W4297349384
DO  - https://doi.org/10.1101/2022.09.27.22280420
TI  - Label-based meta-analysis of functional brain dysconnectivity across mood and psychotic disorders
AB  - ABSTRACT BACKGROUND Psychiatric diseases are increasingly conceptualized as brain network disorders. Hundreds of resting-state functional magnetic resonance imaging (rsfMRI) studies have revealed patterns of functional brain dysconnectivity in disorders such as major depression disorder (MDD), bipolar disorder (BD) and schizophrenia (SZ). Although these disorders have been mostly studied in isolation, there is mounting evidence of shared neurobiological alterations across disorders. METHODS To uncover the nature of the relatedness between these psychiatric disorders, we conducted an innovative meta-analysis of past functional brain dysconnectivity findings obtained separately in MDD, BD and SZ. Rather than relying on a classical coordinate-based approach at the voxel level, our procedure extracted relevant neuroanatomical labels from text data and reported findings at the whole brain network level. Data were drawn from 428 rsfMRI studies investigating MDD (158 studies, 7429 patients / 7414 controls), BD (81 studies, 3330 patients / 4096 patients) and/or SZ (223 studies, 11168 patients / 11754 controls). Permutation testing revealed commonalities and specificities in hypoconnectivity and hyperconnectivity patterns across disorders. RESULTS Among 78 connections within or between 12 cortico-subcortical networks, hypoconnectivity and hyperconnectivity patterns of higher-order cognitive (default-mode, fronto-parietal, cingulo-opercular) networks were similarly observed across the 3 disorders. By contrast, dysconnectivity of lower-order (somatomotor, visual, auditory) networks in some cases differed between disorders, notably dissociating SZ from BD and MDD. CONCLUSIONS Our label-based meta-analytic approach allowed a comprehensive inclusion of prior studies. Findings suggest that functional brain dysconnectivity of higher-order cognitive networks is largely transdiagnostic in nature while that of lower-order networks may best discriminate mood and psychotic disorders, thus emphasizing the relevance of motor and sensory networks to psychiatric neuroscience. spur continued value-adding innovation and interdisciplinary collaboration for the benefit of the collective systematic review community.</ns3:p> only 9 (41%) offer living/updatable reviews. </sec> <sec> <title>CONCLUSIONS</title> DistillerSR, EPPI-Reviewer Web, and Nested Knowledge each offer a high density of SR-focused web-based tools. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. </sec> scientific assessments. Our pilot study suggests that directly asking authors to provide that data, via structured templates, may be a viable approach to achieving this: participants were willing to do so, and the overall process was not prohibitively arduous. We also found some support for the hypothesis that use of study templates may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken. have been widely applied in this context, especially since the recognition task can be formulated as a sentence classification task, and therefore can be addressed using classification techniques. This thesis presents a scientific artefact classifier that is trained on a novel set of discriminative features. The results indicate that this approach represents a marked improvement compared to the state of the art. In order to be able to find those related scientific artefacts (or evidence) extracted from a large number of published abstracts and then consolidate those that are conceptually similar, this thesis proposes an improved semantic similarity quantification approach. A unique set of similarity measures, which examines similarity of sentences from different syntactic, structural, and semantic features, is presented and then used to train an ensemble regressor. This ensemble can accurately predict the semantic similarity of both generic and domain-specific English sentences. The quantified similarities of scientific artefacts are then employed to consolidate and link those that are highly similar. The resulting Knowledge Base comprises a network of semantically related scientific artefacts, abstracts and publications. The holistic framework described in this thesis, has the potential to transform large corpuses of unstructured text into an enriched, consolidated and linked network of scientific artefacts. The resulting Knowledge Base (which will evolve, improve and expand over time) enables one to quickly gain a broad and deep understanding of the current state of evidence (PIBOSO scientific artefacts) related to a medical topic.
PY  - 2022
DA  - 2022-09-27
JO  - {'id': None, 'issn_l': None, 'issn': None, 'display_name': None, 'publisher': None, 'type': None, 'url': 'https://doi.org/10.1101/2022.09.27.22280420', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Stephanie Grot
AU  - Salima Smine
AU  - Stephane Potvin
AU  - Maeliss Darcey
AU  - Vilena Pavlov
AU  - Sarah Genon
AU  - Hien Nguyen
AU  - Pierre Orban
ER  - 

697.
TY  - journal-article
ID  - https://openalex.org/W4310065946
DO  - https://doi.org/10.1016/j.ijmedinf.2022.104928
TI  - Towards semantic-driven boolean query formalization for biomedical systematic literature reviews
AB  - Study identification refers to formalizing an effective search over biomedical databases for retrieving all eligible evidence for a systematic review. Manual construction of queries, where a user submit a search query for which a biomedical search system such as PubMed would identify the most relevant documents, has been recognized as a very costly step in conducting systematic reviews. The objective of this paper is to present an automatic query generation approach to reduce the time and labor cost of manual biomedical study identification.The evaluation benchmark is the widely adopted CLEF 2018 Technology Assisted Reviews (TAR) collection, with 72 systematic reviews on Diagnosis Test Accuracy. We use and fine-tune pre-trained language models for generating high-level key-phrases and their dense embeddings. We constructed and published a dataset consists of almost one million PubMed articles' abstracts and their keywords for fine-tuning pre-trained language models. We also use concepts that are represented in the Unified Medical Language System, UMLS, for query expansion and embedding generation. We exploit and test different clustering methods, namely Agglomerative clustering, Affinity Propagation, and K-Means, over the generated embeddings to form query clauses.Our proposed methods outperform existing state-of-the-art automatic query generation models across Precision (0.0821 compared with 0.005), Recall (0.9676 compared with 0.878), and F-measures (0.2898 compared with 0.0356 in F3 measure). In addition, some of the proposed methods can even outperform the performance of the manually crafted queries in some specific measures.The proposed model in this paper can be utilized to form an effective initial search query that can be further refined and updated by human reviewers for achieving the desired performance. For future work, we would like to explore the application of the presented query formalization methods in existing study identification methodologies and techniques, especially those that iteratively train machine learning models based on the domain experts' feedback on the relevancy of the retrieved studies. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. </sec> scientific assessments. Our pilot study suggests that directly asking authors to provide that data, via structured templates, may be a viable approach to achieving this: participants were willing to do so, and the overall process was not prohibitively arduous. We also found some support for the hypothesis that use of study templates may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken. have been widely applied in this context, especially since the recognition task can be formulated as a sentence classification task, and therefore can be addressed using classification techniques. This thesis presents a scientific artefact classifier that is trained on a novel set of discriminative features. The results indicate that this approach represents a marked improvement compared to the state of the art. In order to be able to find those related scientific artefacts (or evidence) extracted from a large number of published abstracts and then consolidate those that are conceptually similar, this thesis proposes an improved semantic similarity quantification approach. A unique set of similarity measures, which examines similarity of sentences from different syntactic, structural, and semantic features, is presented and then used to train an ensemble regressor. This ensemble can accurately predict the semantic similarity of both generic and domain-specific English sentences. The quantified similarities of scientific artefacts are then employed to consolidate and link those that are highly similar. The resulting Knowledge Base comprises a network of semantically related scientific artefacts, abstracts and publications. The holistic framework described in this thesis, has the potential to transform large corpuses of unstructured text into an enriched, consolidated and linked network of scientific artefacts. The resulting Knowledge Base (which will evolve, improve and expand over time) enables one to quickly gain a broad and deep understanding of the current state of evidence (PIBOSO scientific artefacts) related to a medical topic.
PY  - 2023
DA  - 2023-02-01
JO  - {'id': 'https://openalex.org/S53142634', 'issn_l': '1386-5056', 'issn': ['1386-5056', '1872-8243'], 'display_name': 'International Journal of Medical Informatics', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Mohammadreza Pourreza
AU  - Faezeh Ensan
ER  - 

698.
TY  - journal-article
ID  - https://openalex.org/W4312191068
DO  - https://doi.org/10.1177/09610006221142029
TI  - Defining artificial intelligence for librarians
AB  - The aim of the paper is to define Artificial Intelligence (AI) for librarians by examining general definitions of AI, analysing the umbrella of technologies that make up AI, defining types of use case by area of library operation, and then reflecting on the implications for the profession, including from an equality, diversity and inclusion perspective. The paper is a conceptual piece based on an exploratory literature review, targeting librarians interested in AI from a strategic rather than a technical perspective. Five distinct types of use cases of AI are identified for libraries, each with its own underlying drivers and barriers, and skills demands. They are applications in library back-end processes, in library services, through the creation of communities of data scientists, in data and AI literacy and in user management. Each of the different applications has its own drivers and barriers. It is hard to anticipate the impact on professional work but as information environment becomes more complex it is likely that librarians will continue to have a very important role, especially given AI’s dependence on data. However, there could be some negative impacts on equality, diversity and inclusion if AI skills are not spread widely. with 0.005), Recall (0.9676 compared with 0.878), and F-measures (0.2898 compared with 0.0356 in F3 measure). In addition, some of the proposed methods can even outperform the performance of the manually crafted queries in some specific measures.The proposed model in this paper can be utilized to form an effective initial search query that can be further refined and updated by human reviewers for achieving the desired performance. For future work, we would like to explore the application of the presented query formalization methods in existing study identification methodologies and techniques, especially those that iteratively train machine learning models based on the domain experts' feedback on the relevancy of the retrieved studies. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. </sec> scientific assessments. Our pilot study suggests that directly asking authors to provide that data, via structured templates, may be a viable approach to achieving this: participants were willing to do so, and the overall process was not prohibitively arduous. We also found some support for the hypothesis that use of study templates may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken. have been widely applied in this context, especially since the recognition task can be formulated as a sentence classification task, and therefore can be addressed using classification techniques. This thesis presents a scientific artefact classifier that is trained on a novel set of discriminative features. The results indicate that this approach represents a marked improvement compared to the state of the art. In order to be able to find those related scientific artefacts (or evidence) extracted from a large number of published abstracts and then consolidate those that are conceptually similar, this thesis proposes an improved semantic similarity quantification approach. A unique set of similarity measures, which examines similarity of sentences from different syntactic, structural, and semantic features, is presented and then used to train an ensemble regressor. This ensemble can accurately predict the semantic similarity of both generic and domain-specific English sentences. The quantified similarities of scientific artefacts are then employed to consolidate and link those that are highly similar. The resulting Knowledge Base comprises a network of semantically related scientific artefacts, abstracts and publications. The holistic framework described in this thesis, has the potential to transform large corpuses of unstructured text into an enriched, consolidated and linked network of scientific artefacts. The resulting Knowledge Base (which will evolve, improve and expand over time) enables one to quickly gain a broad and deep understanding of the current state of evidence (PIBOSO scientific artefacts) related to a medical topic.
PY  - 2022
DA  - 2022-12-22
JO  - {'id': 'https://openalex.org/S115019648', 'issn_l': '0961-0006', 'issn': ['1741-6477', '0961-0006'], 'display_name': 'Journal of Librarianship and Information Science', 'publisher': 'SAGE Publishing', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Andrew Cox
AU  - Suvodeep Mazumdar
ER  - 

699.
TY  - journal-article
ID  - https://openalex.org/W4318225126
DO  - https://doi.org/10.12688/f1000research.125198.2
TI  - (Semi)automated approaches to data extraction for systematic reviews and meta-analyses in social sciences: A living review protocol
AB  - <ns3:p><ns3:bold>Background</ns3:bold>: An abundance of rapidly accumulating scientific evidence presents novel opportunities for researchers and practitioners alike, yet such advantages are often overshadowed by resource demands associated with finding and aggregating a continually expanding body of scientific information. Across social science disciplines, the use of automation technologies for timely and accurate knowledge synthesis can enhance research translation value, better inform key policy development, and expand the current understanding of human interactions, organizations, and systems. Ongoing developments surrounding automation are highly concentrated in research for evidence-based medicine with limited evidence surrounding tools and techniques applied outside of the clinical research community. Our objective is to conduct a living systematic review of automated data extraction techniques supporting systematic reviews and meta-analyses in the social sciences. The aim of this study is to extend the automation knowledge base by synthesizing current trends in the application of extraction technologies of key data elements of interest for social scientists.</ns3:p><ns3:p> <ns3:bold>Methods</ns3:bold>: The proposed study is a living systematic review employing a partial replication framework based on extant literature surrounding automation of data extraction for systematic reviews and meta-analyses. Protocol development, base review, and updates follow PRISMA standards for reporting systematic reviews. This protocol is preregistered in OSF: <ns3:ext-link xmlns:ns4="http://www.w3.org/1999/xlink" ext-link-type="uri" ns4:href="https://doi.org/10.17605/OSF.IO/YWTF9">(Semi)Automated Approaches to Data Extraction for Systematic Reviews and Meta-Analyses in Social Sciences: A Living Review Protocol</ns3:ext-link> on August 14, 2022.</ns3:p><ns3:p> <ns3:bold>Conclusions</ns3:bold>: Anticipated outcomes of this study include: (a) generate insights supporting advancement in transferring existing reliable methods to social science research; (b) provide a foundation for protocol development leading to enhancement of comparability and benchmarking standards across disciplines; and (c) uncover exigencies that spur continued value-adding innovation and interdisciplinary collaboration for the benefit of the collective systematic review community.</ns3:p> methodologies and techniques, especially those that iteratively train machine learning models based on the domain experts' feedback on the relevancy of the retrieved studies. By transparent comparison and discussion regarding SR tool functionality, the medical community can both choose among existing software offerings and note the areas of growth needed, most notably in the support of living reviews. </sec> scientific assessments. Our pilot study suggests that directly asking authors to provide that data, via structured templates, may be a viable approach to achieving this: participants were willing to do so, and the overall process was not prohibitively arduous. We also found some support for the hypothesis that use of study templates may have halo benefits in improving the conduct and completeness of reporting of future research. While limitations in the generalizability of our findings mean that the conditions of success of templates cannot be assumed, further research into how such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken. have been widely applied in this context, especially since the recognition task can be formulated as a sentence classification task, and therefore can be addressed using classification techniques. This thesis presents a scientific artefact classifier that is trained on a novel set of discriminative features. The results indicate that this approach represents a marked improvement compared to the state of the art. In order to be able to find those related scientific artefacts (or evidence) extracted from a large number of published abstracts and then consolidate those that are conceptually similar, this thesis proposes an improved semantic similarity quantification approach. A unique set of similarity measures, which examines similarity of sentences from different syntactic, structural, and semantic features, is presented and then used to train an ensemble regressor. This ensemble can accurately predict the semantic similarity of both generic and domain-specific English sentences. The quantified similarities of scientific artefacts are then employed to consolidate and link those that are highly similar. The resulting Knowledge Base comprises a network of semantically related scientific artefacts, abstracts and publications. The holistic framework described in this thesis, has the potential to transform large corpuses of unstructured text into an enriched, consolidated and linked network of scientific artefacts. The resulting Knowledge Base (which will evolve, improve and expand over time) enables one to quickly gain a broad and deep understanding of the current state of evidence (PIBOSO scientific artefacts) related to a medical topic.
PY  - 2023
DA  - 2023-01-27
JO  - {'id': 'https://openalex.org/S4210239046', 'issn_l': '2046-1402', 'issn': ['2046-1402'], 'display_name': 'F1000Research', 'publisher': 'Faculty of 1000', 'type': 'journal', 'url': 'https://f1000research.com/articles/11-1036/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Amanda Legate
AU  - Kim Nimon
ER  - 

700.
TY  - journal-article
ID  - https://openalex.org/W4318664208
DO  - https://doi.org/10.2196/35568
TI  - Automating Quality Assessment of Medical Evidence in Systematic Reviews (Preprint)
AB  - Assessment of the quality of medical evidence available online is a critical step in the systematic review of clinical evidence. Existing tools that automate parts of this task validate the quality of individual studies but not of entire bodies of evidence, and focus on a restricted set of quality criteria.We propose a quality assessment task that consists of providing an overall quality rating for each outcome, as well as finer-grained justification for different quality criteria according to the GRADE formalisation framework. For this, we construct a new dataset and develop a machine-learning baseline system (EvidenceGRADEr). Our goal is to work towards evaluating the quality of a body of evidence (BoE) for a specific clinical question, rather than assessing the quality of individual primary studies.We algorithmically extracted quality-related data from all summaries of findings found in the Cochrane Database of Systematic Reviews (CDSR). Each BoE is defined by a set of PICO criteria (population-intervention-comparison-outcome) and assigned a quality grade (high/moderate/low/very low) together with quality criteria (justification) that influenced that decision. Different statistical data, metadata about the review, and parts of review text are extracted as support for grading each BoE. After pruning the resulting dataset with various quality checks, we used it to train several variants of a feature-rich neural model. The predictions were compared against the labels originally assigned by the authors of the systematic reviews.Our quality assessment dataset, CDSR-QoE, contains 13,440 instances, or BoEs labelled for quality, originating from 2,252 systematic reviews published on the Internet in the years 2002--2020. Based on 10-fold cross-validation, the best neural binary classifiers for quality criteria detect risk of bias at .78 F1 (P: .68, R: .92) and imprecision at .75 F1 (P: .66, R: .86), while the performance on inconsistency, indirectness and publication bias criteria is lower (F1 in the range of .3-.4). The prediction of the overall quality grade into one of the four levels results in 0.5 F1. When casting the task as a binary problem by merging the GRADE classes (high+moderate vs. low+very low quality evidence), we attain .74 F1. We also find that the results vary depending on what supporting information is provided as input to the models.There are different factors affecting the quality of evidence in the context of systematic reviews of medical evidence. Some of them (risk of bias and imprecision) can be automated with reasonable accuracy. Other quality dimensions such as indirectness, inconsistency, and publication bias prove more challenging for machine learning, largely because they are much rarer. This technology could substantially reduce reviewer workload in the future and expedite quality assessment as part of evidence synthesis. such templates might be designed and implemented does seem to have enough chance of success that it ought to be undertaken. have been widely applied in this context, especially since the recognition task can be formulated as a sentence classification task, and therefore can be addressed using classification techniques. This thesis presents a scientific artefact classifier that is trained on a novel set of discriminative features. The results indicate that this approach represents a marked improvement compared to the state of the art. In order to be able to find those related scientific artefacts (or evidence) extracted from a large number of published abstracts and then consolidate those that are conceptually similar, this thesis proposes an improved semantic similarity quantification approach. A unique set of similarity measures, which examines similarity of sentences from different syntactic, structural, and semantic features, is presented and then used to train an ensemble regressor. This ensemble can accurately predict the semantic similarity of both generic and domain-specific English sentences. The quantified similarities of scientific artefacts are then employed to consolidate and link those that are highly similar. The resulting Knowledge Base comprises a network of semantically related scientific artefacts, abstracts and publications. The holistic framework described in this thesis, has the potential to transform large corpuses of unstructured text into an enriched, consolidated and linked network of scientific artefacts. The resulting Knowledge Base (which will evolve, improve and expand over time) enables one to quickly gain a broad and deep understanding of the current state of evidence (PIBOSO scientific artefacts) related to a medical topic.
PY  - 2021
DA  - 2021-12-12
JO  - {'id': 'https://openalex.org/V17147534', 'issn_l': '1438-8871', 'issn': ['1439-4456', '1438-8871'], 'display_name': 'Journal of Medical Internet Research', 'publisher': 'JMIR Publications', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Simon Šuster
AU  - Timothy Baldwin
AU  - Jey Han Lau
AU  - Antonio Jimeno Yepes
AU  - David Martinez Iraola
AU  - Yulia Otmakhova
AU  - Karin Verspoor
ER  - 

701.
TY  - journal-article
ID  - https://openalex.org/W3000482183
DO  - https://doi.org/10.3389/fvets.2020.00011
TI  - Scoping Reviews, Systematic Reviews, and Meta-Analysis: Applications in Veterinary Medicine
AB  - Evidence-based decision making is a hallmark of effective veterinary clinical practice. Scoping reviews, systematic reviews, and meta-analyses all are methods intended to provide transparent and replicable ways of summarizing a body of research to address an important clinical or public health issue. As these methods increasingly are being used by researchers and read by practitioners, it is important to understand the distinction between these techniques and to understand what research questions they can, and cannot, address. This review provides an overview of scoping reviews, systematic reviews, and meta-analysis, including a discussion of the method and uses. A sample dataset and coding to conduct a simple meta-analysis in the statistical program R also are provided. Scoping reviews are a descriptive approach, designed to chart the literature around a particular topic. The approach involves an extensive literature search, following by a structured mapping, or charting, of the literature. The results of scoping reviews can help to inform future research by identifying gaps in the existing literature and also can be used to identify areas where there may be a sufficient depth of literature to warrant a systematic review. Systematic reviews are intended to address a specific question by identifying and summarizing all of the available research that has addressed the review question. Questions types that can be addressed by a systematic review include prevalence/incidence questions, and questions related to etiology, intervention efficacy, and diagnostic test accuracy. The systematic review process follows structured steps with multiple reviewers working in parallel to reduce the potential for bias. An extensive literature search is undertaken and, for each relevant study identified by the search, a formal extraction of data, including the effect size, and assessment of the risk of bias is performed. The results from multiple studies can be combined using meta-analysis. Meta-analysis provides a summary effect size, and allows heterogeneity of effect among studies to be quantified and explored. These evidence synthesis approaches can provide scientific input to evidence-based clinical decision-making for veterinarians and regulatory bodies, and also can be useful for identifying gaps in the literature to enhance the efficiency of future research in a topic area.
PY  - 2020
DA  - 2020-01-28
JO  - {'id': 'https://openalex.org/S2594976040', 'issn_l': '2297-1769', 'issn': ['2297-1769'], 'display_name': 'Frontiers in Veterinary Science', 'publisher': 'Frontiers Media', 'type': 'journal', 'url': 'https://doi.org/10.3389/fvets.2020.00011', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Jan M. Sargeant
AU  - Annette M. O'Connor
ER  - 

702.
TY  - journal-article
ID  - https://openalex.org/W3149778443
DO  - https://doi.org/10.1016/j.infsof.2021.106589
TI  - Automation of systematic literature reviews: A systematic literature review
AB  - Systematic Literature Review (SLR) studies aim to identify relevant primary papers, extract the required data, analyze, and synthesize results to gain further and broader insight into the investigated domain. Multiple SLR studies have been conducted in several domains, such as software engineering, medicine, and pharmacy. Conducting an SLR is a time-consuming, laborious, and costly effort. As such, several researchers developed different techniques to automate the SLR process. However, a systematic overview of the current state-of-the-art in SLR automation seems to be lacking. This study aims to collect and synthesize the studies that focus on the automation of SLR to pave the way for further research. A systematic literature review is conducted on published primary studies on the automation of SLR studies, in which 41 primary studies have been analyzed. This SLR identifies the objectives of automation studies, application domains, automated steps of the SLR, automation techniques, and challenges and solution directions. According to our study, the leading automated step is the Selection of Primary Studies . Although many studies have provided automation approaches for systematic literature reviews, no study has been found to apply automation techniques in the planning and reporting phase. Further research is needed to support the automation of the other activities of the SLR process. review question. Questions types that can be addressed by a systematic review include prevalence/incidence questions, and questions related to etiology, intervention efficacy, and diagnostic test accuracy. The systematic review process follows structured steps with multiple reviewers working in parallel to reduce the potential for bias. An extensive literature search is undertaken and, for each relevant study identified by the search, a formal extraction of data, including the effect size, and assessment of the risk of bias is performed. The results from multiple studies can be combined using meta-analysis. Meta-analysis provides a summary effect size, and allows heterogeneity of effect among studies to be quantified and explored. These evidence synthesis approaches can provide scientific input to evidence-based clinical decision-making for veterinarians and regulatory bodies, and also can be useful for identifying gaps in the literature to enhance the efficiency of future research in a topic area.
PY  - 2021
DA  - 2021-08-01
JO  - {'id': 'https://openalex.org/S205010575', 'issn_l': '0950-5849', 'issn': ['0950-5849', '1873-6025'], 'display_name': 'Information & Software Technology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Raymon van Dinter
AU  - Bedir Tekinerdogan
AU  - Daniel Rodriguez
ER  - 

703.
TY  - journal-article
ID  - https://openalex.org/W2982683456
DO  - https://doi.org/10.1186/s13643-019-1222-2
TI  - Performance and usability of machine learning for screening in systematic reviews: a comparative evaluation of three tools
AB  - Abstract Background We explored the performance of three machine learning tools designed to facilitate title and abstract screening in systematic reviews (SRs) when used to (a) eliminate irrelevant records (automated simulation) and (b) complement the work of a single reviewer (semi-automated simulation). We evaluated user experiences for each tool. Methods We subjected three SRs to two retrospective screening simulations. In each tool (Abstrackr, DistillerSR, RobotAnalyst), we screened a 200-record training set and downloaded the predicted relevance of the remaining records. We calculated the proportion missed and workload and time savings compared to dual independent screening. To test user experiences, eight research staff tried each tool and completed a survey. Results Using Abstrackr, DistillerSR, and RobotAnalyst, respectively, the median (range) proportion missed was 5 (0 to 28) percent, 97 (96 to 100) percent, and 70 (23 to 100) percent for the automated simulation and 1 (0 to 2) percent, 2 (0 to 7) percent, and 2 (0 to 4) percent for the semi-automated simulation. The median (range) workload savings was 90 (82 to 93) percent, 99 (98 to 99) percent, and 85 (85 to 88) percent for the automated simulation and 40 (32 to 43) percent, 49 (48 to 49) percent, and 35 (34 to 38) percent for the semi-automated simulation. The median (range) time savings was 154 (91 to 183), 185 (95 to 201), and 157 (86 to 172) hours for the automated simulation and 61 (42 to 82), 92 (46 to 100), and 64 (37 to 71) hours for the semi-automated simulation. Abstrackr identified 33–90% of records missed by a single reviewer. RobotAnalyst performed less well and DistillerSR provided no relative advantage. User experiences depended on user friendliness, qualities of the user interface, features and functions, trustworthiness, ease and speed of obtaining predictions, and practicality of the export file(s). Conclusions The workload savings afforded in the automated simulation came with increased risk of missing relevant records. Supplementing a single reviewer’s decisions with relevance predictions (semi-automated simulation) sometimes reduced the proportion missed, but performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable.
PY  - 2019
DA  - 2019-11-15
JO  - {'id': 'https://openalex.org/V82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://doi.org/10.1186/s13643-019-1222-2', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Allison Gates
AU  - Samantha Guitard
AU  - Jennifer Pillay
AU  - Sarah A. Elliott
AU  - Michele P Dyson
AU  - Amanda S Newton
AU  - Lisa Hartling
ER  - 

704.
TY  - journal-article
ID  - https://openalex.org/W2999536597
DO  - https://doi.org/10.1371/journal.pone.0227742
TI  - Error rates of human reviewers during abstract screening in systematic reviews
AB  - Automated approaches to improve the efficiency of systematic reviews are greatly needed. When testing any of these approaches, the criterion standard of comparison (gold standard) is usually human reviewers. Yet, human reviewers make errors in inclusion and exclusion of references.To determine citation false inclusion and false exclusion rates during abstract screening by pairs of independent reviewers. These rates can help in designing, testing and implementing automated approaches.We identified all systematic reviews conducted between 2010 and 2017 by an evidence-based practice center in the United States. Eligible reviews had to follow standard systematic review procedures with dual independent screening of abstracts and full texts, in which citation inclusion by one reviewer prompted automatic inclusion through the next level of screening. Disagreements between reviewers during full text screening were reconciled via consensus or arbitration by a third reviewer. A false inclusion or exclusion was defined as a decision made by a single reviewer that was inconsistent with the final included list of studies.We analyzed a total of 139,467 citations that underwent 329,332 inclusion and exclusion decisions from 86 unique reviewers. The final systematic reviews included 5.48% of the potential references identified through bibliographic database search (95% confidence interval (CI): 2.38% to 8.58%). After abstract screening, the total error rate (false inclusion and false exclusion) was 10.76% (95% CI: 7.43% to 14.09%).This study suggests important false inclusion and exclusion rates by human reviewers. When deciding the validity of a future automated study selection algorithm, it is important to keep in mind that the gold standard is not perfect and that achieving error rates similar to humans may be adequate and can save resources and time. advantage. User experiences depended on user friendliness, qualities of the user interface, features and functions, trustworthiness, ease and speed of obtaining predictions, and practicality of the export file(s). Conclusions The workload savings afforded in the automated simulation came with increased risk of missing relevant records. Supplementing a single reviewer’s decisions with relevance predictions (semi-automated simulation) sometimes reduced the proportion missed, but performance varied by tool and SR. Designing tools based on reviewers’ self-identified preferences may improve their compatibility with present workflows. Systematic review registration Not applicable.
PY  - 2020
DA  - 2020-01-14
JO  - {'id': 'https://openalex.org/S202381698', 'issn_l': '1932-6203', 'issn': ['1932-6203'], 'display_name': 'PLOS ONE', 'publisher': 'Public Library of Science', 'type': 'journal', 'url': 'https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0227742&type=printable', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Zhen Wang
AU  - Tarek Nayfeh
AU  - Jennifer Tetzlaff
AU  - Peter O’Blenis
AU  - Mohammad Hassan Murad
ER  - 

705.
TY  - journal-article
ID  - https://openalex.org/W3093336514
DO  - https://doi.org/10.1186/s12874-020-01129-1
TI  - An evaluation of DistillerSR’s machine learning-based prioritization tool for title/abstract screening – impact on reviewer-relevant outcomes
AB  - Abstract Background Systematic reviews often require substantial resources, partially due to the large number of records identified during searching. Although artificial intelligence may not be ready to fully replace human reviewers, it may accelerate and reduce the screening burden. Using DistillerSR (May 2020 release), we evaluated the performance of the prioritization simulation tool to determine the reduction in screening burden and time savings. Methods Using a true recall @ 95%, response sets from 10 completed systematic reviews were used to evaluate: (i) the reduction of screening burden; (ii) the accuracy of the prioritization algorithm; and (iii) the hours saved when a modified screening approach was implemented. To account for variation in the simulations, and to introduce randomness (through shuffling the references), 10 simulations were run for each review. Means, standard deviations, medians and interquartile ranges (IQR) are presented. Results Among the 10 systematic reviews, using true recall @ 95% there was a median reduction in screening burden of 47.1% (IQR: 37.5 to 58.0%). A median of 41.2% (IQR: 33.4 to 46.9%) of the excluded records needed to be screened to achieve true recall @ 95%. The median title/abstract screening hours saved using a modified screening approach at a true recall @ 95% was 29.8 h (IQR: 28.1 to 74.7 h). This was increased to a median of 36 h (IQR: 32.2 to 79.7 h) when considering the time saved not retrieving and screening full texts of the remaining 5% of records not yet identified as included at title/abstract. Among the 100 simulations (10 simulations per review), none of these 5% of records were a final included study in the systematic review. The reduction in screening burden to achieve true recall @ 95% compared to @ 100% resulted in a reduced screening burden median of 40.6% (IQR: 38.3 to 54.2%). Conclusions The prioritization tool in DistillerSR can reduce screening burden. A modified or stop screening approach once a true recall @ 95% is achieved appears to be a valid method for rapid reviews, and perhaps systematic reviews. This needs to be further evaluated in prospective reviews using the estimated recall. compatibility with present workflows. Systematic review registration Not applicable.
PY  - 2020
DA  - 2020-10-15
JO  - {'id': 'https://openalex.org/S185874209', 'issn_l': '1471-2288', 'issn': ['1471-2288'], 'display_name': 'BMC Medical Research Methodology', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://doi.org/10.1186/s12874-020-01129-1', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Candyce Hamel
AU  - Shannon Kelly
AU  - Walter P. Wodchis
AU  - Danielle B. Rice
AU  - George A. Wells
AU  - Brian Hutton
ER  - 

706.
TY  - journal-article
ID  - https://openalex.org/W3014512586
DO  - https://doi.org/10.1186/s13643-020-01324-7
TI  - Machine learning for screening prioritization in systematic reviews: comparative performance of Abstrackr and EPPI-Reviewer
AB  - Abstract Background Improving the speed of systematic review (SR) development is key to supporting evidence-based medicine. Machine learning tools which semi-automate citation screening might improve efficiency. Few studies have assessed use of screening prioritization functionality or compared two tools head to head. In this project, we compared performance of two machine-learning tools for potential use in citation screening. Methods Using 9 evidence reports previously completed by the ECRI Institute Evidence-based Practice Center team, we compared performance of Abstrackr and EPPI-Reviewer, two off-the-shelf citations screening tools, for identifying relevant citations. Screening prioritization functionality was tested for 3 large reports and 6 small reports on a range of clinical topics. Large report topics were imaging for pancreatic cancer, indoor allergen reduction, and inguinal hernia repair. We trained Abstrackr and EPPI-Reviewer and screened all citations in 10% increments. In Task 1, we inputted whether an abstract was ordered for full-text screening; in Task 2, we inputted whether an abstract was included in the final report. For both tasks, screening continued until all studies ordered and included for the actual reports were identified. We assessed potential reductions in hypothetical screening burden (proportion of citations screened to identify all included studies) offered by each tool for all 9 reports. Results For the 3 large reports, both EPPI-Reviewer and Abstrackr performed well with potential reductions in screening burden of 4 to 49% (Abstrackr) and 9 to 60% (EPPI-Reviewer). Both tools had markedly poorer performance for 1 large report (inguinal hernia), possibly due to its heterogeneous key questions. Based on McNemar’s test for paired proportions in the 3 large reports, EPPI-Reviewer outperformed Abstrackr for identifying articles ordered for full-text review, but Abstrackr performed better in 2 of 3 reports for identifying articles included in the final report. For small reports, both tools provided benefits but EPPI-Reviewer generally outperformed Abstrackr in both tasks, although these results were often not statistically significant. Conclusions Abstrackr and EPPI-Reviewer performed well, but prioritization accuracy varied greatly across reports. Our work suggests screening prioritization functionality is a promising modality offering efficiency gains without giving up human involvement in the screening process. recall. compatibility with present workflows. Systematic review registration Not applicable.
PY  - 2020
DA  - 2020-04-02
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://doi.org/10.1186/s13643-020-01324-7', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Amy Tsou
AU  - Jonathan Treadwell
AU  - Eileen Erinoff
AU  - Karen M Schoelles
ER  - 

707.
TY  - journal-article
ID  - https://openalex.org/W3029811621
DO  - https://doi.org/10.1186/s12874-020-01031-w
TI  - The semi-automation of title and abstract screening: a retrospective exploration of ways to leverage Abstrackr’s relevance predictions in systematic and rapid reviews
AB  - Abstract Background We investigated the feasibility of using a machine learning tool’s relevance predictions to expedite title and abstract screening. Methods We subjected 11 systematic reviews and six rapid reviews to four retrospective screening simulations (automated and semi-automated approaches to single-reviewer and dual independent screening) in Abstrackr, a freely-available machine learning software. We calculated the proportion missed, workload savings, and time savings compared to single-reviewer and dual independent screening by human reviewers. We performed cited reference searches to determine if missed studies would be identified via reference list scanning. Results For systematic reviews, the semi-automated, dual independent screening approach provided the best balance of time savings (median (range) 20 (3–82) hours) and reliability (median (range) proportion missed records, 1 (0–14)%). The cited references search identified 59% ( n = 10/17) of the records missed. For the rapid reviews, the fully and semi-automated approaches saved time (median (range) 9 (2–18) hours and 3 (1–10) hours, respectively), but less so than for the systematic reviews. The median (range) proportion missed records for both approaches was 6 (0–22)%. Conclusion Using Abstrackr to assist one of two reviewers in systematic reviews saves time with little risk of missing relevant records. Many missed records would be identified via other means. For the 3 large reports, both EPPI-Reviewer and Abstrackr performed well with potential reductions in screening burden of 4 to 49% (Abstrackr) and 9 to 60% (EPPI-Reviewer). Both tools had markedly poorer performance for 1 large report (inguinal hernia), possibly due to its heterogeneous key questions. Based on McNemar’s test for paired proportions in the 3 large reports, EPPI-Reviewer outperformed Abstrackr for identifying articles ordered for full-text review, but Abstrackr performed better in 2 of 3 reports for identifying articles included in the final report. For small reports, both tools provided benefits but EPPI-Reviewer generally outperformed Abstrackr in both tasks, although these results were often not statistically significant. Conclusions Abstrackr and EPPI-Reviewer performed well, but prioritization accuracy varied greatly across reports. Our work suggests screening prioritization functionality is a promising modality offering efficiency gains without giving up human involvement in the screening process. recall. compatibility with present workflows. Systematic review registration Not applicable.
PY  - 2020
DA  - 2020-06-03
JO  - {'id': 'https://openalex.org/S185874209', 'issn_l': '1471-2288', 'issn': ['1471-2288'], 'display_name': 'BMC Medical Research Methodology', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://doi.org/10.1186/s12874-020-01031-w', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Allison Gates
AU  - Michelle Gates
AU  - Meghan Sebastianski
AU  - Samantha Guitard
AU  - Sarah A. Elliott
AU  - Lisa Hartling
ER  - 

708.
TY  - journal-article
ID  - https://openalex.org/W2987303508
DO  - https://doi.org/10.1186/s13643-019-1221-3
TI  - Assessing the accuracy of machine-assisted abstract screening with DistillerAI: a user study
AB  - Abstract Background Web applications that employ natural language processing technologies to support systematic reviewers during abstract screening have become more common. The goal of our project was to conduct a case study to explore a screening approach that temporarily replaces a human screener with a semi-automated screening tool. Methods We evaluated the accuracy of the approach using DistillerAI as a semi-automated screening tool. A published comparative effectiveness review served as the reference standard. Five teams of professional systematic reviewers screened the same 2472 abstracts in parallel. Each team trained DistillerAI with 300 randomly selected abstracts that the team screened dually. For all remaining abstracts, DistillerAI replaced one human screener and provided predictions about the relevance of records. A single reviewer also screened all remaining abstracts. A second human screener resolved conflicts between the single reviewer and DistillerAI. We compared the decisions of the machine-assisted approach, single-reviewer screening, and screening with DistillerAI alone against the reference standard. Results The combined sensitivity of the machine-assisted screening approach across the five screening teams was 78% (95% confidence interval [CI], 66 to 90%), and the combined specificity was 95% (95% CI, 92 to 97%). By comparison, the sensitivity of single-reviewer screening was similar (78%; 95% CI, 66 to 89%); however, the sensitivity of DistillerAI alone was substantially worse (14%; 95% CI, 0 to 31%) than that of the machine-assisted screening approach. Specificities for single-reviewer screening and DistillerAI were 94% (95% CI, 91 to 97%) and 98% (95% CI, 97 to 100%), respectively. Machine-assisted screening and single-reviewer screening had similar areas under the curve (0.87 and 0.86, respectively); by contrast, the area under the curve for DistillerAI alone was just slightly better than chance (0.56). The interrater agreement between human screeners and DistillerAI with a prevalence-adjusted kappa was 0.85 (95% CI, 0.84 to 0.86%). Conclusions The accuracy of DistillerAI is not yet adequate to replace a human screener temporarily during abstract screening for systematic reviews. Rapid reviews, which do not require detecting the totality of the relevant evidence, may find semi-automation tools to have greater utility than traditional systematic reviews. the screening process. recall. compatibility with present workflows. Systematic review registration Not applicable.
PY  - 2019
DA  - 2019-11-14
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://doi.org/10.1186/s13643-019-1221-3', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Gerald Gartlehner
AU  - Gernot Wagner
AU  - Linda J Lux
AU  - Lisa Affengruber
AU  - Andreea Dobrescu
AU  - Angela Kaminski-Hartenthaler
AU  - Meera Viswanathan
ER  - 

709.
TY  - journal-article
ID  - https://openalex.org/W3021591766
DO  - https://doi.org/10.1186/s13643-020-01351-4
TI  - A focus on cross-purpose tools, automated recognition of study design in multiple disciplines, and evaluation of automation tools: a summary of significant discussions at the fourth meeting of the International Collaboration for Automation of Systematic Reviews (ICASR)
AB  - Abstract The fourth meeting of the International Collaboration for Automation of Systematic Reviews (ICASR) was held 5–6 November 2019 in The Hague, the Netherlands. ICASR is an interdisciplinary group whose goal is to maximize the use of technology for conducting rapid, accurate, and efficient systematic reviews of scientific evidence. The group seeks to facilitate the development and acceptance of automated techniques for systematic reviews. In 2018, the major themes discussed were the transferability of automation tools (i.e., tools developed for other purposes that might be used by systematic reviewers), the automated recognition of study design in multiple disciplines and applications, and approaches for the evaluation of automation tools. screener and provided predictions about the relevance of records. A single reviewer also screened all remaining abstracts. A second human screener resolved conflicts between the single reviewer and DistillerAI. We compared the decisions of the machine-assisted approach, single-reviewer screening, and screening with DistillerAI alone against the reference standard. Results The combined sensitivity of the machine-assisted screening approach across the five screening teams was 78% (95% confidence interval [CI], 66 to 90%), and the combined specificity was 95% (95% CI, 92 to 97%). By comparison, the sensitivity of single-reviewer screening was similar (78%; 95% CI, 66 to 89%); however, the sensitivity of DistillerAI alone was substantially worse (14%; 95% CI, 0 to 31%) than that of the machine-assisted screening approach. Specificities for single-reviewer screening and DistillerAI were 94% (95% CI, 91 to 97%) and 98% (95% CI, 97 to 100%), respectively. Machine-assisted screening and single-reviewer screening had similar areas under the curve (0.87 and 0.86, respectively); by contrast, the area under the curve for DistillerAI alone was just slightly better than chance (0.56). The interrater agreement between human screeners and DistillerAI with a prevalence-adjusted kappa was 0.85 (95% CI, 0.84 to 0.86%). Conclusions The accuracy of DistillerAI is not yet adequate to replace a human screener temporarily during abstract screening for systematic reviews. Rapid reviews, which do not require detecting the totality of the relevant evidence, may find semi-automation tools to have greater utility than traditional systematic reviews. the screening process. recall. compatibility with present workflows. Systematic review registration Not applicable.
PY  - 2020
DA  - 2020-05-04
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://systematicreviewsjournal.biomedcentral.com/track/pdf/10.1186/s13643-020-01351-4', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Annette M. O'Connor
AU  - Paul Glasziou
AU  - M. Taylor
AU  - James D. Thomas
AU  - René Spijker
AU  - Mary Leigh Wolfe
ER  - 

710.
TY  - journal-article
ID  - https://openalex.org/W2932069670
DO  - https://doi.org/10.1186/s13643-019-0974-z
TI  - Editorial: Systematic review automation thematic series
AB  - No Abstract Found
PY  - 2019
DA  - 2019-03-11
JO  - {'id': 'https://openalex.org/V82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://doi.org/10.1186/s13643-019-0974-z', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Joseph Lau
ER  - 

711.
TY  - journal-article
ID  - https://openalex.org/W3143985904
DO  - https://doi.org/10.1186/s13643-021-01635-3
TI  - Research Screener: a machine learning tool to semi-automate abstract screening for systematic reviews
AB  - Systematic reviews and meta-analyses provide the highest level of evidence to help inform policy and practice, yet their rigorous nature is associated with significant time and economic demands. The screening of titles and abstracts is the most time consuming part of the review process with analysts required review thousands of articles manually, taking on average 33 days. New technologies aimed at streamlining the screening process have provided initial promising findings, yet there are limitations with current approaches and barriers to the widespread use of these tools. In this paper, we introduce and report initial evidence on the utility of Research Screener, a semi-automated machine learning tool to facilitate abstract screening.Three sets of analyses (simulation, interactive and sensitivity) were conducted to provide evidence of the utility of the tool through both simulated and real-world examples.Research Screener delivered a workload saving of between 60 and 96% across nine systematic reviews and two scoping reviews. Findings from the real-world interactive analysis demonstrated a time saving of 12.53 days compared to the manual screening, which equates to a financial saving of USD 2444. Conservatively, our results suggest that analysts who scan 50% of the total pool of articles identified via a systematic search are highly likely to have identified 100% of eligible papers.In light of these findings, Research Screener is able to reduce the burden for researchers wishing to conduct a comprehensive systematic review without reducing the scientific rigour for which they strive to achieve. 98% (95% CI, 97 to 100%), respectively. Machine-assisted screening and single-reviewer screening had similar areas under the curve (0.87 and 0.86, respectively); by contrast, the area under the curve for DistillerAI alone was just slightly better than chance (0.56). The interrater agreement between human screeners and DistillerAI with a prevalence-adjusted kappa was 0.85 (95% CI, 0.84 to 0.86%). Conclusions The accuracy of DistillerAI is not yet adequate to replace a human screener temporarily during abstract screening for systematic reviews. Rapid reviews, which do not require detecting the totality of the relevant evidence, may find semi-automation tools to have greater utility than traditional systematic reviews. the screening process. recall. compatibility with present workflows. Systematic review registration Not applicable.
PY  - 2021
DA  - 2021-04-01
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://systematicreviewsjournal.biomedcentral.com/counter/pdf/10.1186/s13643-021-01635-3', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Kevin Chai
AU  - Robin L. J. Lines
AU  - Daniel F. Gucciardi
AU  - Leo Ng
ER  - 

712.
TY  - journal-article
ID  - https://openalex.org/W3093359890
DO  - https://doi.org/10.1186/s12874-020-01143-3
TI  - Development, testing and use of data extraction forms in systematic reviews: a review of methodological guidance
AB  - Abstract Background Data extraction forms link systematic reviews with primary research and provide the foundation for appraising, analysing, summarising and interpreting a body of evidence. This makes their development, pilot testing and use a crucial part of the systematic reviews process. Several studies have shown that data extraction errors are frequent in systematic reviews, especially regarding outcome data. Methods We reviewed guidance on the development and pilot testing of data extraction forms and the data extraction process. We reviewed four types of sources: 1) methodological handbooks of systematic review organisations (SRO); 2) textbooks on conducting systematic reviews; 3) method documents from health technology assessment (HTA) agencies and 4) journal articles. HTA documents were retrieved in February 2019 and database searches conducted in December 2019. One author extracted the recommendations and a second author checked them for accuracy. Results are presented descriptively. Results Our analysis includes recommendations from 25 documents: 4 SRO handbooks, 11 textbooks, 5 HTA method documents and 5 journal articles. Across these sources the most common recommendations on form development are to use customized or adapted standardised extraction forms (14/25); provide detailed instructions on their use (10/25); ensure clear and consistent coding and response options (9/25); plan in advance which data are needed (9/25); obtain additional data if required (8/25); and link multiple reports of the same study (8/25). The most frequent recommendations on piloting extractions forms are that forms should be piloted on a sample of studies (18/25); and that data extractors should be trained in the use of the forms (7/25). The most frequent recommendations on data extraction are that extraction should be conducted by at least two people (17/25); that independent parallel extraction should be used (11/25); and that procedures to resolve disagreements between data extractors should be in place (14/25). Conclusions Overall, our results suggest a lack of comprehensiveness of recommendations. This may be particularly problematic for less experienced reviewers. Limitations of our method are the scoping nature of the review and that we did not analyse internal documents of health technology agencies. greater utility than traditional systematic reviews. the screening process. recall. compatibility with present workflows. Systematic review registration Not applicable.
PY  - 2020
DA  - 2020-10-19
JO  - {'id': 'https://openalex.org/V185874209', 'issn_l': '1471-2288', 'issn': ['1471-2288'], 'display_name': 'BMC Medical Research Methodology', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://bmcmedresmethodol.biomedcentral.com/track/pdf/10.1186/s12874-020-01143-3', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Roland Brian Büchter
AU  - Alina Weise
AU  - Dawid Pieper
ER  - 

713.
TY  - journal-article
ID  - https://openalex.org/W3024831471
DO  - https://doi.org/10.1186/s12874-020-01004-z
TI  - Current methods for development of rapid reviews about diagnostic tests: an international survey
AB  - Abstract Background Rapid reviews (RRs) have emerged as an efficient alternative to time-consuming systematic reviews—they can help meet the demand for accelerated evidence synthesis to inform decision-making in healthcare. The synthesis of diagnostic evidence has important methodological challenges. Here, we performed an international survey to identify the current practice of producing RRs for diagnostic tests. Methods We developed and administered an online survey inviting institutions that perform RRs of diagnostic tests from all over the world. Results All participants ( N = 25) reported the implementation of one or more methods to define the scope of the RR; however, only one strategy (defining a structured question) was used by ≥90% of participants. All participants used at least one methodological shortcut including the use of a previous review as a starting point (92%) and the use of limits on the search (96%). Parallelization and automation of review tasks were not extensively used (48 and 20%, respectively). Conclusion Our survey indicates a greater use of shortcuts and limits for conducting diagnostic test RRs versus the results of a recent scoping review analyzing published RRs. Several shortcuts are used without knowing how their implementation affects the results of the evidence synthesis in the setting of diagnostic test reviews. Thus, a structured evaluation of the challenges and implications of the adoption of these RR methods is warranted. frequent recommendations on piloting extractions forms are that forms should be piloted on a sample of studies (18/25); and that data extractors should be trained in the use of the forms (7/25). The most frequent recommendations on data extraction are that extraction should be conducted by at least two people (17/25); that independent parallel extraction should be used (11/25); and that procedures to resolve disagreements between data extractors should be in place (14/25). Conclusions Overall, our results suggest a lack of comprehensiveness of recommendations. This may be particularly problematic for less experienced reviewers. Limitations of our method are the scoping nature of the review and that we did not analyse internal documents of health technology agencies. greater utility than traditional systematic reviews. the screening process. recall. compatibility with present workflows. Systematic review registration Not applicable.
PY  - 2020
DA  - 2020-05-13
JO  - {'id': 'https://openalex.org/S185874209', 'issn_l': '1471-2288', 'issn': ['1471-2288'], 'display_name': 'BMC Medical Research Methodology', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://bmcmedresmethodol.biomedcentral.com/track/pdf/10.1186/s12874-020-01004-z', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Ingrid Arevalo-Rodriguez
AU  - Karen R Steingart
AU  - Andrea C. Tricco
AU  - Barbara Nussbaumer-Streit
AU  - David Kaunelis
AU  - Pablo Alonso-Coello
AU  - Susan Baxter
AU  - Patrick M.M. Bossuyt
AU  - Jose I. Emparanza
AU  - Javier Zamora
ER  - 

714.
TY  - journal-article
ID  - https://openalex.org/W3098386911
DO  - https://doi.org/10.1002/cl2.1129
TI  - On the use of computer‐assistance to facilitate systematic mapping
AB  - The volume of published academic research is growing rapidly and this new era of “big literature” poses new challenges to evidence synthesis, pushing traditional, manual methods of evidence synthesis to their limits. New technology developments, including machine learning, are likely to provide solutions to the problem of information overload and allow scaling of systematic maps to large and even vast literatures. In this paper, we outline how systematic maps lend themselves well to automation and computer‐assistance. We believe that it is a major priority to consolidate efforts to develop and validate efficient, rigorous and robust applications of these novel technologies, ensuring the challenges of big literature do not prevent the future production of systematic maps. at least one methodological shortcut including the use of a previous review as a starting point (92%) and the use of limits on the search (96%). Parallelization and automation of review tasks were not extensively used (48 and 20%, respectively). Conclusion Our survey indicates a greater use of shortcuts and limits for conducting diagnostic test RRs versus the results of a recent scoping review analyzing published RRs. Several shortcuts are used without knowing how their implementation affects the results of the evidence synthesis in the setting of diagnostic test reviews. Thus, a structured evaluation of the challenges and implications of the adoption of these RR methods is warranted. frequent recommendations on piloting extractions forms are that forms should be piloted on a sample of studies (18/25); and that data extractors should be trained in the use of the forms (7/25). The most frequent recommendations on data extraction are that extraction should be conducted by at least two people (17/25); that independent parallel extraction should be used (11/25); and that procedures to resolve disagreements between data extractors should be in place (14/25). Conclusions Overall, our results suggest a lack of comprehensiveness of recommendations. This may be particularly problematic for less experienced reviewers. Limitations of our method are the scoping nature of the review and that we did not analyse internal documents of health technology agencies. greater utility than traditional systematic reviews. the screening process. recall. compatibility with present workflows. Systematic review registration Not applicable.
PY  - 2020
DA  - 2020-12-01
JO  - {'id': 'https://openalex.org/S2739193000', 'issn_l': '1891-1803', 'issn': ['1891-1803'], 'display_name': 'Campbell Systematic Reviews', 'publisher': 'The Campbell Collaboration', 'type': 'journal', 'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/cl2.1129', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Neal R. Haddaway
AU  - Max Callaghan
AU  - Alexandra B. Collins
AU  - William F. Lamb
AU  - Jan C. Minx
AU  - James D. Thomas
AU  - Denny John
ER  - 

715.
TY  - journal-article
ID  - https://openalex.org/W3168270921
DO  - https://doi.org/10.3389/frma.2021.685591
TI  - SYMBALS: A Systematic Review Methodology Blending Active Learning and Snowballing
AB  - Research output has grown significantly in recent years, often making it difficult to see the forest for the trees. Systematic reviews are the natural scientific tool to provide clarity in these situations. However, they are protracted processes that require expertise to execute. These are problematic characteristics in a constantly changing environment. To solve these challenges, we introduce an innovative systematic review methodology: SYMBALS. SYMBALS blends the traditional method of backward snowballing with the machine learning method of active learning. We applied our methodology in a case study, demonstrating its ability to swiftly yield broad research coverage. We proved the validity of our method using a replication study, where SYMBALS was shown to accelerate title and abstract screening by a factor of 6. Additionally, four benchmarking experiments demonstrated the ability of our methodology to outperform the state-of-the-art systematic review methodology FAST 2 . and automation of review tasks were not extensively used (48 and 20%, respectively). Conclusion Our survey indicates a greater use of shortcuts and limits for conducting diagnostic test RRs versus the results of a recent scoping review analyzing published RRs. Several shortcuts are used without knowing how their implementation affects the results of the evidence synthesis in the setting of diagnostic test reviews. Thus, a structured evaluation of the challenges and implications of the adoption of these RR methods is warranted. frequent recommendations on piloting extractions forms are that forms should be piloted on a sample of studies (18/25); and that data extractors should be trained in the use of the forms (7/25). The most frequent recommendations on data extraction are that extraction should be conducted by at least two people (17/25); that independent parallel extraction should be used (11/25); and that procedures to resolve disagreements between data extractors should be in place (14/25). Conclusions Overall, our results suggest a lack of comprehensiveness of recommendations. This may be particularly problematic for less experienced reviewers. Limitations of our method are the scoping nature of the review and that we did not analyse internal documents of health technology agencies. greater utility than traditional systematic reviews. the screening process. recall. compatibility with present workflows. Systematic review registration Not applicable.
PY  - 2021
DA  - 2021-05-28
JO  - {'id': 'https://openalex.org/S2596295431', 'issn_l': '2504-0537', 'issn': ['2504-0537'], 'display_name': 'Frontiers in Research Metrics and Analytics', 'publisher': 'Frontiers Media', 'type': 'journal', 'url': 'https://www.frontiersin.org/articles/10.3389/frma.2021.685591/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Max van Haastrecht
AU  - Injy Sarhan
AU  - Bilge Yigit Ozkan
AU  - Matthieu J. S. Brinkhuis
AU  - Marco Spruit
ER  - 

716.
TY  - journal-article
ID  - https://openalex.org/W3104156511
DO  - https://doi.org/10.1186/s13643-020-01528-x
TI  - Decoding semi-automated title-abstract screening: findings from a convenience sample of reviews
AB  - Abstract Background We evaluated the benefits and risks of using the Abstrackr machine learning (ML) tool to semi-automate title-abstract screening and explored whether Abstrackr’s predictions varied by review or study-level characteristics. Methods For a convenience sample of 16 reviews for which adequate data were available to address our objectives (11 systematic reviews and 5 rapid reviews), we screened a 200-record training set in Abstrackr and downloaded the relevance (relevant or irrelevant) of the remaining records, as predicted by the tool. We retrospectively simulated the liberal-accelerated screening approach. We estimated the time savings and proportion missed compared with dual independent screening. For reviews with pairwise meta-analyses, we evaluated changes to the pooled effects after removing the missed studies. We explored whether the tool’s predictions varied by review and study-level characteristics. Results Using the ML-assisted liberal-accelerated approach, we wrongly excluded 0 to 3 (0 to 14%) records that were included in the final reports, but saved a median (IQR) 26 (9, 42) h of screening time. One missed study was included in eight pairwise meta-analyses in one systematic review. The pooled effect for just one of those meta-analyses changed considerably (from MD (95% CI) − 1.53 (− 2.92, − 0.15) to − 1.17 (− 2.70, 0.36)). Of 802 records in the final reports, 87% were correctly predicted as relevant. The correctness of the predictions did not differ by review (systematic or rapid, P = 0.37) or intervention type (simple or complex, P = 0.47). The predictions were more often correct in reviews with multiple (89%) vs. single (83%) research questions ( P = 0.01), or that included only trials (95%) vs. multiple designs (86%) ( P = 0.003). At the study level, trials (91%), mixed methods (100%), and qualitative (93%) studies were more often correctly predicted as relevant compared with observational studies (79%) or reviews (83%) ( P = 0.0006). Studies at high or unclear (88%) vs. low risk of bias (80%) ( P = 0.039), and those published more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2020
DA  - 2020-11-27
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://systematicreviewsjournal.biomedcentral.com/track/pdf/10.1186/s13643-020-01528-x', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Allison Gates
AU  - Michelle Gates
AU  - D. DaRosa
AU  - Sarah A. Elliott
AU  - Jennifer Pillay
AU  - Sholeh Rahman
AU  - Ben Vandermeer
AU  - Lisa Hartling
ER  - 

717.
TY  - journal-article
ID  - https://openalex.org/W3165198619
DO  - https://doi.org/10.1016/j.eswa.2021.115261
TI  - A decision support system for automating document retrieval and citation screening
AB  - • A Decision Support System for two steps in the Systematic Review process. • Automated document retrieval and citation screening. • Implementation of a Multi-Channel CNN model into the system. • A quantitative analysis of the effect of the system. • Our system is available at https://github.com/rvdinter/decision-support-system . The systematic literature review (SLR) process includes several steps to collect secondary data and analyze it to answer research questions. In this context, the document retrieval and primary study selection steps are heavily intertwined and known for their repetitiveness, high human workload, and difficulty identifying all relevant literature. This study aims to reduce human workload and error of the document retrieval and primary study selection processes using a decision support system (DSS). An open-source DSS is proposed that supports the document retrieval step, dataset preprocessing, and citation classification. The DSS is domain-independent, as it has proven to carefully select an article’s relevance based solely on the title and abstract. These features can be consistently retrieved from scientific database APIs. Additionally, the DSS is designed to run in the cloud without any required programming knowledge for reviewers. A Multi-Channel CNN architecture is implemented to support the citation screening process. With the provided DSS, reviewers can fill in their search strategy and manually label only a subset of the citations. The remaining unlabeled citations are automatically classified and sorted based on probability. It was shown that for four out of five review datasets, the DSS's use achieved significant workload savings of at least 10%. The cross-validation results show that the system provides consistent results up to 88.3% of work saved during citation screening. In two cases, our model yielded a better performance over the benchmark review datasets. As such, the proposed approach can assist the development of systematic literature reviews independent of the domain. The proposed DSS is effective and can substantially decrease the document retrieval and citation screening steps' workload and error rate. ( P = 0.039), and those published more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2021
DA  - 2021-11-15
JO  - {'id': 'https://openalex.org/S13144211', 'issn_l': '0957-4174', 'issn': ['1873-6793', '0957-4174'], 'display_name': 'Expert Systems With Applications', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'https://doi.org/10.1016/j.eswa.2021.115261', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Raymon van Dinter
AU  - Daniel Rodriguez
AU  - Bedir Tekinerdogan
ER  - 

718.
TY  - journal-article
ID  - https://openalex.org/W3033427052
DO  - https://doi.org/10.1097/gco.0000000000000643
TI  - Artificial intelligence and automation of systematic reviews in women's health
AB  - Purpose of review Support Evidence-based women's healthcare is underpinned by systematic reviews and guidelines. Generating an evidence synthesis to support guidance for clinical practice is a time-consuming and labour-intensive activity that delays transfer of research into practice. Artificial intelligence has the potential to rapidly collate, combine, and update high-quality medical evidence with accuracy and precision, and without bias. collect Recent findings and This article describes the main fields of artificial intelligence with examples of its application to systematic reviews. These include the capabilities of processing natural language texts, retrieving information, reasoning, and learning. The complementarity and interconnection of the various artificial intelligence techniques can be harnessed to solve difficult problems in automation of reviews. Computer science can advance evidence-based medicine through development, testing, and refinement of artificial intelligence tools to deploy automation, creating 'living' evidence syntheses. The Summary is Groundbreaking, high-quality, and impactful artificial intelligence will accelerate the transfer of individual research studies seamlessly into evidence syntheses for contemporaneously improving the quality of healthcare. scientific database APIs. Additionally, the DSS is designed to run in the cloud without any required programming knowledge for reviewers. A Multi-Channel CNN architecture is implemented to support the citation screening process. With the provided DSS, reviewers can fill in their search strategy and manually label only a subset of the citations. The remaining unlabeled citations are automatically classified and sorted based on probability. It was shown that for four out of five review datasets, the DSS's use achieved significant workload savings of at least 10%. The cross-validation results show that the system provides consistent results up to 88.3% of work saved during citation screening. In two cases, our model yielded a better performance over the benchmark review datasets. As such, the proposed approach can assist the development of systematic literature reviews independent of the domain. The proposed DSS is effective and can substantially decrease the document retrieval and citation screening steps' workload and error rate. ( P = 0.039), and those published more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2020
DA  - 2020-10-01
JO  - {'id': 'https://openalex.org/S203280300', 'issn_l': '1040-872X', 'issn': ['1080-8256', '1040-872X', '1473-656X'], 'display_name': 'Current Opinion in Obstetrics & Gynecology', 'publisher': 'Lippincott Williams & Wilkins', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Carmen Amezcua-Prieto
AU  - Juan M. Fernández-Luna
AU  - Juan F Huete-Guadix
AU  - Aurora Bueno-Cavanillas
AU  - Khalid Mohammed Khan
ER  - 

719.
TY  - journal-article
ID  - https://openalex.org/W3144391370
DO  - https://doi.org/10.1186/s13643-021-01632-6
TI  - Successful incorporation of single reviewer assessments during systematic review screening: development and validation of sensitivity and work-saved of an algorithm that considers exclusion criteria and count.
AB  - Accepted systematic review (SR) methodology requires citation screening by two reviewers to maximise retrieval of eligible studies. We hypothesized that records could be excluded by a single reviewer without loss of sensitivity in two conditions; the record was ineligible for multiple reasons, or the record was ineligible for one or more specific reasons that could be reliably assessed.Twenty-four SRs performed at CHEO, a pediatric health care and research centre in Ottawa, Canada, were divided into derivation and validation sets. Exclusion criteria during abstract screening were sorted into 11 specific categories, with loss in sensitivity determined by individual category and by number of exclusion criteria endorsed. Five single reviewer algorithms that combined individual categories and multiple exclusion criteria were then tested on the derivation and validation sets, with success defined a priori as less than 5% loss of sensitivity.The 24 SRs included 930 eligible and 27390 ineligible citations. The reviews were mostly focused on pediatrics (70.8%, N=17/24), but covered various specialties. Using a single reviewer to exclude any citation led to an average loss of sensitivity of 8.6% (95%CI, 6.0-12.1%). Excluding citations with ≥2 exclusion criteria led to 1.2% average loss of sensitivity (95%CI, 0.5-3.1%). Five specific exclusion criteria performed with perfect sensitivity: conference abstract, ineligible age group, case report/series, not human research, and review article. In the derivation set, the five algorithms achieved a loss of sensitivity ranging from 0.0 to 1.9% and work-saved ranging from 14.8 to 39.1%. In the validation set, the loss of sensitivity for all 5 algorithms remained below 2.6%, with work-saved between 10.5% and 48.2%.Findings suggest that targeted application of single-reviewer screening, considering both type and number of exclusion criteria, could retain sensitivity and significantly decrease workload. Further research is required to investigate the potential for combining this approach with crowdsourcing or machine learning methodologies. The proposed DSS is effective and can substantially decrease the document retrieval and citation screening steps' workload and error rate. ( P = 0.039), and those published more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2021
DA  - 2021-04-05
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Nassr Nama
AU  - Mirna Hennawy
AU  - Nick Barrowman
AU  - Katie O’Hearn
AU  - Margaret Sampson
AU  - James G. McNally
ER  - 

720.
TY  - journal-article
ID  - https://openalex.org/W4200362342
DO  - https://doi.org/10.1186/s12874-021-01451-2
TI  - Guidance for using artificial intelligence for title and abstract screening while conducting knowledge syntheses
AB  - Systematic reviews are the cornerstone of evidence-based medicine. However, systematic reviews are time consuming and there is growing demand to produce evidence more quickly, while maintaining robust methods. In recent years, artificial intelligence and active-machine learning (AML) have been implemented into several SR software applications. As some of the barriers to adoption of new technologies are the challenges in set-up and how best to use these technologies, we have provided different situations and considerations for knowledge synthesis teams to consider when using artificial intelligence and AML for title and abstract screening.We retrospectively evaluated the implementation and performance of AML across a set of ten historically completed systematic reviews. Based upon the findings from this work and in consideration of the barriers we have encountered and navigated during the past 24 months in using these tools prospectively in our research, we discussed and developed a series of practical recommendations for research teams to consider in seeking to implement AML tools for citation screening into their workflow.We developed a seven-step framework and provide guidance for when and how to integrate artificial intelligence and AML into the title and abstract screening process. Steps include: (1) Consulting with Knowledge user/Expert Panel; (2) Developing the search strategy; (3) Preparing your review team; (4) Preparing your database; (5) Building the initial training set; (6) Ongoing screening; and (7) Truncating screening. During Step 6 and/or 7, you may also choose to optimize your team, by shifting some members to other review stages (e.g., full-text screening, data extraction).Artificial intelligence and, more specifically, AML are well-developed tools for title and abstract screening and can be integrated into the screening process in several ways. Regardless of the method chosen, transparent reporting of these methods is critical for future studies evaluating artificial intelligence and AML. with crowdsourcing or machine learning methodologies. The proposed DSS is effective and can substantially decrease the document retrieval and citation screening steps' workload and error rate. ( P = 0.039), and those published more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2021
DA  - 2021-12-01
JO  - {'id': 'https://openalex.org/S185874209', 'issn_l': '1471-2288', 'issn': ['1471-2288'], 'display_name': 'BMC Medical Research Methodology', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://bmcmedresmethodol.biomedcentral.com/track/pdf/10.1186/s12874-021-01451-2', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Candyce Hamel
AU  - Mona Hersi
AU  - Shannon Kelly
AU  - Andrea C. Tricco
AU  - Sharon E. Straus
AU  - George A. Wells
AU  - Ba' Pham
AU  - Brian Hutton
ER  - 

721.
TY  - journal-article
ID  - https://openalex.org/W3022138475
DO  - https://doi.org/10.1007/s13278-020-00635-w
TI  - Enhancing information retrieval performance by using social analysis
AB  - No Abstract Found
PY  - 2020
DA  - 2020-12-01
JO  - {'id': 'https://openalex.org/S2764891196', 'issn_l': '1869-5450', 'issn': ['1869-5450', '1869-5469'], 'display_name': 'Social Network Analysis and Mining', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Hamid Khalifi
AU  - Sarah Dahir
AU  - Abderrahim El Qadi
AU  - Youssef Ghanou
ER  - 

722.
TY  - journal-article
ID  - https://openalex.org/W4211223593
DO  - https://doi.org/10.1016/j.jisa.2022.103121
TI  - Towards a robust and trustworthy machine learning system development: An engineering perspective
AB  - While Machine Learning (ML) technologies are widely adopted in many mission critical fields to support intelligent decision-making, concerns remain about system resilience against ML-specific security attacks and privacy breaches as well as the trust that users have in these systems. In this article, we present our recent systematic and comprehensive survey on the state-of-the-art ML robustness and trustworthiness from a security engineering perspective, focusing on the problems in system threat analysis, design and evaluation faced in developing practical machine learning applications, in terms of robustness and user trust. Accordingly, we organize the presentation of this survey intended to facilitate the convey of the body of knowledge from this angle. We then describe a metamodel we created that represents the body of knowledge in a standard and visualized way. We further illustrate how to leverage the metamodel to guide a systematic threat analysis and security design process which extends and scales up the classic process. Finally, we propose the future research directions motivated by our findings. Our work differs itself from the existing surveys by (i) exploring the fundamental principles and best practices to support robust and trustworthy ML system development, and (ii) studying the interplay of robustness and user trust in the context of ML systems. We expect this survey provides a big picture for machine learning security practitioners. screening; and (7) Truncating screening. During Step 6 and/or 7, you may also choose to optimize your team, by shifting some members to other review stages (e.g., full-text screening, data extraction).Artificial intelligence and, more specifically, AML are well-developed tools for title and abstract screening and can be integrated into the screening process in several ways. Regardless of the method chosen, transparent reporting of these methods is critical for future studies evaluating artificial intelligence and AML. with crowdsourcing or machine learning methodologies. The proposed DSS is effective and can substantially decrease the document retrieval and citation screening steps' workload and error rate. ( P = 0.039), and those published more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2022
DA  - 2022-03-01
JO  - {'id': 'https://openalex.org/S4210191536', 'issn_l': '2214-2126', 'issn': ['2214-2134', '2214-2126'], 'display_name': 'Journal of information security and applications', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Pulei Xiong
AU  - Scott Buffett
AU  - Shahrear Iqbal
AU  - Philippe Lamontagne
AU  - Mohammad Saiful Islam Mamun
AU  - Heather Molyneaux
ER  - 

723.
TY  - journal-article
ID  - https://openalex.org/W4281788268
DO  - https://doi.org/10.1016/j.iswa.2022.200091
TI  - Search strategy formulation for systematic reviews: Issues, challenges and opportunities
AB  - • Boolean logic is dominant in the formulation of search strategies for evidence synthesis in professional search, notably healthcare, but in other domains such as law, patents and recruitment. • Boolean methods are complex, time consuming, resource intensive and error prone, and a new approach is required. • Alternative approaches either suffer from the same problems as Boolean methods or introduce further problems such as lack of trust and transparency. • We propose a set of design principles to address the shortcomings of Boolean logic when formulating search strategies for evidence synthesis. Systematic literature reviews play a vital role in identifying the best available evidence for health and social care research, policy, and practice. The resources required to produce systematic reviews can be significant, and a key to the success of any review is the search strategy used to identify relevant literature. However, the methods used to construct search strategies can be complex, time consuming, resource intensive and error prone. In this review, we examine the state of the art in resolving complex structured information needs, focusing primarily on the healthcare context. We analyse the literature to identify key challenges and issues and explore appropriate solutions and workarounds. From this analysis we propose a way forward to facilitate trust and to aid explainability and transparency, reproducibility and replicability through a set of key design principles for tools to support the development of search strategies in systematic literature reviews. shifting some members to other review stages (e.g., full-text screening, data extraction).Artificial intelligence and, more specifically, AML are well-developed tools for title and abstract screening and can be integrated into the screening process in several ways. Regardless of the method chosen, transparent reporting of these methods is critical for future studies evaluating artificial intelligence and AML. with crowdsourcing or machine learning methodologies. The proposed DSS is effective and can substantially decrease the document retrieval and citation screening steps' workload and error rate. ( P = 0.039), and those published more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2022
DA  - 2022-06-01
JO  - {'id': 'https://openalex.org/V4210234522', 'issn_l': '2667-3053', 'issn': ['2667-3053'], 'display_name': 'Intelligent systems with applications', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'https://doi.org/10.1016/j.iswa.2022.200091', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc-nd'}
DP  - OpenAlex
AU  - Andrew MacFarlane
AU  - Tony Russell-Rose
AU  - Farhad Shokraneh
ER  - 

724.
TY  - journal-article
ID  - https://openalex.org/W3115545833
DO  - https://doi.org/10.1002/cl2.1128
TI  - Editorial: Evidence synthesis for accelerated learning on climate solutions
AB  - No Abstract Found
PY  - 2020
DA  - 2020-12-01
JO  - {'id': 'https://openalex.org/V2739193000', 'issn_l': '1891-1803', 'issn': ['1891-1803'], 'display_name': 'Campbell Systematic Reviews', 'publisher': 'The Campbell Collaboration', 'type': 'journal', 'url': 'https://doi.org/10.1002/cl2.1128', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Lea Berrang-Ford
AU  - Friederike C. Döbbe
AU  - Ruth Garside
AU  - Neal R. Haddaway
AU  - William F. Lamb
AU  - Jan C. Minx
AU  - Wolfgang Viechtbauer
AU  - Vivian Welch
AU  - Howard White
ER  - 

725.
TY  - journal-article
ID  - https://openalex.org/W3134878552
DO  - https://doi.org/10.1186/s12911-021-01444-7
TI  - The concept of justifiable healthcare and how big data can help us to achieve it
AB  - Abstract Over the last decades, the face of health care has changed dramatically, with big improvements in what is technically feasible. However, there are indicators that the current approach to evaluating evidence in health care is not holistic and hence in the long run, health care will not be sustainable. New conceptual and normative frameworks for the evaluation of health care need to be developed and investigated. The current paper presents a novel framework of justifiable health care and explores how the use of artificial intelligence and big data can contribute to achieving the goals of this framework. role in identifying the best available evidence for health and social care research, policy, and practice. The resources required to produce systematic reviews can be significant, and a key to the success of any review is the search strategy used to identify relevant literature. However, the methods used to construct search strategies can be complex, time consuming, resource intensive and error prone. In this review, we examine the state of the art in resolving complex structured information needs, focusing primarily on the healthcare context. We analyse the literature to identify key challenges and issues and explore appropriate solutions and workarounds. From this analysis we propose a way forward to facilitate trust and to aid explainability and transparency, reproducibility and replicability through a set of key design principles for tools to support the development of search strategies in systematic literature reviews. shifting some members to other review stages (e.g., full-text screening, data extraction).Artificial intelligence and, more specifically, AML are well-developed tools for title and abstract screening and can be integrated into the screening process in several ways. Regardless of the method chosen, transparent reporting of these methods is critical for future studies evaluating artificial intelligence and AML. with crowdsourcing or machine learning methodologies. The proposed DSS is effective and can substantially decrease the document retrieval and citation screening steps' workload and error rate. ( P = 0.039), and those published more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2021
DA  - 2021-03-06
JO  - {'id': 'https://openalex.org/S107516304', 'issn_l': '1472-6947', 'issn': ['1472-6947'], 'display_name': 'BMC Medical Informatics and Decision Making', 'publisher': 'BioMed Central', 'type': 'journal', 'url': 'https://bmcmedinformdecismak.biomedcentral.com/track/pdf/10.1186/s12911-021-01444-7', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Wim Van Biesen
AU  - Catherine Van Der Straeten
AU  - Sigrid Sterckx
AU  - Johan B. Steen
AU  - Lisa Diependaele
AU  - Johan Decruyenaere
ER  - 

726.
TY  - journal-article
ID  - https://openalex.org/W3164471952
DO  - https://doi.org/10.1002/jat.4204
TI  - Toxic effects of nanomaterials for health applications: How automation can support a systematic review of the literature?
AB  - Systematic reviews of the scientific literature can be an important source of information supporting the daily work of the regulators in their decision making, particularly in areas of innovative technologies where the regulatory experience is still limited. Significant research activities in the field of nanotechnology resulted in a huge number of publications in the last decades. However, even if the published data can provide relevant information, scientific articles are often of diverse quality, and it is nearly impossible to manually process and evaluate such amount of data in a systematic manner. In this feasibility study, we investigated to what extent open-access automation tools can support a systematic review of toxic effects of nanomaterials for health applications reported in the scientific literature. In this study, we used a battery of available tools to perform the initial steps of a systematic review such as targeted searches, data curation and abstract screening. This work was complemented with an in-house developed tool that allowed us to extract specific sections of the articles such as the materials and methods part or the results section where we could perform subsequent text analysis. We ranked the articles according to quality criteria based on the reported nanomaterial characterisation and extracted most frequently described toxic effects induced by different types of nanomaterials. Even if further demonstration of the reliability and applicability of automation tools is necessary, this study demonstrated the potential to leverage information from the scientific literature by using automation systems in a tiered strategy. screening, data extraction).Artificial intelligence and, more specifically, AML are well-developed tools for title and abstract screening and can be integrated into the screening process in several ways. Regardless of the method chosen, transparent reporting of these methods is critical for future studies evaluating artificial intelligence and AML. with crowdsourcing or machine learning methodologies. The proposed DSS is effective and can substantially decrease the document retrieval and citation screening steps' workload and error rate. ( P = 0.039), and those published more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2022
DA  - 2022-01-01
JO  - {'id': 'https://openalex.org/S81851855', 'issn_l': '0260-437X', 'issn': ['1099-1263', '0260-437X'], 'display_name': 'Journal of Applied Toxicology', 'publisher': 'Wiley', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Blanka Halamoda-Kenzaoui
AU  - Etienne Rolland
AU  - Jacopo Piovesan
AU  - Antonio Gallardo
AU  - Susanne Bremer-Hoffmann
ER  - 

727.
TY  - journal-article
ID  - https://openalex.org/W4200392107
DO  - https://doi.org/10.1016/j.envint.2021.107025
TI  - Evaluation of a semi-automated data extraction tool for public health literature-based reviews: Dextr
AB  - There has been limited development and uptake of machine-learning methods to automate data extraction for literature-based assessments. Although advanced extraction approaches have been applied to some clinical research reviews, existing methods are not well suited for addressing toxicology or environmental health questions due to unique data needs to support reviews in these fields.To develop and evaluate a flexible, web-based tool for semi-automated data extraction that: 1) makes data extraction predictions with user verification, 2) integrates token-level annotations, and 3) connects extracted entities to support hierarchical data extraction.Dextr was developed with Agile software methodology using a two-team approach. The development team outlined proposed features and coded the software. The advisory team guided developers and evaluated Dextr's performance on precision, recall, and extraction time by comparing a manual extraction workflow to a semi-automated extraction workflow using a dataset of 51 environmental health animal studies.The semi-automated workflow did not appear to affect precision rate (96.0% vs. 95.4% manual, p = 0.38), resulted in a small reduction in recall rate (91.8% vs. 97.0% manual, p < 0.01), and substantially reduced the median extraction time (436 s vs. 933 s per study manual, p < 0.01) compared to a manual workflow.Dextr provides similar performance to manual extraction in terms of recall and precision and greatly reduces data extraction time. Unlike other tools, Dextr provides the ability to extract complex concepts (e.g., multiple experiments with various exposures and doses within a single study), properly connect the extracted elements within a study, and effectively limit the work required by researchers to generate machine-readable, annotated exports. The Dextr tool addresses data-extraction challenges associated with environmental health sciences literature with a simple user interface, incorporates the key capabilities of user verification and entity connecting, provides a platform for further automation developments, and has the potential to improve data extraction for literature reviews in this and other fields. decrease the document retrieval and citation screening steps' workload and error rate. ( P = 0.039), and those published more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2022
DA  - 2022-01-01
JO  - {'id': 'https://openalex.org/S143381477', 'issn_l': '0160-4120', 'issn': ['0160-4120', '1873-6750'], 'display_name': 'Environment International', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'https://doi.org/10.1016/j.envint.2021.107025', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc-nd'}
DP  - OpenAlex
AU  - Vickie R. Walker
AU  - Charles B. Schmitt
AU  - Mary Leigh Wolfe
AU  - Artur Nowak
AU  - Kuba Kulesza
AU  - Ashley J. Williams
AU  - Rob Shin
AU  - Jonathan D. Cohen
AU  - Dave Burch
AU  - Matthew D. Stout
AU  - Kelly A. Shipkowski
AU  - Andrew A. Rooney
ER  - 

728.
TY  - journal-article
ID  - https://openalex.org/W4225303562
DO  - https://doi.org/10.1007/s00228-022-03329-8
TI  - Feasibility study and evaluation of expert opinion on the semi-automated meta-analysis and the conventional meta-analysis
AB  - No Abstract Found
PY  - 2022
DA  - 2022-05-03
JO  - {'id': 'https://openalex.org/S31780008', 'issn_l': '0031-6970', 'issn': ['0031-6970', '0369-9498', '1432-1041'], 'display_name': 'European Journal of Clinical Pharmacology', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Priscilla Ajiji
AU  - Judith Cottin
AU  - Cyndie Picot
AU  - Anil Uzunali
AU  - Emmanuelle Ripoche
AU  - Michel Cucherat
AU  - Patrick Maison
ER  - 

729.
TY  - posted-content
ID  - https://openalex.org/W3118297265
DO  - nan
TI  - Towards a Robust and Trustworthy Machine Learning System Development.
AB  - Machine Learning (ML) technologies have been widely adopted in many mission critical fields, such as cyber security, autonomous vehicle control, healthcare, etc. to support intelligent decision-making. While ML has demonstrated impressive performance over conventional methods in these applications, concerns arose with respect to system resilience against ML-specific security attacks and privacy breaches as well as the trust that users have in these systems. In this article, firstly we present our recent systematic and comprehensive survey on the state-of-the-art ML robustness and trustworthiness technologies from a security engineering perspective, which covers all aspects of secure ML system development including threat modeling, common offensive and defensive technologies, privacy-preserving machine learning, user trust in the context of machine learning, and empirical evaluation for ML model robustness. Secondly, we then push our studies forward above and beyond a survey by describing a metamodel we created that represents the body of knowledge in a standard and visualized way for ML practitioners. We further illustrate how to leverage the metamodel to guide a systematic threat analysis and security design process in a context of generic ML system development, which extends and scales up the classic process. Thirdly, we propose future research directions motivated by our findings to advance the development of robust and trustworthy ML systems. Our work differs from existing surveys in this area in that, to the best of our knowledge, it is the first of its kind of engineering effort to (i) explore the fundamental principles and best practices to support robust and trustworthy ML system development; and (ii) study the interplay of robustness and user trust in the context of ML systems. with a simple user interface, incorporates the key capabilities of user verification and entity connecting, provides a platform for further automation developments, and has the potential to improve data extraction for literature reviews in this and other fields. decrease the document retrieval and citation screening steps' workload and error rate. ( P = 0.039), and those published more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2021
DA  - 2021-01-08
JO  - {'id': 'https://openalex.org/S2597173376', 'issn_l': None, 'issn': None, 'display_name': 'arXiv: Learning', 'publisher': None, 'type': 'journal', 'url': 'http://export.arxiv.org/pdf/2101.03042', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Pulei Xiong
AU  - Scott Buffett
AU  - Shahrear Iqbal
AU  - Philippe Lamontagne
AU  - Mohammad Saiful Islam Mamun
AU  - Heather Molyneaux
ER  - 

730.
TY  - book-chapter
ID  - https://openalex.org/W3199830233
DO  - https://doi.org/10.1007/978-1-0716-1566-9_2
TI  - Semi-automated Tools for Systematic Searches
AB  - Traditionally, literature identification for systematic reviews has relied on a two-step process: first, searching databases to identify potentially relevant citations, and then manually screening those citations. A number of tools have been developed to streamline and semi-automate this process, including tools to generate terms; to visualize and evaluate search queries; to trace citation linkages; to deduplicate, limit, or translate searches across databases; and to prioritize relevant abstracts for screening. Research is ongoing into tools that can unify searching and screening into a single step, and several protype tools have been developed. As this field grows, it is becoming increasingly important to develop and codify methods for evaluating the extent to which these tools fulfill their purpose. and empirical evaluation for ML model robustness. Secondly, we then push our studies forward above and beyond a survey by describing a metamodel we created that represents the body of knowledge in a standard and visualized way for ML practitioners. We further illustrate how to leverage the metamodel to guide a systematic threat analysis and security design process in a context of generic ML system development, which extends and scales up the classic process. Thirdly, we propose future research directions motivated by our findings to advance the development of robust and trustworthy ML systems. Our work differs from existing surveys in this area in that, to the best of our knowledge, it is the first of its kind of engineering effort to (i) explore the fundamental principles and best practices to support robust and trustworthy ML system development; and (ii) study the interplay of robustness and user trust in the context of ML systems. with a simple user interface, incorporates the key capabilities of user verification and entity connecting, provides a platform for further automation developments, and has the potential to improve data extraction for literature reviews in this and other fields. decrease the document retrieval and citation screening steps' workload and error rate. ( P = 0.039), and those published more recently (mean (SD) 2008 (7) vs. 2006 (10), P = 0.02) were more often correctly predicted as relevant. Conclusion Our screening approach saved time and may be suitable in conditions where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2022
DA  - 2022-01-01
JO  - {'id': 'https://openalex.org/S4210172139', 'issn_l': '1064-3745', 'issn': ['1940-6029', '1064-3745'], 'display_name': 'Methods in molecular biology', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Gaelen P Adam
AU  - Byron C. Wallace
AU  - Thomas A Trikalinos
ER  - 

731.
TY  - journal-article
ID  - https://openalex.org/W3011937335
DO  - https://doi.org/10.1016/j.jhqr.2019.07.012
TI  - Inteligencia artificial en asistencia sanitaria. ¿Están protegidos los derechos de los pacientes?
AB  - No Abstract Found
PY  - 2021
DA  - 2021-11-01
JO  - {'id': 'https://openalex.org/S2898249226', 'issn_l': '2603-6479', 'issn': ['2603-6479'], 'display_name': 'Journal of Healthcare Quality Research', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - J.D. Sánchez López
AU  - J. Cambil Martín
AU  - M. Villegas Calvo
AU  - Fernando J. Martinez
ER  - 

732.
TY  - journal-article
ID  - https://openalex.org/W3153307512
DO  - https://doi.org/10.1186/s13643-021-01665-x
TI  - LOCATE: a prospective evaluation of the value of Leveraging Ongoing Citation Acquisition Techniques for living Evidence syntheses
AB  - Abstract Background Living systematic reviews (LSRs) can expedite evidence synthesis by incorporating new evidence in real time. However, the methods needed to identify new studies in a timely manner are not well established. Objectives To explore the value of complementary search approaches in terms of search performance, impact on results and conclusions, screening workload, and feasibility compared to the reference standard. Methods We developed three complementary search approaches for a systematic review on treatments for bronchiolitis: Automated Full Search, PubMed Similar Articles, and Scopus Citing References. These were automated to retrieve results monthly; pairs of reviewers screened the records and commented on feasibility. After 1 year, we conducted a full update search (reference standard). For each complementary approach, we compared search performance (proportion missed, number needed to read [NNR]) and reviewer workload (number of records screened, time required) to the reference standard. We investigated the impact of the new trials on the effect estimate and certainty of evidence for the primary outcomes. We summarized comments about feasibility. Results Via the reference standard, reviewers screened 505 titles/abstracts, 24 full texts, and identified four new trials (NNR 127; 12.4 h). Of the complementary approaches, only the Automated Full Search located all four trials; these were located 6 to 12 months sooner than via the reference standard but did not alter the results nor certainty in the evidence. The Automated Full Search was the most resource-intensive approach (816 records screened; NNR 204; 17.1 h). The PubMed Similar Articles and Scopus Citing References approaches located far fewer records (452 and 244, respectively), thereby requiring less screening time (9.4 and 5.2 h); however, each approach located only one of the four new trials. Reviewers found it feasible and convenient to conduct monthly screening for searches of this yield (median 15–65 records/month). Conclusions The Automated Full Search was the most resource-intensive approach, but also the only to locate all of the newly published trials. Although the monthly screening time for the PubMed Similar Articles and Scopus Citing Articles was far less, most relevant records were missed. These approaches were feasible to integrate into reviewer work processes. Systematic review registration Open Science Framework. 10.17605/OSF.IO/6M28H . where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2021
DA  - 2021-04-19
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://systematicreviewsjournal.biomedcentral.com/track/pdf/10.1186/s13643-021-01665-x', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Michelle Gates
AU  - Sarah A. Elliott
AU  - Allison Gates
AU  - Meghan Sebastianski
AU  - Jennifer Pillay
AU  - Liza Bialy
AU  - Lisa Hartling
ER  - 

733.
TY  - journal-article
ID  - https://openalex.org/W3179388700
DO  - https://doi.org/10.1186/s12874-021-01335-5
TI  - Evaluating the relationship between citation set size, team size and screening methods used in systematic reviews: a cross-sectional study
AB  - Abstract Background Standard practice for conducting systematic reviews (SRs) is time consuming and involves the study team screening hundreds or thousands of citations. As the volume of medical literature grows, the citation set sizes and corresponding screening efforts increase. While larger team size and alternate screening methods have the potential to reduce workload and decrease SR completion times, it is unknown whether investigators adapt team size or methods in response to citation set sizes. Using a cross-sectional design, we sought to understand how citation set size impacts (1) the total number of authors or individuals contributing to screening and (2) screening methods. Methods MEDLINE was searched in April 2019 for SRs on any health topic. A total of 1880 unique publications were identified and sorted into five citation set size categories (after deduplication): &lt; 1,000, 1,001–2,500, 2,501–5,000, 5,001–10,000, and &gt; 10,000. A random sample of 259 SRs were selected (~ 50 per category) for data extraction and analysis. Results With the exception of the pairwise t test comparing the under 1000 and over 10,000 categories (median 5 vs. 6, p = 0.049) no statistically significant relationship was evident between author number and citation set size. While visual inspection was suggestive, statistical testing did not consistently identify a relationship between citation set size and number of screeners (title-abstract, full text) or data extractors. However, logistic regression identified investigators were significantly more likely to deviate from gold-standard screening methods (i.e. independent duplicate screening) with larger citation sets. For every doubling of citation size, the odds of using gold-standard screening decreased by 15 and 20% at title-abstract and full text review, respectively. Finally, few SRs reported using crowdsourcing ( n = 2) or computer-assisted screening ( n = 1). Conclusions Large citation set sizes present a challenge to SR teams, especially when faced with time-sensitive health policy questions. Our study suggests that with increasing citation set size, authors are less likely to adhere to gold-standard screening methods. It is possible that adjunct screening methods, such as crowdsourcing (large team) and computer-assisted technologies, may provide a viable solution for authors to complete their SRs in a timely manner. Science Framework. 10.17605/OSF.IO/6M28H . where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2021
DA  - 2021-07-08
JO  - {'id': 'https://openalex.org/S185874209', 'issn_l': '1471-2288', 'issn': ['1471-2288'], 'display_name': 'BMC Medical Research Methodology', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://doi.org/10.1186/s12874-021-01335-5', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Katie O’Hearn
AU  - Cameron MacDonald
AU  - Anne Tsampalieros
AU  - Leo Kadota
AU  - Ryan Sandarage
AU  - Supun Kotteduwa Jayawarden
AU  - Michele Datko
AU  - John V. Reynolds
AU  - Thanh Bui
AU  - Shagufta Sultan
AU  - Margaret Sampson
AU  - Misty Pratt
AU  - Nick Barrowman
AU  - Nassr Nama
AU  - Matthew J. Page
AU  - James G. McNally
ER  - 

734.
TY  - journal-article
ID  - https://openalex.org/W3193212524
DO  - https://doi.org/10.29173/jchla29510
TI  - Evolution-revolution-devolution
AB  - From 1993 to 2009 the University of Manitoba (UM), the Regional Health Authorities of Manitoba (RHAM), and the Manitoba Health Department signed affiliation agreements that changed the access to knowledge-based information for health professionals. These agreements transferred the management and delivery of library service from the home organizations to the UM Libraries. This three-part paper describes the events that led to the evolution of change in health information access in Winnipeg, subsequent revolutionary changes in the nature of the services, and their eventual devolution due to a significant array of unexpected challenges. authors or individuals contributing to screening and (2) screening methods. Methods MEDLINE was searched in April 2019 for SRs on any health topic. A total of 1880 unique publications were identified and sorted into five citation set size categories (after deduplication): &lt; 1,000, 1,001–2,500, 2,501–5,000, 5,001–10,000, and &gt; 10,000. A random sample of 259 SRs were selected (~ 50 per category) for data extraction and analysis. Results With the exception of the pairwise t test comparing the under 1000 and over 10,000 categories (median 5 vs. 6, p = 0.049) no statistically significant relationship was evident between author number and citation set size. While visual inspection was suggestive, statistical testing did not consistently identify a relationship between citation set size and number of screeners (title-abstract, full text) or data extractors. However, logistic regression identified investigators were significantly more likely to deviate from gold-standard screening methods (i.e. independent duplicate screening) with larger citation sets. For every doubling of citation size, the odds of using gold-standard screening decreased by 15 and 20% at title-abstract and full text review, respectively. Finally, few SRs reported using crowdsourcing ( n = 2) or computer-assisted screening ( n = 1). Conclusions Large citation set sizes present a challenge to SR teams, especially when faced with time-sensitive health policy questions. Our study suggests that with increasing citation set size, authors are less likely to adhere to gold-standard screening methods. It is possible that adjunct screening methods, such as crowdsourcing (large team) and computer-assisted technologies, may provide a viable solution for authors to complete their SRs in a timely manner. Science Framework. 10.17605/OSF.IO/6M28H . where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2021
DA  - 2021-08-01
JO  - {'id': 'https://openalex.org/S4210216250', 'issn_l': '1708-6892', 'issn': ['1708-6892'], 'display_name': 'The journal of the Canadian Health Libraries Association', 'publisher': 'University of Alberta', 'type': 'journal', 'url': 'https://journals.library.ualberta.ca/jchla/index.php/jchla/article/download/29510/21766', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Ada M. Ducas
AU  - Tania Gottschalk
AU  - Analyn Cohen-Baker
ER  - 

735.
TY  - journal-article
ID  - https://openalex.org/W4286377221
DO  - nan
TI  - Testing a filtering strategy for systematic reviews: evaluating work savings and recall.
AB  - Systematic reviews are extremely time-consuming. The goal of this work is to assess work savings and recall for a publication type filtering strategy that uses the output of two machine learning models, Multi-Tagger and web RCT Tagger, applied retrospectively to 10 systematic reviews on drug effectiveness. Our filtering strategy resulted in mean work savings of 33.6% and recall of 98.3%. Of 363 articles finally included in any of the systematic reviews, 7 were filtered out by our strategy, but 1 "error" was actually an article using a publication type that the SR team had not pre-specified as relevant for inclusion. Our analysis suggests that automated publication type filtering can potentially provide substantial work savings with minimal loss of included articles. Publication type filtering should be personalized for each systematic review and might be combined with other filtering or ranking methods to provide additional work savings for manual triage. selected (~ 50 per category) for data extraction and analysis. Results With the exception of the pairwise t test comparing the under 1000 and over 10,000 categories (median 5 vs. 6, p = 0.049) no statistically significant relationship was evident between author number and citation set size. While visual inspection was suggestive, statistical testing did not consistently identify a relationship between citation set size and number of screeners (title-abstract, full text) or data extractors. However, logistic regression identified investigators were significantly more likely to deviate from gold-standard screening methods (i.e. independent duplicate screening) with larger citation sets. For every doubling of citation size, the odds of using gold-standard screening decreased by 15 and 20% at title-abstract and full text review, respectively. Finally, few SRs reported using crowdsourcing ( n = 2) or computer-assisted screening ( n = 1). Conclusions Large citation set sizes present a challenge to SR teams, especially when faced with time-sensitive health policy questions. Our study suggests that with increasing citation set size, authors are less likely to adhere to gold-standard screening methods. It is possible that adjunct screening methods, such as crowdsourcing (large team) and computer-assisted technologies, may provide a viable solution for authors to complete their SRs in a timely manner. Science Framework. 10.17605/OSF.IO/6M28H . where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2022
DA  - 2022-01-01
JO  - {'id': None, 'issn_l': None, 'issn': None, 'display_name': 'AMIA ... Annual Symposium proceedings. AMIA Symposium', 'publisher': None, 'type': None, 'url': 'https://pubmed.ncbi.nlm.nih.gov/35854734/', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Randi Proescholdt
AU  - Tzu Kun Hsiao
AU  - Jodi Schneider
AU  - Aaron Cohen
AU  - Marian McDonagh
AU  - Neil R. Smalheiser
ER  - 

736.
TY  - journal-article
ID  - https://openalex.org/W4296546700
DO  - https://doi.org/10.12688/f1000research.125198.1
TI  - (Semi)automated approaches to data extraction for systematic reviews and meta-analyses in social sciences: A living review protocol
AB  - <ns3:p><ns3:bold>Background</ns3:bold>: An abundance of rapidly accumulating scientific evidence presents novel opportunities for researchers and practitioners alike, yet such advantages are often overshadowed by resource demands associated with finding and aggregating a continually expanding body of scientific information. Across social science disciplines, the use of automation technologies for timely and accurate knowledge synthesis can enhance research translation value, better inform key policy development, and expand the current understanding of human interactions, organizations, and systems. Ongoing developments surrounding automation are highly concentrated in research for evidence-based medicine with limited evidence surrounding tools and techniques applied outside of the clinical research community. Our objective is to conduct a living systematic review of automated data extraction techniques supporting systematic reviews and meta-analyses in the social sciences. The aim of this study is to extend the automation knowledge base by synthesizing current trends in the application of extraction technologies of key data elements of interest for social scientists.</ns3:p><ns3:p> <ns3:bold>Methods</ns3:bold>: The proposed study is a living systematic review employing a partial replication framework based on extant literature surrounding automation of data extraction for systematic reviews and meta-analyses. Protocol development, base review, and updates follow PRISMA standards for reporting systematic reviews. This protocol is preregistered in OSF: <ns3:ext-link xmlns:ns4="http://www.w3.org/1999/xlink" ext-link-type="uri" ns4:href="https://doi.org/10.17605/OSF.IO/YWTF9">(Semi)Automated Approaches to Data Extraction for Systematic Reviews and Meta-Analyses in Social Sciences: A Living Review Protocol</ns3:ext-link> on August 14, 2022.</ns3:p><ns3:p> <ns3:bold>Conclusions</ns3:bold>: Anticipated outcomes of this study include: (a) generate insights supporting advancement in transferring existing reliable methods to social science research; (b) provide a foundation for protocol development leading to enhancement of comparability and benchmarking standards across disciplines; and (c) uncover exigencies that spur continued value-adding innovation and interdisciplinary collaboration for the benefit of the collective systematic review community.</ns3:p> n = 1). Conclusions Large citation set sizes present a challenge to SR teams, especially when faced with time-sensitive health policy questions. Our study suggests that with increasing citation set size, authors are less likely to adhere to gold-standard screening methods. It is possible that adjunct screening methods, such as crowdsourcing (large team) and computer-assisted technologies, may provide a viable solution for authors to complete their SRs in a timely manner. Science Framework. 10.17605/OSF.IO/6M28H . where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2022
DA  - 2022-09-12
JO  - {'id': 'https://openalex.org/S4210239046', 'issn_l': '2046-1402', 'issn': ['2046-1402'], 'display_name': 'F1000Research', 'publisher': 'Faculty of 1000', 'type': 'journal', 'url': 'https://f1000research.com/articles/11-1036/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Amanda Legate
AU  - Kim Nimon
ER  - 

737.
TY  - posted-content
ID  - https://openalex.org/W4309542200
DO  - https://doi.org/10.1101/2022.11.17.22282374
TI  - Validation of semi-automatic citation screening software for creating clinical practice guidelines: A protocol for a prospective observational study
AB  - Abstract Background This study aims to investigate the quality of the literature search and workload saving using the semi-automatic software for citation screening in the development of the Japanese Clinical Practice Guidelines for Management of Sepsis and Septic Shock (J-SSCG). Methods We will conduct a prospective study to compare the efficiency of citation screening between the conventional method using Rayyan and semi-automatic citation screening using ASReview. The two independent reviewers will conduct literature searches for clinical questions. During the session, we objectively measure the time to accomplish the citation screening. After the citation screening, we will calculate the sensitivity and specificity from the results of the conventional and semi-automatic procedures. Also, we will compare the accumulated time between the two methods. Trial registration This research is submitted with the University hospital medical information network clinical trial registry (UMIN-CTR) [UMIN000049366]. Conflicts of interest All authors declare no conflicts of interest to have. Funding None <ns3:bold>Methods</ns3:bold>: The proposed study is a living systematic review employing a partial replication framework based on extant literature surrounding automation of data extraction for systematic reviews and meta-analyses. Protocol development, base review, and updates follow PRISMA standards for reporting systematic reviews. This protocol is preregistered in OSF: <ns3:ext-link xmlns:ns4="http://www.w3.org/1999/xlink" ext-link-type="uri" ns4:href="https://doi.org/10.17605/OSF.IO/YWTF9">(Semi)Automated Approaches to Data Extraction for Systematic Reviews and Meta-Analyses in Social Sciences: A Living Review Protocol</ns3:ext-link> on August 14, 2022.</ns3:p><ns3:p> <ns3:bold>Conclusions</ns3:bold>: Anticipated outcomes of this study include: (a) generate insights supporting advancement in transferring existing reliable methods to social science research; (b) provide a foundation for protocol development leading to enhancement of comparability and benchmarking standards across disciplines; and (c) uncover exigencies that spur continued value-adding innovation and interdisciplinary collaboration for the benefit of the collective systematic review community.</ns3:p> n = 1). Conclusions Large citation set sizes present a challenge to SR teams, especially when faced with time-sensitive health policy questions. Our study suggests that with increasing citation set size, authors are less likely to adhere to gold-standard screening methods. It is possible that adjunct screening methods, such as crowdsourcing (large team) and computer-assisted technologies, may provide a viable solution for authors to complete their SRs in a timely manner. Science Framework. 10.17605/OSF.IO/6M28H . where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2022
DA  - 2022-11-18
JO  - {'id': 'https://openalex.org/V4306400573', 'issn_l': None, 'issn': None, 'display_name': 'Cold Spring Harbor Laboratory - medRxiv', 'publisher': 'Cold Spring Harbor Laboratory', 'type': 'repository', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Takehiko Oami
AU  - Yohei Okada
AU  - Tatsuma Fukuda
AU  - Masaaki Sakuraya
AU  - Taka-aki Nakada
AU  - Nobuaki Shime
ER  - 

738.
TY  - journal-article
ID  - https://openalex.org/W4310805038
DO  - https://doi.org/10.1016/j.zefq.2022.11.008
TI  - Editorial
AB  - No Abstract Found
PY  - 2022
DA  - 2022-12-01
JO  - {'id': 'https://openalex.org/S124485727', 'issn_l': '1865-9217', 'issn': ['1865-9217', '2212-0289'], 'display_name': 'Zeitschrift für Evidenz, Fortbildung und Qualität im Gesundheitswesen', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Waldemar Siemens
AU  - Claudia Breuer
AU  - Jörg J. Meerpohl
ER  - 

739.
TY  - journal-article
ID  - https://openalex.org/W4317935779
DO  - https://doi.org/10.1016/j.zefq.2022.11.007
TI  - From standard systematic reviews to living systematic reviews
AB  - <h2>Abstract</h2> Systematic reviews (SRs) have become a central tool for evidence-based health care over the last 30 years. The number of SRs being published has increased steadily. However, concerns have been raised regarding the duplication of work, methodological flaws and the currency of many systematic reviews, also in the context of the COVID-19 pandemic. Living systematic reviews (LSRs) offer a new approach to updating systematic reviews, particularly in high-priority research fields that face the challenge of dynamically evolving and sometimes uncertain evidence. Continual updates serve to ensure that LSRs remain current and methodologically rigorous. As a new element of the evidence ecosystem, LSRs can inform living guidelines and recommendations, user-adapted formats, decisions at the patient and system level as well as gaps in primary research. is submitted with the University hospital medical information network clinical trial registry (UMIN-CTR) [UMIN000049366]. Conflicts of interest All authors declare no conflicts of interest to have. Funding None <ns3:bold>Methods</ns3:bold>: The proposed study is a living systematic review employing a partial replication framework based on extant literature surrounding automation of data extraction for systematic reviews and meta-analyses. Protocol development, base review, and updates follow PRISMA standards for reporting systematic reviews. This protocol is preregistered in OSF: <ns3:ext-link xmlns:ns4="http://www.w3.org/1999/xlink" ext-link-type="uri" ns4:href="https://doi.org/10.17605/OSF.IO/YWTF9">(Semi)Automated Approaches to Data Extraction for Systematic Reviews and Meta-Analyses in Social Sciences: A Living Review Protocol</ns3:ext-link> on August 14, 2022.</ns3:p><ns3:p> <ns3:bold>Conclusions</ns3:bold>: Anticipated outcomes of this study include: (a) generate insights supporting advancement in transferring existing reliable methods to social science research; (b) provide a foundation for protocol development leading to enhancement of comparability and benchmarking standards across disciplines; and (c) uncover exigencies that spur continued value-adding innovation and interdisciplinary collaboration for the benefit of the collective systematic review community.</ns3:p> n = 1). Conclusions Large citation set sizes present a challenge to SR teams, especially when faced with time-sensitive health policy questions. Our study suggests that with increasing citation set size, authors are less likely to adhere to gold-standard screening methods. It is possible that adjunct screening methods, such as crowdsourcing (large team) and computer-assisted technologies, may provide a viable solution for authors to complete their SRs in a timely manner. Science Framework. 10.17605/OSF.IO/6M28H . where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2023
DA  - 2023-01-01
JO  - {'id': 'https://openalex.org/S124485727', 'issn_l': '1865-9217', 'issn': ['1865-9217', '2212-0289'], 'display_name': 'Zeitschrift für Evidenz, Fortbildung und Qualität im Gesundheitswesen', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Claudia Breuer
AU  - Jörg J. Meerpohl
AU  - Waldemar Siemens
ER  - 

740.
TY  - journal-article
ID  - https://openalex.org/W4318225126
DO  - https://doi.org/10.12688/f1000research.125198.2
TI  - (Semi)automated approaches to data extraction for systematic reviews and meta-analyses in social sciences: A living review protocol
AB  - <ns3:p><ns3:bold>Background</ns3:bold>: An abundance of rapidly accumulating scientific evidence presents novel opportunities for researchers and practitioners alike, yet such advantages are often overshadowed by resource demands associated with finding and aggregating a continually expanding body of scientific information. Across social science disciplines, the use of automation technologies for timely and accurate knowledge synthesis can enhance research translation value, better inform key policy development, and expand the current understanding of human interactions, organizations, and systems. Ongoing developments surrounding automation are highly concentrated in research for evidence-based medicine with limited evidence surrounding tools and techniques applied outside of the clinical research community. Our objective is to conduct a living systematic review of automated data extraction techniques supporting systematic reviews and meta-analyses in the social sciences. The aim of this study is to extend the automation knowledge base by synthesizing current trends in the application of extraction technologies of key data elements of interest for social scientists.</ns3:p><ns3:p> <ns3:bold>Methods</ns3:bold>: The proposed study is a living systematic review employing a partial replication framework based on extant literature surrounding automation of data extraction for systematic reviews and meta-analyses. Protocol development, base review, and updates follow PRISMA standards for reporting systematic reviews. This protocol is preregistered in OSF: <ns3:ext-link xmlns:ns4="http://www.w3.org/1999/xlink" ext-link-type="uri" ns4:href="https://doi.org/10.17605/OSF.IO/YWTF9">(Semi)Automated Approaches to Data Extraction for Systematic Reviews and Meta-Analyses in Social Sciences: A Living Review Protocol</ns3:ext-link> on August 14, 2022.</ns3:p><ns3:p> <ns3:bold>Conclusions</ns3:bold>: Anticipated outcomes of this study include: (a) generate insights supporting advancement in transferring existing reliable methods to social science research; (b) provide a foundation for protocol development leading to enhancement of comparability and benchmarking standards across disciplines; and (c) uncover exigencies that spur continued value-adding innovation and interdisciplinary collaboration for the benefit of the collective systematic review community.</ns3:p> n = 1). Conclusions Large citation set sizes present a challenge to SR teams, especially when faced with time-sensitive health policy questions. Our study suggests that with increasing citation set size, authors are less likely to adhere to gold-standard screening methods. It is possible that adjunct screening methods, such as crowdsourcing (large team) and computer-assisted technologies, may provide a viable solution for authors to complete their SRs in a timely manner. Science Framework. 10.17605/OSF.IO/6M28H . where the limited risk of missing relevant records is acceptable. Several of our findings are paradoxical and require further study to fully understand the tasks to which ML-assisted screening is best suited. The findings should be interpreted in light of the fact that the protocol was prepared for the funder, but not published a priori. Because we used a convenience sample, the findings may be prone to selection bias. The results may not be generalizable to other samples of reviews, ML tools, or screening approaches. The small number of missed studies across reviews with pairwise meta-analyses hindered strong conclusions about the effect of missed studies on the results and conclusions of systematic reviews.
PY  - 2023
DA  - 2023-01-27
JO  - {'id': 'https://openalex.org/S4210239046', 'issn_l': '2046-1402', 'issn': ['2046-1402'], 'display_name': 'F1000Research', 'publisher': 'Faculty of 1000', 'type': 'journal', 'url': 'https://f1000research.com/articles/11-1036/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Amanda Legate
AU  - Kim Nimon
ER  - 

741.
TY  - journal-article
ID  - https://openalex.org/W3161180380
DO  - https://doi.org/10.3390/jrfm14050228
TI  - Risk Management: Exploring Emerging Human Resource Issues during the COVID-19 Pandemic
AB  - The unanticipated coronavirus disease 2019 (COVID-19) pandemic has hit global business heavily, disrupting the management of human resources across numerous industries. More than 500 articles (indexed in Scopus and the Web of Science) on the impact of the COVID-19 outbreak on emerging human resources issues and related practices were published from 1 January 2020 to 31 January 2021. In this study, we conduct a systematic literature review on emerging studies in the business and management field to explore what the emerging human resource issues are during the COVID-19 pandemic and propose related practices to solve these issues. The analysis of the published literature identifies nine main human resource issues across 13 industries. The findings of this study suggest that COVID-19 has enormous impact on conventional human resource management and requires the theoretical and empirical attention of researchers. The propositions nominate related human resource practices to deal with emerging human resources issues and identify several research venues for future studies in this field.
PY  - 2021
DA  - 2021-05-19
JO  - {'id': 'https://openalex.org/S4210217951', 'issn_l': '1911-8066', 'issn': ['1911-8074', '1911-8066'], 'display_name': 'Journal of risk and financial management', 'publisher': 'MDPI', 'type': 'journal', 'url': 'https://www.mdpi.com/1911-8074/14/5/228/pdf?version=1621507391', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Yifan Zhong
AU  - Yameng Li
AU  - Jian Ding
AU  - Yiyi Liao
ER  - 

742.
TY  - journal-article
ID  - https://openalex.org/W3165532503
DO  - https://doi.org/10.3390/s21113778
TI  - Research Trends and Future Perspectives in Marine Biomimicking Robotics
AB  - Mechatronic and soft robotics are taking inspiration from the animal kingdom to create new high-performance robots. Here, we focused on marine biomimetic research and used innovative bibliographic statistics tools, to highlight established and emerging knowledge domains. A total of 6980 scientific publications retrieved from the Scopus database (1950–2020), evidencing a sharp research increase in 2003–2004. Clustering analysis of countries collaborations showed two major Asian-North America and European clusters. Three significant areas appeared: (i) energy provision, whose advancement mainly relies on microbial fuel cells, (ii) biomaterials for not yet fully operational soft-robotic solutions; and finally (iii), design and control, chiefly oriented to locomotor designs. In this scenario, marine biomimicking robotics still lacks solutions for the long-lasting energy provision, which presently hinders operation autonomy. In the research environment, identifying natural processes by which living organisms obtain energy is thus urgent to sustain energy-demanding tasks while, at the same time, the natural designs must increasingly inform to optimize energy consumption. future studies in this field.
PY  - 2021
DA  - 2021-05-29
JO  - {'id': 'https://openalex.org/S101949793', 'issn_l': '1424-8220', 'issn': ['1424-8220'], 'display_name': 'Sensors', 'publisher': 'MDPI', 'type': 'journal', 'url': 'https://www.mdpi.com/1424-8220/21/11/3778/pdf?version=1622549902', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Jacopo Aguzzi
AU  - Corrado Costa
AU  - Marcello Calisti
AU  - Valerio Funari
AU  - Sergio Stefanni
AU  - Roberto Danovaro
AU  - Helena I. Gomes
AU  - F. Vecchi
AU  - Lewis Dartnell
AU  - Peter Weiss
AU  - Kathrin Nowak
AU  - Damianos Chatzievangelou
AU  - Simone Marini
ER  - 

743.
TY  - journal-article
ID  - https://openalex.org/W3204036093
DO  - https://doi.org/10.3390/su131910974
TI  - Eco-Innovation Diversity in a Circular Economy: Towards Circular Innovation Studies
AB  - Transition to a Circular Economy (CE) is about structural change and is predicated on the introduction of transformative eco-innovation (EI). Research on the CE–EI nexus has recently attracted attention both from an analytical and regulatory perspective. However, in-depth research exploring EI dynamics within the CE is still marginal, especially concerning the trends and dynamics of the pro-CE innovation policy and strategy. This paper addresses this gap by taking advantage of the burgeoning research on CE of the last 20 years and offers a new working synthesis. By implementing a “(systematic) review of (systematic) reviews”, this paper provides a new comprehensive framework for understanding pro-circular innovation strategies and, as a complement, argues the need to advance “circular innovation studies” as an agenda in its own right. Innovations related to recycling and recovery CE strategies along with business-model innovations and systemic/transformative innovations are found to be a major current trend in the research, connecting supply and demand side innovations and also driving other forms of innovation linked to design, product manufacturing, logistics and reverse logistics and end-of-life management and recovery. Additionally, of note is that the conceptual understanding of EI dynamics within a CE is still mainly implicit (rather than explicitly discussed) limiting the possibilities to advance knowledge in the area of innovation for CE: this is why we propose a “circular innovation studies” agenda.
PY  - 2021
DA  - 2021-10-02
JO  - {'id': 'https://openalex.org/V10134376', 'issn_l': '2071-1050', 'issn': ['2071-1050'], 'display_name': 'Sustainability', 'publisher': 'MDPI', 'type': 'journal', 'url': 'https://www.mdpi.com/2071-1050/13/19/10974/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Ana de Jesus
AU  - Minna Lammi
AU  - Teresa Domenech
AU  - Fedra Vanhuyse
AU  - Sandro Mendonça
ER  - 

744.
TY  - journal-article
ID  - https://openalex.org/W3207456925
DO  - https://doi.org/10.1177/02683962211048201
TI  - Artificial intelligence and the conduct of literature reviews
AB  - Artificial intelligence (AI) is beginning to transform traditional research practices in many areas. In this context, literature reviews stand out because they operate on large and rapidly growing volumes of documents, that is, partially structured (meta)data, and pervade almost every type of paper published in information systems research or related social science disciplines. To familiarize researchers with some of the recent trends in this area, we outline how AI can expedite individual steps of the literature review process. Considering that the use of AI in this context is in an early stage of development, we propose a comprehensive research agenda for AI-based literature reviews (AILRs) in our field. With this agenda, we would like to encourage design science research and a broader constructive discourse on shaping the future of AILRs in research. strategies along with business-model innovations and systemic/transformative innovations are found to be a major current trend in the research, connecting supply and demand side innovations and also driving other forms of innovation linked to design, product manufacturing, logistics and reverse logistics and end-of-life management and recovery. Additionally, of note is that the conceptual understanding of EI dynamics within a CE is still mainly implicit (rather than explicitly discussed) limiting the possibilities to advance knowledge in the area of innovation for CE: this is why we propose a “circular innovation studies” agenda.
PY  - 2021
DA  - 2021-10-08
JO  - {'id': 'https://openalex.org/S135086714', 'issn_l': '0268-3962', 'issn': ['0268-3962', '1466-4437'], 'display_name': 'Journal of Information Technology', 'publisher': 'Macmillan Publishers', 'type': 'journal', 'url': 'https://journals.sagepub.com/doi/pdf/10.1177/02683962211048201', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Gerit Wagner
AU  - Roman Lukyanenko
AU  - Guy Paré
ER  - 

745.
TY  - journal-article
ID  - https://openalex.org/W3188646638
DO  - https://doi.org/10.1016/j.asoc.2021.107765
TI  - A Multi-Channel Convolutional Neural Network approach to automate the citation screening process
AB  - The systematic literature review (SLR) process is separated into several steps to increase rigor and reproducibility. The selection of primary studies (i.e., citation screening) is an important step in the SLR process. The citation screening process aims to identify the relevant primary studies fairly and with high rigor using selection criteria. Through the study selection criteria, reviewers determine whether an article should be included or excluded from the SLR. However, the screening process is highly time-consuming and error-prone as the researchers must read each title and possibly hundreds to thousands of abstracts and full-text documents. This study aims to automate the citation screening process using Deep Learning algorithms. With this, it is aimed to reduce the time and costs of the citation screening process and increase the precision and recall of the relevant primary studies. A Multi-Channel Convolutional Neural Network (CNN) is proposed, which can automatically classify a given set of citations. As the architecture uses the title and abstract as features, our end-to-end pipeline is domain-independent. We have performed six experiments to assess the performance of Multi-Channel CNNs across 20 publicly available systematic literature review datasets. It was shown that for 18 out of 20 review datasets, the proposed method achieved significant workload savings of at least 10%, while in several cases, our model yielded a statistically significantly better performance over two benchmark review datasets. We conclude that Multi-Channel CNNs are effective for the citation screening process in SLRs. Multi-Channel CNNs perform best on large datasets of over 2500 samples with few abstracts missing. • Multi-Channel CNN model was developed to support the citation screening process. • Our model uses the Glove Embeddings to gain insight from each word’s context. • 20 systematic review datasets from the medical domain were used for evaluation. • Significant workload savings of at least 10% in 18 out of 20 review datasets.
PY  - 2021
DA  - 2021-11-01
JO  - {'id': 'https://openalex.org/S140556538', 'issn_l': '1568-4946', 'issn': ['1568-4946', '1872-9681'], 'display_name': 'Applied Soft Computing', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'https://doi.org/10.1016/j.asoc.2021.107765', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Raymon van Dinter
AU  - Daniel Rodriguez
AU  - Bedir Tekinerdogan
ER  - 

746.
TY  - journal-article
ID  - https://openalex.org/W4285032067
DO  - https://doi.org/10.1016/j.infsof.2022.107008
TI  - Predictive maintenance using digital twins: A systematic literature review
AB  - • The first SLR in predictive maintenance using Digital Twins. • 42 primary studies were analyzed. • Key questions for designing a predictive maintance model were answered. • Key challenges were presented in the study. Predictive maintenance is a technique for creating a more sustainable, safe, and profitable industry. One of the key challenges for creating predictive maintenance systems is the lack of failure data, as the machine is frequently repaired before failure. Digital Twins provide a real-time representation of the physical machine and generate data, such as asset degradation, which the predictive maintenance algorithm can use. Since 2018, scientific literature on the utilization of Digital Twins for predictive maintenance has accelerated, indicating the need for a thorough review. This research aims to gather and synthesize the studies that focus on predictive maintenance using Digital Twins to pave the way for further research. A systematic literature review (SLR) using an active learning tool is conducted on published primary studies on predictive maintenance using Digital Twins, in which 42 primary studies have been analyzed. This SLR identifies several aspects of predictive maintenance using Digital Twins, including the objectives, application domains, Digital Twin platforms, Digital Twin representation types, approaches, abstraction levels, design patterns, communication protocols, twinning parameters, and challenges and solution directions. These results contribute to a Software Engineering approach for developing predictive maintenance using Digital Twins in academics and the industry. This study is the first SLR in predictive maintenance using Digital Twins. We answer key questions for designing a successful predictive maintenance model leveraging Digital Twins. We found that to this day, computational burden, data variety, and complexity of models, assets, or components are the key challenges in designing these models. • 20 systematic review datasets from the medical domain were used for evaluation. • Significant workload savings of at least 10% in 18 out of 20 review datasets.
PY  - 2022
DA  - 2022-07-01
JO  - {'id': 'https://openalex.org/S205010575', 'issn_l': '0950-5849', 'issn': ['0950-5849', '1873-6025'], 'display_name': 'Information & Software Technology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'https://doi.org/10.1016/j.infsof.2022.107008', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Raymon van Dinter
AU  - Bedir Tekinerdogan
AU  - Daniel Rodriguez
ER  - 

747.
TY  - journal-article
ID  - https://openalex.org/W3174349820
DO  - https://doi.org/10.31757/euer.426
TI  - Distributed Leadership: A Bibliometric Analysis Using Scopus Database (1981-2020)
AB  - Distributed Leadership is a conceptual and analytical approach to understanding leadership that is focused on interactions between leaders and those they lead with the goal of driving instructional improvement and improving student outcomes by developing high-quality teaching and an educational culture that enables all students to thrive. This article provides an overview of the state-of-the-art research available on distributed leadership. As new social and educational demands emerge, leadership responses need to be reformed at all school levels to ensure a school’s ability to provide a high-quality education. These transformations must be promoted from within each school center. The author describes and covers a deep review of the literature between 1981 and 2020. The source data for this research, (321 articles), is derived from SCOPUS, Biblometrix Studio, and VOSviewer. The terms and their clusters were illustrated on graphs, and density maps were utilized. General recommendations are provided and challenges are identified for the incorporation of DL changes into the management of schools. The findings show that the literature refers explicitly to DL, wherein there are a number of interesting insights provided by theoretical articles. A conclusion is given with recommendations for further multidisciplinary research at the intersection of the fields in order to show the holistic landscape of this field. directions. These results contribute to a Software Engineering approach for developing predictive maintenance using Digital Twins in academics and the industry. This study is the first SLR in predictive maintenance using Digital Twins. We answer key questions for designing a successful predictive maintenance model leveraging Digital Twins. We found that to this day, computational burden, data variety, and complexity of models, assets, or components are the key challenges in designing these models. • 20 systematic review datasets from the medical domain were used for evaluation. • Significant workload savings of at least 10% in 18 out of 20 review datasets.
PY  - 2021
DA  - 2021-06-15
JO  - {'id': 'https://openalex.org/S4210183189', 'issn_l': '2517-6323', 'issn': ['2517-6323'], 'display_name': 'The European educational researcher', 'publisher': 'European Star Academic Publishing Ltd', 'type': 'journal', 'url': 'https://doi.org/10.31757/euer.426', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - I V García-Carreño
ER  - 

748.
TY  - journal-article
ID  - https://openalex.org/W3195929942
DO  - https://doi.org/10.1136/bmjhci-2021-100363
TI  - Turbulence health systems: engineering a rapidly adaptive health system for times of crisis
AB  - The coronavirus epidemic has provided us a teachable moment in how to run a healthcare system. Dealing with this pandemic has required near-wartime levels of health system reconfiguration and reinvention—often with heroic effort and unprecedented commitment of resources. By the time this pandemic all students to thrive. This article provides an overview of the state-of-the-art research available on distributed leadership. As new social and educational demands emerge, leadership responses need to be reformed at all school levels to ensure a school’s ability to provide a high-quality education. These transformations must be promoted from within each school center. The author describes and covers a deep review of the literature between 1981 and 2020. The source data for this research, (321 articles), is derived from SCOPUS, Biblometrix Studio, and VOSviewer. The terms and their clusters were illustrated on graphs, and density maps were utilized. General recommendations are provided and challenges are identified for the incorporation of DL changes into the management of schools. The findings show that the literature refers explicitly to DL, wherein there are a number of interesting insights provided by theoretical articles. A conclusion is given with recommendations for further multidisciplinary research at the intersection of the fields in order to show the holistic landscape of this field. directions. These results contribute to a Software Engineering approach for developing predictive maintenance using Digital Twins in academics and the industry. This study is the first SLR in predictive maintenance using Digital Twins. We answer key questions for designing a successful predictive maintenance model leveraging Digital Twins. We found that to this day, computational burden, data variety, and complexity of models, assets, or components are the key challenges in designing these models. • 20 systematic review datasets from the medical domain were used for evaluation. • Significant workload savings of at least 10% in 18 out of 20 review datasets.
PY  - 2021
DA  - 2021-08-01
JO  - {'id': 'https://openalex.org/V4210217889', 'issn_l': '2632-1009', 'issn': ['2632-1009'], 'display_name': 'BMJ health & care informatics', 'publisher': 'BMJ', 'type': 'journal', 'url': 'https://informatics.bmj.com/content/bmjhci/28/1/e100363.full.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc'}
DP  - OpenAlex
AU  - Enrico Coiera
AU  - Jeffrey Braithwaite
ER  - 

749.
TY  - journal-article
ID  - https://openalex.org/W4206924758
DO  - https://doi.org/10.1108/bfj-09-2021-1075
TI  - Consumer behaviour in relation to food waste: a systematic literature review
AB  - Purpose The purpose of this systematic literature review (SLR) is to analyse which consumer behaviours are more evident in relation to food waste, in addition to seeking to identify which types of food are most wasted in homes and the methods which have been used by studies for such particularities. In this paper, it was possible to identify the universe of consumer characteristics covering the main contributions to the development of this theme with different points of view. Design/methodology/approach To achieve this goal, the authors performed a SLR according to well-established guidelines set. The authors used tools to partially support the process, which relies on a four-member research team. Findings The authors report on 49 primary studies that deal the lack of planning, excessive purchases and the non-reuse of food leftovers by the consumer as the characteristics most evidenced as a consequence of food waste. Furthermore, fruits, vegetables and bread are the most wasted food. Regarding the most used research methods, some studies in this SLR use the qualitative method, but mostly food waste is analysed using the quantitative method. Originality/value This SLR is different because it seeks to group different aspects of food waste, mapping not only the consumer’s behavioural characteristics but also seeking to identify the most wasted food. The research contributed to finding theoretical gaps on the subject in favour of reducing waste, based on the findings that demonstrate causing food waste. SLR in predictive maintenance using Digital Twins. We answer key questions for designing a successful predictive maintenance model leveraging Digital Twins. We found that to this day, computational burden, data variety, and complexity of models, assets, or components are the key challenges in designing these models. • 20 systematic review datasets from the medical domain were used for evaluation. • Significant workload savings of at least 10% in 18 out of 20 review datasets.
PY  - 2022
DA  - 2022-01-25
JO  - {'id': 'https://openalex.org/S99313352', 'issn_l': '0007-070X', 'issn': ['0007-070X', '1758-4108'], 'display_name': 'British Food Journal', 'publisher': 'Emerald Publishing Limited', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Joina Ijuniclair Arruda Silva dos Santos
AU  - Denis Silva da Silveira
AU  - Marconi Freitas da Costa
AU  - Rafael F. Duarte
ER  - 

750.
TY  - journal-article
ID  - https://openalex.org/W4285009637
DO  - https://doi.org/10.1080/24750158.2022.2087954
TI  - The Development of a Living Knowledge System and Implications for Future Systematic Searching
AB  - No Abstract Found
PY  - 2022
DA  - 2022-07-03
JO  - {'id': 'https://openalex.org/S4210204890', 'issn_l': '2475-0158', 'issn': ['2475-0158', '2475-0166'], 'display_name': 'Journal of the Australian Library and Information Association', 'publisher': 'Taylor & Francis', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Lisa Grbin
AU  - Peter D. Nichols
AU  - Fiona M. Russell
AU  - Matthew Fuller-Tyszkiewicz
AU  - Craig A. Olsson
ER  - 

751.
TY  - journal-article
ID  - https://openalex.org/W3184058630
DO  - https://doi.org/10.47909/ijsmc.52
TI  - A roadmap toward the automatic composition of systematic literature reviews
AB  - Objective. This paper presents an overview of existing artificial intelligence tools to produce systematic literature reviews. Furthermore, we propose a general framework resulting from combining these techniques to highlight the challenges and possibilities currently existing in this research area. Design/Methodology/Approach. We undertook a scoping review on the systematic literature review steps to automate them via computational techniques. Results/Discussion. The process of creating a literature review is both creative and technical. The technical part of this process is liable to automation. Based on the literature, we chose to divide this technical part into four steps: searching, screening, extraction, and synthesis. For each one of these steps, we presented practical artificial intelligence techniques to carry them out. In addition, we presented the obstacles encountered in the application of each technique. Conclusion. We proposed a framework for automatically creating systematic literature reviews by combining and placing existing techniques in stages where they possess the greatest potential to be useful. Despite still lacking practical assessment in different areas of knowledge, this proposal indicates ways with the potential to reduce the time-consuming and repetitive work embedded in the systematic literature review process. Originality/Value. The paper presents the current possibilities for automating systematic literature reviews and how they can work together to reduce researchers’ operational workload. food. The research contributed to finding theoretical gaps on the subject in favour of reducing waste, based on the findings that demonstrate causing food waste. SLR in predictive maintenance using Digital Twins. We answer key questions for designing a successful predictive maintenance model leveraging Digital Twins. We found that to this day, computational burden, data variety, and complexity of models, assets, or components are the key challenges in designing these models. • 20 systematic review datasets from the medical domain were used for evaluation. • Significant workload savings of at least 10% in 18 out of 20 review datasets.
PY  - 2021
DA  - 2021-07-27
JO  - {'id': 'https://openalex.org/V4210199169', 'issn_l': '2709-3158', 'issn': ['2709-7595', '2709-3158'], 'display_name': 'Iberoamerican journal of science measurement and communication', 'publisher': 'ColNes', 'type': 'journal', 'url': 'https://pub.colnes.org/index.php/ijsmc/article/download/52/88', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc'}
DP  - OpenAlex
AU  - Eugênio Monteiro da Silva Júnior
AU  - Moisés Lima Dutra
ER  - 

752.
TY  - book-chapter
ID  - https://openalex.org/W4225658850
DO  - https://doi.org/10.1007/978-3-030-99736-6_39
TI  - Automation of Citation Screening for Systematic Literature Reviews Using Neural Networks: A Replicability Study
AB  - AbstractIn the process of Systematic Literature Review, citation screening is estimated to be one of the most time-consuming steps. Multiple approaches to automate it using various machine learning techniques have been proposed. The first research papers that apply deep neural networks to this problem were published in the last two years. In this work, we conduct a replicability study of the first two deep learning papers for citation screening [8, 16] and evaluate their performance on 23 publicly available datasets. While we succeeded in replicating the results of one of the papers, we were unable to replicate the results of the other. We summarise the challenges involved in the replication, including difficulties in obtaining the datasets to match the experimental setup of the original papers and problems with executing the original source code. Motivated by this experience, we subsequently present a simpler model based on averaging word embeddings that outperforms one of the models on 18 out of 23 datasets and is, on average, 72 times faster than the second replicated approach. Finally, we measure the training time and the invariance of the models when exposed to a variety of input features and random initialisations, demonstrating differences in the robustness of these approaches.KeywordsCitation screeningStudy selectionSystematic literature review (SLR)Document retrievalReplicability workload. food. The research contributed to finding theoretical gaps on the subject in favour of reducing waste, based on the findings that demonstrate causing food waste. SLR in predictive maintenance using Digital Twins. We answer key questions for designing a successful predictive maintenance model leveraging Digital Twins. We found that to this day, computational burden, data variety, and complexity of models, assets, or components are the key challenges in designing these models. • 20 systematic review datasets from the medical domain were used for evaluation. • Significant workload savings of at least 10% in 18 out of 20 review datasets.
PY  - 2022
DA  - 2022-01-01
JO  - {'id': 'https://openalex.org/S4306463941', 'issn_l': None, 'issn': None, 'display_name': 'Springer International Publishing eBooks', 'publisher': 'Springer Nature', 'type': 'ebook platform', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Wojciech Kusa
AU  - Allan Hanbury
AU  - Petr Knoth
ER  - 

753.
TY  - journal-article
ID  - https://openalex.org/W4283394823
DO  - https://doi.org/10.3390/s22134734
TI  - Deep Learning-Based Defect Prediction for Mobile Applications
AB  - Smartphones have enabled the widespread use of mobile applications. However, there are unrecognized defects of mobile applications that can affect businesses due to a negative user experience. To avoid this, the defects of applications should be detected and removed before release. This study aims to develop a defect prediction model for mobile applications. We performed cross-project and within-project experiments and also used deep learning algorithms, such as convolutional neural networks (CNN) and long short term memory (LSTM) to develop a defect prediction model for Android-based applications. Based on our within-project experimental results, the CNN-based model provides the best performance for mobile application defect prediction with a 0.933 average area under ROC curve (AUC) value. For cross-project mobile application defect prediction, there is still room for improvement when deep learning algorithms are preferred. code. Motivated by this experience, we subsequently present a simpler model based on averaging word embeddings that outperforms one of the models on 18 out of 23 datasets and is, on average, 72 times faster than the second replicated approach. Finally, we measure the training time and the invariance of the models when exposed to a variety of input features and random initialisations, demonstrating differences in the robustness of these approaches.KeywordsCitation screeningStudy selectionSystematic literature review (SLR)Document retrievalReplicability workload. food. The research contributed to finding theoretical gaps on the subject in favour of reducing waste, based on the findings that demonstrate causing food waste. SLR in predictive maintenance using Digital Twins. We answer key questions for designing a successful predictive maintenance model leveraging Digital Twins. We found that to this day, computational burden, data variety, and complexity of models, assets, or components are the key challenges in designing these models. • 20 systematic review datasets from the medical domain were used for evaluation. • Significant workload savings of at least 10% in 18 out of 20 review datasets.
PY  - 2022
DA  - 2022-06-23
JO  - {'id': 'https://openalex.org/S101949793', 'issn_l': '1424-8220', 'issn': ['1424-8220'], 'display_name': 'Sensors', 'publisher': 'MDPI', 'type': 'journal', 'url': 'https://www.mdpi.com/1424-8220/22/13/4734/pdf?version=1656067143', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Manzura Jorayeva
AU  - Akhan Akbulut
AU  - Daniel Rodriguez
AU  - Alok Mishra
ER  - 

754.
TY  - journal-article
ID  - https://openalex.org/W4307278198
DO  - https://doi.org/10.1365/s40702-022-00909-1
TI  - Extraktion und Analyse von Schlüsselwörtern für eine automatisierte Literaturauswertung zum Thema Empfehlungssysteme
AB  - Zusammenfassung Mit der zunehmenden Anzahl an wissenschaftlichen Publikationen steigt die Komplexität zur Durchführung einer Literaturauswertung. Insbesondere die Analyse einer Vielzahl an wissenschaftlichen Publikationen ist mit manuellen Tätigkeiten verbunden, die in der Regel nur sehr zeitaufwendig umzusetzen sind. Um diesem Aufwand entgegenzuwirken, existieren unterschiedliche Methoden der deskriptiven Berechnung und des maschinellen Lernens, die zur Unterstützung einer wissenschaftlichen Literaturauswertung eingesetzt werden können. In diesem Zusammenhang kann Keyword Extraction genutzt werden, um Schlüsselwörter von Texten automatisiert zu erkennen. In diesem Beitrag wird vorgestellt, wie Keyword Extraction zur Unterstützung einer wissenschaftlichen Literaturauswertung zum Thema „Empfehlungssysteme“ eingesetzt werden kann. model provides the best performance for mobile application defect prediction with a 0.933 average area under ROC curve (AUC) value. For cross-project mobile application defect prediction, there is still room for improvement when deep learning algorithms are preferred. code. Motivated by this experience, we subsequently present a simpler model based on averaging word embeddings that outperforms one of the models on 18 out of 23 datasets and is, on average, 72 times faster than the second replicated approach. Finally, we measure the training time and the invariance of the models when exposed to a variety of input features and random initialisations, demonstrating differences in the robustness of these approaches.KeywordsCitation screeningStudy selectionSystematic literature review (SLR)Document retrievalReplicability workload. food. The research contributed to finding theoretical gaps on the subject in favour of reducing waste, based on the findings that demonstrate causing food waste. SLR in predictive maintenance using Digital Twins. We answer key questions for designing a successful predictive maintenance model leveraging Digital Twins. We found that to this day, computational burden, data variety, and complexity of models, assets, or components are the key challenges in designing these models. • 20 systematic review datasets from the medical domain were used for evaluation. • Significant workload savings of at least 10% in 18 out of 20 review datasets.
PY  - 2022
DA  - 2022-09-22
JO  - {'id': 'https://openalex.org/S4210205328', 'issn_l': '1436-3011', 'issn': ['1436-3011', '2198-2775'], 'display_name': 'HMD. Praxis der Wirtschaftsinformatik', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://link.springer.com/content/pdf/10.1365/s40702-022-00909-1.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Thomas Barton
AU  - Andreas Peuker
ER  - 

755.
TY  - posted-content
ID  - https://openalex.org/W3204032926
DO  - https://doi.org/10.1101/2021.09.30.462652
TI  - Are Machines-learning Methods More Efficient than Humans in Triaging Literature for Systematic Reviews?
AB  - Abstract Systematic literature reviews provide rigorous assessments of clinical, cost-effectiveness, and humanistic data. Accordingly, there is a growing trend worldwide among healthcare agencies and decision-makers to require them in order to make informed decisions. Because these reviews are labor-intensive and time consuming, we applied advanced analytic methods (AAM) to determine if machine learning methods could classify abstracts as well as humans. Literature searches were run for metastatic non-small cell lung cancer treatments (mNSCLC) and metastatic castration-resistant prostate cancer (mCRPC). Records were reviewed by humans and two AAMs. AAM-1 involved a pre-trained data-mining model specialized in biomedical literature, and AAM-2 was based on support vector machine algorithms. The AAMs assigned an accept/reject status, with reasons for exclusion. Automatic results were compared to those of humans. For mNSCLC, 5820 records were processed by humans and 440 (8%) records were accepted and the remaining items rejected. AAM-1 correctly accepted 6% of records and correctly excluded 79%. AAM-2 correctly accepted 6% of records and correctly excluded 82%. The review was completed by AAM-1 or AAM-2 in 52 hours, compared to 196 hours for humans. Work saved was estimated to be 76% and 79% by AAM-1 and AAM-2, respectively. For mCRPC, 2434 records were processed by humans and 26% of these were accepted and 74% rejected. AAM-1 correctly accepted 23% of records and rejected 62%. AAM-2 correctly accepted 20% of records and rejected 66%. The review was completed by AAM-1, AAM-2, and humans in 25, 25 and 85 hours, respectively. Work saved was estimated to be 61% and 68% by AAM-1 and AAM-2, respectively. AAMs can markedly reduce the time required for searching and triaging records during a systematic review. Methods similar to AAMs should be assessed in future research for how consistent their performances are in SLRs of economic, epidemiological and humanistic evidence. at least 10% in 18 out of 20 review datasets.
PY  - 2021
DA  - 2021-09-30
JO  - {'id': 'https://openalex.org/S2734324842', 'issn_l': None, 'issn': None, 'display_name': 'bioRxiv', 'publisher': None, 'type': 'repository', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - S. Abogunrin
AU  - L. Queiros
AU  - M. Bednarski
AU  - Malcolm E. Sumner
AU  - David Baehrens
AU  - A. Witzmann
ER  - 

756.
TY  - journal-article
ID  - https://openalex.org/W4221100316
DO  - https://doi.org/10.1080/08993408.2022.2039504
TI  - Empirical research on pair programming in higher education: a literature review
AB  - No Abstract Found
PY  - 2022
DA  - 2022-03-06
JO  - {'id': 'https://openalex.org/S97147119', 'issn_l': '0899-3408', 'issn': ['0899-3408', '1744-5175'], 'display_name': 'Computer Science Education', 'publisher': 'Taylor & Francis', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Anja Hawlitschek
AU  - Sarah Berndt
AU  - Sandra Schulz
ER  - 

757.
TY  - journal-article
ID  - https://openalex.org/W4281625986
DO  - https://doi.org/10.1200/cci.21.00129
TI  - Machine Learning Approach to Facilitate Knowledge Synthesis at the Intersection of Liver Cancer, Epidemiology, and Health Disparities Research
AB  - PURPOSE Liver cancer is a global challenge, and disparities exist across multiple domains and throughout the disease continuum. However, liver cancer's global epidemiology and etiology are shifting, and the literature is rapidly evolving, presenting a challenge to the synthesis of knowledge needed to identify areas of research needs and to develop research agendas focusing on disparities. Machine learning (ML) techniques can be used to semiautomate the literature review process and improve efficiency. In this study, we detail our approach and provide practical benchmarks for the development of a ML approach to classify literature and extract data at the intersection of three fields: liver cancer, health disparities, and epidemiology. METHODS We performed a six-phase process including: training (I), validating (II), confirming (III), and performing error analysis (IV) for a ML classifier. We then developed an extraction model (V) and applied it (VI) to the liver cancer literature identified through PubMed. We present precision, recall, F1, and accuracy metrics for the classifier and extraction models as appropriate for each phase of the process. We also provide the results for the application of our extraction model. RESULTS With limited training data, we achieved a high degree of accuracy for both our classifier and for the extraction model for liver cancer disparities research literature performed using epidemiologic methods. The disparities concept was the most challenging to accurately classify, and concepts that appeared infrequently in our data set were the most difficult to extract. CONCLUSION We provide a roadmap for using ML to classify and extract comprehensive information on multidisciplinary literature. Our technique can be adapted and modified for other cancers or diseases where disparities persist. during a systematic review. Methods similar to AAMs should be assessed in future research for how consistent their performances are in SLRs of economic, epidemiological and humanistic evidence. at least 10% in 18 out of 20 review datasets.
PY  - 2022
DA  - 2022-05-01
JO  - {'id': 'https://openalex.org/S4210181501', 'issn_l': '2473-4276', 'issn': ['2473-4276'], 'display_name': 'JCO clinical cancer informatics', 'publisher': 'American Society of Clinical Oncology', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Travis Hyams
AU  - Ling Luo
AU  - Brionna Hair
AU  - Sanghyuk Lee
AU  - Zhiyong Lu
AU  - Daniela Seminara
ER  - 

758.
TY  - proceedings-article
ID  - https://openalex.org/W4283367682
DO  - https://doi.org/10.1109/icapai55158.2022.9801564
TI  - The application of artificial intelligence on different types of literature reviews - A comparative study
AB  - The growing number of published academic literature poses challenges to the research community which struggles to keep up with the vast amount of publications through traditional research methods that are highly manual in nature. Researchers are struggling to determine the most relevant research gaps, yielding insignificant publications that constitute a waste of resources. As a consequence, AI applications are being applied increasingly to automate and facilitate the review process of these vast amounts of papers. However, scholars have so far only addressed a limited number of scientific fields and focused their efforts on one end of the spectrum in automating systematic literature reviews (SLRs). Yet, these are not sufficient to cover the full range of research questions and available data sources. This paper offers a comparative study of systematic and semi-systematic literature reviews to determine the potential of AI applications in both types of literature review processes. The analysis addresses the status quo and discusses apparent limitations of AI to automate reviews. Results are synthesized in proposing a new tool integrating various AI applications along the research process that improve the speed, quality, and cost-efficiency of the overall research process. a high degree of accuracy for both our classifier and for the extraction model for liver cancer disparities research literature performed using epidemiologic methods. The disparities concept was the most challenging to accurately classify, and concepts that appeared infrequently in our data set were the most difficult to extract. CONCLUSION We provide a roadmap for using ML to classify and extract comprehensive information on multidisciplinary literature. Our technique can be adapted and modified for other cancers or diseases where disparities persist. during a systematic review. Methods similar to AAMs should be assessed in future research for how consistent their performances are in SLRs of economic, epidemiological and humanistic evidence. at least 10% in 18 out of 20 review datasets.
PY  - 2022
DA  - 2022-05-05
JO  - {'id': None, 'issn_l': None, 'issn': None, 'display_name': '2022 International Conference on Applied Artificial Intelligence (ICAPAI)', 'publisher': None, 'type': None, 'url': 'https://doi.org/10.1109/icapai55158.2022.9801564', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Henry R. Muller
AU  - Simran Pachnanda
AU  - Felix Hendrik Pahl
AU  - Christopher Rosenqvist
ER  - 

759.
TY  - proceedings-article
ID  - https://openalex.org/W4283708657
DO  - https://doi.org/10.23919/mipro55190.2022.9803778
TI  - Improving stability of detected topics in learning analytics
AB  - Due to exponential increase in the number of published research papers, it is becoming more and more difficult to review current research in any discipline. It is especially true for disciplines undergoing fast development like learning analytics and educational data mining. Natural language processing offers opportunity to facilitate extraction of information/knowledge from a large volume of documents. In an attempt to organize papers on application of learning analytics and educational data mining for supporting self-regulated learning, we have used Latent Dirichlet Allocation to identify topics in a set of 107 research papers. Results of Latent Dirichlet Allocation depend on the initial choice of a random number generator seed, and replicated runs do not result in the same topics. Stability of allocation of documents to topics was analyzed using Jaccard similarity coefficient. The proposed method enables identifying stabile clusters of research papers sharing the same topics. review processes. The analysis addresses the status quo and discusses apparent limitations of AI to automate reviews. Results are synthesized in proposing a new tool integrating various AI applications along the research process that improve the speed, quality, and cost-efficiency of the overall research process. a high degree of accuracy for both our classifier and for the extraction model for liver cancer disparities research literature performed using epidemiologic methods. The disparities concept was the most challenging to accurately classify, and concepts that appeared infrequently in our data set were the most difficult to extract. CONCLUSION We provide a roadmap for using ML to classify and extract comprehensive information on multidisciplinary literature. Our technique can be adapted and modified for other cancers or diseases where disparities persist. during a systematic review. Methods similar to AAMs should be assessed in future research for how consistent their performances are in SLRs of economic, epidemiological and humanistic evidence. at least 10% in 18 out of 20 review datasets.
PY  - 2022
DA  - 2022-05-23
JO  - {'id': None, 'issn_l': None, 'issn': None, 'display_name': '2022 45th Jubilee International Convention on Information, Communication and Electronic Technology (MIPRO)', 'publisher': None, 'type': None, 'url': 'https://doi.org/10.23919/mipro55190.2022.9803778', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - S. Rako
AU  - D. Simic
AU  - Barbara Šlibar
AU  - J. Gusic-Mundar
ER  - 

760.
TY  - journal-article
ID  - https://openalex.org/W4285391605
DO  - https://doi.org/10.1155/2022/6933523
TI  - Construction of a Meta-Evidence Prototype Database of Traditional Chinese Medicine Splenogastric Diseases and Its Application in an Automatic Meta-Analysis System
AB  - Traditional Chinese medicine splenogastric diseases (TCMSDs) are equivalent to digestive system diseases in modern medicine. The forms of clinical evidence of TCMSDs include clinical trials, such as randomized controlled trials (RCTs) and systematic reviews (SRs). SRs mainly rely on manual operations and have the shortcomings of time consumption and low efficiency; therefore, they cannot meet the needs of rapid clinical decision-making. It is urgent to establish a new and smart form of a database to support the progress of SRs.We searched and screened all TCMSD RCT reports, in both Chinese and English, and extracted them into meta-evidence through predesigned structural Microsoft Excel tables. All meta-evidence was imported into an online clinical meta-evidence collection and management system after data quality checking. The meta-evidence database of traditional Chinese medicine (TCM) splenogastric disease (MED-TCMSD) was then tested as a backend of an automatic meta-analysis system.A total of 405 cases of TCMSD RCTs were processed into meta-evidence. The most common diseases were stomach stuffiness disease, epigastralgia, and chronic atrophic gastritis. Banxiaxiexin decoction and its modifications were the most used interventions. More than half of the cases employed TCM in conjunction with regular therapeutics. The top reported outcomes included clinical effects, adverse events, and TCM syndromes. The MED-TCMSD worked well as a part of the automatic meta-analysis system.We developed and tested a new form of clinical evidence, meta-evidence, for automatic SR and fast evidence-based decision-making. As an example of the MED, the MED-TCMSD can improve the production and updating efficiency of the evidence of TCMSDs. The methods of constructing the MED-TCMSD can be further applied to the development of MEDs of other diseases. where disparities persist. during a systematic review. Methods similar to AAMs should be assessed in future research for how consistent their performances are in SLRs of economic, epidemiological and humanistic evidence. at least 10% in 18 out of 20 review datasets.
PY  - 2022
DA  - 2022-07-13
JO  - {'id': 'https://openalex.org/S15444899', 'issn_l': '1741-427X', 'issn': ['1741-427X', '1741-4288'], 'display_name': 'Evidence-based Complementary and Alternative Medicine', 'publisher': 'Hindawi Publishing Corporation', 'type': 'journal', 'url': 'https://downloads.hindawi.com/journals/ecam/2022/6933523.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Xueqin Zhang
AU  - Wang Chunying
AU  - YanNing Yao
AU  - Wenyu Sun
AU  - Yujie Guo
AU  - Lin Ma
AU  - Xin-Yuan Lu
AU  - Hongyong Deng
ER  - 

761.
TY  - journal-article
ID  - https://openalex.org/W4295904088
DO  - https://doi.org/10.1088/1748-3190/ac9208
TI  - Using natural language processing to find research topics in Living Machines conferences and their intersections with Bioinspiration &amp; Biomimetics publications
AB  - Abstract The number of published scientific articles is increasing dramatically and makes it difficult to keep track of research topics. This is particularly difficult in interdisciplinary research areas where different communities from different disciplines are working together. It would be useful to develop methods to automate the detection of research topics in a research domain. Here we propose a natural language processing (NLP) based method to automatically detect topics in defined corpora. We start by automatically generating a global state of the art of Living Machines conferences. Our NLP-based method classifies all published papers into different clusters corresponding to the research topic published in these conferences. We perform the same study on all papers published in the journals Bioinspiration &amp; Biomimetics and Soft Robotics. In total this analysis concerns 2099 articles. Next, we analyze the intersection between the research themes published in the conferences and the corpora of these two journals. We also examine the evolution of the number of papers per research theme which determines the research trends. Together, these analyses provide a snapshot of the current state of the field, help to highlight open questions, and provide insights into the future. included clinical effects, adverse events, and TCM syndromes. The MED-TCMSD worked well as a part of the automatic meta-analysis system.We developed and tested a new form of clinical evidence, meta-evidence, for automatic SR and fast evidence-based decision-making. As an example of the MED, the MED-TCMSD can improve the production and updating efficiency of the evidence of TCMSDs. The methods of constructing the MED-TCMSD can be further applied to the development of MEDs of other diseases. where disparities persist. during a systematic review. Methods similar to AAMs should be assessed in future research for how consistent their performances are in SLRs of economic, epidemiological and humanistic evidence. at least 10% in 18 out of 20 review datasets.
PY  - 2022
DA  - 2022-09-14
JO  - {'id': 'https://openalex.org/S87464931', 'issn_l': '1748-3182', 'issn': ['1748-3190', '1748-3182'], 'display_name': 'Bioinspiration & Biomimetics', 'publisher': 'IOP Publishing', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Theophile Carniel
AU  - Leo Cazenille
AU  - Jean-Michel Dalle
AU  - José Halloy
ER  - 

762.
TY  - book-chapter
ID  - https://openalex.org/W4297811485
DO  - https://doi.org/10.1007/978-3-031-16474-3_5
TI  - A Rapid Semi-automated Literature Review on Legal Precedents Retrieval
AB  - AbstractPrecedents constitute the starting point of judges’ reasoning in national legal systems. Precedents are also an essential input for case-based reasoning (CBR) methodologies. Although considerable research has been done on CBR applied to legal practice, the precedent retrieval techniques are a relatively new and unexplored field of AI & Law. Only a few works have tested or developed methods for identifying such previous similar cases. This work uses text mining (TM), natural language processing (NLP), and data visualization methods to provide a semi-automated rapid literature review and identify how justice courts and legal practitioners may use AI to retrieve similar cases. Based on Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA), automation techniques were used to expedite the literature review. In this study, we confirmed the feasibility of automation tools for expediting literature reviews and provided an overview of the current research state on legal precedents retrieval.KeywordsPrecedents retrievalRapid reviewAutomated journals. We also examine the evolution of the number of papers per research theme which determines the research trends. Together, these analyses provide a snapshot of the current state of the field, help to highlight open questions, and provide insights into the future. included clinical effects, adverse events, and TCM syndromes. The MED-TCMSD worked well as a part of the automatic meta-analysis system.We developed and tested a new form of clinical evidence, meta-evidence, for automatic SR and fast evidence-based decision-making. As an example of the MED, the MED-TCMSD can improve the production and updating efficiency of the evidence of TCMSDs. The methods of constructing the MED-TCMSD can be further applied to the development of MEDs of other diseases. where disparities persist. during a systematic review. Methods similar to AAMs should be assessed in future research for how consistent their performances are in SLRs of economic, epidemiological and humanistic evidence. at least 10% in 18 out of 20 review datasets.
PY  - 2022
DA  - 2022-01-01
JO  - {'id': 'https://openalex.org/S106296714', 'issn_l': '0302-9743', 'issn': ['1611-3349', '0302-9743'], 'display_name': 'Lecture Notes in Computer Science', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Hugo Silva
AU  - Nuno Antonio
AU  - Fernando Bacao
ER  - 

763.
TY  - journal-article
ID  - https://openalex.org/W4306784343
DO  - https://doi.org/10.1016/j.aei.2022.101774
TI  - Data-driven engineering design: A systematic review using scientometric approach
AB  - In the last two decades, data regarding engineering design and product development has increased rapidly. Big data exploration and mining offer numerous opportunities for engineering design; however, owing to the multitude of data sources and formats coupled with the high complexity of the design process, these techniques are yet to be utilised to the best of their full potential. In this study, a comprehensive assessment of the state-of-the-art data-driven engineering design (DDED) in the last 20 years was conducted. A scientometric approach was employed wherein first, a systematic article acquisition procedure was performed, where a dataset of 3339 articles related to engineering design and big data analytics applications were extracted from Web of Science (WoS) and Scopus. Thereafter, this dataset was reduced to a dataset of 366 articles based on concise data screening. The resulting articles were used to analyse the dynamics of research in DDED throughout the last 20 years and to detect the primary research topics related to DDED, the most influential authors, and the papers with the highest impact in the DDED domain. Furthermore, the co-occurrence network of keywords/keyphrases and co-authorship networks were constructed and analysed to reveal the interconnection of the research topics and the collaboration between the most prolific authors. Finally, an insight how big data analytics is being applied through product development activities to support decision-making in engineering design was presented. fast evidence-based decision-making. As an example of the MED, the MED-TCMSD can improve the production and updating efficiency of the evidence of TCMSDs. The methods of constructing the MED-TCMSD can be further applied to the development of MEDs of other diseases. where disparities persist. during a systematic review. Methods similar to AAMs should be assessed in future research for how consistent their performances are in SLRs of economic, epidemiological and humanistic evidence. at least 10% in 18 out of 20 review datasets.
PY  - 2022
DA  - 2022-10-01
JO  - {'id': 'https://openalex.org/S112141509', 'issn_l': '1474-0346', 'issn': ['1474-0346', '1873-5320'], 'display_name': 'Advanced Engineering Informatics', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'https://doi.org/10.1016/j.aei.2022.101774', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Daria Vlah
AU  - Andrej Kastrin
AU  - Janez Povh
AU  - Nikola Vukašinović
ER  - 

764.
TY  - journal-article
ID  - https://openalex.org/W4307282726
DO  - https://doi.org/10.1108/imr-09-2022-390
TI  - Guest editorial: Systematic literature reviews in international marketing: from the past to the future and beyond
AB  - No Abstract Found
PY  - 2022
DA  - 2022-10-25
JO  - {'id': 'https://openalex.org/S35673206', 'issn_l': '0265-1335', 'issn': ['0265-1335', '1758-6763'], 'display_name': 'International Marketing Review', 'publisher': 'Emerald Publishing Limited', 'type': 'journal', 'url': 'https://www.emerald.com/insight/content/doi/10.1108/IMR-09-2022-390/full/pdf?title=guest-editorial-systematic-literature-reviews-in-international-marketing-from-the-past-to-the-future-and-beyond', 'is_oa': True, 'version': 'publishedVersion', 'license': None}
DP  - OpenAlex
AU  - Demetris Vrontis
AU  - John Hulland
AU  - Jason D. Shaw
AU  - Ajai Gaur
AU  - Michael R. Czinkota
AU  - Michael Christofi
ER  - 

765.
TY  - journal-article
ID  - https://openalex.org/W4307460327
DO  - https://doi.org/10.1016/j.heliyon.2022.e11256
TI  - State of microalgae-based swine manure digestate treatment: An overview
AB  - Global pork production has an annual growth of approximately 2.1%, and its economic and environmental impact are related with the treatment of waste in the production chain. There is little evidence of research advances to generate alternatives for using these wastes. The lack of research related to microalgae cultivation using digestate produced by porcine residues generates negative environmental impact, inadequate and inefficient technologies, low recovery and use of waste and loss of value and competitiveness in the market. The available literature focuses mainly on the treatment of anaerobic digestion liquid effluents for the removal of components, but not on the generation of value-added products. Therefore, there is a need to collect the available information, analyze it and propose other new methodologies. This article presents the information obtained from conducting a systematic review of the literature with a bibliometric and a comparative analysis; achieving an analysis of the temporal and geographical distribution, the main topics, the most influential players, the degree of maturity of the research and different strategies collected for microalgae-based swine manure digestate treatment. In this way, it was possible to capture an overview of the current state of the development of research focused on the use of digestate for the cultivation of microalgae, visualizing important aspects as the evolution of publications, identifying China and USA as the main players in research, biomass and wastewater as potential topics also Spirulina, Astaxanthin and beta-carotene as the main products based on microalgae. Thus, achieving an structure, organized and synthesized landscape of scientific and technological knowledge available for the proposal of investigations that allow the use of anaerobic digestion liquid effluents as cultivation medium for microalgae. review. Methods similar to AAMs should be assessed in future research for how consistent their performances are in SLRs of economic, epidemiological and humanistic evidence. at least 10% in 18 out of 20 review datasets.
PY  - 2022
DA  - 2022-10-01
JO  - {'id': 'https://openalex.org/S2898612692', 'issn_l': '2405-8440', 'issn': ['2405-8440'], 'display_name': 'Heliyon', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'http://www.cell.com/article/S2405844022025440/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc-nd'}
DP  - OpenAlex
AU  - Claudia M. Sichel-Crespo
AU  - Erika Y. Ortiz-Montoya
AU  - Nelson H. Caicedo-Ortega
AU  - Fiderman Machuca-Martínez
ER  - 

766.
TY  - posted-content
ID  - https://openalex.org/W4309912626
DO  - https://doi.org/10.21203/rs.3.rs-2292464/v1
TI  - Automation of legal precedents retrieval: findings from a rapid literature review
AB  - Abstract Judges frequently rely their reasoning on precedents. In every circumstance, courts must preserve uniformity in case law and, depending on the legal system, previous cases compel rulings. The search for methods to accurately identify similar previous cases is not new and has been a vital input, for example, to case-based reasoning (CBR) methodologies. Innovations in language processing and machine learning (ML) brought momentum to identifying precedents while providing tools for automating this task. This rapid literature review investigated how research on the identification of legal precedents has evolved. It also examined the most promising automation strategies for this task and confirmed the growing interest in using artificial intelligence for legal precedents retrieval. The findings demonstrate that no artificial intelligence solution currently stands out as the most effective at finding past similar cases. Also, existing results require validation with statistically significant samples and ground truth provided by specialists. In addition, this work employed text mining (TM) to automate part of the literature review while still delivering an accurate picture of research in the field. Ultimately, this review suggests directions for future work, as more experimentation is required. current state of the development of research focused on the use of digestate for the cultivation of microalgae, visualizing important aspects as the evolution of publications, identifying China and USA as the main players in research, biomass and wastewater as potential topics also Spirulina, Astaxanthin and beta-carotene as the main products based on microalgae. Thus, achieving an structure, organized and synthesized landscape of scientific and technological knowledge available for the proposal of investigations that allow the use of anaerobic digestion liquid effluents as cultivation medium for microalgae. review. Methods similar to AAMs should be assessed in future research for how consistent their performances are in SLRs of economic, epidemiological and humanistic evidence. at least 10% in 18 out of 20 review datasets.
PY  - 2022
DA  - 2022-11-23
JO  - {'id': 'https://openalex.org/S4306402450', 'issn_l': None, 'issn': None, 'display_name': 'Research Square (Research Square)', 'publisher': 'Research Square', 'type': 'repository', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Hugo Mentzingen
AU  - Fernando Bacao
AU  - Nuno António
ER  - 

767.
TY  - book-chapter
ID  - https://openalex.org/W4312607671
DO  - https://doi.org/10.1007/978-3-031-20470-8_2
TI  - Ten Years of Living Machines Conferences: Transformers-Based Automated Topic Grouping
AB  - No Abstract Found
PY  - 2022
DA  - 2022-01-01
JO  - {'id': 'https://openalex.org/S4306463941', 'issn_l': None, 'issn': None, 'display_name': 'Springer International Publishing eBooks', 'publisher': 'Springer Nature', 'type': 'ebook platform', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Théophile Carniel
AU  - Leo Cazenille
AU  - Jean-Michel Dalle
AU  - José Halloy
ER  - 

768.
TY  - journal-article
ID  - https://openalex.org/W4313420643
DO  - https://doi.org/10.1016/j.ipm.2022.103255
TI  - Exploring science-technology linkages: A deep learning-empowered solution
AB  - No Abstract Found
PY  - 2023
DA  - 2023-03-01
JO  - {'id': 'https://openalex.org/S174847851', 'issn_l': '0306-4573', 'issn': ['0306-4573', '1873-5371'], 'display_name': 'Information Processing and Management', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Xiang Chen
AU  - Peifeng Ye
AU  - Lu Huang
AU  - Changtian Wang
AU  - Yijie Cai
AU  - Lijie Deng
AU  - Haiping Ren
ER  - 

769.
TY  - journal-article
ID  - https://openalex.org/W4313494591
DO  - https://doi.org/10.3934/aci.2023003
TI  - Affective algorithmic composition of music: A systematic review
AB  - &lt;abstract&gt; &lt;p&gt;Affective music composition systems are known to trigger emotions in humans. However, the design of such systems to stimulate users' emotions continues to be a challenge because, studies that aggregate existing literature in the domain to help advance research and knowledge is limited. This study presents a systematic literature review on affective algorithmic composition systems. Eighteen primary studies were selected from IEEE Xplore, ACM Digital Library, SpringerLink, PubMed, ScienceDirect, and Google Scholar databases following a systematic review protocol. The findings revealed that there is a lack of a unique definition that encapsulates the various types of affective algorithmic composition systems. Accordingly, a unique definition is provided. The findings also show that most affective algorithmic composition systems are designed for games to provide background music. The generative composition method was the most used compositional approach. Overall, there was rather a low amount of research in the domain. Possible reasons for these trends are the lack of a common definition for affective music composition systems and also the lack of detailed documentation of the design, implementation and evaluation of the existing systems.&lt;/p&gt; &lt;/abstract&gt; as more experimentation is required. current state of the development of research focused on the use of digestate for the cultivation of microalgae, visualizing important aspects as the evolution of publications, identifying China and USA as the main players in research, biomass and wastewater as potential topics also Spirulina, Astaxanthin and beta-carotene as the main products based on microalgae. Thus, achieving an structure, organized and synthesized landscape of scientific and technological knowledge available for the proposal of investigations that allow the use of anaerobic digestion liquid effluents as cultivation medium for microalgae. review. Methods similar to AAMs should be assessed in future research for how consistent their performances are in SLRs of economic, epidemiological and humanistic evidence. at least 10% in 18 out of 20 review datasets.
PY  - 2023
DA  - 2023-01-01
JO  - {'id': None, 'issn_l': None, 'issn': None, 'display_name': 'Applied Computing and Intelligence', 'publisher': None, 'type': None, 'url': 'https://doi.org/10.3934/aci.2023003', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc-sa'}
DP  - OpenAlex
AU  - Abigail Wiafe
AU  - Pasi Fränti
ER  - 

770.
TY  - journal-article
ID  - https://openalex.org/W4317510597
DO  - https://doi.org/10.1007/s10844-022-00772-y
TI  - Reducing the user labeling effort in effective high recall tasks by fine-tuning active learning
AB  - No Abstract Found
PY  - 2023
DA  - 2023-01-19
JO  - {'id': 'https://openalex.org/S36033921', 'issn_l': '0925-9902', 'issn': ['1573-7675', '0925-9902'], 'display_name': 'Journal of Intelligent Information Systems', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Guilherme Dal Bianco
AU  - Denio Duarte
AU  - Marcos André Gonçalves
ER  - 

771.
TY  - proceedings-article
ID  - https://openalex.org/W4318147814
DO  - https://doi.org/10.1109/bigdata55660.2022.10020376
TI  - Academic Graph: A Literature Review System
AB  - No Abstract Found
PY  - 2022
DA  - 2022-12-17
JO  - {'id': None, 'issn_l': None, 'issn': None, 'display_name': '2022 IEEE International Conference on Big Data (Big Data)', 'publisher': None, 'type': None, 'url': 'https://doi.org/10.1109/bigdata55660.2022.10020376', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Mustafa Cataltas
AU  - Semih Yumusak
AU  - Kasim Oztoprak
ER  - 

772.
TY  - journal-article
ID  - https://openalex.org/W4319039935
DO  - https://doi.org/10.1007/s12652-023-04530-y
TI  - Machine learning in crime prediction
AB  - Abstract Predicting crimes before they occur can save lives and losses of property. With the help of machine learning, many researchers have studied predicting crimes extensively. In this paper, we evaluate state-of-the-art crime prediction techniques that are available in the last decade, discuss possible challenges, and provide a discussion about the future work that could be conducted in the field of crime prediction. Although many works aim to predict crimes, the datasets they used and methods that are applied are numerous. Using a Systematic Literature Review (SLR) methodology, we aim to collect and synthesize the required knowledge regarding machine learning-based crime prediction and help both law enforcement authorities and scientists to mitigate and prevent future crime occurrences. We focus primarily on 68 selected machine learning papers that predict crime. We formulate eight research questions and observe that the majority of the papers used a supervised machine learning approach, assuming that there is prior labeled data, and however in some cases, there is no labeled data in real-world scenarios. We have also discussed the main challenges found while conducting some of the studies by the researchers. We consider that this research paves the way for further research to help governments and countries fight crime and decrease this for better safety and security. of publications, identifying China and USA as the main players in research, biomass and wastewater as potential topics also Spirulina, Astaxanthin and beta-carotene as the main products based on microalgae. Thus, achieving an structure, organized and synthesized landscape of scientific and technological knowledge available for the proposal of investigations that allow the use of anaerobic digestion liquid effluents as cultivation medium for microalgae. review. Methods similar to AAMs should be assessed in future research for how consistent their performances are in SLRs of economic, epidemiological and humanistic evidence. at least 10% in 18 out of 20 review datasets.
PY  - 2023
DA  - 2023-02-02
JO  - {'id': 'https://openalex.org/S48031226', 'issn_l': '1868-5137', 'issn': ['1868-5137', '1868-5145'], 'display_name': 'Journal of Ambient Intelligence and Humanized Computing', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://link.springer.com/content/pdf/10.1007/s12652-023-04530-y.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Karabo Jenga
AU  - Cagatay Catal
AU  - Gorkem Kar
ER  - 

773.
TY  - journal-article
ID  - https://openalex.org/W4319297895
DO  - https://doi.org/10.3390/electronics12040800
TI  - Towards Nuts and Bolts of Conducting Literature Review: A Typology of Literature Review
AB  - Literature reviews demonstrate the progress of knowledge and a comprehensive understanding of related phenomena, contexts, and variables in any subject. Learning how to efficiently conduct a literature review is crucial to succeeding in an academic and even up-to-speed career. Summing up and synthesizing previous research in a particular field of interest indicates enjoying a thorough grasp of the available knowledge. It also lends a hand in learning and moving forward towards being professional in a particular milieu. However, an unorganized growth in literature may hinder amelioration by broaching the probability of complicated, competing, and implausible arguments in the scholarly inquiry. This study is a just-out attempt to develop a typology of review types and present an explanatory insight into the most typical and applicable literature reviews by relying on the aim, significance, applicability, and pros and cons. The goals of conducted typology are to study and analysis different types of literature review to assist researchers to commence their evaluations and place their contribution. labeled data in real-world scenarios. We have also discussed the main challenges found while conducting some of the studies by the researchers. We consider that this research paves the way for further research to help governments and countries fight crime and decrease this for better safety and security. of publications, identifying China and USA as the main players in research, biomass and wastewater as potential topics also Spirulina, Astaxanthin and beta-carotene as the main products based on microalgae. Thus, achieving an structure, organized and synthesized landscape of scientific and technological knowledge available for the proposal of investigations that allow the use of anaerobic digestion liquid effluents as cultivation medium for microalgae. review. Methods similar to AAMs should be assessed in future research for how consistent their performances are in SLRs of economic, epidemiological and humanistic evidence. at least 10% in 18 out of 20 review datasets.
PY  - 2023
DA  - 2023-02-05
JO  - {'id': 'https://openalex.org/S4210202905', 'issn_l': '2079-9292', 'issn': ['2079-9292'], 'display_name': 'Electronics', 'publisher': 'MDPI', 'type': 'journal', 'url': 'https://www.mdpi.com/2079-9292/12/4/800/pdf?version=1675601556', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Hamed Taherdoost
ER  - 

774.
TY  - journal-article
ID  - https://openalex.org/W4319962920
DO  - https://doi.org/10.1016/j.iswa.2023.200193
TI  - An Analysis of Work Saved over Sampling in the Evaluation of Automated Citation Screening in Systematic Literature Reviews
AB  - No Abstract Found
PY  - 2023
DA  - 2023-02-01
JO  - {'id': 'https://openalex.org/S4210234522', 'issn_l': '2667-3053', 'issn': ['2667-3053'], 'display_name': 'Intelligent systems with applications', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'https://doi.org/10.1016/j.iswa.2023.200193', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Wojciech Kusa
AU  - Aldo Lipani
AU  - Petr Knoth
AU  - Allan Hanbury
ER  - 

775.
TY  - journal-article
ID  - https://openalex.org/W4320919839
DO  - https://doi.org/10.3390/su15043480
TI  - Maturity Models for Testing and Calibration Laboratories: A Systematic Literature Review
AB  - Currently, testing and calibration laboratories are undergoing organizational restructuring in view of technical and regulatory requirements. To assist these laboratories, maturity models (MMs) can be used for the implementation and maintenance of management systems. The use of fuzzy logic is often found in association with the construction of MMs. Fuzzy logic helps in the construction of these models, removing subjective elements from the maturity assessment. Therefore, the objective of this study was to perform a systematic literature review (SLR) using the Methodi Ordinatio focused on MMs built with fuzzy logic that aim to evaluate the degree of maturity of testing and calibration laboratories that have implemented ISO/IEC 17025 for their quality management systems (QMSs). This analysis was performed with articles published between 2012 and 2022 in several databases using keywords such as “maturity model”, “fuzzy” and “ISO 17025” and resulted in 18 articles, which made up the bibliographic portfolio. After analyzing the content of these studies, it was possible to conclude that, although no study specifically discussed this MM, the discovered articles were important for presenting ideas and suggestions for future research. by the researchers. We consider that this research paves the way for further research to help governments and countries fight crime and decrease this for better safety and security. of publications, identifying China and USA as the main players in research, biomass and wastewater as potential topics also Spirulina, Astaxanthin and beta-carotene as the main products based on microalgae. Thus, achieving an structure, organized and synthesized landscape of scientific and technological knowledge available for the proposal of investigations that allow the use of anaerobic digestion liquid effluents as cultivation medium for microalgae. review. Methods similar to AAMs should be assessed in future research for how consistent their performances are in SLRs of economic, epidemiological and humanistic evidence. at least 10% in 18 out of 20 review datasets.
PY  - 2023
DA  - 2023-02-14
JO  - {'id': 'https://openalex.org/S10134376', 'issn_l': '2071-1050', 'issn': ['2071-1050'], 'display_name': 'Sustainability', 'publisher': 'MDPI', 'type': 'journal', 'url': 'https://www.mdpi.com/2071-1050/15/4/3480/pdf?version=1676368540', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Bruna Maria Gerônimo
AU  - Giane Gonçalves Lenzi
ER  - 

776.
TY  - journal-article
ID  - https://openalex.org/W3123893780
DO  - https://doi.org/10.1136/bmj.n160
TI  - PRISMA 2020 explanation and elaboration: updated guidance and exemplars for reporting systematic reviews
AB  - The methods and results of systematic reviews should be reported in sufficient detail to allow users to assess the trustworthiness and applicability of the review findings. The Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) statement was developed to facilitate transparent and complete reporting of systematic reviews and has been updated (to PRISMA 2020) to reflect recent advances in systematic review methodology and terminology. Here, we present the explanation and elaboration paper for PRISMA 2020, where we explain why reporting of each item is recommended, present bullet points that detail the reporting recommendations, and present examples from published reviews. We hope that changes to the content and structure of PRISMA 2020 will facilitate uptake of the guideline and lead to more transparent, complete, and accurate reporting of systematic reviews.
PY  - 2021
DA  - 2021-03-29
JO  - {'id': 'https://openalex.org/S4210185579', 'issn_l': '1756-1833', 'issn': ['1756-1833'], 'display_name': 'BMJ', 'publisher': 'BMJ', 'type': 'journal', 'url': 'https://www.bmj.com/content/bmj/372/bmj.n160.full.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Matthew J. Page
AU  - David Moher
AU  - Patrick M.M. Bossuyt
AU  - Isabelle Boutron
AU  - Tammy Hoffmann
AU  - Cynthia D. Mulrow
AU  - Larissa Shamseer
AU  - Jennifer Tetzlaff
AU  - Elie A. Akl
AU  - Sue E. Brennan
AU  - Roger Chou
AU  - Julie Glanville
AU  - Jeremy M. Grimshaw
AU  - Asbjørn Hróbjartsson
AU  - Manoj M. Lalu
AU  - Tianjing Li
AU  - Elizabeth Loder
AU  - Evan Mayo-Wilson
AU  - Steve McDonald
AU  - Adrian M. Price-Whelan
AU  - Lesley A. Stewart
AU  - James D. Thomas
AU  - Andrea C. Tricco
AU  - Vivian Welch
AU  - Penny Whiting
AU  - Joanne E. McKenzie
ER  - 

777.
TY  - journal-article
ID  - https://openalex.org/W3123497531
DO  - https://doi.org/10.1186/s13643-020-01542-z
TI  - PRISMA-S: an extension to the PRISMA Statement for Reporting Literature Searches in Systematic Reviews
AB  - Literature searches underlie the foundations of systematic reviews and related review types. Yet, the literature searching component of systematic reviews and related review types is often poorly reported. Guidance for literature search reporting has been diverse, and, in many cases, does not offer enough detail to authors who need more specific information about reporting search methods and information sources in a clear, reproducible way. This document presents the PRISMA-S (Preferred Reporting Items for Systematic reviews and Meta-Analyses literature search extension) checklist, and explanation and elaboration.The checklist was developed using a 3-stage Delphi survey process, followed by a consensus conference and public review process.The final checklist includes 16 reporting items, each of which is detailed with exemplar reporting and rationale.The intent of PRISMA-S is to complement the PRISMA Statement and its extensions by providing a checklist that could be used by interdisciplinary authors, editors, and peer reviewers to verify that each component of a search is completely reported and therefore reproducible.
PY  - 2021
DA  - 2021-01-26
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://systematicreviewsjournal.biomedcentral.com/track/pdf/10.1186/s13643-020-01542-z', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Melissa L. Rethlefsen
AU  - Shona Kirtley
AU  - Siw Waffenschmidt
AU  - Ana Patricia Ayala
AU  - David Moher
AU  - Matthew J. Page
AU  - Jonathan Koffel
ER  - 

778.
TY  - journal-article
ID  - https://openalex.org/W2887238869
DO  - https://doi.org/10.1186/s12874-018-0545-3
TI  - Defining the process to literature searching in systematic reviews: a literature review of guidance and supporting studies
AB  - Systematic literature searching is recognised as a critical component of the systematic review process. It involves a systematic search for studies and aims for a transparent report of study identification, leaving readers clear about what was done to identify studies, and how the findings of the review are situated in the relevant evidence. Information specialists and review teams appear to work from a shared and tacit model of the literature search process. How this tacit model has developed and evolved is unclear, and it has not been explicitly examined before. The purpose of this review is to determine if a shared model of the literature searching process can be detected across systematic review guidance documents and, if so, how this process is reported in the guidance and supported by published studies.A literature review. Two types of literature were reviewed: guidance and published studies. Nine guidance documents were identified, including: The Cochrane and Campbell Handbooks. Published studies were identified through 'pearl growing', citation chasing, a search of PubMed using the systematic review methods filter, and the authors' topic knowledge. The relevant sections within each guidance document were then read and re-read, with the aim of determining key methodological stages. Methodological stages were identified and defined. This data was reviewed to identify agreements and areas of unique guidance between guidance documents. Consensus across multiple guidance documents was used to inform selection of 'key stages' in the process of literature searching.Eight key stages were determined relating specifically to literature searching in systematic reviews. They were: who should literature search, aims and purpose of literature searching, preparation, the search strategy, searching databases, supplementary searching, managing references and reporting the search process.Eight key stages to the process of literature searching in systematic reviews were identified. These key stages are consistently reported in the nine guidance documents, suggesting consensus on the key stages of literature searching, and therefore the process of literature searching as a whole, in systematic reviews. Further research to determine the suitability of using the same process of literature searching for all types of systematic review is indicated.
PY  - 2018
DA  - 2018-08-14
JO  - {'id': 'https://openalex.org/V185874209', 'issn_l': '1471-2288', 'issn': ['1471-2288'], 'display_name': 'BMC Medical Research Methodology', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://bmcmedresmethodol.biomedcentral.com/track/pdf/10.1186/s12874-018-0545-3', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Chris E. Cooper
AU  - Andrew Booth
AU  - Jo Varley-Campbell
AU  - Nicky Britten
AU  - Ruth Garside
ER  - 

779.
TY  - journal-article
ID  - https://openalex.org/W2963483681
DO  - https://doi.org/10.1111/2041-210x.13268
TI  - An automated approach to identifying search terms for systematic reviews using keyword co‐occurrence networks
AB  - No Abstract Found
PY  - 2019
DA  - 2019-10-01
JO  - {'id': 'https://openalex.org/V1131227', 'issn_l': '2041-210X', 'issn': ['2041-210X'], 'display_name': 'Methods in Ecology and Evolution', 'publisher': 'Wiley-Blackwell', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Eliza M. Grames
AU  - Andrew N. Stillman
AU  - Morgan W. Tingley
AU  - Chris S. Elphick
ER  - 

780.
TY  - journal-article
ID  - https://openalex.org/W3032972760
DO  - https://doi.org/10.1016/j.envint.2020.105739
TI  - The effect of exposure to long working hours on ischaemic heart disease: A systematic review and meta-analysis from the WHO/ILO Joint Estimates of the Work-related Burden of Disease and Injury
AB  - The World Health Organization (WHO) and the International Labour Organization (ILO) are developing Joint Estimates of the work-related burden of disease and injury (WHO/ILO Joint Estimates), with contributions from a large network of experts. Evidence from mechanistic data suggests that exposure to long working hours may cause ischaemic heart disease (IHD). In this paper, we present a systematic review and meta-analysis of parameters for estimating the number of deaths and disability-adjusted life years from IHD that are attributable to exposure to long working hours, for the development of the WHO/ILO Joint Estimates.We aimed to systematically review and meta-analyse estimates of the effect of exposure to long working hours (three categories: 41-48, 49-54 and ≥55 h/week), compared with exposure to standard working hours (35-40 h/week), on IHD (three outcomes: prevalence, incidence and mortality).We developed and published a protocol, applying the Navigation Guide as an organizing systematic review framework where feasible. We searched electronic databases for potentially relevant records from published and unpublished studies, including MEDLINE, Scopus, Web of Science, CISDOC, PsycINFO, and WHO ICTRP. We also searched grey literature databases, Internet search engines and organizational websites; hand-searched reference lists of previous systematic reviews; and consulted additional experts.We included working-age (≥15 years) workers in the formal and informal economy in any WHO and/or ILO Member State but excluded children (aged < 15 years) and unpaid domestic workers. We included randomized controlled trials, cohort studies, case-control studies and other non-randomized intervention studies which contained an estimate of the effect of exposure to long working hours (41-48, 49-54 and ≥55 h/week), compared with exposure to standard working hours (35-40 h/week), on IHD (prevalence, incidence or mortality).At least two review authors independently screened titles and abstracts against the eligibility criteria at a first stage and full texts of potentially eligible records at a second stage, followed by extraction of data from qualifying studies. Missing data were requested from principal study authors. We combined relative risks using random-effect meta-analysis. Two or more review authors assessed the risk of bias, quality of evidence and strength of evidence, using Navigation Guide and GRADE tools and approaches adapted to this project.Thirty-seven studies (26 prospective cohort studies and 11 case-control studies) met the inclusion criteria, comprising a total of 768,751 participants (310,954 females) in 13 countries in three WHO regions (Americas, Europe and Western Pacific). The exposure was measured using self-reports in all studies, and the outcome was assessed with administrative health records (30 studies) or self-reported physician diagnosis (7 studies). The outcome was defined as incident non-fatal IHD event in 19 studies (8 cohort studies, 11 case-control studies), incident fatal IHD event in two studies (both cohort studies), and incident non-fatal or fatal ("mixed") event in 16 studies (all cohort studies). Because we judged cohort studies to have a relatively lower risk of bias, we prioritized evidence from these studies and treated evidence from case-control studies as supporting evidence. For the bodies of evidence for both outcomes with any eligible studies (i.e. IHD incidence and mortality), we did not have serious concerns for risk of bias (at least for the cohort studies). No eligible study was found on the effect of long working hours on IHD prevalence. Compared with working 35-40 h/week, we are uncertain about the effect on acquiring (or incidence of) IHD of working 41-48 h/week (relative risk (RR) 0.98, 95% confidence interval (CI) 0.91 to 1.07, 20 studies, 312,209 participants, I2 0%, low quality of evidence) and 49-54 h/week (RR 1.05, 95% CI 0.94 to 1.17, 18 studies, 308,405 participants, I2 0%, low quality of evidence). Compared with working 35-40 h/week, working ≥55 h/week may have led to a moderately, clinically meaningful increase in the risk of acquiring IHD, when followed up between one year and 20 years (RR 1.13, 95% CI 1.02 to 1.26, 22 studies, 339,680 participants, I2 5%, moderate quality of evidence). Compared with working 35-40 h/week, we are very uncertain about the effect on dying (mortality) from IHD of working 41-48 h/week (RR 0.99, 95% CI 0.88 to 1.12, 13 studies, 288,278 participants, I2 8%, low quality of evidence) and 49-54 h/week (RR 1.01, 95% CI 0.82 to 1.25, 11 studies, 284,474 participants, I2 13%, low quality of evidence). Compared with working 35-40 h/week, working ≥55 h/week may have led to a moderate, clinically meaningful increase in the risk of dying from IHD when followed up between eight and 30 years (RR 1.17, 95% CI 1.05 to 1.31, 16 studies, 726,803 participants, I2 0%, moderate quality of evidence). Subgroup analyses found no evidence for differences by WHO region and sex, but RRs were higher among persons with lower SES. Sensitivity analyses found no differences by outcome definition (exclusively non-fatal or fatal versus "mixed"), outcome measurement (health records versus self-reports) and risk of bias ("high"/"probably high" ratings in any domain versus "low"/"probably low" in all domains).We judged the existing bodies of evidence for human evidence as "inadequate evidence for harmfulness" for the exposure categories 41-48 and 49-54 h/week for IHD prevalence, incidence and mortality, and for the exposure category ≥55 h/week for IHD prevalence. Evidence on exposure to working ≥55 h/week was judged as "sufficient evidence of harmfulness" for IHD incidence and mortality. Producing estimates for the burden of IHD attributable to exposure to working ≥55 h/week appears evidence-based, and the pooled effect estimates presented in this systematic review could be used as input data for the WHO/ILO Joint Estimates.
PY  - 2020
DA  - 2020-09-01
JO  - {'id': 'https://openalex.org/S143381477', 'issn_l': '0160-4120', 'issn': ['0160-4120', '1873-6750'], 'display_name': 'Environment International', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'https://doi.org/10.1016/j.envint.2020.105739', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Jian Li
AU  - Frank Pega
AU  - Yuka Ujita
AU  - Chantal Brisson
AU  - Els Clays
AU  - Alexis Descatha
AU  - Marco M Ferrario
AU  - Lode Godderis
AU  - Sergio Iavicoli
AU  - Paul Landsbergis
AU  - Maria-Inti Metzendorf
AU  - Rebecca L. Morgan
AU  - Daniela Vianna Pachito
AU  - Hynek Pikhart
AU  - Bernd Richter
AU  - Mattia Roncaioli
AU  - Reiner Rugulies
AU  - Peter L. Schnall
AU  - Grace Sembajwe
AU  - Xavier Trudel
AU  - Akizumi Tsutsumi
AU  - Tracey J. Woodruff
AU  - Johannes Siegrist
ER  - 

781.
TY  - journal-article
ID  - https://openalex.org/W2954766934
DO  - https://doi.org/10.1108/ecam-07-2018-0307
TI  - Construction delay risk taxonomy, associations and regional contexts
AB  - Purpose The purpose of this paper is to systematically develop a delay risk terminology and taxonomy. This research also explores two external and internal dimensions of the taxonomy to determine how much the taxonomy as a whole or combinations of its elements are generalisable. Design/methodology/approach Using mixed methods research, this systematic literature review incorporated data from 46 articles to establish delay risk terminology and taxonomy. Qualitative data of the top 10 delay risks identified in each article were coded based on the grounded theory and constant comparative analysis using a three-stage coding approach. Word frequency analysis and cross-tabulation were used to develop the terminology and taxonomy. Association rules within the taxonomy were also explored to define risk paths and to unmask associations among the risks. Findings In total, 26 delay risks were identified and grouped into ten categories to form the risk breakdown structure. The universal delay risks and other delay risks that are more or less depending on the project location were determined. Also, it is realized that delays connected to equipment, sub-contractors and design drawings are highly connected to project planning, finance and owner slow decision making, respectively. Originality/value The established terminology and taxonomy may be used in manual or automated risk management systems as a baseline for delay risk identification, management and communication. In addition, the association rules assist the risk management process by enabling mitigation of a combination of risks together. other non-randomized intervention studies which contained an estimate of the effect of exposure to long working hours (41-48, 49-54 and ≥55 h/week), compared with exposure to standard working hours (35-40 h/week), on IHD (prevalence, incidence or mortality).At least two review authors independently screened titles and abstracts against the eligibility criteria at a first stage and full texts of potentially eligible records at a second stage, followed by extraction of data from qualifying studies. Missing data were requested from principal study authors. We combined relative risks using random-effect meta-analysis. Two or more review authors assessed the risk of bias, quality of evidence and strength of evidence, using Navigation Guide and GRADE tools and approaches adapted to this project.Thirty-seven studies (26 prospective cohort studies and 11 case-control studies) met the inclusion criteria, comprising a total of 768,751 participants (310,954 females) in 13 countries in three WHO regions (Americas, Europe and Western Pacific). The exposure was measured using self-reports in all studies, and the outcome was assessed with administrative health records (30 studies) or self-reported physician diagnosis (7 studies). The outcome was defined as incident non-fatal IHD event in 19 studies (8 cohort studies, 11 case-control studies), incident fatal IHD event in two studies (both cohort studies), and incident non-fatal or fatal ("mixed") event in 16 studies (all cohort studies). Because we judged cohort studies to have a relatively lower risk of bias, we prioritized evidence from these studies and treated evidence from case-control studies as supporting evidence. For the bodies of evidence for both outcomes with any eligible studies (i.e. IHD incidence and mortality), we did not have serious concerns for risk of bias (at least for the cohort studies). No eligible study was found on the effect of long working hours on IHD prevalence. Compared with working 35-40 h/week, we are uncertain about the effect on acquiring (or incidence of) IHD of working 41-48 h/week (relative risk (RR) 0.98, 95% confidence interval (CI) 0.91 to 1.07, 20 studies, 312,209 participants, I2 0%, low quality of evidence) and 49-54 h/week (RR 1.05, 95% CI 0.94 to 1.17, 18 studies, 308,405 participants, I2 0%, low quality of evidence). Compared with working 35-40 h/week, working ≥55 h/week may have led to a moderately, clinically meaningful increase in the risk of acquiring IHD, when followed up between one year and 20 years (RR 1.13, 95% CI 1.02 to 1.26, 22 studies, 339,680 participants, I2 5%, moderate quality of evidence). Compared with working 35-40 h/week, we are very uncertain about the effect on dying (mortality) from IHD of working 41-48 h/week (RR 0.99, 95% CI 0.88 to 1.12, 13 studies, 288,278 participants, I2 8%, low quality of evidence) and 49-54 h/week (RR 1.01, 95% CI 0.82 to 1.25, 11 studies, 284,474 participants, I2 13%, low quality of evidence). Compared with working 35-40 h/week, working ≥55 h/week may have led to a moderate, clinically meaningful increase in the risk of dying from IHD when followed up between eight and 30 years (RR 1.17, 95% CI 1.05 to 1.31, 16 studies, 726,803 participants, I2 0%, moderate quality of evidence). Subgroup analyses found no evidence for differences by WHO region and sex, but RRs were higher among persons with lower SES. Sensitivity analyses found no differences by outcome definition (exclusively non-fatal or fatal versus "mixed"), outcome measurement (health records versus self-reports) and risk of bias ("high"/"probably high" ratings in any domain versus "low"/"probably low" in all domains).We judged the existing bodies of evidence for human evidence as "inadequate evidence for harmfulness" for the exposure categories 41-48 and 49-54 h/week for IHD prevalence, incidence and mortality, and for the exposure category ≥55 h/week for IHD prevalence. Evidence on exposure to working ≥55 h/week was judged as "sufficient evidence of harmfulness" for IHD incidence and mortality. Producing estimates for the burden of IHD attributable to exposure to working ≥55 h/week appears evidence-based, and the pooled effect estimates presented in this systematic review could be used as input data for the WHO/ILO Joint Estimates.
PY  - 2019
DA  - 2019-11-18
JO  - {'id': 'https://openalex.org/S120049674', 'issn_l': '0969-9988', 'issn': ['1365-232X', '0969-9988'], 'display_name': 'Engineering, Construction and Architectural Management', 'publisher': 'Emerald Publishing Limited', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Hossein Derakhshanfar
AU  - J. Jorge Ochoa
AU  - Konstantinos Kirytopoulos
AU  - Wolfgang J. Mayer
AU  - Vivian W.Y. Tam
ER  - 

782.
TY  - journal-article
ID  - https://openalex.org/W3127164948
DO  - https://doi.org/10.5195/jmla.2021.962
TI  - PRISMA-S: an extension to the PRISMA statement for reporting literature searches in systematic reviews
AB  - Literature searches underlie the foundations of systematic reviews and related review types. Yet, the literature searching component of systematic reviews and related review types is often poorly reported. Guidance for literature search reporting has been diverse and, in many cases, does not offer enough detail to authors who need more specific information about reporting search methods and information sources in a clear, reproducible way. This document presents the PRISMA-S (Preferred Reporting Items for Systematic reviews and Meta-Analyses literature search extension) checklist, and explanation and elaboration.The checklist was developed using a three-stage Delphi survey process, followed by a consensus conference and public review process.The final checklist includes sixteen reporting items, each of which is detailed with exemplar reporting and rationale.The intent of PRISMA-S is to complement the PRISMA Statement and its extensions by providing a checklist that could be used by interdisciplinary authors, editors, and peer reviewers to verify that each component of a search is completely reported and, therefore, reproducible. project location were determined. Also, it is realized that delays connected to equipment, sub-contractors and design drawings are highly connected to project planning, finance and owner slow decision making, respectively. Originality/value The established terminology and taxonomy may be used in manual or automated risk management systems as a baseline for delay risk identification, management and communication. In addition, the association rules assist the risk management process by enabling mitigation of a combination of risks together. other non-randomized intervention studies which contained an estimate of the effect of exposure to long working hours (41-48, 49-54 and ≥55 h/week), compared with exposure to standard working hours (35-40 h/week), on IHD (prevalence, incidence or mortality).At least two review authors independently screened titles and abstracts against the eligibility criteria at a first stage and full texts of potentially eligible records at a second stage, followed by extraction of data from qualifying studies. Missing data were requested from principal study authors. We combined relative risks using random-effect meta-analysis. Two or more review authors assessed the risk of bias, quality of evidence and strength of evidence, using Navigation Guide and GRADE tools and approaches adapted to this project.Thirty-seven studies (26 prospective cohort studies and 11 case-control studies) met the inclusion criteria, comprising a total of 768,751 participants (310,954 females) in 13 countries in three WHO regions (Americas, Europe and Western Pacific). The exposure was measured using self-reports in all studies, and the outcome was assessed with administrative health records (30 studies) or self-reported physician diagnosis (7 studies). The outcome was defined as incident non-fatal IHD event in 19 studies (8 cohort studies, 11 case-control studies), incident fatal IHD event in two studies (both cohort studies), and incident non-fatal or fatal ("mixed") event in 16 studies (all cohort studies). Because we judged cohort studies to have a relatively lower risk of bias, we prioritized evidence from these studies and treated evidence from case-control studies as supporting evidence. For the bodies of evidence for both outcomes with any eligible studies (i.e. IHD incidence and mortality), we did not have serious concerns for risk of bias (at least for the cohort studies). No eligible study was found on the effect of long working hours on IHD prevalence. Compared with working 35-40 h/week, we are uncertain about the effect on acquiring (or incidence of) IHD of working 41-48 h/week (relative risk (RR) 0.98, 95% confidence interval (CI) 0.91 to 1.07, 20 studies, 312,209 participants, I2 0%, low quality of evidence) and 49-54 h/week (RR 1.05, 95% CI 0.94 to 1.17, 18 studies, 308,405 participants, I2 0%, low quality of evidence). Compared with working 35-40 h/week, working ≥55 h/week may have led to a moderately, clinically meaningful increase in the risk of acquiring IHD, when followed up between one year and 20 years (RR 1.13, 95% CI 1.02 to 1.26, 22 studies, 339,680 participants, I2 5%, moderate quality of evidence). Compared with working 35-40 h/week, we are very uncertain about the effect on dying (mortality) from IHD of working 41-48 h/week (RR 0.99, 95% CI 0.88 to 1.12, 13 studies, 288,278 participants, I2 8%, low quality of evidence) and 49-54 h/week (RR 1.01, 95% CI 0.82 to 1.25, 11 studies, 284,474 participants, I2 13%, low quality of evidence). Compared with working 35-40 h/week, working ≥55 h/week may have led to a moderate, clinically meaningful increase in the risk of dying from IHD when followed up between eight and 30 years (RR 1.17, 95% CI 1.05 to 1.31, 16 studies, 726,803 participants, I2 0%, moderate quality of evidence). Subgroup analyses found no evidence for differences by WHO region and sex, but RRs were higher among persons with lower SES. Sensitivity analyses found no differences by outcome definition (exclusively non-fatal or fatal versus "mixed"), outcome measurement (health records versus self-reports) and risk of bias ("high"/"probably high" ratings in any domain versus "low"/"probably low" in all domains).We judged the existing bodies of evidence for human evidence as "inadequate evidence for harmfulness" for the exposure categories 41-48 and 49-54 h/week for IHD prevalence, incidence and mortality, and for the exposure category ≥55 h/week for IHD prevalence. Evidence on exposure to working ≥55 h/week was judged as "sufficient evidence of harmfulness" for IHD incidence and mortality. Producing estimates for the burden of IHD attributable to exposure to working ≥55 h/week appears evidence-based, and the pooled effect estimates presented in this systematic review could be used as input data for the WHO/ILO Joint Estimates.
PY  - 2021
DA  - 2021-07-20
JO  - {'id': 'https://openalex.org/S146304353', 'issn_l': '1536-5050', 'issn': ['1536-5050', '1558-9439'], 'display_name': 'Journal of The Medical Library Association', 'publisher': 'University Library System, University of Pittsburgh', 'type': 'journal', 'url': 'https://jmla.pitt.edu/ojs/jmla/article/download/962/1274', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Melissa L. Rethlefsen
AU  - Shona Kirtley
AU  - Siw Waffenschmidt
AU  - Ana Patricia Ayala
AU  - David Moher
AU  - Matthew J. Page
AU  - Jonathan Koffel
ER  - 

783.
TY  - journal-article
ID  - https://openalex.org/W3185786724
DO  - https://doi.org/10.1016/j.compind.2021.103525
TI  - Using text mining to retrieve information about circular economy
AB  - • Method for automatically retrieving knowledge about circular economy from patents. • Automatic identification of modalities and systems for waste recycling and reuse. • Identification of dedicated dependency patterns to improve syntactic analysis. • Context knowledge is not required unless during the check of the obtained results. • Average precision of the method of 87 %–99 %, average recall of 75 %–89 %. This paper proposes a method of text mining to automatically retrieve knowledge from patents on how to recycle and reuse a waste. The main novelties are the introduction of a set of specific dependency patterns and the introduction of a partially revised TRIZ (Russian acronym for "Theory of Inventive Problem Solving") ontology to classify the retrieved information. The proposed dependency patterns were manually extracted from a sample patents pool about waste recycling and reuse. The classification of the information is based on different classes: (1) what transformations can be carried out on the waste, (2) what technologies can be used to carry out these transformations, (3) what products can be obtained by transforming the waste, (4) what functions can be carried out by the waste, (5) with which technologies, and (6) on which entities. An automatic implementation of the proposed method, involving the manual check of the retrieved results, was tested through a case study about wood chip recycling and reuse. Compared to the dependency patterns from the literature, the proposed ones allowed to retrieve 28 % more pertinent information. This results mainly depends by better ability of the proposed patterns to better discriminate the relevant sentences from which to extract information, compared to the other patterns (i.e. + 40 %). The automatic classification of the information was also correctly performed: in almost each class, precision and recall were higher than 60 % and on average equal to 90 %. of data from qualifying studies. Missing data were requested from principal study authors. We combined relative risks using random-effect meta-analysis. Two or more review authors assessed the risk of bias, quality of evidence and strength of evidence, using Navigation Guide and GRADE tools and approaches adapted to this project.Thirty-seven studies (26 prospective cohort studies and 11 case-control studies) met the inclusion criteria, comprising a total of 768,751 participants (310,954 females) in 13 countries in three WHO regions (Americas, Europe and Western Pacific). The exposure was measured using self-reports in all studies, and the outcome was assessed with administrative health records (30 studies) or self-reported physician diagnosis (7 studies). The outcome was defined as incident non-fatal IHD event in 19 studies (8 cohort studies, 11 case-control studies), incident fatal IHD event in two studies (both cohort studies), and incident non-fatal or fatal ("mixed") event in 16 studies (all cohort studies). Because we judged cohort studies to have a relatively lower risk of bias, we prioritized evidence from these studies and treated evidence from case-control studies as supporting evidence. For the bodies of evidence for both outcomes with any eligible studies (i.e. IHD incidence and mortality), we did not have serious concerns for risk of bias (at least for the cohort studies). No eligible study was found on the effect of long working hours on IHD prevalence. Compared with working 35-40 h/week, we are uncertain about the effect on acquiring (or incidence of) IHD of working 41-48 h/week (relative risk (RR) 0.98, 95% confidence interval (CI) 0.91 to 1.07, 20 studies, 312,209 participants, I2 0%, low quality of evidence) and 49-54 h/week (RR 1.05, 95% CI 0.94 to 1.17, 18 studies, 308,405 participants, I2 0%, low quality of evidence). Compared with working 35-40 h/week, working ≥55 h/week may have led to a moderately, clinically meaningful increase in the risk of acquiring IHD, when followed up between one year and 20 years (RR 1.13, 95% CI 1.02 to 1.26, 22 studies, 339,680 participants, I2 5%, moderate quality of evidence). Compared with working 35-40 h/week, we are very uncertain about the effect on dying (mortality) from IHD of working 41-48 h/week (RR 0.99, 95% CI 0.88 to 1.12, 13 studies, 288,278 participants, I2 8%, low quality of evidence) and 49-54 h/week (RR 1.01, 95% CI 0.82 to 1.25, 11 studies, 284,474 participants, I2 13%, low quality of evidence). Compared with working 35-40 h/week, working ≥55 h/week may have led to a moderate, clinically meaningful increase in the risk of dying from IHD when followed up between eight and 30 years (RR 1.17, 95% CI 1.05 to 1.31, 16 studies, 726,803 participants, I2 0%, moderate quality of evidence). Subgroup analyses found no evidence for differences by WHO region and sex, but RRs were higher among persons with lower SES. Sensitivity analyses found no differences by outcome definition (exclusively non-fatal or fatal versus "mixed"), outcome measurement (health records versus self-reports) and risk of bias ("high"/"probably high" ratings in any domain versus "low"/"probably low" in all domains).We judged the existing bodies of evidence for human evidence as "inadequate evidence for harmfulness" for the exposure categories 41-48 and 49-54 h/week for IHD prevalence, incidence and mortality, and for the exposure category ≥55 h/week for IHD prevalence. Evidence on exposure to working ≥55 h/week was judged as "sufficient evidence of harmfulness" for IHD incidence and mortality. Producing estimates for the burden of IHD attributable to exposure to working ≥55 h/week appears evidence-based, and the pooled effect estimates presented in this systematic review could be used as input data for the WHO/ILO Joint Estimates.
PY  - 2021
DA  - 2021-11-01
JO  - {'id': 'https://openalex.org/S60779006', 'issn_l': '0166-3615', 'issn': ['1872-6194', '0166-3615'], 'display_name': 'Computers in Industry', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Christian Spreafico
AU  - Matteo Spreafico
ER  - 

784.
TY  - journal-article
ID  - https://openalex.org/W3098386911
DO  - https://doi.org/10.1002/cl2.1129
TI  - On the use of computer‐assistance to facilitate systematic mapping
AB  - The volume of published academic research is growing rapidly and this new era of “big literature” poses new challenges to evidence synthesis, pushing traditional, manual methods of evidence synthesis to their limits. New technology developments, including machine learning, are likely to provide solutions to the problem of information overload and allow scaling of systematic maps to large and even vast literatures. In this paper, we outline how systematic maps lend themselves well to automation and computer‐assistance. We believe that it is a major priority to consolidate efforts to develop and validate efficient, rigorous and robust applications of these novel technologies, ensuring the challenges of big literature do not prevent the future production of systematic maps. to classify the retrieved information. The proposed dependency patterns were manually extracted from a sample patents pool about waste recycling and reuse. The classification of the information is based on different classes: (1) what transformations can be carried out on the waste, (2) what technologies can be used to carry out these transformations, (3) what products can be obtained by transforming the waste, (4) what functions can be carried out by the waste, (5) with which technologies, and (6) on which entities. An automatic implementation of the proposed method, involving the manual check of the retrieved results, was tested through a case study about wood chip recycling and reuse. Compared to the dependency patterns from the literature, the proposed ones allowed to retrieve 28 % more pertinent information. This results mainly depends by better ability of the proposed patterns to better discriminate the relevant sentences from which to extract information, compared to the other patterns (i.e. + 40 %). The automatic classification of the information was also correctly performed: in almost each class, precision and recall were higher than 60 % and on average equal to 90 %. of data from qualifying studies. Missing data were requested from principal study authors. We combined relative risks using random-effect meta-analysis. Two or more review authors assessed the risk of bias, quality of evidence and strength of evidence, using Navigation Guide and GRADE tools and approaches adapted to this project.Thirty-seven studies (26 prospective cohort studies and 11 case-control studies) met the inclusion criteria, comprising a total of 768,751 participants (310,954 females) in 13 countries in three WHO regions (Americas, Europe and Western Pacific). The exposure was measured using self-reports in all studies, and the outcome was assessed with administrative health records (30 studies) or self-reported physician diagnosis (7 studies). The outcome was defined as incident non-fatal IHD event in 19 studies (8 cohort studies, 11 case-control studies), incident fatal IHD event in two studies (both cohort studies), and incident non-fatal or fatal ("mixed") event in 16 studies (all cohort studies). Because we judged cohort studies to have a relatively lower risk of bias, we prioritized evidence from these studies and treated evidence from case-control studies as supporting evidence. For the bodies of evidence for both outcomes with any eligible studies (i.e. IHD incidence and mortality), we did not have serious concerns for risk of bias (at least for the cohort studies). No eligible study was found on the effect of long working hours on IHD prevalence. Compared with working 35-40 h/week, we are uncertain about the effect on acquiring (or incidence of) IHD of working 41-48 h/week (relative risk (RR) 0.98, 95% confidence interval (CI) 0.91 to 1.07, 20 studies, 312,209 participants, I2 0%, low quality of evidence) and 49-54 h/week (RR 1.05, 95% CI 0.94 to 1.17, 18 studies, 308,405 participants, I2 0%, low quality of evidence). Compared with working 35-40 h/week, working ≥55 h/week may have led to a moderately, clinically meaningful increase in the risk of acquiring IHD, when followed up between one year and 20 years (RR 1.13, 95% CI 1.02 to 1.26, 22 studies, 339,680 participants, I2 5%, moderate quality of evidence). Compared with working 35-40 h/week, we are very uncertain about the effect on dying (mortality) from IHD of working 41-48 h/week (RR 0.99, 95% CI 0.88 to 1.12, 13 studies, 288,278 participants, I2 8%, low quality of evidence) and 49-54 h/week (RR 1.01, 95% CI 0.82 to 1.25, 11 studies, 284,474 participants, I2 13%, low quality of evidence). Compared with working 35-40 h/week, working ≥55 h/week may have led to a moderate, clinically meaningful increase in the risk of dying from IHD when followed up between eight and 30 years (RR 1.17, 95% CI 1.05 to 1.31, 16 studies, 726,803 participants, I2 0%, moderate quality of evidence). Subgroup analyses found no evidence for differences by WHO region and sex, but RRs were higher among persons with lower SES. Sensitivity analyses found no differences by outcome definition (exclusively non-fatal or fatal versus "mixed"), outcome measurement (health records versus self-reports) and risk of bias ("high"/"probably high" ratings in any domain versus "low"/"probably low" in all domains).We judged the existing bodies of evidence for human evidence as "inadequate evidence for harmfulness" for the exposure categories 41-48 and 49-54 h/week for IHD prevalence, incidence and mortality, and for the exposure category ≥55 h/week for IHD prevalence. Evidence on exposure to working ≥55 h/week was judged as "sufficient evidence of harmfulness" for IHD incidence and mortality. Producing estimates for the burden of IHD attributable to exposure to working ≥55 h/week appears evidence-based, and the pooled effect estimates presented in this systematic review could be used as input data for the WHO/ILO Joint Estimates.
PY  - 2020
DA  - 2020-12-01
JO  - {'id': 'https://openalex.org/S2739193000', 'issn_l': '1891-1803', 'issn': ['1891-1803'], 'display_name': 'Campbell Systematic Reviews', 'publisher': 'The Campbell Collaboration', 'type': 'journal', 'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/cl2.1129', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Neal R. Haddaway
AU  - Max Callaghan
AU  - Alexandra B. Collins
AU  - William F. Lamb
AU  - Jan C. Minx
AU  - James D. Thomas
AU  - Denny John
ER  - 

785.
TY  - journal-article
ID  - https://openalex.org/W3139443298
DO  - https://doi.org/10.1016/j.jclinepi.2021.03.013
TI  - A prospective comparison of evidence synthesis search strategies developed with and without text-mining tools
AB  - We compared the process of developing searches with and without using text-mining tools (TMTs) for evidence synthesis products.This descriptive comparative analysis included seven systematic reviews, classified as simple or complex. Two librarians created MEDLINE strategies for each review, using either usual practice (UP) or TMTs. For each search we calculated sensitivity, number-needed-to-read (NNR) and time spent developing the search strategy.We found UP searches were more sensitive (UP 92% (95% CI, 85-99); TMT 84.9% (95% CI, 74.4-95.4)), with lower NNR (UP 83 (SD 34); TMT 90 (SD 68)). UP librarians spent an average of 12 h (SD 8) developing search strategies, compared to TMT librarians' 5 hours (SD 2).Across all reviews, TMT searches were less sensitive than UP searches, but confidence intervals overlapped. For simple SR topics, TMT searches were faster and slightly less sensitive than UP. For complex SR topics, TMT searches were faster and less sensitive than UP searches but identified unique eligible citations not found by the UP searches. be used to carry out these transformations, (3) what products can be obtained by transforming the waste, (4) what functions can be carried out by the waste, (5) with which technologies, and (6) on which entities. An automatic implementation of the proposed method, involving the manual check of the retrieved results, was tested through a case study about wood chip recycling and reuse. Compared to the dependency patterns from the literature, the proposed ones allowed to retrieve 28 % more pertinent information. This results mainly depends by better ability of the proposed patterns to better discriminate the relevant sentences from which to extract information, compared to the other patterns (i.e. + 40 %). The automatic classification of the information was also correctly performed: in almost each class, precision and recall were higher than 60 % and on average equal to 90 %. of data from qualifying studies. Missing data were requested from principal study authors. We combined relative risks using random-effect meta-analysis. Two or more review authors assessed the risk of bias, quality of evidence and strength of evidence, using Navigation Guide and GRADE tools and approaches adapted to this project.Thirty-seven studies (26 prospective cohort studies and 11 case-control studies) met the inclusion criteria, comprising a total of 768,751 participants (310,954 females) in 13 countries in three WHO regions (Americas, Europe and Western Pacific). The exposure was measured using self-reports in all studies, and the outcome was assessed with administrative health records (30 studies) or self-reported physician diagnosis (7 studies). The outcome was defined as incident non-fatal IHD event in 19 studies (8 cohort studies, 11 case-control studies), incident fatal IHD event in two studies (both cohort studies), and incident non-fatal or fatal ("mixed") event in 16 studies (all cohort studies). Because we judged cohort studies to have a relatively lower risk of bias, we prioritized evidence from these studies and treated evidence from case-control studies as supporting evidence. For the bodies of evidence for both outcomes with any eligible studies (i.e. IHD incidence and mortality), we did not have serious concerns for risk of bias (at least for the cohort studies). No eligible study was found on the effect of long working hours on IHD prevalence. Compared with working 35-40 h/week, we are uncertain about the effect on acquiring (or incidence of) IHD of working 41-48 h/week (relative risk (RR) 0.98, 95% confidence interval (CI) 0.91 to 1.07, 20 studies, 312,209 participants, I2 0%, low quality of evidence) and 49-54 h/week (RR 1.05, 95% CI 0.94 to 1.17, 18 studies, 308,405 participants, I2 0%, low quality of evidence). Compared with working 35-40 h/week, working ≥55 h/week may have led to a moderately, clinically meaningful increase in the risk of acquiring IHD, when followed up between one year and 20 years (RR 1.13, 95% CI 1.02 to 1.26, 22 studies, 339,680 participants, I2 5%, moderate quality of evidence). Compared with working 35-40 h/week, we are very uncertain about the effect on dying (mortality) from IHD of working 41-48 h/week (RR 0.99, 95% CI 0.88 to 1.12, 13 studies, 288,278 participants, I2 8%, low quality of evidence) and 49-54 h/week (RR 1.01, 95% CI 0.82 to 1.25, 11 studies, 284,474 participants, I2 13%, low quality of evidence). Compared with working 35-40 h/week, working ≥55 h/week may have led to a moderate, clinically meaningful increase in the risk of dying from IHD when followed up between eight and 30 years (RR 1.17, 95% CI 1.05 to 1.31, 16 studies, 726,803 participants, I2 0%, moderate quality of evidence). Subgroup analyses found no evidence for differences by WHO region and sex, but RRs were higher among persons with lower SES. Sensitivity analyses found no differences by outcome definition (exclusively non-fatal or fatal versus "mixed"), outcome measurement (health records versus self-reports) and risk of bias ("high"/"probably high" ratings in any domain versus "low"/"probably low" in all domains).We judged the existing bodies of evidence for human evidence as "inadequate evidence for harmfulness" for the exposure categories 41-48 and 49-54 h/week for IHD prevalence, incidence and mortality, and for the exposure category ≥55 h/week for IHD prevalence. Evidence on exposure to working ≥55 h/week was judged as "sufficient evidence of harmfulness" for IHD incidence and mortality. Producing estimates for the burden of IHD attributable to exposure to working ≥55 h/week appears evidence-based, and the pooled effect estimates presented in this systematic review could be used as input data for the WHO/ILO Joint Estimates.
PY  - 2021
DA  - 2021-03-20
JO  - {'id': 'https://openalex.org/S64418186', 'issn_l': '0895-4356', 'issn': ['1878-5921', '0895-4356'], 'display_name': 'Journal of Clinical Epidemiology', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'http://www.jclinepi.com/article/S0895435621000858/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Robin Paynter
AU  - Robin Featherstone
AU  - Elizabeth Stoeger
AU  - Celia Fiordalisi
AU  - Christiane Voisin
AU  - Gaelen P Adam
ER  - 

786.
TY  - journal-article
ID  - https://openalex.org/W2817179587
DO  - https://doi.org/10.1080/19439342.2018.1478875
TI  - Approaches to evidence synthesis in international development: a research agenda
AB  - This article discusses the spectrum of synthesis methods available to generate, explore and text theory, their value to the field of international development and innovations required to make better use of the primary research available. It argues for clearer distinctions between syntheses produced as public goods and those tailored to specific circumstances, and strengthening knowledge systems through greater use of maps to navigate existing and missing evidence, harmonised outcomes and measures, and advances in automation technologies. Improved methods and guidance are required for synthesising formative research and investigating contextual factors. Engaging stakeholders and working across academic disciplines support the production of policy-relevant syntheses and inspire methods development. 2).Across all reviews, TMT searches were less sensitive than UP searches, but confidence intervals overlapped. For simple SR topics, TMT searches were faster and slightly less sensitive than UP. For complex SR topics, TMT searches were faster and less sensitive than UP searches but identified unique eligible citations not found by the UP searches. be used to carry out these transformations, (3) what products can be obtained by transforming the waste, (4) what functions can be carried out by the waste, (5) with which technologies, and (6) on which entities. An automatic implementation of the proposed method, involving the manual check of the retrieved results, was tested through a case study about wood chip recycling and reuse. Compared to the dependency patterns from the literature, the proposed ones allowed to retrieve 28 % more pertinent information. This results mainly depends by better ability of the proposed patterns to better discriminate the relevant sentences from which to extract information, compared to the other patterns (i.e. + 40 %). The automatic classification of the information was also correctly performed: in almost each class, precision and recall were higher than 60 % and on average equal to 90 %. of data from qualifying studies. Missing data were requested from principal study authors. We combined relative risks using random-effect meta-analysis. Two or more review authors assessed the risk of bias, quality of evidence and strength of evidence, using Navigation Guide and GRADE tools and approaches adapted to this project.Thirty-seven studies (26 prospective cohort studies and 11 case-control studies) met the inclusion criteria, comprising a total of 768,751 participants (310,954 females) in 13 countries in three WHO regions (Americas, Europe and Western Pacific). The exposure was measured using self-reports in all studies, and the outcome was assessed with administrative health records (30 studies) or self-reported physician diagnosis (7 studies). The outcome was defined as incident non-fatal IHD event in 19 studies (8 cohort studies, 11 case-control studies), incident fatal IHD event in two studies (both cohort studies), and incident non-fatal or fatal ("mixed") event in 16 studies (all cohort studies). Because we judged cohort studies to have a relatively lower risk of bias, we prioritized evidence from these studies and treated evidence from case-control studies as supporting evidence. For the bodies of evidence for both outcomes with any eligible studies (i.e. IHD incidence and mortality), we did not have serious concerns for risk of bias (at least for the cohort studies). No eligible study was found on the effect of long working hours on IHD prevalence. Compared with working 35-40 h/week, we are uncertain about the effect on acquiring (or incidence of) IHD of working 41-48 h/week (relative risk (RR) 0.98, 95% confidence interval (CI) 0.91 to 1.07, 20 studies, 312,209 participants, I2 0%, low quality of evidence) and 49-54 h/week (RR 1.05, 95% CI 0.94 to 1.17, 18 studies, 308,405 participants, I2 0%, low quality of evidence). Compared with working 35-40 h/week, working ≥55 h/week may have led to a moderately, clinically meaningful increase in the risk of acquiring IHD, when followed up between one year and 20 years (RR 1.13, 95% CI 1.02 to 1.26, 22 studies, 339,680 participants, I2 5%, moderate quality of evidence). Compared with working 35-40 h/week, we are very uncertain about the effect on dying (mortality) from IHD of working 41-48 h/week (RR 0.99, 95% CI 0.88 to 1.12, 13 studies, 288,278 participants, I2 8%, low quality of evidence) and 49-54 h/week (RR 1.01, 95% CI 0.82 to 1.25, 11 studies, 284,474 participants, I2 13%, low quality of evidence). Compared with working 35-40 h/week, working ≥55 h/week may have led to a moderate, clinically meaningful increase in the risk of dying from IHD when followed up between eight and 30 years (RR 1.17, 95% CI 1.05 to 1.31, 16 studies, 726,803 participants, I2 0%, moderate quality of evidence). Subgroup analyses found no evidence for differences by WHO region and sex, but RRs were higher among persons with lower SES. Sensitivity analyses found no differences by outcome definition (exclusively non-fatal or fatal versus "mixed"), outcome measurement (health records versus self-reports) and risk of bias ("high"/"probably high" ratings in any domain versus "low"/"probably low" in all domains).We judged the existing bodies of evidence for human evidence as "inadequate evidence for harmfulness" for the exposure categories 41-48 and 49-54 h/week for IHD prevalence, incidence and mortality, and for the exposure category ≥55 h/week for IHD prevalence. Evidence on exposure to working ≥55 h/week was judged as "sufficient evidence of harmfulness" for IHD incidence and mortality. Producing estimates for the burden of IHD attributable to exposure to working ≥55 h/week appears evidence-based, and the pooled effect estimates presented in this systematic review could be used as input data for the WHO/ILO Joint Estimates.
PY  - 2018
DA  - 2018-07-11
JO  - {'id': 'https://openalex.org/S136516072', 'issn_l': '1943-9407', 'issn': ['1943-9342', '1943-9407'], 'display_name': 'Journal of Development Effectiveness', 'publisher': 'Taylor & Francis', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Sandy Oliver
AU  - David Gough
AU  - James Copestake
AU  - James D. Thomas
ER  - 

787.
TY  - journal-article
ID  - https://openalex.org/W3006694184
DO  - https://doi.org/10.1080/02763869.2020.1704598
TI  - A Microsoft Excel Approach to Reduce Errors and Increase Efficiency in Systematic Searching
AB  - Developing a search strategy for a systematic review is a time-consuming process in which small errors around the formatting and compilation of terms can have large consequences. Microsoft Excel was identified as a potentially useful software to streamline the process and reduce manual errors. Ultimately a spreadsheet was created that largely automates the process of creating a single-line search string with correctly formatted terms, Boolean operators and parentheses. outcomes and measures, and advances in automation technologies. Improved methods and guidance are required for synthesising formative research and investigating contextual factors. Engaging stakeholders and working across academic disciplines support the production of policy-relevant syntheses and inspire methods development. 2).Across all reviews, TMT searches were less sensitive than UP searches, but confidence intervals overlapped. For simple SR topics, TMT searches were faster and slightly less sensitive than UP. For complex SR topics, TMT searches were faster and less sensitive than UP searches but identified unique eligible citations not found by the UP searches. be used to carry out these transformations, (3) what products can be obtained by transforming the waste, (4) what functions can be carried out by the waste, (5) with which technologies, and (6) on which entities. An automatic implementation of the proposed method, involving the manual check of the retrieved results, was tested through a case study about wood chip recycling and reuse. Compared to the dependency patterns from the literature, the proposed ones allowed to retrieve 28 % more pertinent information. This results mainly depends by better ability of the proposed patterns to better discriminate the relevant sentences from which to extract information, compared to the other patterns (i.e. + 40 %). The automatic classification of the information was also correctly performed: in almost each class, precision and recall were higher than 60 % and on average equal to 90 %. of data from qualifying studies. Missing data were requested from principal study authors. We combined relative risks using random-effect meta-analysis. Two or more review authors assessed the risk of bias, quality of evidence and strength of evidence, using Navigation Guide and GRADE tools and approaches adapted to this project.Thirty-seven studies (26 prospective cohort studies and 11 case-control studies) met the inclusion criteria, comprising a total of 768,751 participants (310,954 females) in 13 countries in three WHO regions (Americas, Europe and Western Pacific). The exposure was measured using self-reports in all studies, and the outcome was assessed with administrative health records (30 studies) or self-reported physician diagnosis (7 studies). The outcome was defined as incident non-fatal IHD event in 19 studies (8 cohort studies, 11 case-control studies), incident fatal IHD event in two studies (both cohort studies), and incident non-fatal or fatal ("mixed") event in 16 studies (all cohort studies). Because we judged cohort studies to have a relatively lower risk of bias, we prioritized evidence from these studies and treated evidence from case-control studies as supporting evidence. For the bodies of evidence for both outcomes with any eligible studies (i.e. IHD incidence and mortality), we did not have serious concerns for risk of bias (at least for the cohort studies). No eligible study was found on the effect of long working hours on IHD prevalence. Compared with working 35-40 h/week, we are uncertain about the effect on acquiring (or incidence of) IHD of working 41-48 h/week (relative risk (RR) 0.98, 95% confidence interval (CI) 0.91 to 1.07, 20 studies, 312,209 participants, I2 0%, low quality of evidence) and 49-54 h/week (RR 1.05, 95% CI 0.94 to 1.17, 18 studies, 308,405 participants, I2 0%, low quality of evidence). Compared with working 35-40 h/week, working ≥55 h/week may have led to a moderately, clinically meaningful increase in the risk of acquiring IHD, when followed up between one year and 20 years (RR 1.13, 95% CI 1.02 to 1.26, 22 studies, 339,680 participants, I2 5%, moderate quality of evidence). Compared with working 35-40 h/week, we are very uncertain about the effect on dying (mortality) from IHD of working 41-48 h/week (RR 0.99, 95% CI 0.88 to 1.12, 13 studies, 288,278 participants, I2 8%, low quality of evidence) and 49-54 h/week (RR 1.01, 95% CI 0.82 to 1.25, 11 studies, 284,474 participants, I2 13%, low quality of evidence). Compared with working 35-40 h/week, working ≥55 h/week may have led to a moderate, clinically meaningful increase in the risk of dying from IHD when followed up between eight and 30 years (RR 1.17, 95% CI 1.05 to 1.31, 16 studies, 726,803 participants, I2 0%, moderate quality of evidence). Subgroup analyses found no evidence for differences by WHO region and sex, but RRs were higher among persons with lower SES. Sensitivity analyses found no differences by outcome definition (exclusively non-fatal or fatal versus "mixed"), outcome measurement (health records versus self-reports) and risk of bias ("high"/"probably high" ratings in any domain versus "low"/"probably low" in all domains).We judged the existing bodies of evidence for human evidence as "inadequate evidence for harmfulness" for the exposure categories 41-48 and 49-54 h/week for IHD prevalence, incidence and mortality, and for the exposure category ≥55 h/week for IHD prevalence. Evidence on exposure to working ≥55 h/week was judged as "sufficient evidence of harmfulness" for IHD incidence and mortality. Producing estimates for the burden of IHD attributable to exposure to working ≥55 h/week appears evidence-based, and the pooled effect estimates presented in this systematic review could be used as input data for the WHO/ILO Joint Estimates.
PY  - 2020
DA  - 2020-02-18
JO  - {'id': 'https://openalex.org/V200967711', 'issn_l': '0276-3869', 'issn': ['0276-3869', '1540-9597', '1540-9567'], 'display_name': 'Medical Reference Services Quarterly', 'publisher': 'Taylor & Francis', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Amelia Brunskill
ER  - 

788.
TY  - journal-article
ID  - https://openalex.org/W3162580010
DO  - https://doi.org/10.2196/28666
TI  - Redundancy of Terms in Search Strategies. Comment on “Searching PubMed to Retrieve Publications on the COVID-19 Pandemic: Comparative Analysis of Search Strings”
AB  - Developing a search strategy for a systematic review is a time-consuming process in which small errors around the formatting and compilation of terms can have large consequences. Microsoft Excel was identified as a potentially useful software to streamline the process and reduce manual errors. Ultimately a spreadsheet was created that largely automates the process of creating a single-line search string with correctly formatted terms, Boolean operators and parentheses. outcomes and measures, and advances in automation technologies. Improved methods and guidance are required for synthesising formative research and investigating contextual factors. Engaging stakeholders and working across academic disciplines support the production of policy-relevant syntheses and inspire methods development. 2).Across all reviews, TMT searches were less sensitive than UP searches, but confidence intervals overlapped. For simple SR topics, TMT searches were faster and slightly less sensitive than UP. For complex SR topics, TMT searches were faster and less sensitive than UP searches but identified unique eligible citations not found by the UP searches. be used to carry out these transformations, (3) what products can be obtained by transforming the waste, (4) what functions can be carried out by the waste, (5) with which technologies, and (6) on which entities. An automatic implementation of the proposed method, involving the manual check of the retrieved results, was tested through a case study about wood chip recycling and reuse. Compared to the dependency patterns from the literature, the proposed ones allowed to retrieve 28 % more pertinent information. This results mainly depends by better ability of the proposed patterns to better discriminate the relevant sentences from which to extract information, compared to the other patterns (i.e. + 40 %). The automatic classification of the information was also correctly performed: in almost each class, precision and recall were higher than 60 % and on average equal to 90 %. of data from qualifying studies. Missing data were requested from principal study authors. We combined relative risks using random-effect meta-analysis. Two or more review authors assessed the risk of bias, quality of evidence and strength of evidence, using Navigation Guide and GRADE tools and approaches adapted to this project.Thirty-seven studies (26 prospective cohort studies and 11 case-control studies) met the inclusion criteria, comprising a total of 768,751 participants (310,954 females) in 13 countries in three WHO regions (Americas, Europe and Western Pacific). The exposure was measured using self-reports in all studies, and the outcome was assessed with administrative health records (30 studies) or self-reported physician diagnosis (7 studies). The outcome was defined as incident non-fatal IHD event in 19 studies (8 cohort studies, 11 case-control studies), incident fatal IHD event in two studies (both cohort studies), and incident non-fatal or fatal ("mixed") event in 16 studies (all cohort studies). Because we judged cohort studies to have a relatively lower risk of bias, we prioritized evidence from these studies and treated evidence from case-control studies as supporting evidence. For the bodies of evidence for both outcomes with any eligible studies (i.e. IHD incidence and mortality), we did not have serious concerns for risk of bias (at least for the cohort studies). No eligible study was found on the effect of long working hours on IHD prevalence. Compared with working 35-40 h/week, we are uncertain about the effect on acquiring (or incidence of) IHD of working 41-48 h/week (relative risk (RR) 0.98, 95% confidence interval (CI) 0.91 to 1.07, 20 studies, 312,209 participants, I2 0%, low quality of evidence) and 49-54 h/week (RR 1.05, 95% CI 0.94 to 1.17, 18 studies, 308,405 participants, I2 0%, low quality of evidence). Compared with working 35-40 h/week, working ≥55 h/week may have led to a moderately, clinically meaningful increase in the risk of acquiring IHD, when followed up between one year and 20 years (RR 1.13, 95% CI 1.02 to 1.26, 22 studies, 339,680 participants, I2 5%, moderate quality of evidence). Compared with working 35-40 h/week, we are very uncertain about the effect on dying (mortality) from IHD of working 41-48 h/week (RR 0.99, 95% CI 0.88 to 1.12, 13 studies, 288,278 participants, I2 8%, low quality of evidence) and 49-54 h/week (RR 1.01, 95% CI 0.82 to 1.25, 11 studies, 284,474 participants, I2 13%, low quality of evidence). Compared with working 35-40 h/week, working ≥55 h/week may have led to a moderate, clinically meaningful increase in the risk of dying from IHD when followed up between eight and 30 years (RR 1.17, 95% CI 1.05 to 1.31, 16 studies, 726,803 participants, I2 0%, moderate quality of evidence). Subgroup analyses found no evidence for differences by WHO region and sex, but RRs were higher among persons with lower SES. Sensitivity analyses found no differences by outcome definition (exclusively non-fatal or fatal versus "mixed"), outcome measurement (health records versus self-reports) and risk of bias ("high"/"probably high" ratings in any domain versus "low"/"probably low" in all domains).We judged the existing bodies of evidence for human evidence as "inadequate evidence for harmfulness" for the exposure categories 41-48 and 49-54 h/week for IHD prevalence, incidence and mortality, and for the exposure category ≥55 h/week for IHD prevalence. Evidence on exposure to working ≥55 h/week was judged as "sufficient evidence of harmfulness" for IHD incidence and mortality. Producing estimates for the burden of IHD attributable to exposure to working ≥55 h/week appears evidence-based, and the pooled effect estimates presented in this systematic review could be used as input data for the WHO/ILO Joint Estimates.
PY  - 2021
DA  - 2021-05-28
JO  - {'id': 'https://openalex.org/V17147534', 'issn_l': '1438-8871', 'issn': ['1439-4456', '1438-8871'], 'display_name': 'Journal of Medical Internet Research', 'publisher': 'JMIR Publications', 'type': 'journal', 'url': 'https://www.jmir.org/2021/5/e28666/PDF', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Daniel Melo de Oliveira Campos
AU  - Umberto L. Fulco
AU  - Jonas Oliveira
ER  - 

789.
TY  - book-chapter
ID  - https://openalex.org/W2962666873
DO  - https://doi.org/10.1007/978-3-030-25719-4_8
TI  - Overview of Natural Language Processing Approaches in Modern Search Engines
AB  - This article provides an overview of modern natural language processing and understanding methods. All the monitored technologies are covered in the context of search engines. The authors do not consider any particular implementations of the search engines; however take in consideration some scientific research to show natural language processing techniques application prospects in the informational search industry. single-line search string with correctly formatted terms, Boolean operators and parentheses. outcomes and measures, and advances in automation technologies. Improved methods and guidance are required for synthesising formative research and investigating contextual factors. Engaging stakeholders and working across academic disciplines support the production of policy-relevant syntheses and inspire methods development. 2).Across all reviews, TMT searches were less sensitive than UP searches, but confidence intervals overlapped. For simple SR topics, TMT searches were faster and slightly less sensitive than UP. For complex SR topics, TMT searches were faster and less sensitive than UP searches but identified unique eligible citations not found by the UP searches. be used to carry out these transformations, (3) what products can be obtained by transforming the waste, (4) what functions can be carried out by the waste, (5) with which technologies, and (6) on which entities. An automatic implementation of the proposed method, involving the manual check of the retrieved results, was tested through a case study about wood chip recycling and reuse. Compared to the dependency patterns from the literature, the proposed ones allowed to retrieve 28 % more pertinent information. This results mainly depends by better ability of the proposed patterns to better discriminate the relevant sentences from which to extract information, compared to the other patterns (i.e. + 40 %). The automatic classification of the information was also correctly performed: in almost each class, precision and recall were higher than 60 % and on average equal to 90 %. of data from qualifying studies. Missing data were requested from principal study authors. We combined relative risks using random-effect meta-analysis. Two or more review authors assessed the risk of bias, quality of evidence and strength of evidence, using Navigation Guide and GRADE tools and approaches adapted to this project.Thirty-seven studies (26 prospective cohort studies and 11 case-control studies) met the inclusion criteria, comprising a total of 768,751 participants (310,954 females) in 13 countries in three WHO regions (Americas, Europe and Western Pacific). The exposure was measured using self-reports in all studies, and the outcome was assessed with administrative health records (30 studies) or self-reported physician diagnosis (7 studies). The outcome was defined as incident non-fatal IHD event in 19 studies (8 cohort studies, 11 case-control studies), incident fatal IHD event in two studies (both cohort studies), and incident non-fatal or fatal ("mixed") event in 16 studies (all cohort studies). Because we judged cohort studies to have a relatively lower risk of bias, we prioritized evidence from these studies and treated evidence from case-control studies as supporting evidence. For the bodies of evidence for both outcomes with any eligible studies (i.e. IHD incidence and mortality), we did not have serious concerns for risk of bias (at least for the cohort studies). No eligible study was found on the effect of long working hours on IHD prevalence. Compared with working 35-40 h/week, we are uncertain about the effect on acquiring (or incidence of) IHD of working 41-48 h/week (relative risk (RR) 0.98, 95% confidence interval (CI) 0.91 to 1.07, 20 studies, 312,209 participants, I2 0%, low quality of evidence) and 49-54 h/week (RR 1.05, 95% CI 0.94 to 1.17, 18 studies, 308,405 participants, I2 0%, low quality of evidence). Compared with working 35-40 h/week, working ≥55 h/week may have led to a moderately, clinically meaningful increase in the risk of acquiring IHD, when followed up between one year and 20 years (RR 1.13, 95% CI 1.02 to 1.26, 22 studies, 339,680 participants, I2 5%, moderate quality of evidence). Compared with working 35-40 h/week, we are very uncertain about the effect on dying (mortality) from IHD of working 41-48 h/week (RR 0.99, 95% CI 0.88 to 1.12, 13 studies, 288,278 participants, I2 8%, low quality of evidence) and 49-54 h/week (RR 1.01, 95% CI 0.82 to 1.25, 11 studies, 284,474 participants, I2 13%, low quality of evidence). Compared with working 35-40 h/week, working ≥55 h/week may have led to a moderate, clinically meaningful increase in the risk of dying from IHD when followed up between eight and 30 years (RR 1.17, 95% CI 1.05 to 1.31, 16 studies, 726,803 participants, I2 0%, moderate quality of evidence). Subgroup analyses found no evidence for differences by WHO region and sex, but RRs were higher among persons with lower SES. Sensitivity analyses found no differences by outcome definition (exclusively non-fatal or fatal versus "mixed"), outcome measurement (health records versus self-reports) and risk of bias ("high"/"probably high" ratings in any domain versus "low"/"probably low" in all domains).We judged the existing bodies of evidence for human evidence as "inadequate evidence for harmfulness" for the exposure categories 41-48 and 49-54 h/week for IHD prevalence, incidence and mortality, and for the exposure category ≥55 h/week for IHD prevalence. Evidence on exposure to working ≥55 h/week was judged as "sufficient evidence of harmfulness" for IHD incidence and mortality. Producing estimates for the burden of IHD attributable to exposure to working ≥55 h/week appears evidence-based, and the pooled effect estimates presented in this systematic review could be used as input data for the WHO/ILO Joint Estimates.
PY  - 2019
DA  - 2019-08-15
JO  - {'id': 'https://openalex.org/S2764905038', 'issn_l': '2194-5365', 'issn': ['2194-5357', '2194-5365'], 'display_name': 'Advances in intelligent systems and computing', 'publisher': 'Springer Nature', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Artem Chernyshov
AU  - Anita Balandina
AU  - Valentin Klimov
ER  - 

790.
TY  - book-chapter
ID  - https://openalex.org/W3199830233
DO  - https://doi.org/10.1007/978-1-0716-1566-9_2
TI  - Semi-automated Tools for Systematic Searches
AB  - Traditionally, literature identification for systematic reviews has relied on a two-step process: first, searching databases to identify potentially relevant citations, and then manually screening those citations. A number of tools have been developed to streamline and semi-automate this process, including tools to generate terms; to visualize and evaluate search queries; to trace citation linkages; to deduplicate, limit, or translate searches across databases; and to prioritize relevant abstracts for screening. Research is ongoing into tools that can unify searching and screening into a single step, and several protype tools have been developed. As this field grows, it is becoming increasingly important to develop and codify methods for evaluating the extent to which these tools fulfill their purpose. UP searches, but confidence intervals overlapped. For simple SR topics, TMT searches were faster and slightly less sensitive than UP. For complex SR topics, TMT searches were faster and less sensitive than UP searches but identified unique eligible citations not found by the UP searches. be used to carry out these transformations, (3) what products can be obtained by transforming the waste, (4) what functions can be carried out by the waste, (5) with which technologies, and (6) on which entities. An automatic implementation of the proposed method, involving the manual check of the retrieved results, was tested through a case study about wood chip recycling and reuse. Compared to the dependency patterns from the literature, the proposed ones allowed to retrieve 28 % more pertinent information. This results mainly depends by better ability of the proposed patterns to better discriminate the relevant sentences from which to extract information, compared to the other patterns (i.e. + 40 %). The automatic classification of the information was also correctly performed: in almost each class, precision and recall were higher than 60 % and on average equal to 90 %. of data from qualifying studies. Missing data were requested from principal study authors. We combined relative risks using random-effect meta-analysis. Two or more review authors assessed the risk of bias, quality of evidence and strength of evidence, using Navigation Guide and GRADE tools and approaches adapted to this project.Thirty-seven studies (26 prospective cohort studies and 11 case-control studies) met the inclusion criteria, comprising a total of 768,751 participants (310,954 females) in 13 countries in three WHO regions (Americas, Europe and Western Pacific). The exposure was measured using self-reports in all studies, and the outcome was assessed with administrative health records (30 studies) or self-reported physician diagnosis (7 studies). The outcome was defined as incident non-fatal IHD event in 19 studies (8 cohort studies, 11 case-control studies), incident fatal IHD event in two studies (both cohort studies), and incident non-fatal or fatal ("mixed") event in 16 studies (all cohort studies). Because we judged cohort studies to have a relatively lower risk of bias, we prioritized evidence from these studies and treated evidence from case-control studies as supporting evidence. For the bodies of evidence for both outcomes with any eligible studies (i.e. IHD incidence and mortality), we did not have serious concerns for risk of bias (at least for the cohort studies). No eligible study was found on the effect of long working hours on IHD prevalence. Compared with working 35-40 h/week, we are uncertain about the effect on acquiring (or incidence of) IHD of working 41-48 h/week (relative risk (RR) 0.98, 95% confidence interval (CI) 0.91 to 1.07, 20 studies, 312,209 participants, I2 0%, low quality of evidence) and 49-54 h/week (RR 1.05, 95% CI 0.94 to 1.17, 18 studies, 308,405 participants, I2 0%, low quality of evidence). Compared with working 35-40 h/week, working ≥55 h/week may have led to a moderately, clinically meaningful increase in the risk of acquiring IHD, when followed up between one year and 20 years (RR 1.13, 95% CI 1.02 to 1.26, 22 studies, 339,680 participants, I2 5%, moderate quality of evidence). Compared with working 35-40 h/week, we are very uncertain about the effect on dying (mortality) from IHD of working 41-48 h/week (RR 0.99, 95% CI 0.88 to 1.12, 13 studies, 288,278 participants, I2 8%, low quality of evidence) and 49-54 h/week (RR 1.01, 95% CI 0.82 to 1.25, 11 studies, 284,474 participants, I2 13%, low quality of evidence). Compared with working 35-40 h/week, working ≥55 h/week may have led to a moderate, clinically meaningful increase in the risk of dying from IHD when followed up between eight and 30 years (RR 1.17, 95% CI 1.05 to 1.31, 16 studies, 726,803 participants, I2 0%, moderate quality of evidence). Subgroup analyses found no evidence for differences by WHO region and sex, but RRs were higher among persons with lower SES. Sensitivity analyses found no differences by outcome definition (exclusively non-fatal or fatal versus "mixed"), outcome measurement (health records versus self-reports) and risk of bias ("high"/"probably high" ratings in any domain versus "low"/"probably low" in all domains).We judged the existing bodies of evidence for human evidence as "inadequate evidence for harmfulness" for the exposure categories 41-48 and 49-54 h/week for IHD prevalence, incidence and mortality, and for the exposure category ≥55 h/week for IHD prevalence. Evidence on exposure to working ≥55 h/week was judged as "sufficient evidence of harmfulness" for IHD incidence and mortality. Producing estimates for the burden of IHD attributable to exposure to working ≥55 h/week appears evidence-based, and the pooled effect estimates presented in this systematic review could be used as input data for the WHO/ILO Joint Estimates.
PY  - 2022
DA  - 2022-01-01
JO  - {'id': 'https://openalex.org/S4210172139', 'issn_l': '1064-3745', 'issn': ['1940-6029', '1064-3745'], 'display_name': 'Methods in molecular biology', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Gaelen P Adam
AU  - Byron C. Wallace
AU  - Thomas A Trikalinos
ER  - 

791.
TY  - journal-article
ID  - https://openalex.org/W4200030287
DO  - https://doi.org/10.1080/07317131.2021.1973797
TI  - Artificial Intelligence: The Possibilities for Metadata Creation
AB  - No Abstract Found
PY  - 2021
DA  - 2021-10-02
JO  - {'id': 'https://openalex.org/S49429790', 'issn_l': '0731-7131', 'issn': ['1555-3337', '0731-7131'], 'display_name': 'Technical Services Quarterly', 'publisher': 'Taylor & Francis', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Edward M. Corrado
ER  - 

792.
TY  - journal-article
ID  - https://openalex.org/W2940299311
DO  - https://doi.org/10.1002/jrsm.1350
TI  - Potential Technologies Review: A hybrid information retrieval framework to accelerate demand‐pull innovation in biomedical engineering
AB  - Launching biomedical innovations based on clinical demands instead of translating basic research findings to practice reduces the risk that the results will not fit the clinical routine. To realize this type of innovation, a meta-analysis of the body of research is necessary to reveal demand-matching concepts. However, both the data deluge and the narrow time constraints for innovation make it impossible to perform such reviews manually. Thus, this paper proposes a specifically adapted “Potential Technologies Review” approach focusing on automated text mining and information retrieval techniques. The novel framework combines features from both systematic and scoping reviews. It aims at high coverage and reproducibility while mapping technologies-even with a fuzzy initial scope. To achieve these goals for search and triage, a set of closely interrelated methods has been developed: (a) automated query optimization, (b) screening prioritization, and (c) recall estimation. To determine appropriate parameters, a variety of published literature corpora were used and compared with an evaluation on a real-world dataset. Our results show that it is feasible to automate the identification of relevant works using this newly introduced framework. It achieved a workload reduction of up to 91% “Work-saved-over Sampling (WSS)” with a 76% overall recall compared with manually screening search results. Reducing the workload is a prerequisite for a rapid Potential Technologies Review when conducting demand-pull innovations. Moreover, it facilitates the updating and closer monitoring of latest findings. Studying the robustness of the framework and expanding it to patent documents are future tasks. mainly depends by better ability of the proposed patterns to better discriminate the relevant sentences from which to extract information, compared to the other patterns (i.e. + 40 %). The automatic classification of the information was also correctly performed: in almost each class, precision and recall were higher than 60 % and on average equal to 90 %. of data from qualifying studies. Missing data were requested from principal study authors. We combined relative risks using random-effect meta-analysis. Two or more review authors assessed the risk of bias, quality of evidence and strength of evidence, using Navigation Guide and GRADE tools and approaches adapted to this project.Thirty-seven studies (26 prospective cohort studies and 11 case-control studies) met the inclusion criteria, comprising a total of 768,751 participants (310,954 females) in 13 countries in three WHO regions (Americas, Europe and Western Pacific). The exposure was measured using self-reports in all studies, and the outcome was assessed with administrative health records (30 studies) or self-reported physician diagnosis (7 studies). The outcome was defined as incident non-fatal IHD event in 19 studies (8 cohort studies, 11 case-control studies), incident fatal IHD event in two studies (both cohort studies), and incident non-fatal or fatal ("mixed") event in 16 studies (all cohort studies). Because we judged cohort studies to have a relatively lower risk of bias, we prioritized evidence from these studies and treated evidence from case-control studies as supporting evidence. For the bodies of evidence for both outcomes with any eligible studies (i.e. IHD incidence and mortality), we did not have serious concerns for risk of bias (at least for the cohort studies). No eligible study was found on the effect of long working hours on IHD prevalence. Compared with working 35-40 h/week, we are uncertain about the effect on acquiring (or incidence of) IHD of working 41-48 h/week (relative risk (RR) 0.98, 95% confidence interval (CI) 0.91 to 1.07, 20 studies, 312,209 participants, I2 0%, low quality of evidence) and 49-54 h/week (RR 1.05, 95% CI 0.94 to 1.17, 18 studies, 308,405 participants, I2 0%, low quality of evidence). Compared with working 35-40 h/week, working ≥55 h/week may have led to a moderately, clinically meaningful increase in the risk of acquiring IHD, when followed up between one year and 20 years (RR 1.13, 95% CI 1.02 to 1.26, 22 studies, 339,680 participants, I2 5%, moderate quality of evidence). Compared with working 35-40 h/week, we are very uncertain about the effect on dying (mortality) from IHD of working 41-48 h/week (RR 0.99, 95% CI 0.88 to 1.12, 13 studies, 288,278 participants, I2 8%, low quality of evidence) and 49-54 h/week (RR 1.01, 95% CI 0.82 to 1.25, 11 studies, 284,474 participants, I2 13%, low quality of evidence). Compared with working 35-40 h/week, working ≥55 h/week may have led to a moderate, clinically meaningful increase in the risk of dying from IHD when followed up between eight and 30 years (RR 1.17, 95% CI 1.05 to 1.31, 16 studies, 726,803 participants, I2 0%, moderate quality of evidence). Subgroup analyses found no evidence for differences by WHO region and sex, but RRs were higher among persons with lower SES. Sensitivity analyses found no differences by outcome definition (exclusively non-fatal or fatal versus "mixed"), outcome measurement (health records versus self-reports) and risk of bias ("high"/"probably high" ratings in any domain versus "low"/"probably low" in all domains).We judged the existing bodies of evidence for human evidence as "inadequate evidence for harmfulness" for the exposure categories 41-48 and 49-54 h/week for IHD prevalence, incidence and mortality, and for the exposure category ≥55 h/week for IHD prevalence. Evidence on exposure to working ≥55 h/week was judged as "sufficient evidence of harmfulness" for IHD incidence and mortality. Producing estimates for the burden of IHD attributable to exposure to working ≥55 h/week appears evidence-based, and the pooled effect estimates presented in this systematic review could be used as input data for the WHO/ILO Joint Estimates.
PY  - 2019
DA  - 2019-09-01
JO  - {'id': 'https://openalex.org/S205768342', 'issn_l': '1759-2879', 'issn': ['1759-2879', '1759-2887'], 'display_name': 'Research Synthesis Methods', 'publisher': 'Wiley-Blackwell', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Tom Schmitz
AU  - Mark Bukowski
AU  - Steffen Koschmieder
AU  - Thomas Schmitz-Rode
AU  - Róbert Farkas
ER  - 

793.
TY  - journal-article
ID  - https://openalex.org/W3138584238
DO  - https://doi.org/10.15407/jai2020.01.051
TI  - Development of knowledge oriented decision making support subsystem for intellectual information system
AB  - It is proposed to expand the structure of the intelligent information system with an addition of knowledge-oriented decision support subsystem. The description of an intellectual workplace is given. Based on this, the main procedures of the subsystem are proposed: the creation of a knowledge base and the search for appropriate responses to a given action. The structure and stages of creating a knowledge base based on the analysis of rules set in natural language are described. The advantages of this approach in comparison with the common approaches based on neural networks are substantiated. systematic and scoping reviews. It aims at high coverage and reproducibility while mapping technologies-even with a fuzzy initial scope. To achieve these goals for search and triage, a set of closely interrelated methods has been developed: (a) automated query optimization, (b) screening prioritization, and (c) recall estimation. To determine appropriate parameters, a variety of published literature corpora were used and compared with an evaluation on a real-world dataset. Our results show that it is feasible to automate the identification of relevant works using this newly introduced framework. It achieved a workload reduction of up to 91% “Work-saved-over Sampling (WSS)” with a 76% overall recall compared with manually screening search results. Reducing the workload is a prerequisite for a rapid Potential Technologies Review when conducting demand-pull innovations. Moreover, it facilitates the updating and closer monitoring of latest findings. Studying the robustness of the framework and expanding it to patent documents are future tasks. mainly depends by better ability of the proposed patterns to better discriminate the relevant sentences from which to extract information, compared to the other patterns (i.e. + 40 %). The automatic classification of the information was also correctly performed: in almost each class, precision and recall were higher than 60 % and on average equal to 90 %. of data from qualifying studies. Missing data were requested from principal study authors. We combined relative risks using random-effect meta-analysis. Two or more review authors assessed the risk of bias, quality of evidence and strength of evidence, using Navigation Guide and GRADE tools and approaches adapted to this project.Thirty-seven studies (26 prospective cohort studies and 11 case-control studies) met the inclusion criteria, comprising a total of 768,751 participants (310,954 females) in 13 countries in three WHO regions (Americas, Europe and Western Pacific). The exposure was measured using self-reports in all studies, and the outcome was assessed with administrative health records (30 studies) or self-reported physician diagnosis (7 studies). The outcome was defined as incident non-fatal IHD event in 19 studies (8 cohort studies, 11 case-control studies), incident fatal IHD event in two studies (both cohort studies), and incident non-fatal or fatal ("mixed") event in 16 studies (all cohort studies). Because we judged cohort studies to have a relatively lower risk of bias, we prioritized evidence from these studies and treated evidence from case-control studies as supporting evidence. For the bodies of evidence for both outcomes with any eligible studies (i.e. IHD incidence and mortality), we did not have serious concerns for risk of bias (at least for the cohort studies). No eligible study was found on the effect of long working hours on IHD prevalence. Compared with working 35-40 h/week, we are uncertain about the effect on acquiring (or incidence of) IHD of working 41-48 h/week (relative risk (RR) 0.98, 95% confidence interval (CI) 0.91 to 1.07, 20 studies, 312,209 participants, I2 0%, low quality of evidence) and 49-54 h/week (RR 1.05, 95% CI 0.94 to 1.17, 18 studies, 308,405 participants, I2 0%, low quality of evidence). Compared with working 35-40 h/week, working ≥55 h/week may have led to a moderately, clinically meaningful increase in the risk of acquiring IHD, when followed up between one year and 20 years (RR 1.13, 95% CI 1.02 to 1.26, 22 studies, 339,680 participants, I2 5%, moderate quality of evidence). Compared with working 35-40 h/week, we are very uncertain about the effect on dying (mortality) from IHD of working 41-48 h/week (RR 0.99, 95% CI 0.88 to 1.12, 13 studies, 288,278 participants, I2 8%, low quality of evidence) and 49-54 h/week (RR 1.01, 95% CI 0.82 to 1.25, 11 studies, 284,474 participants, I2 13%, low quality of evidence). Compared with working 35-40 h/week, working ≥55 h/week may have led to a moderate, clinically meaningful increase in the risk of dying from IHD when followed up between eight and 30 years (RR 1.17, 95% CI 1.05 to 1.31, 16 studies, 726,803 participants, I2 0%, moderate quality of evidence). Subgroup analyses found no evidence for differences by WHO region and sex, but RRs were higher among persons with lower SES. Sensitivity analyses found no differences by outcome definition (exclusively non-fatal or fatal versus "mixed"), outcome measurement (health records versus self-reports) and risk of bias ("high"/"probably high" ratings in any domain versus "low"/"probably low" in all domains).We judged the existing bodies of evidence for human evidence as "inadequate evidence for harmfulness" for the exposure categories 41-48 and 49-54 h/week for IHD prevalence, incidence and mortality, and for the exposure category ≥55 h/week for IHD prevalence. Evidence on exposure to working ≥55 h/week was judged as "sufficient evidence of harmfulness" for IHD incidence and mortality. Producing estimates for the burden of IHD attributable to exposure to working ≥55 h/week appears evidence-based, and the pooled effect estimates presented in this systematic review could be used as input data for the WHO/ILO Joint Estimates.
PY  - 2020
DA  - 2020-03-09
JO  - {'id': 'https://openalex.org/S4210173017', 'issn_l': '2710-1673', 'issn': ['2710-1673', '2710-1681'], 'display_name': 'Štučnij ìntelekt', 'publisher': 'National Academy of Sciences of Ukraine (Co. LTD Ukrinformnauka)', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Klymenko
ER  - 

794.
TY  - posted-content
ID  - https://openalex.org/W4206079750
DO  - https://doi.org/10.2196/preprints.28666
TI  - Redundancy of Terms in Search Strategies. Comment on “Searching PubMed to Retrieve Publications on the COVID-19 Pandemic: Comparative Analysis of Search Strings” (Preprint)
AB  - <sec> <title>UNSTRUCTURED</title> N/A </sec> expand the structure of the intelligent information system with an addition of knowledge-oriented decision support subsystem. The description of an intellectual workplace is given. Based on this, the main procedures of the subsystem are proposed: the creation of a knowledge base and the search for appropriate responses to a given action. The structure and stages of creating a knowledge base based on the analysis of rules set in natural language are described. The advantages of this approach in comparison with the common approaches based on neural networks are substantiated. systematic and scoping reviews. It aims at high coverage and reproducibility while mapping technologies-even with a fuzzy initial scope. To achieve these goals for search and triage, a set of closely interrelated methods has been developed: (a) automated query optimization, (b) screening prioritization, and (c) recall estimation. To determine appropriate parameters, a variety of published literature corpora were used and compared with an evaluation on a real-world dataset. Our results show that it is feasible to automate the identification of relevant works using this newly introduced framework. It achieved a workload reduction of up to 91% “Work-saved-over Sampling (WSS)” with a 76% overall recall compared with manually screening search results. Reducing the workload is a prerequisite for a rapid Potential Technologies Review when conducting demand-pull innovations. Moreover, it facilitates the updating and closer monitoring of latest findings. Studying the robustness of the framework and expanding it to patent documents are future tasks. mainly depends by better ability of the proposed patterns to better discriminate the relevant sentences from which to extract information, compared to the other patterns (i.e. + 40 %). The automatic classification of the information was also correctly performed: in almost each class, precision and recall were higher than 60 % and on average equal to 90 %. of data from qualifying studies. Missing data were requested from principal study authors. We combined relative risks using random-effect meta-analysis. Two or more review authors assessed the risk of bias, quality of evidence and strength of evidence, using Navigation Guide and GRADE tools and approaches adapted to this project.Thirty-seven studies (26 prospective cohort studies and 11 case-control studies) met the inclusion criteria, comprising a total of 768,751 participants (310,954 females) in 13 countries in three WHO regions (Americas, Europe and Western Pacific). The exposure was measured using self-reports in all studies, and the outcome was assessed with administrative health records (30 studies) or self-reported physician diagnosis (7 studies). The outcome was defined as incident non-fatal IHD event in 19 studies (8 cohort studies, 11 case-control studies), incident fatal IHD event in two studies (both cohort studies), and incident non-fatal or fatal ("mixed") event in 16 studies (all cohort studies). Because we judged cohort studies to have a relatively lower risk of bias, we prioritized evidence from these studies and treated evidence from case-control studies as supporting evidence. For the bodies of evidence for both outcomes with any eligible studies (i.e. IHD incidence and mortality), we did not have serious concerns for risk of bias (at least for the cohort studies). No eligible study was found on the effect of long working hours on IHD prevalence. Compared with working 35-40 h/week, we are uncertain about the effect on acquiring (or incidence of) IHD of working 41-48 h/week (relative risk (RR) 0.98, 95% confidence interval (CI) 0.91 to 1.07, 20 studies, 312,209 participants, I2 0%, low quality of evidence) and 49-54 h/week (RR 1.05, 95% CI 0.94 to 1.17, 18 studies, 308,405 participants, I2 0%, low quality of evidence). Compared with working 35-40 h/week, working ≥55 h/week may have led to a moderately, clinically meaningful increase in the risk of acquiring IHD, when followed up between one year and 20 years (RR 1.13, 95% CI 1.02 to 1.26, 22 studies, 339,680 participants, I2 5%, moderate quality of evidence). Compared with working 35-40 h/week, we are very uncertain about the effect on dying (mortality) from IHD of working 41-48 h/week (RR 0.99, 95% CI 0.88 to 1.12, 13 studies, 288,278 participants, I2 8%, low quality of evidence) and 49-54 h/week (RR 1.01, 95% CI 0.82 to 1.25, 11 studies, 284,474 participants, I2 13%, low quality of evidence). Compared with working 35-40 h/week, working ≥55 h/week may have led to a moderate, clinically meaningful increase in the risk of dying from IHD when followed up between eight and 30 years (RR 1.17, 95% CI 1.05 to 1.31, 16 studies, 726,803 participants, I2 0%, moderate quality of evidence). Subgroup analyses found no evidence for differences by WHO region and sex, but RRs were higher among persons with lower SES. Sensitivity analyses found no differences by outcome definition (exclusively non-fatal or fatal versus "mixed"), outcome measurement (health records versus self-reports) and risk of bias ("high"/"probably high" ratings in any domain versus "low"/"probably low" in all domains).We judged the existing bodies of evidence for human evidence as "inadequate evidence for harmfulness" for the exposure categories 41-48 and 49-54 h/week for IHD prevalence, incidence and mortality, and for the exposure category ≥55 h/week for IHD prevalence. Evidence on exposure to working ≥55 h/week was judged as "sufficient evidence of harmfulness" for IHD incidence and mortality. Producing estimates for the burden of IHD attributable to exposure to working ≥55 h/week appears evidence-based, and the pooled effect estimates presented in this systematic review could be used as input data for the WHO/ILO Joint Estimates.
PY  - 2021
DA  - 2021-03-10
JO  - {'id': None, 'issn_l': None, 'issn': None, 'display_name': None, 'publisher': None, 'type': None, 'url': 'https://doi.org/10.2196/preprints.28666', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Daniel Melo de Oliveira Campos
AU  - Umberto L. Fulco
AU  - Jonas Oliveira
ER  - 

795.
TY  - other
ID  - https://openalex.org/W4280590092
DO  - https://doi.org/10.1002/9781119099369.ch16
TI  - Systematic Reviews of Diagnostic Accuracy
AB  - No Abstract Found
PY  - 2022
DA  - 2022-04-22
JO  - {'id': None, 'issn_l': None, 'issn': None, 'display_name': 'Systematic Reviews in Health Research', 'publisher': None, 'type': None, 'url': 'https://doi.org/10.1002/9781119099369.ch16', 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Yemisi Takwoingi
AU  - Jonathan J Deeks
ER  - 

796.
TY  - journal-article
ID  - https://openalex.org/W4281782963
DO  - https://doi.org/10.1007/s10664-021-10084-4
TI  - SeSG: a search string generator for Secondary Studies with hybrid search strategies using text mining
AB  - No Abstract Found
PY  - 2022
DA  - 2022-05-30
JO  - {'id': 'https://openalex.org/S109852484', 'issn_l': '1382-3256', 'issn': ['1382-3256', '1573-7616'], 'display_name': 'Empirical Software Engineering', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Leonardo Alcântara Alves
AU  - Francisco J. S. Vasconcellos
AU  - Bruno Nogueira
ER  - 

797.
TY  - journal-article
ID  - https://openalex.org/W4294969066
DO  - https://doi.org/10.1155/2022/3133096
TI  - To Explore the Molecular Mechanism of Acupuncture Alleviating Inflammation and Treating Obesity Based on Text Mining
AB  - To explore the related mechanism of acupuncture affecting obesity by regulating inflammation using bioinformatics methods.The genes related to obesity, inflammation, and acupuncture and inflammation were mined using GenCLiP 3, and the intersecting genes were extracted using Venn diagram. The DAVID database was employed for pathway enrichment analysis and functional annotation of coexpressed genes. Then, the protein-protein interaction (PPI) network was constructed with the STRING database and visualized by the Cytoscape software and screened out important hub genes. Finally, the Boxplot and Survival Analysis of the hub genes in various cancers were performed by GEPIA.755 genes related to obesity and inflammation and 38 genes related to acupuncture and inflammation were identified, and 24 coexpressed genes related to obesity, inflammation, and acupuncture were extracted from the Venn diagram. Eight hub genes including interleukin-6 (IL-6), interleukin-10 (IL-10), Toll-like receptor 4 (TLR4), signal transduction and transcriptional activation factor 3 (STAT3), C-X-C motif chemokine 10 (CXCL10), interleukin-17A (IL-17A), prostaglandin peroxide synthesis-2 (PTGS2), signal transistors, and transcriptional activation factor 6 (STAT6) were identified by gene ontology (GO), Kyoto Encyclopedia of Genes (KEGG), and PPI network analysis. Among them, IL-6 is suggested to play an essential role in the treatment of obesity and inflammation by acupuncture, and IL-6 was significant in both Boxplot and Survival Analysis of pancreatic cancer (PAAD). Therefore, in this study, the core gene, IL-6 was used as the breakthrough point to explore the possible mechanism of acupuncture in treating obesity and pancreatic cancer by regulating IL-6.(1) Acupuncture can regulate the expression of IL-6 through the TLR4/nuclear factor-κB (NF-κB) pathway, thereby alleviating inflammation, which can be used as a potential strategy for the treatment of obesity. (2) IL-6/STAT3 is closely related to the occurrence, development, and metastasis of pancreatic cancer. Acupuncture affecting pancreatic cancer through TLR4/NF-κB/IL-6/STAT3 pathway may be a potential method for the treatment of pancreatic cancer. data from qualifying studies. Missing data were requested from principal study authors. We combined relative risks using random-effect meta-analysis. Two or more review authors assessed the risk of bias, quality of evidence and strength of evidence, using Navigation Guide and GRADE tools and approaches adapted to this project.Thirty-seven studies (26 prospective cohort studies and 11 case-control studies) met the inclusion criteria, comprising a total of 768,751 participants (310,954 females) in 13 countries in three WHO regions (Americas, Europe and Western Pacific). The exposure was measured using self-reports in all studies, and the outcome was assessed with administrative health records (30 studies) or self-reported physician diagnosis (7 studies). The outcome was defined as incident non-fatal IHD event in 19 studies (8 cohort studies, 11 case-control studies), incident fatal IHD event in two studies (both cohort studies), and incident non-fatal or fatal ("mixed") event in 16 studies (all cohort studies). Because we judged cohort studies to have a relatively lower risk of bias, we prioritized evidence from these studies and treated evidence from case-control studies as supporting evidence. For the bodies of evidence for both outcomes with any eligible studies (i.e. IHD incidence and mortality), we did not have serious concerns for risk of bias (at least for the cohort studies). No eligible study was found on the effect of long working hours on IHD prevalence. Compared with working 35-40 h/week, we are uncertain about the effect on acquiring (or incidence of) IHD of working 41-48 h/week (relative risk (RR) 0.98, 95% confidence interval (CI) 0.91 to 1.07, 20 studies, 312,209 participants, I2 0%, low quality of evidence) and 49-54 h/week (RR 1.05, 95% CI 0.94 to 1.17, 18 studies, 308,405 participants, I2 0%, low quality of evidence). Compared with working 35-40 h/week, working ≥55 h/week may have led to a moderately, clinically meaningful increase in the risk of acquiring IHD, when followed up between one year and 20 years (RR 1.13, 95% CI 1.02 to 1.26, 22 studies, 339,680 participants, I2 5%, moderate quality of evidence). Compared with working 35-40 h/week, we are very uncertain about the effect on dying (mortality) from IHD of working 41-48 h/week (RR 0.99, 95% CI 0.88 to 1.12, 13 studies, 288,278 participants, I2 8%, low quality of evidence) and 49-54 h/week (RR 1.01, 95% CI 0.82 to 1.25, 11 studies, 284,474 participants, I2 13%, low quality of evidence). Compared with working 35-40 h/week, working ≥55 h/week may have led to a moderate, clinically meaningful increase in the risk of dying from IHD when followed up between eight and 30 years (RR 1.17, 95% CI 1.05 to 1.31, 16 studies, 726,803 participants, I2 0%, moderate quality of evidence). Subgroup analyses found no evidence for differences by WHO region and sex, but RRs were higher among persons with lower SES. Sensitivity analyses found no differences by outcome definition (exclusively non-fatal or fatal versus "mixed"), outcome measurement (health records versus self-reports) and risk of bias ("high"/"probably high" ratings in any domain versus "low"/"probably low" in all domains).We judged the existing bodies of evidence for human evidence as "inadequate evidence for harmfulness" for the exposure categories 41-48 and 49-54 h/week for IHD prevalence, incidence and mortality, and for the exposure category ≥55 h/week for IHD prevalence. Evidence on exposure to working ≥55 h/week was judged as "sufficient evidence of harmfulness" for IHD incidence and mortality. Producing estimates for the burden of IHD attributable to exposure to working ≥55 h/week appears evidence-based, and the pooled effect estimates presented in this systematic review could be used as input data for the WHO/ILO Joint Estimates.
PY  - 2022
DA  - 2022-09-05
JO  - {'id': 'https://openalex.org/S1010394304', 'issn_l': '2314-6133', 'issn': ['2314-6133', '2314-6141'], 'display_name': 'BioMed Research International', 'publisher': 'Hindawi Publishing Corporation', 'type': 'journal', 'url': 'https://downloads.hindawi.com/journals/bmri/2022/3133096.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Yi-Kuan Du
AU  - Lu-Lu He
AU  - XinNi Ye
AU  - Shuzhen Chen
AU  - Guan-Hao Li
AU  - Yuanwei Yu
AU  - ErBai Ye
AU  - Yixing Huang
AU  - Yu-Qi Zhou
AU  - WeiChui Zhang
AU  - Chun Yang
ER  - 

798.
TY  - journal-article
ID  - https://openalex.org/W4309811661
DO  - https://doi.org/10.1016/j.mex.2022.101935
TI  - An automated method for developing search strategies for systematic review using Natural Language Processing (NLP)
AB  - The design and implementation of systematic reviews and meta-analyses are often hampered by high financial costs, significant time commitment, and biases due to researchers' familiarity with studies. We proposed and implemented a fast and standardized method for search term selection using Natural Language Processing (NLP) and co-occurrence networks to identify relevant search terms to reduce biases in conducting systematic reviews and meta-analyses.•The method was implemented using Python packaged dubbed Ananse, which is benchmarked on the search terms strategy for naïve search proposed by Grames et al. (2019) written in "R". Ananse was applied to a case example towards finding search terms to implement a systematic literature review on cumulative effect studies on forest ecosystems.•The software automatically corrected and classified 100% of the duplicate articles identified by manual deduplication. Ananse was applied to the cumulative effects assessment case study, but it can serve as a general-purpose, open-source software system that can support extensive systematic reviews within a relatively short period with reduced biases.•Besides generating keywords, Ananse can act as middleware or a data converter for integrating multiple datasets into a database. Among them, IL-6 is suggested to play an essential role in the treatment of obesity and inflammation by acupuncture, and IL-6 was significant in both Boxplot and Survival Analysis of pancreatic cancer (PAAD). Therefore, in this study, the core gene, IL-6 was used as the breakthrough point to explore the possible mechanism of acupuncture in treating obesity and pancreatic cancer by regulating IL-6.(1) Acupuncture can regulate the expression of IL-6 through the TLR4/nuclear factor-κB (NF-κB) pathway, thereby alleviating inflammation, which can be used as a potential strategy for the treatment of obesity. (2) IL-6/STAT3 is closely related to the occurrence, development, and metastasis of pancreatic cancer. Acupuncture affecting pancreatic cancer through TLR4/NF-κB/IL-6/STAT3 pathway may be a potential method for the treatment of pancreatic cancer. data from qualifying studies. Missing data were requested from principal study authors. We combined relative risks using random-effect meta-analysis. Two or more review authors assessed the risk of bias, quality of evidence and strength of evidence, using Navigation Guide and GRADE tools and approaches adapted to this project.Thirty-seven studies (26 prospective cohort studies and 11 case-control studies) met the inclusion criteria, comprising a total of 768,751 participants (310,954 females) in 13 countries in three WHO regions (Americas, Europe and Western Pacific). The exposure was measured using self-reports in all studies, and the outcome was assessed with administrative health records (30 studies) or self-reported physician diagnosis (7 studies). The outcome was defined as incident non-fatal IHD event in 19 studies (8 cohort studies, 11 case-control studies), incident fatal IHD event in two studies (both cohort studies), and incident non-fatal or fatal ("mixed") event in 16 studies (all cohort studies). Because we judged cohort studies to have a relatively lower risk of bias, we prioritized evidence from these studies and treated evidence from case-control studies as supporting evidence. For the bodies of evidence for both outcomes with any eligible studies (i.e. IHD incidence and mortality), we did not have serious concerns for risk of bias (at least for the cohort studies). No eligible study was found on the effect of long working hours on IHD prevalence. Compared with working 35-40 h/week, we are uncertain about the effect on acquiring (or incidence of) IHD of working 41-48 h/week (relative risk (RR) 0.98, 95% confidence interval (CI) 0.91 to 1.07, 20 studies, 312,209 participants, I2 0%, low quality of evidence) and 49-54 h/week (RR 1.05, 95% CI 0.94 to 1.17, 18 studies, 308,405 participants, I2 0%, low quality of evidence). Compared with working 35-40 h/week, working ≥55 h/week may have led to a moderately, clinically meaningful increase in the risk of acquiring IHD, when followed up between one year and 20 years (RR 1.13, 95% CI 1.02 to 1.26, 22 studies, 339,680 participants, I2 5%, moderate quality of evidence). Compared with working 35-40 h/week, we are very uncertain about the effect on dying (mortality) from IHD of working 41-48 h/week (RR 0.99, 95% CI 0.88 to 1.12, 13 studies, 288,278 participants, I2 8%, low quality of evidence) and 49-54 h/week (RR 1.01, 95% CI 0.82 to 1.25, 11 studies, 284,474 participants, I2 13%, low quality of evidence). Compared with working 35-40 h/week, working ≥55 h/week may have led to a moderate, clinically meaningful increase in the risk of dying from IHD when followed up between eight and 30 years (RR 1.17, 95% CI 1.05 to 1.31, 16 studies, 726,803 participants, I2 0%, moderate quality of evidence). Subgroup analyses found no evidence for differences by WHO region and sex, but RRs were higher among persons with lower SES. Sensitivity analyses found no differences by outcome definition (exclusively non-fatal or fatal versus "mixed"), outcome measurement (health records versus self-reports) and risk of bias ("high"/"probably high" ratings in any domain versus "low"/"probably low" in all domains).We judged the existing bodies of evidence for human evidence as "inadequate evidence for harmfulness" for the exposure categories 41-48 and 49-54 h/week for IHD prevalence, incidence and mortality, and for the exposure category ≥55 h/week for IHD prevalence. Evidence on exposure to working ≥55 h/week was judged as "sufficient evidence of harmfulness" for IHD incidence and mortality. Producing estimates for the burden of IHD attributable to exposure to working ≥55 h/week appears evidence-based, and the pooled effect estimates presented in this systematic review could be used as input data for the WHO/ILO Joint Estimates.
PY  - 2022
DA  - 2022-11-01
JO  - {'id': 'https://openalex.org/S2898269294', 'issn_l': '2215-0161', 'issn': ['2215-0161'], 'display_name': 'MethodsX', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': 'http://methods-x.com/article/S2215016122003120/pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Antwi Effah Kwabena
AU  - Owusu-Banahene Wiafe
AU  - Boakye-Danquah John
AU  - Asare Bernard
AU  - Frimpong A.F Boateng
ER  - 

799.
TY  - journal-article
ID  - https://openalex.org/W4318822498
DO  - https://doi.org/10.14324/lre.21.1.11
TI  - Ann Oakley: new learning and global influence from working across conventional boundaries
AB  - Ann Oakley, pioneering social researcher for nearly 60 years, is Professor of Sociology and Social Policy at IOE (Institute of Education), UCL’s Faculty of Education and Society (University College London, UK). This article explores the innovation and influence of her work and the work of her close colleagues at the Social Science Research Unit (SSRU) and its Evidence for Policy and Practice Information and Coordinating Centre (EPPI-Centre). It describes advances in research and knowledge that have their roots in listening to what women have to say about their lives. The resulting novel research methods have straddled academic boundaries – between qualitative and quantitative methodologies, between disciplines, and between academia and wider society – to enhance understanding of complex social issues and approaches to addressing them within the public sector. The impact of this work is seen in terms of influencing science, knowledge management, policy decisions, professional practice and the general public. These achievements come from approaches that are outward looking and straddle academic disciplines to produce evidence that is relevant to policymaking and to practice, with the ultimate aim being to improve day-to-day life. suggested to play an essential role in the treatment of obesity and inflammation by acupuncture, and IL-6 was significant in both Boxplot and Survival Analysis of pancreatic cancer (PAAD). Therefore, in this study, the core gene, IL-6 was used as the breakthrough point to explore the possible mechanism of acupuncture in treating obesity and pancreatic cancer by regulating IL-6.(1) Acupuncture can regulate the expression of IL-6 through the TLR4/nuclear factor-κB (NF-κB) pathway, thereby alleviating inflammation, which can be used as a potential strategy for the treatment of obesity. (2) IL-6/STAT3 is closely related to the occurrence, development, and metastasis of pancreatic cancer. Acupuncture affecting pancreatic cancer through TLR4/NF-κB/IL-6/STAT3 pathway may be a potential method for the treatment of pancreatic cancer. data from qualifying studies. Missing data were requested from principal study authors. We combined relative risks using random-effect meta-analysis. Two or more review authors assessed the risk of bias, quality of evidence and strength of evidence, using Navigation Guide and GRADE tools and approaches adapted to this project.Thirty-seven studies (26 prospective cohort studies and 11 case-control studies) met the inclusion criteria, comprising a total of 768,751 participants (310,954 females) in 13 countries in three WHO regions (Americas, Europe and Western Pacific). The exposure was measured using self-reports in all studies, and the outcome was assessed with administrative health records (30 studies) or self-reported physician diagnosis (7 studies). The outcome was defined as incident non-fatal IHD event in 19 studies (8 cohort studies, 11 case-control studies), incident fatal IHD event in two studies (both cohort studies), and incident non-fatal or fatal ("mixed") event in 16 studies (all cohort studies). Because we judged cohort studies to have a relatively lower risk of bias, we prioritized evidence from these studies and treated evidence from case-control studies as supporting evidence. For the bodies of evidence for both outcomes with any eligible studies (i.e. IHD incidence and mortality), we did not have serious concerns for risk of bias (at least for the cohort studies). No eligible study was found on the effect of long working hours on IHD prevalence. Compared with working 35-40 h/week, we are uncertain about the effect on acquiring (or incidence of) IHD of working 41-48 h/week (relative risk (RR) 0.98, 95% confidence interval (CI) 0.91 to 1.07, 20 studies, 312,209 participants, I2 0%, low quality of evidence) and 49-54 h/week (RR 1.05, 95% CI 0.94 to 1.17, 18 studies, 308,405 participants, I2 0%, low quality of evidence). Compared with working 35-40 h/week, working ≥55 h/week may have led to a moderately, clinically meaningful increase in the risk of acquiring IHD, when followed up between one year and 20 years (RR 1.13, 95% CI 1.02 to 1.26, 22 studies, 339,680 participants, I2 5%, moderate quality of evidence). Compared with working 35-40 h/week, we are very uncertain about the effect on dying (mortality) from IHD of working 41-48 h/week (RR 0.99, 95% CI 0.88 to 1.12, 13 studies, 288,278 participants, I2 8%, low quality of evidence) and 49-54 h/week (RR 1.01, 95% CI 0.82 to 1.25, 11 studies, 284,474 participants, I2 13%, low quality of evidence). Compared with working 35-40 h/week, working ≥55 h/week may have led to a moderate, clinically meaningful increase in the risk of dying from IHD when followed up between eight and 30 years (RR 1.17, 95% CI 1.05 to 1.31, 16 studies, 726,803 participants, I2 0%, moderate quality of evidence). Subgroup analyses found no evidence for differences by WHO region and sex, but RRs were higher among persons with lower SES. Sensitivity analyses found no differences by outcome definition (exclusively non-fatal or fatal versus "mixed"), outcome measurement (health records versus self-reports) and risk of bias ("high"/"probably high" ratings in any domain versus "low"/"probably low" in all domains).We judged the existing bodies of evidence for human evidence as "inadequate evidence for harmfulness" for the exposure categories 41-48 and 49-54 h/week for IHD prevalence, incidence and mortality, and for the exposure category ≥55 h/week for IHD prevalence. Evidence on exposure to working ≥55 h/week was judged as "sufficient evidence of harmfulness" for IHD incidence and mortality. Producing estimates for the burden of IHD attributable to exposure to working ≥55 h/week appears evidence-based, and the pooled effect estimates presented in this systematic review could be used as input data for the WHO/ILO Joint Estimates.
PY  - 2023
DA  - 2023-01-24
JO  - {'id': 'https://openalex.org/S162811609', 'issn_l': '1474-8460', 'issn': ['1474-8479', '1474-8460'], 'display_name': 'London Review of Education', 'publisher': 'UCL Press', 'type': 'journal', 'url': 'https://uclpress.scienceopen.com/document_file/4aa4e71a-3dd7-4d34-8f01-a0837b941a25/ScienceOpen/Lond_Rev_Educ-21-11.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Sandy Oliver
ER  - 

800.
TY  - journal-article
ID  - https://openalex.org/W3000482183
DO  - https://doi.org/10.3389/fvets.2020.00011
TI  - Scoping Reviews, Systematic Reviews, and Meta-Analysis: Applications in Veterinary Medicine
AB  - Evidence-based decision making is a hallmark of effective veterinary clinical practice. Scoping reviews, systematic reviews, and meta-analyses all are methods intended to provide transparent and replicable ways of summarizing a body of research to address an important clinical or public health issue. As these methods increasingly are being used by researchers and read by practitioners, it is important to understand the distinction between these techniques and to understand what research questions they can, and cannot, address. This review provides an overview of scoping reviews, systematic reviews, and meta-analysis, including a discussion of the method and uses. A sample dataset and coding to conduct a simple meta-analysis in the statistical program R also are provided. Scoping reviews are a descriptive approach, designed to chart the literature around a particular topic. The approach involves an extensive literature search, following by a structured mapping, or charting, of the literature. The results of scoping reviews can help to inform future research by identifying gaps in the existing literature and also can be used to identify areas where there may be a sufficient depth of literature to warrant a systematic review. Systematic reviews are intended to address a specific question by identifying and summarizing all of the available research that has addressed the review question. Questions types that can be addressed by a systematic review include prevalence/incidence questions, and questions related to etiology, intervention efficacy, and diagnostic test accuracy. The systematic review process follows structured steps with multiple reviewers working in parallel to reduce the potential for bias. An extensive literature search is undertaken and, for each relevant study identified by the search, a formal extraction of data, including the effect size, and assessment of the risk of bias is performed. The results from multiple studies can be combined using meta-analysis. Meta-analysis provides a summary effect size, and allows heterogeneity of effect among studies to be quantified and explored. These evidence synthesis approaches can provide scientific input to evidence-based clinical decision-making for veterinarians and regulatory bodies, and also can be useful for identifying gaps in the literature to enhance the efficiency of future research in a topic area.
PY  - 2020
DA  - 2020-01-28
JO  - {'id': 'https://openalex.org/S2594976040', 'issn_l': '2297-1769', 'issn': ['2297-1769'], 'display_name': 'Frontiers in Veterinary Science', 'publisher': 'Frontiers Media', 'type': 'journal', 'url': 'https://doi.org/10.3389/fvets.2020.00011', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Jan M. Sargeant
AU  - Annette M. O'Connor
ER  - 

801.
TY  - journal-article
ID  - https://openalex.org/W3163243254
DO  - https://doi.org/10.1016/j.jocn.2021.04.043
TI  - Machine learning applications to neuroimaging for glioma detection and classification: An artificial intelligence augmented systematic review
AB  - Abstract decision making Glioma is the most common primary intraparenchymal tumor of the brain and the 5-year survival rate of high-grade glioma is poor. Magnetic resonance imaging (MRI) is essential for detecting, characterizing and monitoring brain tumors but definitive diagnosis still relies on surgical pathology. Machine learning has been applied to the analysis of MRI data in glioma research and has the potential to change clinical practice and improve patient outcomes. This systematic review synthesizes and analyzes the current state of machine learning applications to glioma MRI data and explores the use of machine learning for systematic review automation. Various datapoints were extracted from the 153 studies that met inclusion criteria and analyzed. Natural language processing (NLP) analysis involved keyword extraction, topic modeling and document classification. Machine learning has been applied to tumor grading and diagnosis, tumor segmentation, non-invasive genomic biomarker identification, detection of progression and patient survival prediction. Model performance was generally strong (AUC = 0.87 ± 0.09; sensitivity = 0.87 ± 0.10; specificity = 0.0.86 ± 0.10; precision = 0.88 ± 0.11). Convolutional neural network, support vector machine and random forest algorithms were top performers. Deep learning document classifiers yielded acceptable performance (mean 5-fold cross-validation AUC = 0.71). Machine learning tools and data resources were synthesized and summarized to facilitate future research. Machine learning has been widely applied to the processing of MRI data in glioma research and has demonstrated substantial utility. NLP and transfer learning resources enabled the successful development of a replicable method for automating the systematic review article screening process, which has potential for shortening the time from discovery to clinical application in medicine. for bias. An extensive literature search is undertaken and, for each relevant study identified by the search, a formal extraction of data, including the effect size, and assessment of the risk of bias is performed. The results from multiple studies can be combined using meta-analysis. Meta-analysis provides a summary effect size, and allows heterogeneity of effect among studies to be quantified and explored. These evidence synthesis approaches can provide scientific input to evidence-based clinical decision-making for veterinarians and regulatory bodies, and also can be useful for identifying gaps in the literature to enhance the efficiency of future research in a topic area.
PY  - 2021
DA  - 2021-07-01
JO  - {'id': 'https://openalex.org/S145023809', 'issn_l': '0967-5868', 'issn': ['0967-5868', '1532-2653'], 'display_name': 'Journal of Clinical Neuroscience', 'publisher': 'Churchill Livingstone', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Quinlan D. Buchlak
AU  - Nazanin Esmaili
AU  - Jean-Christophe Leveque
AU  - Christine Bennett
AU  - Farrokh Farrokhi
AU  - Massimo Piccardi
ER  - 

802.
TY  - journal-article
ID  - https://openalex.org/W3014512586
DO  - https://doi.org/10.1186/s13643-020-01324-7
TI  - Machine learning for screening prioritization in systematic reviews: comparative performance of Abstrackr and EPPI-Reviewer
AB  - Abstract Background Improving the speed of systematic review (SR) development is key to supporting evidence-based medicine. Machine learning tools which semi-automate citation screening might improve efficiency. Few studies have assessed use of screening prioritization functionality or compared two tools head to head. In this project, we compared performance of two machine-learning tools for potential use in citation screening. Methods Using 9 evidence reports previously completed by the ECRI Institute Evidence-based Practice Center team, we compared performance of Abstrackr and EPPI-Reviewer, two off-the-shelf citations screening tools, for identifying relevant citations. Screening prioritization functionality was tested for 3 large reports and 6 small reports on a range of clinical topics. Large report topics were imaging for pancreatic cancer, indoor allergen reduction, and inguinal hernia repair. We trained Abstrackr and EPPI-Reviewer and screened all citations in 10% increments. In Task 1, we inputted whether an abstract was ordered for full-text screening; in Task 2, we inputted whether an abstract was included in the final report. For both tasks, screening continued until all studies ordered and included for the actual reports were identified. We assessed potential reductions in hypothetical screening burden (proportion of citations screened to identify all included studies) offered by each tool for all 9 reports. Results For the 3 large reports, both EPPI-Reviewer and Abstrackr performed well with potential reductions in screening burden of 4 to 49% (Abstrackr) and 9 to 60% (EPPI-Reviewer). Both tools had markedly poorer performance for 1 large report (inguinal hernia), possibly due to its heterogeneous key questions. Based on McNemar’s test for paired proportions in the 3 large reports, EPPI-Reviewer outperformed Abstrackr for identifying articles ordered for full-text review, but Abstrackr performed better in 2 of 3 reports for identifying articles included in the final report. For small reports, both tools provided benefits but EPPI-Reviewer generally outperformed Abstrackr in both tasks, although these results were often not statistically significant. Conclusions Abstrackr and EPPI-Reviewer performed well, but prioritization accuracy varied greatly across reports. Our work suggests screening prioritization functionality is a promising modality offering efficiency gains without giving up human involvement in the screening process. research in a topic area.
PY  - 2020
DA  - 2020-04-02
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://doi.org/10.1186/s13643-020-01324-7', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Amy Tsou
AU  - Jonathan Treadwell
AU  - Eileen Erinoff
AU  - Karen M Schoelles
ER  - 

803.
TY  - journal-article
ID  - https://openalex.org/W3131967293
DO  - https://doi.org/10.1038/s42256-020-00235-5
TI  - Accelerating evidence-informed decision-making for the Sustainable Development Goals using machine learning
AB  - No Abstract Found
PY  - 2020
DA  - 2020-10-01
JO  - {'id': 'https://openalex.org/S2912241403', 'issn_l': '2522-5839', 'issn': ['2522-5839'], 'display_name': 'Nature Machine Intelligence', 'publisher': 'Nature Portfolio', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Jaron Porciello
AU  - Maryia Ivanina
AU  - Maidul Islam
AU  - Stefan Einarson
AU  - Haym Hirsh
ER  - 

804.
TY  - journal-article
ID  - https://openalex.org/W3143985904
DO  - https://doi.org/10.1186/s13643-021-01635-3
TI  - Research Screener: a machine learning tool to semi-automate abstract screening for systematic reviews
AB  - Systematic reviews and meta-analyses provide the highest level of evidence to help inform policy and practice, yet their rigorous nature is associated with significant time and economic demands. The screening of titles and abstracts is the most time consuming part of the review process with analysts required review thousands of articles manually, taking on average 33 days. New technologies aimed at streamlining the screening process have provided initial promising findings, yet there are limitations with current approaches and barriers to the widespread use of these tools. In this paper, we introduce and report initial evidence on the utility of Research Screener, a semi-automated machine learning tool to facilitate abstract screening.Three sets of analyses (simulation, interactive and sensitivity) were conducted to provide evidence of the utility of the tool through both simulated and real-world examples.Research Screener delivered a workload saving of between 60 and 96% across nine systematic reviews and two scoping reviews. Findings from the real-world interactive analysis demonstrated a time saving of 12.53 days compared to the manual screening, which equates to a financial saving of USD 2444. Conservatively, our results suggest that analysts who scan 50% of the total pool of articles identified via a systematic search are highly likely to have identified 100% of eligible papers.In light of these findings, Research Screener is able to reduce the burden for researchers wishing to conduct a comprehensive systematic review without reducing the scientific rigour for which they strive to achieve. report (inguinal hernia), possibly due to its heterogeneous key questions. Based on McNemar’s test for paired proportions in the 3 large reports, EPPI-Reviewer outperformed Abstrackr for identifying articles ordered for full-text review, but Abstrackr performed better in 2 of 3 reports for identifying articles included in the final report. For small reports, both tools provided benefits but EPPI-Reviewer generally outperformed Abstrackr in both tasks, although these results were often not statistically significant. Conclusions Abstrackr and EPPI-Reviewer performed well, but prioritization accuracy varied greatly across reports. Our work suggests screening prioritization functionality is a promising modality offering efficiency gains without giving up human involvement in the screening process. research in a topic area.
PY  - 2021
DA  - 2021-04-01
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://systematicreviewsjournal.biomedcentral.com/counter/pdf/10.1186/s13643-021-01635-3', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Kevin Chai
AU  - Robin L. J. Lines
AU  - Daniel F. Gucciardi
AU  - Leo Ng
ER  - 

805.
TY  - journal-article
ID  - https://openalex.org/W3107597694
DO  - https://doi.org/10.1093/schizbullopen/sgaa061
TI  - Cochrane Schizophrenia Group’s Study-Based Register of Randomized Controlled Trials: Development and Content Analysis
AB  - Abstract Background Study-based registers facilitate systematic reviews through shortening the process for review team and reducing considerable waste during the review process. Such a register also provides new insights about trends of trials in a sub-specialty. This paper reports development and content analysis of Cochrane Schizophrenia Group’s Study-Based Register. Methods The randomized controlled trials were collected through systematic searches of major information sources. Data points were extracted, curated and classified in the register. We report trends using regression analyses in Microsoft Excel and we used GIS mapping (GunnMap 2) to visualize the geographical distribution of the origin of schizophrenia trials. Results Although only 17% of trials were registered, the number of reports form registered trials is steadily increasing and registered trials produce more reports. Clinical trial registers are main source of trial reports followed by sub-specialty journals. Schizophrenia trials have been published in 23 languages from 90 countries while 105 nations do not have any reported schizophrenia trials. Only 9.7% of trials were included in at least one Cochrane review. Pharmacotherapy is the main target of trials while trials targeting psychotherapy are increasing in a continuous rate. The number of people randomized in trials is on average 114 with 60 being the most frequent sample size. Conclusions Curated datasets within the register uncover new patterns in data that have implications for research, policy, and practice for testing new interventions in trials or systematic reviews. rigour for which they strive to achieve. report (inguinal hernia), possibly due to its heterogeneous key questions. Based on McNemar’s test for paired proportions in the 3 large reports, EPPI-Reviewer outperformed Abstrackr for identifying articles ordered for full-text review, but Abstrackr performed better in 2 of 3 reports for identifying articles included in the final report. For small reports, both tools provided benefits but EPPI-Reviewer generally outperformed Abstrackr in both tasks, although these results were often not statistically significant. Conclusions Abstrackr and EPPI-Reviewer performed well, but prioritization accuracy varied greatly across reports. Our work suggests screening prioritization functionality is a promising modality offering efficiency gains without giving up human involvement in the screening process. research in a topic area.
PY  - 2020
DA  - 2020-01-01
JO  - {'id': 'https://openalex.org/S4210209414', 'issn_l': '2632-7899', 'issn': ['2632-7899'], 'display_name': 'Schizophrenia bulletin open', 'publisher': 'Oxford University Press', 'type': 'journal', 'url': 'https://academic.oup.com/schizbullopen/advance-article-pdf/doi/10.1093/schizbullopen/sgaa061/34559040/sgaa061.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by-nc'}
DP  - OpenAlex
AU  - Farhad Shokraneh
AU  - Clive E Adams
ER  - 

806.
TY  - journal-article
ID  - https://openalex.org/W4223614283
DO  - https://doi.org/10.1016/j.scitotenv.2022.155159
TI  - Assay of renewable energy transition: A systematic literature review
AB  - Issues of environmental degradation, finite quantity and uneven spatial distribution of fuels in nature, and growing demand accentuated by volatility of oil prices have led to the global clean renewable energy transition (RET). With an objective of examining the current knowledge-stock on RET, we reviewed 248 journal publications pooled from three databases (ScienceDirect, Web of Science and Scopus) using a Systematic Literature Review method. This study does not focus on the specifications of a particular energy technology or regress relations among a limited set of variables. Rather, the key contribution is the critical assessment of the factors that encourage and those that hinder the transition process to provide a wider perspective through seven broad lenses: technological, investment, market, environmental, government and institutional, policy and social. Research, development and implementation of technology is a direct outcome of policy investment. Developed countries are leading the RET research while the global south is far behind. Most of the studies were found to be donor-driven which faced a serious risk of being counter-welcomed in different settings of the world without compromising the objectives of the transition. A strong international collaboration among the rich and poor countries is urgently felt necessary to foster mutual benefits. Research, planning and implementation of the RET would be highly effective and sustainable through a participatory bottom-up approach promoting local technology instead of imposed expensive imported ones. The need for "demand-pull" and "technology-push" policy instruments is stringent for successful transition. We conclude that there is a unanimous agreement among all the studies on the future prospects of renewable energy in the electricity sector; however, some skepticism still exists regarding other high energy demanding areas. Our review recommends updating existing and designing new robust policy mixes to guide the modality and pace of the RET, adhering to local specificities. EPPI-Reviewer generally outperformed Abstrackr in both tasks, although these results were often not statistically significant. Conclusions Abstrackr and EPPI-Reviewer performed well, but prioritization accuracy varied greatly across reports. Our work suggests screening prioritization functionality is a promising modality offering efficiency gains without giving up human involvement in the screening process. research in a topic area.
PY  - 2022
DA  - 2022-04-01
JO  - {'id': 'https://openalex.org/S86852077', 'issn_l': '0048-9697', 'issn': ['0048-9697', '1879-1026'], 'display_name': 'Science of The Total Environment', 'publisher': 'Elsevier BV', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Utsav Bhattarai
AU  - Tek Narayan Maraseni
AU  - Armando Apan
ER  - 

807.
TY  - journal-article
ID  - https://openalex.org/W2995299295
DO  - https://doi.org/10.1186/s13643-019-1250-y
TI  - The Systematic Review Data Repository (SRDR): descriptive characteristics of publicly available data and opportunities for research
AB  - Abstract Background Conducting systematic reviews (“reviews”) requires a great deal of effort and resources. Making data extracted during reviews available publicly could offer many benefits, including reducing unnecessary duplication of effort, standardizing data, supporting analyses to address secondary research questions, and facilitating methodologic research. Funded by the US Agency for Healthcare Research and Quality (AHRQ), the Systematic Review Data Repository (SRDR) is a free, web-based, open-source, data management and archival platform for reviews. Our specific objectives in this paper are to describe (1) the current extent of usage of SRDR and (2) the characteristics of all projects with publicly available data on the SRDR website. Methods We examined all projects with data made publicly available through SRDR as of November 12, 2019. We extracted information about the characteristics of these projects. Two investigators extracted and verified the data. Results SRDR has had 2552 individual user accounts belonging to users from 80 countries. Since SRDR’s launch in 2012, data have been made available publicly for 152 of the 735 projects in SRDR (21%), at a rate of 24.5 projects per year, on average. Most projects are in clinical fields (144/152 projects; 95%); most have evaluated interventions (therapeutic or preventive) (109/152; 72%). The most frequent health areas addressed are mental and behavioral disorders (31/152; 20%) and diseases of the eye and ocular adnexa (23/152; 15%). Two-thirds of the projects (104/152; 67%) were funded by AHRQ, and one-sixth (23/152; 15%) are Cochrane reviews. The 152 projects each address a median of 3 research questions (IQR 1–5) and include a median of 70 studies (IQR 20–130). Conclusions Until we arrive at a future in which the systematic review and broader research communities are comfortable with the accuracy of automated data extraction, re-use of data extracted by humans has the potential to help reduce redundancy and costs. The 152 projects with publicly available data through SRDR, and the more than 15,000 studies therein, are freely available to researchers and the general public who might be working on similar reviews or updates of reviews or who want access to the data for decision-making, meta-research, or other purposes. topic area.
PY  - 2019
DA  - 2019-12-20
JO  - {'id': 'https://openalex.org/S82452678', 'issn_l': '2046-4053', 'issn': ['2046-4053'], 'display_name': 'Systematic Reviews', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://systematicreviewsjournal.biomedcentral.com/track/pdf/10.1186/s13643-019-1250-y', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Ian J. Saldanha
AU  - Bryant Walker Smith
AU  - Evangelia E. Ntzani
AU  - Jens Jap
AU  - Ethan M Balk
AU  - Joseph Lau
ER  - 

808.
TY  - journal-article
ID  - https://openalex.org/W4200065546
DO  - https://doi.org/10.1002/jrsm.1542
TI  - A new taxonomy was developed for overlap across 'overviews of systematic reviews': A meta‐research study of research waste
AB  - Multiple ‘overviews of reviews’ conducted on the same topic (“overlapping overviews”) represent a waste of research resources and can confuse clinicians making decisions amongst competing treatments. We aimed to assess the frequency and characteristics of overlapping overviews. MEDLINE, Epistemonikos and Cochrane Database of Systematic Reviews were searched for overviews that: synthesized reviews of health interventions and conducted systematic searches. Overlap was defined as: duplication of PICO eligibility criteria, and not reported as an update nor a replication. We categorized overview topics according to 22 WHO ICD-10 medical classifications, overviews as broad or narrow in scope, and overlap as identical, nearly identical, partial, or subsumed. Subsummation was defined as when broad overviews subsumed the populations, interventions and at least one outcome of another overview. Of 541 overviews included, 169 (31%) overlapped across similar PICO, fell within 13 WHO ICD-10 medical classifications, and 62 topics. 148/169 (88%) overlapping overviews were broad in scope. Fifteen overviews were classified as having nearly identical overlap (9%); 123 partial overlap (73%), and 31 subsumed (18%) others. One third of overviews overlapped in content and a majority covered broad topic areas. A multiplicity of overviews on the same topic adds to the ongoing waste of research resources, time, and effort across medical disciplines. Authors of overviews can use this study and the sample of overviews to identify gaps in the evidence for future analysis, and topics that are already studied, which do not need to be duplicated. The 152 projects each address a median of 3 research questions (IQR 1–5) and include a median of 70 studies (IQR 20–130). Conclusions Until we arrive at a future in which the systematic review and broader research communities are comfortable with the accuracy of automated data extraction, re-use of data extracted by humans has the potential to help reduce redundancy and costs. The 152 projects with publicly available data through SRDR, and the more than 15,000 studies therein, are freely available to researchers and the general public who might be working on similar reviews or updates of reviews or who want access to the data for decision-making, meta-research, or other purposes. topic area.
PY  - 2021
DA  - 2021-12-19
JO  - {'id': 'https://openalex.org/S205768342', 'issn_l': '1759-2879', 'issn': ['1759-2879', '1759-2887'], 'display_name': 'Research Synthesis Methods', 'publisher': 'Wiley-Blackwell', 'type': 'journal', 'url': 'https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/jrsm.1542', 'is_oa': True, 'version': 'publishedVersion', 'license': 'cc-by'}
DP  - OpenAlex
AU  - Carole Lunny
AU  - Emma Reid
AU  - Trish Neelakant
AU  - Alyssa Chen
AU  - Jia Zhang
AU  - Gavindeep Shinger
AU  - Adrienne Stevens
AU  - Sara Tasnim
AU  - Shadi Sadeghipouya
AU  - Stephen Adams
AU  - Yi Zheng
AU  - Lester Lin
AU  - Pei Yang
AU  - Manpreet Dosanjh
AU  - Peter Ngsee
AU  - Ursula Ellis
AU  - Beverley Shea
AU  - James D. Wright
ER  - 

809.
TY  - book-chapter
ID  - https://openalex.org/W3016061304
DO  - https://doi.org/10.1007/978-3-030-45439-5_26
TI  - A Computational Approach for Objectively Derived Systematic Review Search Strategies
AB  - Searching literature for a systematic review begins with a manually constructed search strategy by an expert information specialist. The typical process of constructing search strategies is often undocumented, ad-hoc, and subject to individual expertise, which may introduce bias in the systematic review. A new method for objectively deriving search strategies has arisen from information specialists attempting to address these shortcomings. However, this proposed method still presents a number of manual, ad-hoc interventions, and trial-and-error processes, potentially still introducing bias into systematic reviews. Moreover, this method has not been rigorously evaluated on a large set of systematic review cases, thus its generalisability is unknown. In this work, we present a computational adaptation of this proposed objective method. Our adaptation removes the human-in-the-loop processes involved in the initial steps of creating a search strategy for a systematic review; reducing bias due to human factors and increasing the objectivity of the originally proposed method. Our proposed computational adaptation further enables a formal and rigorous evaluation over a large set of systematic reviews. We find that our computational adaptation of the original objective method provides an effective starting point for information specialists to continue refining. We also identify a number of avenues for extending and improving our adaptation to further promote supporting information specialists. use this study and the sample of overviews to identify gaps in the evidence for future analysis, and topics that are already studied, which do not need to be duplicated. The 152 projects each address a median of 3 research questions (IQR 1–5) and include a median of 70 studies (IQR 20–130). Conclusions Until we arrive at a future in which the systematic review and broader research communities are comfortable with the accuracy of automated data extraction, re-use of data extracted by humans has the potential to help reduce redundancy and costs. The 152 projects with publicly available data through SRDR, and the more than 15,000 studies therein, are freely available to researchers and the general public who might be working on similar reviews or updates of reviews or who want access to the data for decision-making, meta-research, or other purposes. topic area.
PY  - 2020
DA  - 2020-04-14
JO  - {'id': 'https://openalex.org/S106296714', 'issn_l': '0302-9743', 'issn': ['1611-3349', '0302-9743'], 'display_name': 'Lecture Notes in Computer Science', 'publisher': 'Springer Science+Business Media', 'type': 'journal', 'url': 'https://link.springer.com/content/pdf/10.1007%2F978-3-030-45439-5_26.pdf', 'is_oa': True, 'version': 'publishedVersion', 'license': None}
DP  - OpenAlex
AU  - Harrisen Scells
AU  - Guido Zuccon
AU  - Bevan Koopman
AU  - Justin Clark
ER  - 

810.
TY  - journal-article
ID  - https://openalex.org/W3164471952
DO  - https://doi.org/10.1002/jat.4204
TI  - Toxic effects of nanomaterials for health applications: How automation can support a systematic review of the literature?
AB  - Systematic reviews of the scientific literature can be an important source of information supporting the daily work of the regulators in their decision making, particularly in areas of innovative technologies where the regulatory experience is still limited. Significant research activities in the field of nanotechnology resulted in a huge number of publications in the last decades. However, even if the published data can provide relevant information, scientific articles are often of diverse quality, and it is nearly impossible to manually process and evaluate such amount of data in a systematic manner. In this feasibility study, we investigated to what extent open-access automation tools can support a systematic review of toxic effects of nanomaterials for health applications reported in the scientific literature. In this study, we used a battery of available tools to perform the initial steps of a systematic review such as targeted searches, data curation and abstract screening. This work was complemented with an in-house developed tool that allowed us to extract specific sections of the articles such as the materials and methods part or the results section where we could perform subsequent text analysis. We ranked the articles according to quality criteria based on the reported nanomaterial characterisation and extracted most frequently described toxic effects induced by different types of nanomaterials. Even if further demonstration of the reliability and applicability of automation tools is necessary, this study demonstrated the potential to leverage information from the scientific literature by using automation systems in a tiered strategy. of 3 research questions (IQR 1–5) and include a median of 70 studies (IQR 20–130). Conclusions Until we arrive at a future in which the systematic review and broader research communities are comfortable with the accuracy of automated data extraction, re-use of data extracted by humans has the potential to help reduce redundancy and costs. The 152 projects with publicly available data through SRDR, and the more than 15,000 studies therein, are freely available to researchers and the general public who might be working on similar reviews or updates of reviews or who want access to the data for decision-making, meta-research, or other purposes. topic area.
PY  - 2022
DA  - 2022-01-01
JO  - {'id': 'https://openalex.org/S81851855', 'issn_l': '0260-437X', 'issn': ['1099-1263', '0260-437X'], 'display_name': 'Journal of Applied Toxicology', 'publisher': 'Wiley', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Blanka Halamoda-Kenzaoui
AU  - Etienne Rolland
AU  - Jacopo Piovesan
AU  - Antonio Gallardo
AU  - Susanne Bremer-Hoffmann
ER  - 

811.
TY  - book-chapter
ID  - https://openalex.org/W3154307759
DO  - https://doi.org/10.1007/978-3-319-52677-5_194-1
TI  - Introduction to Systematic Reviews
AB  - No Abstract Found
PY  - 2021
DA  - 2021-01-01
JO  - {'id': 'https://openalex.org/S4306463941', 'issn_l': None, 'issn': None, 'display_name': 'Springer International Publishing eBooks', 'publisher': 'Springer Nature', 'type': 'ebook platform', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Tianjing Li
AU  - Ian J. Saldanha
AU  - Karen A. Robinson
ER  - 

812.
TY  - book-chapter
ID  - https://openalex.org/W4286370353
DO  - https://doi.org/10.1007/978-3-319-52636-2_194
TI  - Introduction to Systematic Reviews
AB  - No Abstract Found
PY  - 2022
DA  - 2022-01-01
JO  - {'id': 'https://openalex.org/S4306463941', 'issn_l': None, 'issn': None, 'display_name': 'Springer International Publishing eBooks', 'publisher': 'Springer Nature', 'type': 'ebook platform', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Tianjing Li
AU  - Ian J. Saldanha
AU  - Karen A. Robinson
ER  - 

813.
TY  - journal-article
ID  - https://openalex.org/W4320491552
DO  - https://doi.org/10.1002/leap.1514
TI  - The future of scientific journals: The rise of <scp>UniAI</scp>
AB  - No Abstract Found
PY  - 2023
DA  - 2023-02-13
JO  - {'id': 'https://openalex.org/S29676049', 'issn_l': '0953-1513', 'issn': ['0953-1513', '1741-4857'], 'display_name': 'Learned Publishing', 'publisher': 'Wiley', 'type': 'journal', 'url': None, 'is_oa': False, 'version': None, 'license': None}
DP  - OpenAlex
AU  - Farrokh Habibzadeh
ER  - 
